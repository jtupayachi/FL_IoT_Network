[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23a5270b-3099-4e6a-be8b-44da39541c7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7852ab68-a006-4e13-bc92-92523e8413f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e658c683-2b23-4968-817a-a5acdbec5c79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a959ee94-4307-4e4f-aaf7-0ea685775e09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2dbc30fc-17d4-46cc-9240-9a1d22e12fca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39a61e73-df46-4dbe-905c-d64ab5f21b6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c409420-eae7-4a18-9c16-aabc288840fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62066a3d-eb81-488e-a153-abac62528b38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b12b2334-1252-4b3d-abaf-eb4345a360f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8041a83-1348-48ac-b306-c5dc7aca83f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d9a7e69-aa51-4da4-b2cb-0a47746629ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa4d808e-fe23-4267-bbab-4ec1b3bfaaaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49e3ca05-9cc5-4237-97be-04dfc797e436
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ad4512d-8255-423f-b500-d5e722f36ad5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6f6cec6-7bf3-40cb-be66-a5d9a3ca623f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bc00382-a27c-4d6e-97b3-83d3194be82b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9cb41cdf-d37f-4e2e-b95a-ed6f05c4b503
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ed1570f-3871-477a-8f20-688e8160dfba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bac0568-fd09-4b3a-b673-21f24a5894e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0122d554-7f89-4ff3-a80d-923a377f4ddc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a79e4202-4458-4c40-aa16-b6e275141eec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfa559a3-5aed-4f41-a2c3-2b7b71a463f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 969c85b1-de4f-442f-b7ff-5623d897732f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40491191-d5b2-455d-bb15-ee3620eed4c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 574eddf2-0103-4242-bd7d-47db5fb907b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c39d3e0d-742d-4154-b841-74beed40ad47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a47107e-06be-4aa4-9621-013e33bbc439
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a816ac30-92bf-492c-b543-8ddec8025e04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad0a24e0-ed64-4326-bbb1-c570d844454e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fbd7e61-5675-4715-ad96-394a8bd00322
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bb6a49c-9492-4987-8739-d10efc6defce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4efd4c29-cc2a-4bee-b4fb-f2f993ba2f0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3018fc65-094b-4a8e-890d-1846ba4c2d05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35802994-4e20-4b32-b805-08829b449534
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e45aef70-78e0-4769-a7f7-ab26823533e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6629dbf7-a59b-4fac-b061-a82b6c39b1a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcd87ed7-9f90-4586-8082-4e22e0e1d030
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26198ca9-0611-40e1-bfdb-2724d6314ad6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f341c47b-f830-41f6-ab42-cb37936e84a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e10bbdb6-ff10-43d2-9806-c2c627bebb4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21dddf43-d910-4080-ba62-ba06014026b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11e91e35-6bef-487b-a651-d4487f990ba3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b04e3a82-bb2d-4497-8a61-3a29f684fff3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83d1eff2-a19f-43b3-91e5-d0fa5ebba05d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7fd53ad-698f-47cf-8ed3-4eb455b6b087
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 846fff1b-0fd1-4cfa-8ade-4cfdfc66ceb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d31c329f-bd96-400f-bc61-1fcab3db7b6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4801d2bd-8d72-4022-8394-8bf7cdac982a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4aab71b6-8121-4709-80c9-3ee77766f468
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b817e78-556d-4784-be8f-be1fa9aedfc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3263443-30ce-4dcf-9298-c8af749d2a55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35a688cc-36b3-42f2-95ed-6d8de5ffa3dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5503fe6-1c15-4906-b890-e679a1466c93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fd765fd-f802-4154-821d-f1c56cb901bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51c46c7d-b31f-4f58-a516-e4a223f0ec87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d794c71-3f35-4820-afc7-ae2bab200a03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10fd89df-b3fb-4740-92ba-127f140054f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cee4b8d5-4e55-411d-a47f-1f0b0e4978e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f79c4729-2266-4197-a33d-64de52f64518
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b48f45ee-55eb-409f-b5ad-d4beacdf9144
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b75bd785-d3ff-457a-b567-e34a15f7793a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da2c626c-ea2f-42f8-8d0f-6af40714b079
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dab3da44-f11d-4519-8336-de175559c446
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc220edf-ac12-4af9-80cc-bca827c736c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41f41141-1427-43f0-88a8-7081b9c21274
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f2a9e2a-24bb-44c5-adf4-dd2f315b3daf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7641ff8a-875e-42bf-8f43-cf83a9bf6e06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a71cac2b-770c-4c5d-a9fa-178ca84a90be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e35efd16-574a-4241-a5a9-af23ace08566
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e84a2e68-c4c4-4d57-beeb-d250e109ce94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ff42bdf-aa93-4316-89f9-8987f6117786
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b661af1-3944-492d-a4ac-64f50fb6b415
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f60636f5-669a-4e8b-986e-8bd8ccff63f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4caf4195-e3b6-40e9-83e6-8502ab02397f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d776660-1d22-4ac3-bd40-c8b7dbb9a377
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bd49915-43b2-4439-90b9-8b48a3feb9d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e949aec-fe47-4aa6-a778-81ed2cbcd53c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 567293c1-937d-437d-a029-83aade01f408
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a6286cd-84a9-4ec2-a970-c316bc2795e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87913e43-37bd-45c6-b226-29972e44862a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c72b6ff4-e7a4-468f-ab42-62c67a69eec1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 317ee0a8-57b1-4e79-9ba8-746036171391
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29afb80e-057a-40fc-a86e-7ddbd5a1fb6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3cd0ac7-46f0-4546-a5bc-95252a123744
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fb9c655-45b0-4319-8a8c-989986a50707
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec28db05-41aa-48a3-a4bd-8641245da972
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0948a2a-0b7b-44a3-9a7f-9bd99aa28c0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ce598f3-a87a-4cde-9d49-fbdb993510d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b32fbce1-7a18-40e3-a57e-b6d07e94c1dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1cc7ee92-1b94-48b4-a69a-433e1e8471bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74ec2f02-9bd6-4b21-88f7-944bd66e6224
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59358b66-0571-47fb-b555-f7778eb8b625
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51bc3c28-b9ea-4226-afc0-8159a9e99ea5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c6daabd-1115-4458-ad32-63e3fd1beafd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 523f8f47-4c62-43cb-a130-b7a6ace7ea9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ca8ebc0-c36a-4d4e-ad3e-911cbfc189c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8e44b08-d4f6-4f7c-a61f-4024f33a4a48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5964f898-5d11-43a0-9b07-b85d83813ac6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a75b1273-762e-4a85-8315-f35d3c497c01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 091ad6ee-53bd-4cc1-b8df-0c720ced7997
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bf97204-f993-4cf8-ac62-a7b8728a5562
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a73c8f6b-829c-42a2-be27-b8a92e421f3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1247801-5c1d-4920-80fa-c1879e00ab55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 138bbdbc-db63-4463-ab51-44656ba1ce7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fc0525c-5554-4631-b98c-7dac91968b4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0761786-0514-456e-9d92-e525c2ced1da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 277e7790-c924-4cc5-8f47-126ddc0c8748
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae8161ad-96e0-45fb-b00a-2c653018f653
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f35dcf1c-85db-431d-87a7-923b729a4140
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e79b780c-c8ff-42cf-93b9-e3b0b033c522
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ea2533e-5b7b-40cd-95bd-cb8400ed3f0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4e9a36b-b568-41f8-8ad1-addd9f611526
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7209edc5-cbcf-4daa-9ffc-479c290fe9f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dca1c9ff-d124-4c06-a1a7-fcb634e0cca1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff530011-e378-426e-b3f6-8d4af3f054e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a086b1b0-8a33-4649-85c8-ed46ab3975f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c51cfa96-e45f-477f-8d74-f40b1c71063f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4312e15-f07c-40e7-8f06-742ba4cc0a88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ada405b-0c1b-45f3-955e-4324acb008cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a3974aa-dc2c-4e4c-8a64-c58d3c707f9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4ccb0e7-77e8-469e-9ef7-1caec1781b2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0cfb193c-2520-4f97-bfee-356e3c522c0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 629fa94f-b072-4b61-b55f-e46386c928e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2ab3133-c6a0-4de0-8fa0-a27debc50f30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 805c460b-fda7-4ba6-8d4a-d0fb92cc1f2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe261cf0-30c4-47cc-a274-c12db675ccf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a11817e9-d44f-4b15-a092-ee559e52adb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f94ded2f-407a-457e-8c8c-1dcafa0a4477
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33265e39-d706-4729-b154-e1938311e8a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ddbb143-d8af-4c7c-85ee-985e4973b50d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bcba347-f02f-4b6e-9e8a-07eaee18d800
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85950ee5-801c-45a6-a1dd-9c0759ea689e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9bd29ce-bab7-4f8a-bac2-c1c62586cfb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9e9d44e-316d-47ed-84d8-eb7e7f51f45f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c613da01-6a1f-4cff-bc9a-47fe34145aee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9e8f36a-8b5d-4c31-bba2-11ab5f089bcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b82d7604-2bdf-4ae4-b114-86c2dbc264eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72db39c3-9bda-4cf2-a73a-ebb80f031214
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab2dc166-849d-45d8-9249-e48cfe59e85d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0244efd-2679-423a-8aae-305bf608362b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 087d0f33-61e8-4565-b49f-297bc0d60944
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4aea83e4-bdd3-47c6-985d-4f09ae072dc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a66fc83-38a3-4f3e-8bf0-111325501385
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81030cc1-3b60-43ed-b8fb-989ff1635f8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3603da91-52de-43c9-99e8-3b4c0440edd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b802e37-6be5-43e1-9259-8b0db70c6827
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03afd826-c939-4beb-bdab-2b6c849e1d82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5a4cd97-020e-491d-8414-c45746f9ad28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f7d7d44-8ab4-49c8-831e-0e30fd696e11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 027da91f-ebfd-4182-9e45-84224125480f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a13f5a6-1a47-46b2-aae7-6230e2319cd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8be8f55d-4de0-488c-b0cf-2ccf80eab0ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a216352-143d-46f3-9821-543aad63d941
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d67ad8cc-eb3b-4b72-a24e-f7be9b6f5aea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68e8cfe5-c1fb-4383-8536-6426ec789083
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a5ed725-3549-4549-b8b3-288f7074ca91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f39379c7-dba8-4744-9a57-444477de6ef6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47ff9c44-60a5-435e-9b9d-bd62b7496c49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ac54db6-d0e3-4d9e-b794-f3eb8c4fac3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b8f9305-052b-4fba-8195-7228374a8246
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e540be2-e638-4bb4-88db-312e73f5a6fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2cef519-f600-4017-80f0-d7ec54697b36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e2090bf-403f-483f-8181-48f52d5fd70c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d49f14d-26e2-4fae-92fe-7b7c4752cf76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 502f64ae-b250-43de-a0e1-daa00df6fe33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52c893c3-97ff-474e-a8e7-1da8d1374a02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba488b92-0ed2-4916-9e79-50200e38607b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 052beba4-0969-4885-865c-ce450533f130
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 543d0a5d-19e7-4b3b-931d-9beef3b1f0e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59578519-97b7-4ff8-bc49-8e10a4a0ad01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 747135e4-7eb2-42ee-af79-4e776701b823
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7ffcc8d-7d32-4760-be6d-6570a7d6508f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5800b393-277e-4221-9570-bf65c5046770
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fedd5264-1047-41a9-9d9d-d2b7d8bd1429
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 503695cc-6f97-429d-a939-1bc760532690
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b83363a-76d6-4795-be44-6c0b286dada7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7026fa73-e2ae-4fff-aefb-94b82447e267
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8936d41a-15b5-40ee-aa55-8037634d8780
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e73a4527-9247-406a-9d82-35f6eff21c31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 132265b4-4fcf-42d9-9090-84b12c50d3b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d20aa2b-5157-4bc5-8d14-f86c5842d21c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b19f03da-88e3-4d30-8719-8a5bb43b95ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19d61531-c1e4-4dd9-854d-c4085ec0a3f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bace2572-0e67-4bdb-ab19-ad0f900dd886
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 955110c4-0418-4a7c-af9c-50ac90b7ef8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39ef14f5-b2f6-414f-aca4-61a587756254
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bd1917f-5d2a-4604-b9ba-9edb327b909b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b00f0cd-3ab0-4ef5-a2ad-5887e186d68f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df7be56c-2637-41b7-965b-c69b81bd5766
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d3b001a-5430-420b-b7e7-d69da57f70df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 228a2214-8ef1-4442-b065-c57481957fa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 967bc0d1-f156-46a1-a8cd-69f2e3084670
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1245dfa3-22b1-4433-adc2-dd8797f44d29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a553fceb-2fbb-42b4-8065-9a641c2c2d1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd776c87-734d-4fc7-a5bb-f84104c6d801
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 964ef0ac-ef4f-454d-af14-33a8a5f64472
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c382696-695f-48b7-a1be-7ac34cfa4e81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ddca4630-8810-4554-a262-4c009a01243d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15d3b287-7a90-4ebc-9805-c940f83995c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48fcd220-6395-4e7c-ba88-1f3adf2d8e26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 239cbb50-9ece-4fea-bd12-e82c9c695702
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17da78a3-f7f2-4807-98e5-fb4d188992ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 886d9818-b737-4c43-8502-074799a758f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 724aeb75-d59c-45b4-abe9-72b489b6d128
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ffc058a-b961-4f98-9776-957574b48cf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7cd0406-2584-4f4c-9e04-500e519e5c27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c7a89fb-c13e-4d7b-9494-6af6ef947505
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f49986ed-e2f4-4e5b-8729-03f21014c73f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14fb124f-c525-4234-8491-77ec319883f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message daf0e8ed-1113-433e-be32-d122605996af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80a86948-8f36-4c4b-aa67-bf2b58499e1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a61b314d-9c1c-4c52-9dad-b3beb466594b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72b5281b-0b49-4a7e-b1f1-b0a431565d91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e9d8981-6181-41da-b0e3-8038d920572d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee6cb1c7-ada6-4ba0-85d9-db98cfb1b44c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed10bfc9-5e1e-4f41-bd5f-0f956bb81112
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c47c288-517b-40f5-96eb-5d78cb90b710
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad0bc5f8-6080-4644-ad07-f49cca16e728
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ab29029-9f59-4277-ae63-d535ed84e3d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef247fa1-d9ca-4bb3-b8b9-cd9beb7e28b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22b6ff02-46d1-4fd5-8bd9-4049746339f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 902f3aa0-fe4a-4a48-8a0c-cf5689b8c5f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b222fb1-f184-4c1b-85fb-b3b9c7eb23f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 959528b1-90e6-4c94-b3ad-d07d60470fce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4c12629-a33f-436d-9444-44d483d39dd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfb5807e-2e86-4f74-af6d-e538f407e90d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 539036ed-c77a-412a-b5f6-51945cdd867c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c91abed-359a-4ae5-b109-4dc734635474
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54763e0e-e9ce-474c-934c-a6102746d708
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9847da86-a72a-4592-8ac9-05de256b152e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 955438b1-7f21-456f-a59d-78b88f384d35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee3a4b2c-e6a3-4935-88a1-60b5b9bc01c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 737c0ce7-1c99-4f07-a227-086a1c1de026
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 097464f1-965b-406c-a701-5e0aec799cb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50defe1b-7c31-4333-b152-d701a9db928f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4037b2a0-f76b-4aaa-b9ec-a2fb61113beb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c60674c-ace3-4216-a10b-ef0f3d90efbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ceaee8e-65e2-4f38-9f96-647b0aec0635
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2ee94b9-6c62-48f2-8f40-78ed66136912
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6dda73a1-776a-4f1b-a24c-7c384a8aa469
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c5c025a-4bfd-4f12-b2f5-5b8777aa3501
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b716ac4-6c68-49fc-8fcf-335659b6546b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed770753-1a74-460d-ac28-177587d612b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40521100-e3bb-41b3-b23a-fbaa589d0f85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10bd0eb9-3a10-4687-897f-7b6d9fd24840
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe9297b7-ef0b-4961-9068-97736eadc08c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44d97426-a3a1-4ae0-b9a7-82f2b7d8b351
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07a55bb6-d6e1-42a5-b36b-0458066abca7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 374e05af-7ecc-4516-ab40-4ec9d27004c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eccaba7f-30dd-4d69-a296-9d7d87fbdea0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b6eeaa7-46cd-4ce7-80b1-d5765ace8d2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ad4a125-2e62-4d99-8dde-28760fb8d23c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34bcf8fb-5fa2-4451-905c-14e59112761a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19d3e159-97d0-4d08-9ba5-e16a1648ab5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75f484b3-865a-497b-ac31-f28a7117dcd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d1274fa-10e2-4f10-84df-24df6cd497f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6197235f-f93c-4b92-af5d-de647d56bcc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 921c2542-c4b7-4561-ac0b-70d2e9e8fb30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3f50dc5-759c-4239-8cbe-411c18c91866
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b52d228c-7e98-4752-85ab-b0e202874f65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 383059f7-7096-4ca6-9260-7336fb161146
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2d993b1-f773-4ca1-bf51-45b9a5234da1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b713cdcc-60b4-4636-b8cb-3c244b0534d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04657de5-308d-450d-b9e0-21a43c9f954f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1388ecd0-93c3-42f2-b807-96ab4e05f6c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec05bcdc-5e2f-469d-b2ce-aa670c25d623
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c236055e-d580-4f62-b8b8-705143a244f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1442aa91-f107-4fe1-b46a-2e8fad03b795
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19602121-a417-4c26-892a-4a340349e843
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb75f2ef-c466-4e1f-8f3f-e0bdddb7a1ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56791f9b-e875-4d17-a45f-ccacdef10f20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8bd4400-e333-4c91-b577-4e378e45599c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04444fa9-b888-45ad-9c87-d40e8129d89b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2bf60ff-d553-4c24-a06d-25bd972af94f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01658927-8d3f-4c1b-a63c-54eb1e658a63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94b2d465-29c0-4c8c-ba2a-a46f8891453c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8db09ec-f39c-4954-8025-9a60694a14cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb956fbe-f446-4598-b2f5-587831a5fe18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62f21735-dc84-49de-9582-a0280157a389
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc6b06e8-fc36-4930-9bc4-7aed0ee30e41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6b60390-1ef9-40bb-8ffd-d1666a73ba4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9da45d16-df1e-4c1d-807e-e374ff199512
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1dd6cfb6-7680-4e03-92d8-8f8a38942060
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14c48123-a140-4384-9eb7-024d353b1e91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3dd3e757-6481-4a63-bfca-26f402f0b0fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e43aadc4-2e33-4834-bac7-cef301e1691d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d4da84e-57f9-4cdf-b3dd-3addc29782c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f3372fd-c6dd-4237-8108-938556bca835
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d492375-ece0-424e-9e57-dfbaea6da75e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4078da2-3e05-4825-96b2-168fbcfac2c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89d41653-1b08-4274-9708-6b92ea6cf227
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c13e99f-358f-498d-8b3f-5b4d35d1fe3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 665f875e-c736-4b6c-a362-41a9cc235129
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d419c818-7b17-4db7-9987-283d91d3412f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 005a4554-563b-450a-826a-dbb35efc04f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18fd56d3-04f3-4fd5-b011-6000ea412440
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 782a2460-6354-4bb6-b9d5-440e4f4a60d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a459bb5-4598-46ed-bcd8-1211b787d202
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05d49d19-eaae-49b9-97f6-f8a8e32699e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb6a5e07-6f93-4877-b85b-aaecbae50de6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52bfb892-a866-4639-8319-9847d709b5a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e6347e1-2087-464d-8c00-59b3cef782e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db0cd590-acbe-4396-b9a2-f56cbd401082
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a4492ad-3cf4-4afa-a5d2-8476dc4a0433
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d686893d-36de-4b17-a0d2-7306d066fdba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77e1a152-2142-4233-b85b-60b00fe4ef73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3eba0a3-b8b8-4213-ae41-ba5b9e40af23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6ba42dc-bd7e-405c-b7f4-9c7c6ce917c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9eb588f5-88c6-441e-85c0-eda5fa1a375c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e598ac0c-6f8b-42e1-a5c7-d46b07b336dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd1e4d0c-8bdf-41e0-81b1-81f146152e3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fe279a0-7fc2-4697-92e2-eb6ddbd7ea4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fde4525-f1a1-43a8-a61d-b32761d62e2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c01aa94-c2cd-4a55-abb2-1e8572c7dd4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e99e625-b781-4d4e-84da-f3ded6a63c78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be5bddf7-a070-416f-9280-3485293f3b40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce1385f6-fcd5-45ea-a325-9b1122f2e215
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71ce6baa-ef48-4974-8a2e-c9f7c91612b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c78b3cbb-6764-4ca6-a245-ab906a2c2b72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fa2a227-3638-4ded-b4a5-9bf6e87ba063
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8c0f260-e6bc-4b3d-8785-d477251922c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99b5385b-5ec7-4b4a-8bc0-59d3831991a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d364553-900f-4e67-9d2f-a45db1164736
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4828de2d-b9a9-4fd7-b0a9-6e9955382fc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10a03c33-bd99-450d-a5f1-4212b5a87731
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 206e98e3-91e6-46b9-95f5-1fe34852b2b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53018a87-c7e2-49eb-9976-4f98ce2fb3bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2935622b-94f8-4340-a10a-fe6b6eb63bbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b621598a-0397-4bca-8115-a64bd3fdf7b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd63e601-32d9-42f8-b4ac-6eb05c2e58e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 923776b8-1123-4959-9f22-4653bbaaaac2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4a22006-8d87-40ae-9105-5e38a4fb8495
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71f9344a-e069-4d95-b882-6cdde83ea25c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62d0a7ef-6db9-4030-b130-5497747e4a4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a3485d4-5634-475c-9643-4414111a4052
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ccae73e3-0789-42fb-b5d2-ad8b3cb126c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0194b7ab-ae18-487f-ad0d-14bc90ce001b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8975f17-9f75-4225-95ad-8e0c1260f9da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f5198bb-1d8b-4cbf-8a8a-7f07dd2a0e69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17eb7fe9-9cec-457b-8fff-715ec3e82584
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90b2ce68-b423-40a9-bdea-1a112b324d10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9185a00-237d-4fc2-be44-e6304abee76a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1bae1e6-c760-482e-a035-8ba7a91c1688
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1857050-a923-4f90-86bc-21464ed37104
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2435ddb8-eeb0-4c81-8b6e-15bb21c6d05a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8efc6659-f348-4093-8ffb-587334dbda3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21e4601a-d131-435c-a315-c5d3c8e90141
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d28ba3e5-7934-47de-a37e-58eaa584032d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 129967b6-5bb9-4606-b59e-0de48b02b26e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4da06081-fe92-48fc-b9a9-e7736288125d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a9333cf-11d8-47d5-9430-a9c2ae45ea33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98d7a3f4-3f72-4455-a50d-6a592f25c6fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8438b3d6-6edb-4ae4-a8fd-e8980c792145
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9e81b69-7ba5-4960-ad86-a10c200ecb1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5174392-acfe-4644-b808-d5743d97a16b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85b6d4da-2910-4118-b3ad-32164673570d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbfbfafb-3773-4c30-9284-3f523f92956f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d39e0638-fb6d-430b-b031-7e1935b0df25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e9cac75-3c28-4631-ae0e-9945e6194a9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99475fac-f59a-4f65-b38c-51f8e9c2ec27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 090ce219-c0b8-40ff-b129-f2c734ed1244
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b035ea56-d2b5-4d7e-9a65-fffc2306e860
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 525f56a8-579e-46a0-a24b-52fcbe30fc38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e6b6ac7-7a3f-4811-a7a4-e5d12b51e488
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae30fc2c-1b07-4116-b740-86545e197a32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ad68f42-6d59-4115-86d1-c553cbe4f034
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c09fdf6e-3b1a-4ed5-ad08-d3057ad1ebfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32a45822-bc97-45ce-adc0-9e19e7825029
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e7e9b32-ea5c-4af3-a0d9-031c17cc5c37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 255f2b80-3675-47de-afe6-cff220f50d74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee8f6d38-f7a3-4ee3-889a-7e81d955388e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5eddb763-1375-4da9-81f8-45d225b33421
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 291997eb-935f-4bf8-918d-03ae2828bf4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5680f8f9-08e2-4066-8b1f-5ed821f72eee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4118cdd0-e5e1-4698-b37e-25164193df91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe6f3454-4a2a-44a2-93e0-5f249216b28a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eec4e22f-a49d-44e7-b57b-1afe69be42c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8fe1082-e00a-4665-945b-2a6c473fb521
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28e0dc27-5ac0-46e7-a76e-da6662bca82d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 671be0df-a4e2-42fd-b662-a0a889c605ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3eb4314e-9cf9-455c-a8b3-896773dafd93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f04c0a92-2838-4be9-8360-35810ee9538d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6a06235-4704-4662-9827-048d240cc5a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa666d79-eeaf-41ce-9a54-10f3094c2078
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae22f226-5537-4ba5-a161-84983352ac65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92330e0e-801e-49d0-826b-e58885a2195d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18ae1ed8-fa64-4ade-9954-842c4aa118c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c89f6cb0-b5fc-4d2d-af72-d9e4fed907a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b050805f-b15b-48cd-a8df-67c2ca3e97a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9958dca3-235f-4244-b36e-d0af583b89e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1c70acc-9ac7-48b5-a389-429578493836
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58f6afac-239e-45ea-93d1-495cb3553e85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 402ccc66-c7e5-473b-b08e-41deef83db98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 992d009c-b302-4c1e-8231-3583ce49e06d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5ee3f58-f3a9-43da-b51f-b4b984add29e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac8d7938-1251-4e3b-92b0-08278fa5c5dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff800756-157b-467f-8a90-f9305d8bc72f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c20b865-ce68-4014-bff4-ff6415119d8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3505e813-3a16-499b-a60c-bbeb5dbaf039
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95dc25c9-2b37-4f98-96e5-9ac130f53d6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7ccd98a-e9cb-4dbd-8497-6853a8fd2c9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea12d5b5-0502-4292-8ff7-3a6638103ea9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc656461-248c-47aa-9fe5-4c313c127090
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00dcaf60-90d7-488d-b1da-d0ae806e764d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9df6f38d-8bf6-4e3d-bcee-49dea45bd99a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 407dfb01-4c47-481a-9f56-3e980e5f1fa5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3f7cad4-5302-4e0b-b8af-7a189a4c635b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c14b5b56-963e-4f7d-aa76-d41ed00c9c21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d431d778-ccd0-48cb-88f0-dece95830eac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e210a872-6e51-4793-ab42-d33d9bdc1c5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 764bed7b-047a-4b60-ad86-400c27382de1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a189caba-fd88-4934-9adb-da4ad90f5d89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 294b4ad0-19d9-4c4c-a173-da68b8b482fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cb4fe8f-33f5-4d45-aff2-045348dcfaf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af623d68-7137-464f-ace3-5c17304974bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7ee2869-c2f3-46e2-9b96-a9670505593a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 992829a9-f0af-4f1a-adb8-e0ec7d012811
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b279a2f-2708-4f70-89a9-4fdee6a9e459
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 529fa9e6-b7fd-4875-854d-b0cd8f5da5ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b41c632d-b37e-4369-ac83-254473bc61a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c4e4744-480f-49d9-ab68-3d42b2d3c6d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 959f7537-4b32-411c-9f51-e86d4ece53b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2e9b501-1429-47d4-b962-130ef49152d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d56f066-6685-4b40-85f8-87ebe276a45b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7066dc21-fab0-440d-8fff-b194b7ea5de2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8227f8e6-20dc-41dc-be9d-3ddf2174a251
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8ae788c-afa0-4da3-9adc-9905ad10048a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc5d7ab7-ce60-4df2-a20e-eb321fc3bb22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99a00998-8fae-4607-8438-7d4c47f93c1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c44f175-2eea-419d-af26-9555a8f456c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61a776ba-f880-4b5b-8403-e3b7fc356598
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b77cdcd0-f237-44a2-aec6-73c3fc600d5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1521e75f-94e9-40cd-b008-e4fad7a1f54e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f92d8903-1403-46b0-9d80-004d77370c92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7652a578-cb11-4387-97b3-d40a7267857a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0f63b0c-a909-4914-b3ab-6a607d37ddf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d214dbf5-4175-401e-be80-637060c1a917
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31bcdb09-733f-43fe-a0a9-91d497f60eae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd593e89-3591-400f-aa0d-9f81441db363
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1f7194b-f6c9-40c1-996a-5792ba1ecd66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed84d525-bd0b-4dc4-85b6-2c0b905d88da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 891be054-bc47-4103-b734-2bf827e8a0fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c4734b1-ef52-4a9e-b3a1-3523be7d65fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0118f1b9-8c86-4b60-9ea7-ece208f1f634
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abae2099-5b8f-45d3-94cf-30ca3b189685
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92d47652-a7cd-4119-82aa-0ad4a4eb5a37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1eb3c93f-0477-4702-a8b1-34132ff216a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0ee2c31-c773-4258-8505-b3567e4044da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a60abc6d-3692-43ae-9ef0-4300f8924faf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abb833ff-e446-40ea-91ec-1f8364056fc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0befe0f3-dbfc-40de-b705-12719f561a40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b139be6f-176f-4047-abc9-9a8f949d0e47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6a0cc0c-e0a9-45d8-ae77-d218c428afd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e32b8c2-9a7f-4f45-85c6-437fbf246db5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c8c96f1-3b61-4d21-a5ac-0a21df1739c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 818fd620-bb93-4f28-931f-f7390bcc89fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 095e1d12-1ed7-42f6-a833-e3a2156e9d29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dacae5ae-ffeb-406c-a579-ef65348b1f28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 971a41cd-832b-4ff9-82a3-3792a5595bd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff52bb3d-3fe8-44ca-b7f4-cbad1a30a9b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d70e9577-cf62-4b72-a4cb-7d36d4c57804
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0284b98d-4f35-4e27-af75-145deef09848
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9dfe7f12-c923-4563-be7f-a6c5f03fa4ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67885c15-7c4a-43a4-83ab-ced0c1ad245d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4641b3d3-84cc-4edd-b019-8f71db620121
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8d7acb5-7c36-4377-90aa-e62b56d71bad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4006bcd9-2ac2-4d1f-b25a-2ea5303c6699
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73437ba4-9216-4c35-b3cb-efbca203056f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60ab4ffc-f806-4bfe-8fa0-7328afbde1d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c08ccf76-065f-45b8-b08a-34d94176def8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9841c02-05b9-45d9-80d1-99f57544c7de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd0ccbe3-c75e-4447-b480-e644bd9f111d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2820345c-1de0-4b73-b960-7082b94964e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 451bb295-9309-452d-8861-cc067ab59d8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c546a14f-3473-4e2c-aa58-b43cad22ce5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65834e7d-c850-42bb-9eed-92bd5ca76e37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30f26770-e4f9-4347-976a-53fbb7075874
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9b2bb30-7030-4358-887a-170ffdda9901
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1cb2eb2-a0f2-494c-811d-d49d47bb5982
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d44e2fd1-2de0-4e58-8217-e90427832a50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd0b0c01-c8be-480e-88e7-6ce0dfb159b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b32b215-99ea-4cb5-b667-1327dfebe2f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4321a971-0f31-4ee7-9b8c-a3d68faa1728
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 988c1e55-6262-48f6-bb48-daea0a1f4b10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e53274da-8182-4cdf-aaed-f2aeaa253b70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2ca58e7-8ed7-4c05-9c01-d89d3c0558b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d0dd9c5-0fcc-415f-8fc2-9c711713e7c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a85e0e6-4059-4ca4-943d-ed4c0c7dac63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d6e3ead-da47-4e80-84ee-b9d5cf589234
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b53015a4-c4ff-48a4-9333-72731c6d6425
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba2f9d8e-2a80-480c-949d-4009f2c58a9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0325bf7b-306e-49e3-b2a0-d3016c758d43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db2121d8-01fb-4e5b-a97a-1a5b857b3851
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62823d9f-dee2-4a22-bd20-2c486d8ad418
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb2d7f74-3bbd-44e7-9f26-7856568b9fb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11ae9742-a5e8-4bef-8e07-4240831d7892
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c66d31ab-90c7-436d-a193-7cdb6280e299
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 550b6c6c-1aa2-4e31-a224-a603cb7ac405
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0ca0450-8893-44c9-80a2-dd0e73981d44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10a6908b-34b2-4fc0-92ad-ac9fae923f80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84d23735-9927-4c47-bf03-2b56253dd7e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc81c761-abd9-4c38-b93f-c797aa64c2b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6124b41e-d6f4-4af3-9dbd-eb258ae3a7a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4702bbf7-a9b0-4fd9-bf33-73dbe27dff70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe88b8a9-0f1f-4605-99da-21981ac954c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5350407-7a7b-41fa-a8c2-2580d1b9bf07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e004718-9063-4852-aef0-a26beca20d6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73affb8a-a18e-449b-b1fa-7c1bd3abf445
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7038596-d172-459a-ba11-9ff8a479d883
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4525fbd-99c4-481d-b9c9-0ac265ac80ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3045ddf-a73e-4945-8b6d-3ebc6fac6185
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9521fd7-8343-4f8a-975f-e762bae0a87c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04b511f7-59da-463b-8934-b98aafd9b67e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b93be840-f402-4e47-be3e-8f86fe5c44a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 694324a7-7e69-4ca5-bbda-d364d1011bc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 979af96a-cb45-446f-a38d-7b70629bdd8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9ccc6d0-edbb-4074-b1ff-89701a78c988
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28387745-77c6-47e4-acc7-0a3c35d68111
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e1d328a-d9c1-472a-a554-3f3732217c78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57a27236-afde-4fa0-bec5-00c0f6c9f391
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bd9ee86-6f4b-4483-8230-67c1b1907abd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bd3f699-6b6e-45a9-964e-6d28310c8b18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e86e4c2-9393-41b0-9b6c-b701522dbd5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53a3cfcc-9fc2-418c-991f-2bf3f0b3b995
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50d51d01-c8b4-4e2d-a6b1-a4594715f0df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f14e4a18-3519-470c-8c97-603a8995c248
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18c0322c-6fef-498a-90eb-7bd456553fd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a6a0017-3453-41b4-bf42-6bbb4d8f4901
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f037e255-5207-414d-95a9-89be43ce9027
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 323e099a-b078-41a5-a0d8-d43b2e80100a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a51958e1-20d1-4218-91bb-fdab1484fb51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae13f789-9d51-4418-bf97-c0e59d4d6f99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f4203d4-dbe4-4147-b4ed-a5d67f8e3c4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e744550-28ce-4cc5-a262-a6346c203db2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6050472-c51c-41a3-8fb1-a9dbb0f67132
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab07a22e-952e-44d4-a153-3e247dc1a75a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 057b6897-35ab-4590-b02f-ef67bd1f3d80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5ae6627-1ca4-4c2f-8f76-35b679972f96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 541c9a47-ee67-48e4-a927-cb68689ce769
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 283d8b5b-49c3-4bdc-a71a-f313cf8c1c04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f757d88a-d632-4b56-89b7-2336f33cd7e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07a71a8d-964f-41fb-aa27-121ac2985dfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48aaa04f-f29b-4dfd-862c-a76aea017248
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0ebd3fb-e679-461e-be2b-f68a7710b39f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4763b190-b773-43e7-ae2f-70a6df3a04d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f6daa00-bcfb-452a-87fe-99c0c12fe13a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83f60fc2-0cc9-4c3d-804c-da0ff5a34917
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09618df0-89cf-476f-94cd-ca613754989b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 848e8aff-c7a2-4917-96f8-5ae62876c575
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ab6e010-3bd8-47d7-997b-e48144849517
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eeabc818-d366-438b-a6f3-36ebbfabf297
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5dc5cd5-a5cf-4713-a038-4e9352265fde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3aa3931c-6703-49be-b96a-1c667b06093e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6b808b7-02bf-4abb-9dcd-d0de4d74d288
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4781810e-74eb-446a-b69e-9395a72ce5e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c573eab-6719-44e0-baca-5bbf4f9eea46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33956b7e-eef6-40b7-a051-4c7adf8b45d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c70a7e92-3bfb-46ca-abc7-709a0c572fe9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d40692da-18a4-4eb6-b502-329b79c0a7be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66e98a2f-092e-4a0e-a294-979e9005ff78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97045612-215c-49ee-987f-96fead98ab0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 530d2c98-42dd-40b0-97e2-524b7c933e27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38f68345-b443-4abc-a19c-f3c7f956130b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7576dfe2-ee80-409d-96c6-08630ea154a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f84436e-45fe-4806-a9b4-5d28fb4b6dda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d24d70da-a985-480d-9435-8a533534ac15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd5a126f-5f55-49be-b251-7540c8857ccb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f29895a7-c7f8-470f-b62a-d237797c7ede
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd3e6a0a-0634-4853-a4fa-6a82c2d9fd59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 992ac441-db38-4118-91fa-886530ac5888
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b5399dc-f561-4044-b941-52f3f1673fc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e72d4ed1-415b-48e3-8cab-985bc1131021
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c73d407-d72f-4f51-83d5-b5c631713d42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48902bfc-47af-4f11-bf2d-66bd71a54f41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60d65fe3-5a8c-435d-9f0f-851cb9b1b4f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bc2f670-1fe1-4042-9186-63758783b7de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d304fac-4e0b-466e-9d94-36431574223f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f669718-7af2-4419-b12d-f88c17bff581
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4416778-cebd-4e16-b0e5-2d11f87716ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a33c051-5bfa-47b6-aef7-2408513d6568
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2fd8462-a864-4ce4-964d-eea01539dd37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7e4963b-9a67-4a9e-a9e6-e56645aa8d07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45da01c2-762b-4328-a49d-39eded76d316
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdbf4789-2719-4a12-921f-504723bcbfee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d46007a6-6198-4275-b8e8-c4a1e5d944d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3d0bba8-ff74-4c99-9421-df51da2f0132
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9166300-72ae-4662-bcd2-fcab554a65e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a00157f7-781f-4470-986a-b12927079e23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c995d95-f1c8-4383-a1b3-c42be4994b7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67e61bf4-76f9-4d46-b13b-89ec1f4d6763
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 429eb260-09d7-4b34-819f-9d5ca4a86124
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2b4f481-17bf-4290-9cac-38d8449f0d17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1ade17c-9069-44a4-aab5-ccb07a4c4d7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fa54fd3-db17-47a6-96ed-e34503a86016
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8540b879-00a5-4811-b907-0a48e8a982b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 007c805e-04c6-4e14-ad7f-02964dba00a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ebd89a4-32fe-4acf-b5a0-0132b7fb7653
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82be53ea-b0b9-4220-ae0d-1e8dd1157595
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 254460a1-e597-4d50-a7c9-71429aca36ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4df79ed7-05be-49a2-b678-fdae6f9f66ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 705f90b5-c224-49d1-81f5-ac6d55ca8c72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a98b6484-a4b7-4c3f-9b84-67ff5d1c647c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 042b0410-96ef-4009-b483-73bb7d5cd66b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a915891-60b5-4804-876c-e26b191693f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e485af0-bfff-4bad-b2af-cd9cf944aaad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e26fcbe3-acc4-4ea7-80e5-6d2eb4887c52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74c29ac4-d7b0-4b6b-abc3-b72aeb053d03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19e769c5-4814-4acb-b11c-a0ce84164c38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9598106-4e6f-40ab-bc89-e3a17af717e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c850c66b-49c9-418e-9329-f43494c2640f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 230bc55d-b081-4b18-a989-9b880e122166
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ad2e470-5aa2-43d5-9ea7-21e55d3297f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42243c99-d7a5-43db-b917-c9ae1ef7537b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe3fc637-6884-45cc-94a1-e0b522539ea4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3366cb9f-9eb2-4d26-9db7-7180c9fceacf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 547c8ccc-a4fa-4e9d-9d2c-f649b954fe4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f3552fa-ec1e-47aa-854c-a13b018ceb81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b29dc33a-7e94-4af5-806a-2e5e40386ab4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e543ef5e-c4a8-4eeb-b9ba-d288333d19a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11213607-c81e-4fd6-9bc4-fb430914d888
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34c09223-4d27-405b-8a7b-0fa4d9a847f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca07c2f2-3a0d-4832-93bd-b17973824b19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e64cea7-1aed-4b39-a433-e67361e2b6b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a4e261b-a103-459a-800c-ac19b95f52e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d7c3858-d412-4267-83ce-0475d35d5aea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52424251-5b8b-465e-a4f4-a8a09470155c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73d24679-0c1e-472d-bff1-9cf6ef14c74f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3965a782-85cb-495f-8d03-cdc216377d50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ca3df8d-3d08-4076-947f-063aa6d18246
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf50c03d-b3fd-4f85-8599-d7c8a496e25b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0a38339-c7de-4ed5-922b-14baa7f37473
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5f3f83e-bc56-4b81-be17-1537ff0cb1e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ff73417-fc98-4042-aad5-ae761e4321e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccb5d6ca-0d35-42ba-80d9-efa4ee14e39b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 450866c0-af8c-4378-bc08-6061e68b60b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 589a5a0a-f239-43f7-81e9-1763a13da169
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 892783b1-f879-42d0-8f18-5b3e93e93062
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 203340d0-784f-4dde-8af9-ebd12f7a21a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b00375bd-0250-48b3-b39c-70b3075b4289
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf7484f3-ea60-4171-b4a4-84a952716b93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9152262f-60f5-4672-9072-eb9fb050f24e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c78f9f8c-de1b-4f18-a626-b1429ef48111
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef3a08a2-9308-47e6-b53d-30abe0cd2053
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2f8abee-18c2-400f-a06a-e2a21da57b85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2cb17f50-cb4b-4299-a3b4-f63351726dd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 825b3e37-53a6-45aa-8c7e-46ab7ede1da5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02f8060a-a29c-4ca4-903b-05d35a11c36e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e347d5d5-122b-40e7-b388-39d25c556d7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff0ebc19-23b5-4989-8c2e-dda8fb975781
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f3d84ff-ec7c-44ea-89db-e37402a9549b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 477afc81-53fe-486b-9281-bfa72becd2c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc77efef-7daa-4163-8343-7824327f894d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d629717f-19ca-4b1d-8716-e63d0b2395f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2b8c5b4-7f9c-442f-afc8-5ec9759189e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4200390f-d28e-4be1-ac3c-9a1ac9e78531
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1bc946d-0425-4f0f-a50c-736c7d03a161
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cffe9e0-cb3c-49fb-81a3-4a6504092c56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df37c935-51c2-46cf-8f6e-326e62c6c189
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0343a592-1603-4f45-9f33-8cdb85e16cc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9ccfe79-ec94-47f5-b0f5-2470ed39bbbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 208bec62-83bc-45b3-ad6f-a37248662f1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2da474c7-5cce-4b2e-831b-4857162683c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d1318df-f8ed-458d-91c6-1145bfe38e6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 847d003f-7f39-45f4-805d-a82ee17d0854
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1daf043-74ca-4069-9c9a-650da214ebf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 168eef3d-df9b-4529-8e0e-99e4a36266a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 815e64c7-9b9e-4abe-a002-3ece559906c4
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_20
Server: localhost:8686
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_20
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_20/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_20/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_20/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_20/test_labels.txt

📊 Raw data loaded:
   Train: X=(6680, 24), y=(6680,)
   Test:  X=(1670, 24), y=(1670,)

⚠️  Limiting training data: 6680 → 800 samples
⚠️  Limiting test data: 1670 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_20 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0005

📊 Round 0 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2487, R²: -0.0007

============================================================
🔄 Round 6 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0849 (↓), lr=0.001000
   • Epoch   2/100: train=0.0869, val=0.0848, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0883, val=0.0848, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0875, val=0.0853, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0865, val=0.0852, patience=4/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0847, val=0.0865, patience=10/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 6 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0084
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0078
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0009

============================================================
🔄 Round 8 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0834 (↓), lr=0.000250
   • Epoch   2/100: train=0.0871, val=0.0837, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0871, val=0.0832, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0869, val=0.0834, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0869, val=0.0833, patience=4/15, lr=0.000250
   📉 Epoch 9: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0865, val=0.0834, patience=10/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 8 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000125 (1 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=0.0040
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0074
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0823, RMSE: 0.2870, MAE: 0.2488, R²: 0.0000

📊 Round 8 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

📊 Round 8 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

📊 Round 8 Test Metrics:
   Loss: 0.0823, RMSE: 0.2870, MAE: 0.2488, R²: 0.0001

============================================================
🔄 Round 13 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000125 → 0.000063
   ✓ Epoch   1/100: train=0.0860, val=0.0878 (↓), lr=0.000063
   • Epoch   2/100: train=0.0857, val=0.0882, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0857, val=0.0884, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0856, val=0.0885, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0856, val=0.0885, patience=4/15, lr=0.000063
   📉 Epoch 9: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0854, val=0.0887, patience=10/15, lr=0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 13 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0033
   Val:   Loss=0.0878, RMSE=0.2964, R²=-0.0044
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0823, RMSE: 0.2870, MAE: 0.2488, R²: 0.0000

============================================================
🔄 Round 14 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000031 → 0.000016
   ✓ Epoch   1/100: train=0.0853, val=0.0916 (↓), lr=0.000016
   • Epoch   2/100: train=0.0852, val=0.0916, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0852, val=0.0916, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0852, val=0.0916, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0851, val=0.0916, patience=4/15, lr=0.000016
   📉 Epoch 9: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0850, val=0.0917, patience=10/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 14 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0030
   Val:   Loss=0.0916, RMSE=0.3027, R²=-0.0011
============================================================


============================================================
🔄 Round 15 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0821 (↓), lr=0.000008
   • Epoch   2/100: train=0.0873, val=0.0821, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0873, val=0.0821, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0873, val=0.0821, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0873, val=0.0820, patience=4/15, lr=0.000008
   • Epoch  11/100: train=0.0872, val=0.0820, patience=10/15, lr=0.000008
   📉 Epoch 14: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 15 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000004 (1 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=0.0036
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0044
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0002

📊 Round 15 Test Metrics:
   Loss: 0.0823, RMSE: 0.2870, MAE: 0.2488, R²: 0.0001

============================================================
🔄 Round 17 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0786 (↓), lr=0.000004
   • Epoch   2/100: train=0.0882, val=0.0786, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0882, val=0.0786, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0882, val=0.0786, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0882, val=0.0786, patience=4/15, lr=0.000004
   • Epoch  11/100: train=0.0882, val=0.0786, patience=10/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 17 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000004 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=0.0047
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0053
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0001

============================================================
🔄 Round 26 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0866 (↓), lr=0.000004
   • Epoch   2/100: train=0.0864, val=0.0866, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0864, val=0.0866, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0864, val=0.0866, patience=3/15, lr=0.000004
   📉 Epoch 5: LR reduced 0.000004 → 0.000002
   • Epoch   5/100: train=0.0863, val=0.0866, patience=4/15, lr=0.000002
   • Epoch  11/100: train=0.0863, val=0.0866, patience=10/15, lr=0.000002
   📉 Epoch 13: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 26 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0030
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0002
============================================================


============================================================
🔄 Round 28 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 28 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0027
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0022
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0002

📊 Round 28 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0002

📊 Round 28 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0002

============================================================
🔄 Round 33 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 33 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2979, R²=0.0039
   Val:   Loss=0.0770, RMSE=0.2774, R²=-0.0059
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0002

============================================================
🔄 Round 36 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 36 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0014
   Val:   Loss=0.0897, RMSE=0.2995, R²=0.0035
============================================================


============================================================
🔄 Round 37 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 37 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=0.0018
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0039
============================================================


============================================================
🔄 Round 38 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0959 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0959, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0959, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0959, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0959, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0959, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0959)

============================================================
📊 Round 38 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0031
   Val:   Loss=0.0959, RMSE=0.3098, R²=-0.0023
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0002

============================================================
🔄 Round 39 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 39 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=0.0043
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0096
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0002

📊 Round 39 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0002

============================================================
🔄 Round 41 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 41 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0030
   Val:   Loss=0.0855, RMSE=0.2923, R²=-0.0012
============================================================


============================================================
🔄 Round 42 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 42 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0034
   Val:   Loss=0.0882, RMSE=0.2969, R²=-0.0064
============================================================


============================================================
🔄 Round 43 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 43 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0037
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0016
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0002

============================================================
🔄 Round 44 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 44 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=0.0002
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0122
============================================================


============================================================
🔄 Round 45 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 45 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=0.0021
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0014
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0002

📊 Round 45 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0002

============================================================
🔄 Round 47 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 47 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=0.0029
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0036
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0002

📊 Round 47 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0002

📊 Round 47 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0002

============================================================
🔄 Round 50 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 50 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0032
   Val:   Loss=0.0921, RMSE=0.3035, R²=-0.0044
============================================================


============================================================
🔄 Round 52 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 52 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0037
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0017
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0002

============================================================
🔄 Round 54 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 54 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0028
   Val:   Loss=0.0879, RMSE=0.2964, R²=-0.0210
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0002

============================================================
🔄 Round 56 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 56 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0035
   Val:   Loss=0.0923, RMSE=0.3038, R²=-0.0008
============================================================


============================================================
🔄 Round 59 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 59 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2976, R²=0.0005
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0052
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0002

📊 Round 59 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0002

============================================================
🔄 Round 61 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 61 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0016
   Val:   Loss=0.0871, RMSE=0.2952, R²=-0.0071
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0002

============================================================
🔄 Round 62 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 62 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0036
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0013
============================================================


============================================================
🔄 Round 63 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 63 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=0.0037
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0036
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0002

============================================================
🔄 Round 64 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 64 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=0.0034
   Val:   Loss=0.0767, RMSE=0.2769, R²=-0.0004
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0002

📊 Round 64 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0002

============================================================
🔄 Round 66 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 66 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=0.0009
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0093
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0002

============================================================
🔄 Round 69 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 69 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0035
   Val:   Loss=0.0926, RMSE=0.3043, R²=-0.0087
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0002

============================================================
🔄 Round 71 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 71 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0008
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0097
============================================================


============================================================
🔄 Round 72 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 72 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=0.0023
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0072
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0002

📊 Round 72 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0002

============================================================
🔄 Round 74 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 74 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2967, R²=0.0016
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0024
============================================================


============================================================
🔄 Round 76 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 76 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=0.0018
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0276
============================================================


============================================================
🔄 Round 77 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 77 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2909, R²=0.0023
   Val:   Loss=0.0934, RMSE=0.3057, R²=-0.0010
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

📊 Round 77 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

============================================================
🔄 Round 79 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 79 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=0.0011
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0017
============================================================


============================================================
🔄 Round 80 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 80 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0021
   Val:   Loss=0.0925, RMSE=0.3041, R²=0.0030
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0002

📊 Round 80 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

============================================================
🔄 Round 82 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 82 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=0.0002
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0068
============================================================


============================================================
🔄 Round 92 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0938, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 92 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0026
   Val:   Loss=0.0938, RMSE=0.3062, R²=0.0013
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

📊 Round 92 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

============================================================
🔄 Round 96 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 96 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0022
   Val:   Loss=0.0904, RMSE=0.3007, R²=0.0028
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

📊 Round 96 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

============================================================
🔄 Round 99 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0989 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0989, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0988, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0988, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0988, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0988, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0989)

============================================================
📊 Round 99 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0028
   Val:   Loss=0.0989, RMSE=0.3144, R²=0.0021
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

📊 Round 99 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

📊 Round 99 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

============================================================
🔄 Round 102 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 102 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0024
   Val:   Loss=0.0916, RMSE=0.3027, R²=0.0026
============================================================


============================================================
🔄 Round 103 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 103 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=0.0043
   Val:   Loss=0.0855, RMSE=0.2923, R²=-0.0195
============================================================


============================================================
🔄 Round 104 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 104 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=0.0021
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0088
============================================================


============================================================
🔄 Round 105 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 105 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0036
   Val:   Loss=0.0884, RMSE=0.2974, R²=-0.0171
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

📊 Round 105 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

📊 Round 105 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

📊 Round 105 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

📊 Round 105 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

============================================================
🔄 Round 111 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 111 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0036
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0244
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

============================================================
🔄 Round 112 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 112 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0035
   Val:   Loss=0.0924, RMSE=0.3040, R²=-0.0088
============================================================


============================================================
🔄 Round 113 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 113 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2972, R²=0.0015
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0070
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

============================================================
🔄 Round 117 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 117 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=0.0040
   Val:   Loss=0.0859, RMSE=0.2930, R²=-0.0050
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

============================================================
🔄 Round 121 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 121 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=0.0034
   Val:   Loss=0.0751, RMSE=0.2740, R²=-0.0059
============================================================


============================================================
🔄 Round 123 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 123 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=0.0036
   Val:   Loss=0.0830, RMSE=0.2880, R²=-0.0020
============================================================


============================================================
🔄 Round 127 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 127 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=0.0036
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0100
============================================================


============================================================
🔄 Round 129 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 129 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0029
   Val:   Loss=0.0898, RMSE=0.2997, R²=0.0013
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

📊 Round 129 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

============================================================
🔄 Round 135 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 135 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=0.0054
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0198
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

============================================================
🔄 Round 137 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 137 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0028
   Val:   Loss=0.0930, RMSE=0.3049, R²=-0.0023
============================================================


============================================================
🔄 Round 139 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 139 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=0.0033
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0011
============================================================


============================================================
🔄 Round 140 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 140 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=0.0024
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0023
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

============================================================
🔄 Round 141 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 141 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0030
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0010
============================================================


============================================================
🔄 Round 142 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 142 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0044
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0048
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

📊 Round 142 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

============================================================
🔄 Round 148 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 148 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0024
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0033
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

============================================================
🔄 Round 150 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 150 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=0.0019
   Val:   Loss=0.0899, RMSE=0.2999, R²=0.0027
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

============================================================
🔄 Round 152 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 152 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0002
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0131
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

============================================================
🔄 Round 153 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 153 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0025
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0143
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

============================================================
🔄 Round 155 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 155 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0039
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0031
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

📊 Round 155 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

============================================================
🔄 Round 157 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 157 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=0.0018
   Val:   Loss=0.0848, RMSE=0.2911, R²=-0.0012
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

📊 Round 157 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

============================================================
🔄 Round 160 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 160 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=0.0009
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0105
============================================================


============================================================
🔄 Round 164 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 164 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0029
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0004
============================================================


============================================================
🔄 Round 165 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 165 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2940, R²=0.0040
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0060
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

📊 Round 165 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

📊 Round 165 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

📊 Round 165 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

============================================================
🔄 Round 170 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 170 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=0.0020
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0039
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

============================================================
🔄 Round 175 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 175 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=0.0011
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0198
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

============================================================
🔄 Round 176 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 176 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0025
   Val:   Loss=0.0915, RMSE=0.3025, R²=0.0018
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

📊 Round 176 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

📊 Round 176 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

📊 Round 176 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

============================================================
🔄 Round 188 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.1025 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.1025, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.1025, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.1025, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.1025, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.1025, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1025)

============================================================
📊 Round 188 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0037
   Val:   Loss=0.1025, RMSE=0.3202, R²=-0.0010
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

📊 Round 188 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

📊 Round 188 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

📊 Round 188 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

📊 Round 188 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

📊 Round 188 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

📊 Round 188 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

============================================================
🔄 Round 198 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 198 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=0.0020
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0051
============================================================


============================================================
🔄 Round 200 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 200 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0036
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0010
============================================================


============================================================
🔄 Round 206 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 206 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0028
   Val:   Loss=0.0927, RMSE=0.3044, R²=0.0013
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

============================================================
🔄 Round 209 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 209 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=0.0026
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0013
============================================================


============================================================
🔄 Round 211 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 211 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2969, R²=0.0025
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0034
============================================================


============================================================
🔄 Round 212 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 212 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=0.0032
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0331
============================================================


============================================================
🔄 Round 213 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0952 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0952, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0952, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0952, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0952, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0952, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0952)

============================================================
📊 Round 213 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0015
   Val:   Loss=0.0952, RMSE=0.3086, R²=0.0066
============================================================


📊 Round 213 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

============================================================
🔄 Round 214 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 214 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=0.0031
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0050
============================================================


============================================================
🔄 Round 215 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 215 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=0.0008
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0011
============================================================


📊 Round 215 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

============================================================
🔄 Round 216 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 216 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0000
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0164
============================================================


📊 Round 216 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

============================================================
🔄 Round 217 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 217 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=0.0015
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0074
============================================================


============================================================
🔄 Round 218 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 218 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2952, R²=0.0014
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0080
============================================================


============================================================
🔄 Round 219 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 219 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=0.0013
   Val:   Loss=0.0913, RMSE=0.3022, R²=0.0079
============================================================


============================================================
🔄 Round 225 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 225 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=0.0023
   Val:   Loss=0.0798, RMSE=0.2826, R²=-0.0005
============================================================


📊 Round 225 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

============================================================
🔄 Round 227 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 227 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=0.0025
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0027
============================================================


============================================================
🔄 Round 228 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 228 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=0.0038
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0023
============================================================


============================================================
🔄 Round 229 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 229 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0029
   Val:   Loss=0.0901, RMSE=0.3002, R²=0.0022
============================================================


📊 Round 229 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

============================================================
🔄 Round 230 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 230 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=-0.0001
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0091
============================================================


📊 Round 230 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0003

============================================================
🔄 Round 231 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 231 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0022
   Val:   Loss=0.0896, RMSE=0.2993, R²=0.0045
============================================================


📊 Round 231 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0003

============================================================
🔄 Round 235 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 235 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=0.0026
   Val:   Loss=0.0853, RMSE=0.2920, R²=0.0010
============================================================


📊 Round 235 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0003

============================================================
🔄 Round 237 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 237 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=0.0036
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0012
============================================================


📊 Round 237 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0003

📊 Round 237 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0003

============================================================
🔄 Round 239 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.1003 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.1003, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.1003, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.1003, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.1003, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.1003, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1003)

============================================================
📊 Round 239 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0031
   Val:   Loss=0.1003, RMSE=0.3167, R²=0.0014
============================================================


============================================================
🔄 Round 240 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 240 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0029
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0267
============================================================


📊 Round 240 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0003

============================================================
🔄 Round 241 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 241 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=0.0014
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0114
============================================================


📊 Round 241 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0003

📊 Round 241 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0003

============================================================
🔄 Round 244 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 244 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2959, R²=0.0012
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0063
============================================================


📊 Round 244 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

============================================================
🔄 Round 245 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 245 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=0.0010
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0019
============================================================


📊 Round 245 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

📊 Round 245 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0003

============================================================
🔄 Round 248 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 248 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=0.0044
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0163
============================================================


============================================================
🔄 Round 249 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 249 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=0.0017
   Val:   Loss=0.0775, RMSE=0.2783, R²=0.0077
============================================================


============================================================
🔄 Round 252 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 252 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=0.0022
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0030
============================================================


📊 Round 252 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

📊 Round 252 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

📊 Round 252 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

📊 Round 252 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

============================================================
🔄 Round 258 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 258 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0033
   Val:   Loss=0.0938, RMSE=0.3063, R²=-0.0490
============================================================


============================================================
🔄 Round 259 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 259 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=0.0040
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0083
============================================================


============================================================
🔄 Round 260 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 260 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0019
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0008
============================================================


📊 Round 260 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

📊 Round 260 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

============================================================
🔄 Round 267 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 267 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=0.0025
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0035
============================================================


============================================================
🔄 Round 268 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 268 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=0.0032
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0001
============================================================


============================================================
🔄 Round 270 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 270 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0029
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0143
============================================================


📊 Round 270 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

📊 Round 270 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

============================================================
🔄 Round 272 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 272 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0040
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0030
============================================================


📊 Round 272 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

============================================================
🔄 Round 273 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 273 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=0.0026
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0022
============================================================


============================================================
🔄 Round 279 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 279 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=0.0028
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0021
============================================================


📊 Round 279 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

📊 Round 279 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

============================================================
🔄 Round 281 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 281 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0033
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0002
============================================================


============================================================
🔄 Round 283 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 283 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0029
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0014
============================================================


📊 Round 283 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

============================================================
🔄 Round 284 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0942, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0942, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0943, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0943, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 284 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0024
   Val:   Loss=0.0942, RMSE=0.3069, R²=-0.0034
============================================================


📊 Round 284 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

============================================================
🔄 Round 288 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 288 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2964, R²=0.0032
   Val:   Loss=0.0806, RMSE=0.2840, R²=-0.0013
============================================================


📊 Round 288 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0003

============================================================
🔄 Round 290 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 290 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=0.0021
   Val:   Loss=0.0802, RMSE=0.2831, R²=0.0056
============================================================


📊 Round 290 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

============================================================
🔄 Round 294 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 294 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=0.0012
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0032
============================================================


📊 Round 294 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

============================================================
🔄 Round 295 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 295 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=0.0013
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0084
============================================================


📊 Round 295 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

============================================================
🔄 Round 297 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 297 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0028
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0035
============================================================


📊 Round 297 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

============================================================
🔄 Round 298 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 298 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=0.0028
   Val:   Loss=0.0930, RMSE=0.3049, R²=-0.0083
============================================================


📊 Round 298 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

============================================================
🔄 Round 299 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 299 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2940, R²=0.0023
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0028
============================================================


📊 Round 299 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

============================================================
🔄 Round 301 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0994 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0994, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0994, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0995, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0995, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0995, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0994)

============================================================
📊 Round 301 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0029
   Val:   Loss=0.0994, RMSE=0.3153, R²=-0.0109
============================================================


============================================================
🔄 Round 302 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 302 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0049
   Val:   Loss=0.0926, RMSE=0.3043, R²=-0.0096
============================================================


============================================================
🔄 Round 303 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 303 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0006
   Val:   Loss=0.0936, RMSE=0.3060, R²=-0.0102
============================================================


📊 Round 303 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

============================================================
🔄 Round 304 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 304 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0014
   Val:   Loss=0.0893, RMSE=0.2988, R²=0.0035
============================================================


============================================================
🔄 Round 305 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 305 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0020
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0033
============================================================


📊 Round 305 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0003

============================================================
🔄 Round 308 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 308 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0019
   Val:   Loss=0.0909, RMSE=0.3015, R²=0.0053
============================================================


📊 Round 308 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

============================================================
🔄 Round 310 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 310 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0024
   Val:   Loss=0.0924, RMSE=0.3040, R²=-0.0008
============================================================


📊 Round 310 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

============================================================
🔄 Round 312 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 312 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0017
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0078
============================================================


📊 Round 312 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

============================================================
🔄 Round 313 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 313 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=0.0024
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0022
============================================================


📊 Round 313 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

📊 Round 313 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

============================================================
🔄 Round 319 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 319 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=0.0010
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0012
============================================================


============================================================
🔄 Round 320 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 320 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0014
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0020
============================================================


📊 Round 320 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

============================================================
🔄 Round 321 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 321 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2974, R²=0.0039
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0032
============================================================


📊 Round 321 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

📊 Round 321 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

📊 Round 321 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

============================================================
🔄 Round 326 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 326 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0050
   Val:   Loss=0.0939, RMSE=0.3065, R²=-0.0259
============================================================


📊 Round 326 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

============================================================
🔄 Round 327 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 327 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2949, R²=0.0012
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0051
============================================================


============================================================
🔄 Round 328 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 328 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=0.0045
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0077
============================================================


============================================================
🔄 Round 329 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 329 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=0.0036
   Val:   Loss=0.0851, RMSE=0.2918, R²=-0.0558
============================================================


📊 Round 329 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0003

============================================================
🔄 Round 331 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 331 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0035
   Val:   Loss=0.0923, RMSE=0.3039, R²=-0.0020
============================================================


============================================================
🔄 Round 333 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 333 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=0.0027
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0028
============================================================


📊 Round 333 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0003

============================================================
🔄 Round 334 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.1009 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.1009, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.1009, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.1009, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.1009, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.1009, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1009)

============================================================
📊 Round 334 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0022
   Val:   Loss=0.1009, RMSE=0.3177, R²=0.0017
============================================================


📊 Round 334 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0003

============================================================
🔄 Round 335 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 335 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=0.0007
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0140
============================================================


📊 Round 335 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0003

📊 Round 335 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0003

============================================================
🔄 Round 338 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 338 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0016
   Val:   Loss=0.0909, RMSE=0.3014, R²=-0.0018
============================================================


📊 Round 338 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0003

============================================================
🔄 Round 341 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 341 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0035
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0081
============================================================


📊 Round 341 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0003

============================================================
🔄 Round 342 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 342 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0018
   Val:   Loss=0.0916, RMSE=0.3027, R²=0.0016
============================================================


============================================================
🔄 Round 344 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 344 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=0.0021
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0021
============================================================


============================================================
🔄 Round 346 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 346 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2969, R²=0.0020
   Val:   Loss=0.0792, RMSE=0.2815, R²=0.0048
============================================================


📊 Round 346 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0003

============================================================
🔄 Round 349 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 349 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=0.0028
   Val:   Loss=0.0873, RMSE=0.2955, R²=0.0027
============================================================


============================================================
🔄 Round 350 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 350 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0017
   Val:   Loss=0.0881, RMSE=0.2968, R²=0.0035
============================================================


📊 Round 350 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0003

📊 Round 350 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0003

============================================================
🔄 Round 352 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 352 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=0.0034
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0002
============================================================


📊 Round 352 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0003

📊 Round 352 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0003

📊 Round 352 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0003

📊 Round 352 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

============================================================
🔄 Round 359 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 359 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0026
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0029
============================================================


============================================================
🔄 Round 360 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 360 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2969, R²=0.0022
   Val:   Loss=0.0793, RMSE=0.2817, R²=-0.0067
============================================================


============================================================
🔄 Round 361 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 361 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2964, R²=0.0017
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0037
============================================================


📊 Round 361 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

📊 Round 361 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0003

============================================================
🔄 Round 365 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 365 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=0.0041
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0186
============================================================


============================================================
🔄 Round 367 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 367 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=0.0045
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0119
============================================================


📊 Round 367 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

📊 Round 367 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0003

============================================================
🔄 Round 369 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 369 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=0.0025
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0097
============================================================


============================================================
🔄 Round 373 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 373 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0022
   Val:   Loss=0.0920, RMSE=0.3033, R²=0.0018
============================================================


📊 Round 373 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0003

📊 Round 373 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

📊 Round 373 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

📊 Round 373 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

============================================================
🔄 Round 379 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 379 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0015
   Val:   Loss=0.0872, RMSE=0.2953, R²=0.0057
============================================================


📊 Round 379 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

============================================================
🔄 Round 380 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 380 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0018
   Val:   Loss=0.0889, RMSE=0.2982, R²=0.0056
============================================================


============================================================
🔄 Round 381 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 381 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0021
   Val:   Loss=0.0895, RMSE=0.2992, R²=0.0018
============================================================


📊 Round 381 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

============================================================
🔄 Round 382 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 382 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0052
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0082
============================================================


📊 Round 382 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0004

📊 Round 382 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0003

📊 Round 382 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0003

📊 Round 382 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0003

📊 Round 382 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0003

📊 Round 382 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0003

📊 Round 382 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0003

============================================================
🔄 Round 391 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 391 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=0.0022
   Val:   Loss=0.0801, RMSE=0.2829, R²=0.0043
============================================================


📊 Round 391 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0003

============================================================
🔄 Round 394 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0960 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0960, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0960, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0960, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0960, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0961, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0960)

============================================================
📊 Round 394 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0041
   Val:   Loss=0.0960, RMSE=0.3099, R²=-0.0245
============================================================


📊 Round 394 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0003

📊 Round 394 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0004

============================================================
🔄 Round 398 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 398 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=0.0034
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0009
============================================================


============================================================
🔄 Round 399 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 399 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0013
   Val:   Loss=0.0856, RMSE=0.2925, R²=0.0083
============================================================


📊 Round 399 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0003

============================================================
🔄 Round 400 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 400 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=0.0017
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0061
============================================================


📊 Round 400 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

============================================================
🔄 Round 402 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 402 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=0.0038
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0063
============================================================


📊 Round 402 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0004

📊 Round 402 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0003

============================================================
🔄 Round 410 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 410 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2967, R²=0.0004
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0118
============================================================


📊 Round 410 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

============================================================
🔄 Round 411 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 411 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=0.0025
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0038
============================================================


📊 Round 411 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

📊 Round 411 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

============================================================
🔄 Round 413 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 413 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2977, R²=0.0033
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0024
============================================================


📊 Round 413 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

============================================================
🔄 Round 417 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 417 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=0.0029
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0006
============================================================


📊 Round 417 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

============================================================
🔄 Round 419 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0943 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0943, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0943, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0943, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0943, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0944, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0943)

============================================================
📊 Round 419 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0037
   Val:   Loss=0.0943, RMSE=0.3071, R²=-0.0210
============================================================


============================================================
🔄 Round 420 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 420 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=0.0030
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0000
============================================================


📊 Round 420 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

============================================================
🔄 Round 421 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 421 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0019
   Val:   Loss=0.0872, RMSE=0.2952, R²=0.0059
============================================================


📊 Round 421 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

============================================================
🔄 Round 425 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 425 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=0.0007
   Val:   Loss=0.0902, RMSE=0.3003, R²=0.0100
============================================================


📊 Round 425 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

📊 Round 425 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

============================================================
🔄 Round 427 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 427 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0021
   Val:   Loss=0.0911, RMSE=0.3019, R²=-0.0003
============================================================


============================================================
🔄 Round 428 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.1023 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.1023, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.1023, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.1023, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.1023, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.1023, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1023)

============================================================
📊 Round 428 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0033
   Val:   Loss=0.1023, RMSE=0.3198, R²=0.0007
============================================================


📊 Round 428 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

📊 Round 428 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

============================================================
🔄 Round 435 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 435 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0010
   Val:   Loss=0.0936, RMSE=0.3059, R²=-0.0095
============================================================


============================================================
🔄 Round 436 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 436 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0027
   Val:   Loss=0.0912, RMSE=0.3020, R²=0.0028
============================================================


📊 Round 436 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

📊 Round 436 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

============================================================
🔄 Round 441 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 441 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=0.0016
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0046
============================================================


📊 Round 441 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

============================================================
🔄 Round 442 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0898, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 442 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2994, R²=0.0025
   Val:   Loss=0.0734, RMSE=0.2709, R²=0.0032
============================================================


============================================================
🔄 Round 444 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 444 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0025
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0084
============================================================


📊 Round 444 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

📊 Round 444 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

============================================================
🔄 Round 449 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 449 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2974, R²=0.0003
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0078
============================================================


📊 Round 449 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

📊 Round 449 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

============================================================
🔄 Round 451 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 451 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0035
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0009
============================================================


📊 Round 451 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

============================================================
🔄 Round 454 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 454 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=0.0030
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0004
============================================================


============================================================
🔄 Round 455 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 455 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=0.0006
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0111
============================================================


📊 Round 455 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

============================================================
🔄 Round 458 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 458 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0026
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0051
============================================================


📊 Round 458 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

============================================================
🔄 Round 459 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 459 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=0.0022
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0030
============================================================


============================================================
🔄 Round 460 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 460 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0028
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0049
============================================================


📊 Round 460 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

============================================================
🔄 Round 463 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 463 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2986, R²=-0.0003
   Val:   Loss=0.0753, RMSE=0.2745, R²=-0.0015
============================================================


📊 Round 463 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

📊 Round 463 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

📊 Round 463 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

📊 Round 463 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

============================================================
🔄 Round 472 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 472 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=0.0023
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0165
============================================================


📊 Round 472 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

============================================================
🔄 Round 474 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 474 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0048
   Val:   Loss=0.0848, RMSE=0.2913, R²=-0.0072
============================================================


============================================================
🔄 Round 478 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 478 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=0.0012
   Val:   Loss=0.0899, RMSE=0.2998, R²=0.0009
============================================================


============================================================
🔄 Round 479 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 479 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=0.0019
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0039
============================================================


============================================================
🔄 Round 480 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 480 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2933, R²=0.0023
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0027
============================================================


📊 Round 480 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

============================================================
🔄 Round 483 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 483 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=0.0013
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0056
============================================================


📊 Round 483 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

📊 Round 483 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

============================================================
🔄 Round 485 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 485 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=0.0039
   Val:   Loss=0.0789, RMSE=0.2810, R²=-0.0112
============================================================


📊 Round 485 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

============================================================
🔄 Round 488 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 488 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=0.0019
   Val:   Loss=0.0886, RMSE=0.2977, R²=0.0056
============================================================


📊 Round 488 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

============================================================
🔄 Round 492 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 492 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0025
   Val:   Loss=0.0867, RMSE=0.2945, R²=0.0036
============================================================


📊 Round 492 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

============================================================
🔄 Round 495 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 495 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=0.0015
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0064
============================================================


============================================================
🔄 Round 496 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0953 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0953, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0953, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0953, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0953, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0953, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0953)

============================================================
📊 Round 496 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0056
   Val:   Loss=0.0953, RMSE=0.3088, R²=-0.0096
============================================================


📊 Round 496 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

📊 Round 496 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

📊 Round 496 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

============================================================
🔄 Round 500 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 500 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0038
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0028
============================================================


============================================================
🔄 Round 501 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 501 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=0.0013
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0086
============================================================


============================================================
🔄 Round 505 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 505 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0044
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0047
============================================================


📊 Round 505 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

============================================================
🔄 Round 506 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 506 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0000
   Val:   Loss=0.0914, RMSE=0.3024, R²=0.0104
============================================================


📊 Round 506 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

📊 Round 506 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

📊 Round 506 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

📊 Round 506 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

📊 Round 506 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

============================================================
🔄 Round 512 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 512 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0025
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0122
============================================================


============================================================
🔄 Round 515 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 515 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=0.0043
   Val:   Loss=0.0898, RMSE=0.2997, R²=-0.0031
============================================================


📊 Round 515 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

============================================================
🔄 Round 517 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 517 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2954, R²=0.0014
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0015
============================================================


============================================================
🔄 Round 519 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 519 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=0.0040
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0060
============================================================


============================================================
🔄 Round 520 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 520 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=0.0024
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0016
============================================================


============================================================
🔄 Round 521 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 521 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=-0.0005
   Val:   Loss=0.0930, RMSE=0.3049, R²=-0.0028
============================================================


============================================================
🔄 Round 525 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 525 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0004
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0043
============================================================


============================================================
🔄 Round 526 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 526 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0027
   Val:   Loss=0.0882, RMSE=0.2969, R²=0.0013
============================================================


============================================================
🔄 Round 527 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 527 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0017
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0010
============================================================


📊 Round 527 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

============================================================
🔄 Round 528 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 528 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0033
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0004
============================================================


📊 Round 528 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

📊 Round 528 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0004

============================================================
🔄 Round 530 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 530 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0021
   Val:   Loss=0.0924, RMSE=0.3039, R²=0.0029
============================================================


📊 Round 530 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0004

============================================================
🔄 Round 533 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 533 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0003
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0105
============================================================


📊 Round 533 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

============================================================
🔄 Round 537 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 537 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0031
   Val:   Loss=0.0891, RMSE=0.2985, R²=0.0013
============================================================


📊 Round 537 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0004

============================================================
🔄 Round 540 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 540 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=0.0029
   Val:   Loss=0.0825, RMSE=0.2871, R²=0.0023
============================================================


📊 Round 540 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0004

============================================================
🔄 Round 542 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 542 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=0.0035
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0081
============================================================


📊 Round 542 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0004

============================================================
🔄 Round 543 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 543 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0007
   Val:   Loss=0.0860, RMSE=0.2932, R²=0.0047
============================================================


📊 Round 543 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0004

============================================================
🔄 Round 545 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 545 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0013
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0067
============================================================


============================================================
🔄 Round 547 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 547 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=0.0016
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0074
============================================================


📊 Round 547 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0004

📊 Round 547 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0004

📊 Round 547 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0004

📊 Round 547 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0004

============================================================
🔄 Round 552 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 552 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=0.0037
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0374
============================================================


📊 Round 552 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0004

📊 Round 552 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0004

============================================================
🔄 Round 554 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 554 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0030
   Val:   Loss=0.0906, RMSE=0.3010, R²=-0.0011
============================================================


============================================================
🔄 Round 555 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 555 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2994, R²=0.0026
   Val:   Loss=0.0735, RMSE=0.2711, R²=-0.0062
============================================================


📊 Round 555 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0004

============================================================
🔄 Round 556 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 556 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0026
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0008
============================================================


📊 Round 556 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0004

📊 Round 556 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0004

============================================================
🔄 Round 559 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 559 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=0.0031
   Val:   Loss=0.0814, RMSE=0.2854, R²=0.0005
============================================================


============================================================
🔄 Round 560 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 560 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=0.0013
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0075
============================================================


📊 Round 560 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0004

============================================================
🔄 Round 561 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 561 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0029
   Val:   Loss=0.0912, RMSE=0.3020, R²=0.0026
============================================================


============================================================
🔄 Round 564 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 564 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2994, R²=0.0007
   Val:   Loss=0.0733, RMSE=0.2708, R²=0.0032
============================================================


============================================================
🔄 Round 566 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 566 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=0.0025
   Val:   Loss=0.0851, RMSE=0.2916, R²=0.0003
============================================================


📊 Round 566 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0004

============================================================
🔄 Round 568 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 568 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=0.0037
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0008
============================================================


📊 Round 568 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0004

============================================================
🔄 Round 569 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 569 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0017
   Val:   Loss=0.0922, RMSE=0.3036, R²=0.0067
============================================================


============================================================
🔄 Round 570 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 570 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0041
   Val:   Loss=0.0889, RMSE=0.2981, R²=-0.0021
============================================================


📊 Round 570 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0004

📊 Round 570 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0004

============================================================
🔄 Round 576 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 576 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=0.0016
   Val:   Loss=0.0822, RMSE=0.2866, R²=-0.0054
============================================================


📊 Round 576 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0004

📊 Round 576 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0004

============================================================
🔄 Round 580 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 580 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=0.0021
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0044
============================================================


📊 Round 580 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0004

============================================================
🔄 Round 581 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 581 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=0.0012
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0016
============================================================


============================================================
🔄 Round 586 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0935 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0935, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0935, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 586 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0042
   Val:   Loss=0.0935, RMSE=0.3058, R²=-0.0082
============================================================


============================================================
🔄 Round 587 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 587 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0034
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0012
============================================================


📊 Round 587 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0004

📊 Round 587 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0004

============================================================
🔄 Round 591 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 591 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0024
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0049
============================================================


📊 Round 591 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0004

📊 Round 591 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0004

📊 Round 591 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0004

============================================================
🔄 Round 595 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 595 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=0.0024
   Val:   Loss=0.0898, RMSE=0.2996, R²=0.0049
============================================================


📊 Round 595 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0004

📊 Round 595 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0004

============================================================
🔄 Round 597 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 597 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=0.0031
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0020
============================================================


📊 Round 597 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0004

============================================================
🔄 Round 601 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 601 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0010
   Val:   Loss=0.0905, RMSE=0.3009, R²=0.0073
============================================================


📊 Round 601 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0004

📊 Round 601 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0004

============================================================
🔄 Round 604 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 604 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=0.0035
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0004
============================================================


============================================================
🔄 Round 605 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 605 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=0.0009
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0017
============================================================


📊 Round 605 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0004

📊 Round 605 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0004

============================================================
🔄 Round 609 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 609 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0028
   Val:   Loss=0.0906, RMSE=0.3009, R²=0.0031
============================================================


📊 Round 609 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0004

📊 Round 609 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0004

============================================================
🔄 Round 613 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 613 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2928, R²=0.0038
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0008
============================================================


============================================================
🔄 Round 614 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 614 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=0.0045
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0183
============================================================


📊 Round 614 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0004

============================================================
🔄 Round 615 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 615 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0042
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0028
============================================================


📊 Round 615 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0004

============================================================
🔄 Round 617 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0949 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0949, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0949, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0949, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0949, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0949, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0949)

============================================================
📊 Round 617 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0023
   Val:   Loss=0.0949, RMSE=0.3081, R²=0.0035
============================================================


============================================================
🔄 Round 618 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 618 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0025
   Val:   Loss=0.0917, RMSE=0.3027, R²=0.0043
============================================================


📊 Round 618 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0004

============================================================
🔄 Round 620 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 620 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=0.0027
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0032
============================================================


📊 Round 620 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0004

📊 Round 620 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0004

📊 Round 620 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0004

============================================================
🔄 Round 626 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 626 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=0.0008
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0017
============================================================


============================================================
🔄 Round 627 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 627 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0047
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0065
============================================================


============================================================
🔄 Round 629 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 629 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0015
   Val:   Loss=0.0915, RMSE=0.3025, R²=0.0079
============================================================


============================================================
🔄 Round 630 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 630 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=0.0022
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0050
============================================================


📊 Round 630 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0004

============================================================
🔄 Round 632 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0944 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0944, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0945, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0947, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0944)

============================================================
📊 Round 632 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0003
   Val:   Loss=0.0944, RMSE=0.3072, R²=-0.0204
============================================================


📊 Round 632 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0004

============================================================
🔄 Round 633 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 633 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=0.0012
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0063
============================================================


📊 Round 633 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0004

📊 Round 633 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0004

============================================================
🔄 Round 635 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 635 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=0.0041
   Val:   Loss=0.0885, RMSE=0.2974, R²=-0.0020
============================================================


============================================================
🔄 Round 636 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 636 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=0.0026
   Val:   Loss=0.0811, RMSE=0.2849, R²=-0.0013
============================================================


============================================================
🔄 Round 638 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 638 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=0.0035
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0040
============================================================


📊 Round 638 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0004

📊 Round 638 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

📊 Round 638 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

📊 Round 638 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

============================================================
🔄 Round 647 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 647 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0023
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0040
============================================================


📊 Round 647 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

============================================================
🔄 Round 650 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 650 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0036
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0200
============================================================


📊 Round 650 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

============================================================
🔄 Round 653 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 653 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0024
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0014
============================================================


📊 Round 653 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

============================================================
🔄 Round 655 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 655 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0026
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0020
============================================================


============================================================
🔄 Round 656 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 656 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=0.0007
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0072
============================================================


============================================================
🔄 Round 658 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 658 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2993, R²=0.0029
   Val:   Loss=0.0735, RMSE=0.2712, R²=-0.0078
============================================================


📊 Round 658 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

============================================================
🔄 Round 660 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 660 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0002
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0053
============================================================


📊 Round 660 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

============================================================
🔄 Round 661 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 661 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=0.0026
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0037
============================================================


📊 Round 661 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

============================================================
🔄 Round 664 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 664 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0026
   Val:   Loss=0.0905, RMSE=0.3008, R²=0.0017
============================================================


============================================================
🔄 Round 667 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 667 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2989, R²=0.0022
   Val:   Loss=0.0746, RMSE=0.2732, R²=0.0035
============================================================


📊 Round 667 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

============================================================
🔄 Round 669 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 669 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2949, R²=0.0004
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0069
============================================================


📊 Round 669 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

============================================================
🔄 Round 670 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 670 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0039
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0293
============================================================


📊 Round 670 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

============================================================
🔄 Round 672 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 672 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0015
   Val:   Loss=0.0866, RMSE=0.2942, R²=0.0055
============================================================


============================================================
🔄 Round 673 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 673 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0016
   Val:   Loss=0.0897, RMSE=0.2996, R²=-0.0174
============================================================


📊 Round 673 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

📊 Round 673 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

============================================================
🔄 Round 677 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0944 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0944, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0944, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0944, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0944, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0944, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0944)

============================================================
📊 Round 677 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0051
   Val:   Loss=0.0944, RMSE=0.3073, R²=-0.0099
============================================================


============================================================
🔄 Round 678 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 678 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0024
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0060
============================================================


============================================================
🔄 Round 679 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0943 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0943, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0943, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0943, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0943, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0943, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0943)

============================================================
📊 Round 679 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0029
   Val:   Loss=0.0943, RMSE=0.3070, R²=0.0022
============================================================


📊 Round 679 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

============================================================
🔄 Round 681 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 681 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0023
   Val:   Loss=0.0900, RMSE=0.2999, R²=-0.0030
============================================================


============================================================
🔄 Round 682 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0948 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0948, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0948, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0948, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0948, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0948, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0948)

============================================================
📊 Round 682 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0022
   Val:   Loss=0.0948, RMSE=0.3078, R²=0.0032
============================================================


📊 Round 682 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

============================================================
🔄 Round 686 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 686 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0040
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0102
============================================================


============================================================
🔄 Round 687 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 687 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2933, R²=0.0043
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0049
============================================================


============================================================
🔄 Round 689 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 689 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=0.0027
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0003
============================================================


📊 Round 689 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

============================================================
🔄 Round 692 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 692 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0037
   Val:   Loss=0.0926, RMSE=0.3043, R²=-0.0063
============================================================


📊 Round 692 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

============================================================
🔄 Round 698 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 698 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0024
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0020
============================================================


📊 Round 698 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

============================================================
🔄 Round 699 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 699 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0032
   Val:   Loss=0.0860, RMSE=0.2932, R²=0.0002
============================================================


📊 Round 699 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

============================================================
🔄 Round 700 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 700 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0038
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0016
============================================================


============================================================
🔄 Round 701 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 701 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=0.0026
   Val:   Loss=0.0850, RMSE=0.2916, R²=0.0028
============================================================


============================================================
🔄 Round 702 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 702 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0030
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0359
============================================================


============================================================
🔄 Round 704 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 704 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2949, R²=0.0040
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0019
============================================================


============================================================
🔄 Round 705 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 705 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0021
   Val:   Loss=0.0892, RMSE=0.2986, R²=0.0055
============================================================


============================================================
🔄 Round 706 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 706 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=0.0021
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0058
============================================================


============================================================
🔄 Round 707 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 707 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=0.0023
   Val:   Loss=0.0869, RMSE=0.2949, R²=0.0035
============================================================


============================================================
🔄 Round 708 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 708 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2972, R²=0.0025
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0004
============================================================


📊 Round 708 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

📊 Round 708 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

============================================================
🔄 Round 711 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 711 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2986, R²=0.0020
   Val:   Loss=0.0753, RMSE=0.2745, R²=0.0053
============================================================


📊 Round 711 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

📊 Round 711 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

============================================================
🔄 Round 713 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 713 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0018
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0068
============================================================


📊 Round 713 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

============================================================
🔄 Round 714 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 714 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=0.0021
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0225
============================================================


📊 Round 714 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

============================================================
🔄 Round 716 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 716 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=0.0021
   Val:   Loss=0.0901, RMSE=0.3002, R²=0.0032
============================================================


📊 Round 716 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

============================================================
🔄 Round 721 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 721 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=0.0020
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0077
============================================================


============================================================
🔄 Round 722 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 722 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=0.0025
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0164
============================================================


📊 Round 722 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

📊 Round 722 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

============================================================
🔄 Round 724 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 724 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0038
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0022
============================================================


📊 Round 724 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

============================================================
🔄 Round 725 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 725 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0026
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0021
============================================================


📊 Round 725 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

📊 Round 725 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

📊 Round 725 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

============================================================
🔄 Round 729 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 729 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=0.0032
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0077
============================================================


============================================================
🔄 Round 731 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 731 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2983, R²=0.0029
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0022
============================================================


📊 Round 731 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

============================================================
🔄 Round 734 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 734 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0039
   Val:   Loss=0.0909, RMSE=0.3016, R²=-0.0071
============================================================


📊 Round 734 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

============================================================
🔄 Round 735 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 735 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0036
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0004
============================================================


============================================================
🔄 Round 738 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 738 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0012
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0026
============================================================


============================================================
🔄 Round 740 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 740 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2932, R²=0.0020
   Val:   Loss=0.0882, RMSE=0.2970, R²=0.0063
============================================================


📊 Round 740 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

📊 Round 740 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

📊 Round 740 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

============================================================
🔄 Round 746 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 746 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0036
   Val:   Loss=0.0881, RMSE=0.2969, R²=-0.0004
============================================================


📊 Round 746 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0006

📊 Round 746 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0006

============================================================
🔄 Round 750 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0902, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 750 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0901, RMSE=0.3002, R²=-0.0001
   Val:   Loss=0.0714, RMSE=0.2673, R²=0.0036
============================================================


📊 Round 750 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

📊 Round 750 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0006

📊 Round 750 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0006

============================================================
🔄 Round 755 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 755 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=0.0041
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0031
============================================================


📊 Round 755 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0006

============================================================
🔄 Round 756 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 756 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0018
   Val:   Loss=0.0877, RMSE=0.2962, R²=0.0057
============================================================


📊 Round 756 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

📊 Round 756 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0006

📊 Round 756 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0006

============================================================
🔄 Round 761 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0943 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0943, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0943, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0943, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0943, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0944, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0943)

============================================================
📊 Round 761 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0040
   Val:   Loss=0.0943, RMSE=0.3071, R²=-0.0310
============================================================


📊 Round 761 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0006

============================================================
🔄 Round 762 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 762 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=0.0010
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0107
============================================================


============================================================
🔄 Round 763 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 763 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0040
   Val:   Loss=0.0875, RMSE=0.2959, R²=-0.0074
============================================================


📊 Round 763 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0006

============================================================
🔄 Round 767 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 767 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2969, R²=0.0042
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0048
============================================================


📊 Round 767 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0006

============================================================
🔄 Round 768 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 768 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0023
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0061
============================================================


📊 Round 768 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0006

============================================================
🔄 Round 770 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 770 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0032
   Val:   Loss=0.0885, RMSE=0.2974, R²=-0.0006
============================================================


============================================================
🔄 Round 771 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 771 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0029
   Val:   Loss=0.0897, RMSE=0.2995, R²=0.0008
============================================================


📊 Round 771 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0006

============================================================
🔄 Round 772 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 772 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=0.0040
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0117
============================================================


📊 Round 772 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0006

============================================================
🔄 Round 774 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0957 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0957, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0957, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0957, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0957, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0957, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0957)

============================================================
📊 Round 774 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0029
   Val:   Loss=0.0957, RMSE=0.3093, R²=0.0017
============================================================


============================================================
🔄 Round 775 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 775 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0034
   Val:   Loss=0.0915, RMSE=0.3024, R²=-0.0126
============================================================


📊 Round 775 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0006

============================================================
🔄 Round 776 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 776 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=0.0022
   Val:   Loss=0.0858, RMSE=0.2930, R²=0.0014
============================================================


============================================================
🔄 Round 777 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 777 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=0.0022
   Val:   Loss=0.0823, RMSE=0.2870, R²=0.0044
============================================================


============================================================
🔄 Round 780 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 780 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0011
   Val:   Loss=0.0925, RMSE=0.3042, R²=0.0077
============================================================


📊 Round 780 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0006

============================================================
🔄 Round 781 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 781 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=0.0016
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0068
============================================================


📊 Round 781 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0006

📊 Round 781 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0006

============================================================
🔄 Round 785 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0938, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 785 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0012
   Val:   Loss=0.0937, RMSE=0.3062, R²=-0.0050
============================================================


============================================================
🔄 Round 786 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 786 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=0.0016
   Val:   Loss=0.0859, RMSE=0.2930, R²=0.0062
============================================================


📊 Round 786 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0006

📊 Round 786 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0006

📊 Round 786 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0006

📊 Round 786 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 793 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 793 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0037
   Val:   Loss=0.0893, RMSE=0.2989, R²=-0.0325
============================================================


📊 Round 793 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 797 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 797 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=0.0027
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0034
============================================================


============================================================
🔄 Round 798 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0958 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0958, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0958, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0958, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0958, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0958, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0958)

============================================================
📊 Round 798 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0035
   Val:   Loss=0.0958, RMSE=0.3095, R²=-0.0016
============================================================


============================================================
🔄 Round 799 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 799 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=0.0020
   Val:   Loss=0.0853, RMSE=0.2920, R²=0.0021
============================================================


============================================================
🔄 Round 801 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 801 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=0.0038
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0015
============================================================


📊 Round 801 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0007

📊 Round 801 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 805 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 805 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=0.0033
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0005
============================================================


📊 Round 805 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 807 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0945 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0945, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0945, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0945, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0945)

============================================================
📊 Round 807 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0038
   Val:   Loss=0.0945, RMSE=0.3075, R²=-0.0121
============================================================


============================================================
🔄 Round 808 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 808 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=0.0005
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0068
============================================================


❌ Client client_20 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_status:14, grpc_message:"Socket closed"}"
>
