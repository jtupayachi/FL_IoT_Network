[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7a3e3a6-19e5-4e00-ac01-04537325818c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27cf3dc7-d203-4372-90da-095ad0d6beea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d83511d-f0ea-4c61-b419-231b705b1547
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c32516f-5c2d-4d67-b4ab-fad0f5b6a33f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e1dad60-8dd4-4337-a1cf-9cc5f79c220e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86e67760-0ba4-40f9-9114-ad3aba00cb12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0862a977-6cf7-441a-869a-03ec0045320e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f27da96-c904-4cfd-b325-36da97e3295f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 375142b4-58f3-471b-af7a-c91bee9960fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee7d2872-4319-4540-8c4b-85127e1bcbe3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8244928d-1593-44a8-ad5d-a2a7ba45090d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8f4e597-3a57-4a19-998c-a945a1b28fd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dad69bc9-7b04-4502-9cb4-faa704a7d3fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbdc8f18-70bb-4dc6-8f40-f4e2e831c377
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ec6a120-3cb1-4754-8d22-6e079ca6f63d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52142d53-e145-4bab-b1c4-780715f513c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b2d4a87-8141-4be3-b7a5-b31d3bdb301a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb7ee916-64d9-40e0-8efe-08679bd0cd13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54aef076-acfd-4028-8bef-57929c246a0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26d29d83-3b2d-4ffa-ba71-fe2e593955a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1c3f959-82fe-444d-bbcf-5ced68b59394
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 536ef4ec-0b9a-4f75-87b5-3eac16df82ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c527ae4b-5d8b-46ba-b1ee-dc1277ddcdce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89749935-9ee6-4891-84de-84860651f826
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 660a4c1f-2acf-408d-a154-737ba7223948
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message babdf4c9-c220-4046-acfb-5277931abc86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77c52c03-45fa-46d4-9738-9c81b51fd0b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65f3733c-c2d6-43cc-b98d-9839761340ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fb176dc-79a9-4633-8f8c-99c9f7284990
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca7fb9f4-ce80-494d-b205-69b3a2159ee0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae6b5998-4055-4b47-8be6-ddd6831174b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f403d028-0033-488a-9978-4bab21e3dd03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 931ad033-8b71-44e1-a94d-c37ba9cdb9f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50914e36-679b-498e-ac0d-c55c8d559ed3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18a86454-939e-490c-8fd0-e7f6a0c77db6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b156cd0-18b8-4769-a37c-2e66f17b8ad7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36b59e1c-d150-482b-9154-8ea6c7b51169
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9f1eb9e-19f1-4341-b86e-1b756d64f93e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 699264fe-55f1-4dd8-b7d5-3a4beeda8aa0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f3dcf5b-c30e-48e1-9cd0-c8cf770a2380
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec0f8395-fa24-427f-8a1f-0bedd8eec1ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 487c6f4e-ece7-4555-bf0b-fc814364b690
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5089158-1185-4f25-8bfd-115bb5f6f8bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13f153ad-1b8e-4361-a660-a2131fd09307
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6519caa8-151e-4832-adf4-4ba95de6ba2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80c2870c-02ea-43bc-87cc-60e112fc9f8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf0566cf-2a81-4ac9-8dd3-1b0ac431ca59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 111b3dfe-fc3a-4943-879c-dea61a74529c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 433d25e5-40b1-4f03-a21a-e75ec20fbd9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da433c08-cbe7-4f32-bdab-edb012a4d7c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0579ade4-c743-4006-aad4-e348c59fac2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f34ddcf9-1b45-4028-9a39-29a0fa406db9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11bb56f6-54b6-41ce-8bd7-80a5bc0884ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72f580af-2518-4bc9-99e6-3713658c0d6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4fc91e6-36fd-46ae-abef-5ee930b61996
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9634fd06-ff09-47fc-b041-5330a966f1e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8b6e86a-1068-4d17-8da8-44af192ebad9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80b7201d-a1f5-41a2-b8ee-f74b86a90854
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8334d801-22d2-493d-8beb-a54c43966d9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd04a275-6a94-4014-8ca8-817e4712c15b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14e785ce-21d2-4383-9c59-7c2fd4dc1cd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bbbea69-a3ed-4692-a9f4-922f9aaad704
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c49f5574-c475-48dd-b8ba-ceb69df4ad43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6523c4fc-db9a-4463-9269-9754dc31ba19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f02f22f7-e49a-4c80-ac2f-4a15df7d0ba1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7df8b943-a058-409b-bb17-b501607a402e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c56446e-87c1-4b61-8fee-8b576ce5b64f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1daa6064-ea18-4b83-a558-34f2d2d58b1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0323af1-2f34-469f-83ae-a84c491786a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df52696d-852f-456d-a913-8cb67cf9287f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09023025-0c65-4049-9f5e-4cdd83055a6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf6f17ea-5635-4a6f-b76d-ab480d08bb0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e175073b-5c50-4359-9ab9-e04a7285328a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17a4c613-ef1f-48ca-81c9-3fee0256f627
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c12eb784-e96f-43c8-a520-1cc19b2e27d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91454007-731f-452c-932e-4c0f5f62176b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 142a1771-81cc-4120-8b3e-5895c2e7e0e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ccf890c-713f-46d0-99d5-df74a9e314a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 022e966c-2dfa-4500-804a-8fd2706a80a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fff432a-b2cf-4f51-8882-edd48b7ec843
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93ee09a9-769f-4aa8-aac7-ac82456e427a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4682a123-51e1-4755-9342-7c7853b517ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 917ab640-1fcd-4403-bff1-11932cd6d5ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3832e7de-6af0-4025-b674-f0450ffcee17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd3db135-e977-447a-8679-7aa81530740b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e806f6d3-51a2-4c3d-9e70-4355ba922d2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 138e41a1-4ba9-4ad5-8fd5-c3d715a644d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b95fdba-aa7d-4a88-9295-232e43920bdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f45bad1-6bfd-446b-874d-4f58226b33f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88dc4c51-6e8d-4466-a019-93f917c8ebe5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62d3459a-330d-462c-9a04-194640a7de76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 667f1434-be79-4c45-b2a2-9b8604dc75fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a77df5f6-6119-47ef-9273-e986c690839d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a18c523-93d5-4973-ab95-2a380b431600
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c24104e4-c5f0-4897-b3cd-b91c194c8866
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8512ebce-9042-4dc2-b371-5b5db035aa69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fe46f79-3489-467a-957f-7b080d947249
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fff2d842-68b0-4d31-bca7-b9e5ede18bbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message feef2fc9-0fe4-47b6-bdcb-07d3cb7c7c85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e75e742-2746-4f63-871f-7c2e6deecd73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bf4c022-3059-4d6f-b7fe-b19cc469d378
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec1f76c6-1ffc-4322-ad25-5b09d27b68a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e606d44-bc3b-4479-9a08-064e6f70453f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d0f7fd5-8ace-411c-b1a8-24d04e750113
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c752b18-9292-4fd2-b4a0-1d4651e6a309
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fe83b71-4806-4732-9356-0e17d69ba626
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86ae41e5-e27e-478c-9a62-855e0735a42c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 151bbf72-c8dc-4c5b-8a92-e2b3ac43a1f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcaac0b1-cbfc-4780-a214-355b7cdd1290
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d68275e6-ec33-409b-a62b-4654923b655a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32a87129-db79-40f7-8230-398456b74fc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f04ef5d6-79d8-4e2e-8cdc-b9c093a83cb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b3e96eb-373f-4fb5-8a79-ad7df0b0bbc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9601773a-ec97-4d11-bb5e-7ee0fb720aaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f192f543-e07e-47fb-baf6-cbd28df583a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e56e393-b116-4a1e-9d11-74a6bbb523ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ebdbac6-f11e-4c60-8e96-14611c04bd8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ba7921d-2939-4340-b8d2-a61f8536518b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3c1ad3a-1bd7-4850-af92-07f881c6d4d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef887e4e-d33a-4e79-8f88-da5d49ced88f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2da0e91-7459-4945-927b-943aed1a6579
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8eb0fb87-367d-4f8c-ba3f-f39205afe6ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffba3f09-ab3d-4154-b796-26c185d2a11f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 394a25c9-afea-4fda-836e-05f17061033c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b603e0b6-757f-49a7-89c8-38890d6bbee3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecd775f9-92ba-4f1d-a73b-7acc43f137f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c15aca7-ca07-434e-8e53-274567b8f110
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e957357e-cca5-400e-9623-ea3b2fa2e1d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06a58e10-7899-40b3-a267-144ee3dffd2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8347ad89-afa4-4c2d-9479-6ce628d60af6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fd7446d-7dad-4302-90fe-13164f7fbc2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8c98cfc-c5f6-4d3f-afc6-0c33c4bad19c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5136a8d-3d3e-4698-86fb-1d11183ecd04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfc219a0-7ff3-4556-a5f0-09155c12f64b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5535afaf-0100-4d06-abb7-9e437c3cdfb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f4c7073-7c29-4779-a4cf-5c303ee86d4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 388ad119-4c0a-4acd-ae9e-d154943982b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f355122-18b8-452a-9601-90e1eee2c8ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d467bc20-678a-445f-be1b-25642db2782b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e4fc52d-9636-4c17-89a3-a241361fc68a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message deeac28f-b476-403a-890e-a48db80a4868
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfb919b1-9ae9-41ad-be44-6e440acf6fbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36794628-2a42-4c56-a346-dbb1e39d0d86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b573f831-2ea3-4d28-a7b3-91061e9474c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 522f4ce8-13cd-4aac-a34f-5e5c9087b1c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad6bd4f2-95b0-4e71-85f3-1257c340092c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd474884-ff9e-4643-aaef-31e939ea13cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 812845e1-27a1-4b5a-a280-844288996532
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85bc8573-fe27-435c-8633-65db1d874f93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d9b6511-2d2a-4450-a684-b9505f58714c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb6b0a39-af9e-41c1-976f-f9c1ebb95da3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 983f36f9-d9d6-45d2-9de8-cbb8a57a48d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c75cb703-8904-4b1d-959d-9ed758b73905
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 320a7a45-0d8b-4873-8622-1bf13b8dc819
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1ef1d71-c486-45e0-b049-39f62b19fdb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0039af6-3841-4b70-ad1b-6504586bf5fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 370dd8fa-bd59-44b5-bf51-8e4b8aa3e353
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcecdc34-9b6c-4632-b08b-9c8e8d11d51e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0d3cba5-e9b7-46e1-9c04-f6a5d9285793
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25b74878-f04d-48b6-9f56-f7d3125f6ff7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f04125a-6fc6-492b-a3d5-18f90d3f3244
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a09c0f0f-bc6b-494d-8082-aa5dd426c760
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f038123-1ffc-4f52-9267-376128910897
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd91add4-f8fe-47cc-ada1-12183d658287
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fa8f53a-091e-4890-8e5a-691af9740549
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f96fd89-88a6-4207-8055-7f1b24a48e1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ab80009-aa59-4924-998b-ac92d550c2df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 626aa3ac-c696-45e1-93de-6e0f3e49917c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7f3bbe9-dbc3-4a4a-90c8-1f612f36a248
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30c6101f-b1ca-45b0-80ed-2607af71d95c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2185060-f1ff-4e37-b33f-65114cab0f22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca369d10-e693-4831-a4bf-2683bfae5a9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ccb39e64-bcae-4713-8cc6-132e05d6bf94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 991c10f9-e633-41e8-b9d5-715a6be39805
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ae46f8d-91d9-4ed1-a7ec-8dde2323ae5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16ad8d46-24fb-4a0c-adc4-28effb8e826b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c531ec18-b5f3-4982-a9c2-f8ed10468b8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c403f35-afeb-4991-bdb4-bb863d13e015
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc972b51-2714-4671-a485-8e24384726a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82c6d8be-51b3-4ed2-a907-a2804fd0d823
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e279dc3-3cd9-4c3f-a16e-de38131d9796
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 351c0946-e5fd-4256-982a-16f9d5862404
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92becc8a-f36f-4747-b4b3-0de03589bf2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ff91d32-ac0f-424f-880e-7594c858e4b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e27d0cb-8614-46f7-881b-28c5c80d786a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 563251cb-b9b6-493a-b85c-e3053010ec45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ebba437-5f12-460e-9b86-47e103120963
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8665e6ff-d4d3-43b6-a044-28b996b62cfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3127993-1287-4d00-b73f-333aca772ac7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5de1cbf7-8ca3-40b6-a9c7-0c224c9ccf7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e53193da-0e25-41fb-9752-40ebce402e6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ecc6be2-f092-4174-b606-60afeaede644
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d40db32-d410-425d-b9bd-c705c5eac12b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f02fe6e4-f7e1-4553-a960-328e210c20e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5dd76b68-ae99-4bc3-8607-90ad0beecc9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e25b6e8b-457b-43b6-8f70-20e39b19b6e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8760dda0-942b-4dfb-ab7e-931da4212fd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c71c3291-673c-48cf-8076-63801c9e5948
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eed36239-169a-4eb5-b887-132dbab240c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6834f983-9252-4f1d-8baf-9cfa61ae5dfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18baece6-4524-4854-9606-cbd48633acc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c271f12-8c4e-4bcb-a52e-22fd5b5d0b07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 189212bd-ccb5-454e-870d-3a83ee111439
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1444d026-9479-4b3b-a7f9-e1452ea3a44b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b83a8395-0178-4b71-b7a6-3f304d87a9b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 486cc99c-7104-4253-8022-c8c6e709fbf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8298ee11-b07c-498f-ae22-258ccf18a94e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b57e1707-06b6-4d1e-82ad-d2c065b598cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d398ee3f-eeac-4c16-9724-632f8f16475f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 580d81e3-91fa-4f9d-918c-e0c941e95351
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9aef805c-d662-4c38-99ae-cdea8810cde4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70fb9139-963a-48f0-bde7-1fc5afb0f19b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fa31ed1-1763-417a-b947-9d54619dd45f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20d0f4ab-68e1-4e83-9094-0c07c6c29a2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 827bf05c-de30-42b9-a693-973e388d530f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b6aa1c2-b0d3-4268-bd2c-07ecaa636b02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47300e8d-fdc6-443a-b8eb-1d51c50968ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3c9f87e-0612-466b-8491-cfa4b576956a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7908d41d-08b8-4093-a54f-07457a3a2abf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a2a3694-866e-4252-aeff-3fbc12bfcbb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message effb1085-6b06-48ac-b424-0f1c9cf9667b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b302dc9e-79c5-4c26-b096-84d106ac66b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04a4c02d-22a9-4176-a8ea-6ed582eb99eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ce2ae36-f1c5-4208-8d2c-e157bcebee19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c209040-e8f8-415b-8940-9286ac249ffc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2fe648d-e5fc-4708-bf54-2b256415b76f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d969b27-fb24-476e-b4b4-3dbb9f8c4c39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49424ee4-a47c-4c3d-b8af-eb295295e652
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6751d57f-b70c-48cc-b3fa-b32930d68d37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9c6d26d-8a2c-4f67-b9bd-fd1ab36a97fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 383a7563-fee4-48cb-8bb2-f33a68b81d6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edd76bd2-f2be-413a-9a3e-618aa49e519e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 489fad49-b95c-4e2f-b759-8f52cf5f41d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eadd401c-b4c1-4b9e-b3ec-9154e5621574
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c9bc8bc-f3f9-4405-a6e1-aec3869b8dfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c72808ea-ccf1-45a1-8fa0-3b7156b15016
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1149b751-5f57-4e54-8ebc-15072b4c3852
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e00c27c-a168-4625-9808-3fd5335aa6b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b5a5888-327e-44d2-96a1-3af19727e393
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de3ea98f-6552-4c1b-91f9-5597377d3cb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d95b7d7d-e207-4cac-8763-50a1bedbc683
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 296f55cc-691e-4b15-8275-4d75e997c7d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef78d796-1d77-4e42-9d4a-434649574ccf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a080236-21ae-42f5-a3ae-9b02b6c48da3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd4ccf3d-1a56-41c9-a153-a62df32183d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6afd062-e920-4b43-8eda-8bcb655c7995
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59282bae-0995-45fb-8d10-4bdaeb959e2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e680ad0d-c1aa-492c-a961-43af471faa7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 767b7616-4cbe-4656-baae-cb52592b7735
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f321a38f-b70f-45ae-9f0b-974ee36101c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afa253f0-0221-4bcb-ab9f-0b86ae527d31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0975820b-4c3a-4dd8-be6b-0a333282aa7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7f02817-1b3a-4e6e-bfeb-2b48ba1ddd5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0d53135-7445-4115-bbfa-db393ef9d3f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4beaf8c5-b7ea-448f-899a-955b068f4f27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ab05c64-7b0b-4824-b0ed-85f368091ac8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a875ba5-d2f9-4590-929a-5bff50ca46db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31696dad-3346-4c6d-b3ab-a1e1581a7136
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 471258f4-000a-44e6-90bd-fee4d85ad462
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d96131c-3fa9-4fb6-91c5-ad2a77ab057c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eec241d3-514a-40fb-be9b-e08a94b2bce2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18a66efb-5e95-41f0-a474-c56bbcb7fc47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23e3d74a-e65c-4dd1-b8a8-6e5862d0a739
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be662c2f-5e89-4ef8-a5d7-7a27f17f6b21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e62d66b1-e03b-465a-b762-9e703b10aa02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 630c8953-960a-4d07-9526-048d44b8f7e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 027b5ebf-b644-49e6-baa4-abb7dec7d870
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4344e3b-a2d5-48cc-a2fa-e24112cce2f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6044a035-fa1d-4dc3-8df8-ba3c05367c6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac58eea0-06fe-4b6f-81a7-1515f221e48f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a3cbf67-de00-48f5-b42d-514320186e4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36ce5c68-e98f-4857-b400-46de37e95c86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07ab8003-20f7-4bb2-88cc-3c621c1d362b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcd0af75-f95c-43e0-ae64-114800795123
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4532c98d-cc66-475b-8f83-7e25de20c3c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 114f7a08-f725-44e2-9eb1-b018ccb68e40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 680de044-aa18-4f5c-b222-250ae9af8c6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b3980e6-c1d5-4c9f-8cd2-7be1ece23ab3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2bdf089-6279-4bc5-b0fb-34b0951a19bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d713e27-5532-41a3-9ea3-55cb30760b6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2555f721-6171-4df4-b9d6-f6d7ae5a2259
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00304c7b-6e35-4b22-94fa-7895de04af04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cd5ef2f-dedf-4f2d-b772-08a91f2dd8ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 005f8d64-246e-455a-8230-417e18c83580
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55ff5bf8-8d76-4558-a905-ca5939e8485d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7723e890-f6b6-446a-a99b-de4b65285509
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48b01100-8f3f-4fff-85de-0d68aae94362
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ab74c1d-f9da-4ba8-a7f5-d35e8192a1c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2c589ed-5ec9-4414-923e-2f2cef03d19c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0760a87e-b2e8-41a7-937e-fb19484e05aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d365100-0883-42e2-9a72-eee3cfbfe398
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c65932ed-1ba2-4966-922d-d166a327c193
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5f7f072-4793-42df-b6eb-68094f7aeea1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 340ea743-678a-4e9a-8af4-b097f0444525
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3ebfc51-224a-4142-94c5-875c217b1541
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bea079d4-80bf-4af7-87c4-69e13df50cbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f8e4441-3d87-4e36-9dca-dfe3da89cc35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0b818f3-f742-4d6d-9174-1170a909807e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cc38738-c129-43dc-9ddf-5b724cd725ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 245d3799-5a15-45cb-9c64-6350edf78ead
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f7242bf-a51e-43c8-a9cb-4a995a99edd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d939f185-52ab-4452-8b9b-3cf04462c0ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcc9db87-1211-454d-874a-ce6e91949576
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b62e015-d0af-4cc1-b3d2-5c0b9dc09639
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f63cd8ec-2f3d-4617-83ba-73c4c657fb81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 132374cf-a984-4d86-a834-63e4d72d5744
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2031a6d-2ca4-4c24-a3c9-7d2a017f8c72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b0c68a1-951a-4746-ba2a-d3a997793508
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4be25fa-02af-4220-bec5-1e4a98368eb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b10d07a5-6a21-487d-8e92-c381c6f71e69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32822d29-0716-45f3-86df-ecbe77c18e2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4ba0637-0cae-4a32-b869-e44777805a9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f683c32-2bb6-46d7-a5e2-684a433e4dd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 024fe559-e039-43e7-8163-8c94c378feb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20dfb30f-20ab-4e45-b8fb-43dab763a88c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d35043d8-92ef-4c25-88a9-961866c57489
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9424515-bea2-4624-b367-c20d727de4a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1da7a4f0-36a6-4e87-9238-f5fa61d9e416
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cdd97efe-ff42-48fa-816a-ace5a6451e1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 512c0afd-8f9f-456c-92b2-699932757629
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27256fd6-ed5f-44d8-863c-9473a6843d6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e14e30b-6e47-4ebd-8772-7979f7177e9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f3ed61f-95c9-40c6-8295-387e2833ff5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6039a6f1-21b5-4f33-96c1-ef562712ade1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be52d819-1f17-4df9-9864-f70947754a36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b786314e-5360-44ac-b3dc-225962aa910f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90bcebe1-a5bf-444c-91d0-d23b72a6ff24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6f939ff-b00d-4ca5-8f68-633b2f0543a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message febe1d74-0ed3-4b81-8e48-6a430901b5e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 212f949f-4177-4932-8e14-330c3436b6d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84c9c49f-2433-4397-8c9b-01ffdf84880d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d19538e-921f-409c-bab3-b750e0bd5e85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff39af66-6bf0-4df5-817d-17c3639bea7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92413e93-498f-49ad-8c63-c0492fb3aaed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3f4d415-355d-4928-afa7-9b0f75f7316a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfa669f8-a9bc-408a-a1d6-de11c43cfd22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb97e779-896c-48db-99d2-80f6170f1ce7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20313fcb-0341-4d64-acab-520ef6a7df2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8233454-29d8-4114-b36d-ca1a3476691d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a44ac201-478b-4db9-9a8e-d2d352419ff5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 237d0c76-91d6-4e98-b634-66dcd19e18bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4598206f-3390-43f2-987e-c129b4e090b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19d70710-9f47-4304-943d-6f6b9dda725a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76310539-cdab-4098-9892-4784c369d8f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7ec135f-7078-40fc-b77d-89c652ae1b99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a7df5c9-17d2-478e-9b70-ec9208f48d9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a33bc44-c4d5-4275-84bd-6c29b8afd1a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 606f2615-0fd6-49a5-ba05-8bf773cab1ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d733a0b-3684-4ba2-96bc-744d60fe9a93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3ff2648-6dec-46f6-b0e3-53a5887f7bc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9463e1d-f335-471b-b4cd-038342cdf096
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d407c268-d774-45b6-9770-7c10b34b7d60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efcdd778-57a7-4da1-bf11-d9ba7dd21ded
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb785757-18bc-4508-8d6a-b241b3e72788
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30525977-fae5-40b2-a532-62cdc5990ea8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15522a25-cfba-4f6e-9cc5-1a1cbece7f40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 933632e3-9e7a-4dca-affb-016c28f2ee60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a4bac1b-c1b1-4c02-a5c5-cf8eed2ef2f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9098141-fd5b-4660-85d7-b69a252777b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51eeaaa5-3d08-4582-9142-a87f8d5d7064
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed57205c-3cd9-42bf-b59c-910a2ae2e78d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd394bca-0e3d-4d98-a077-c77b87d8f6d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c46db88-6ae9-4d2a-9232-44e962eb81c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b6f3b5d-0ddb-409d-ad35-7c79b4e6b539
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 771abc81-20b1-472f-8f6c-be430437028a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2302f68d-f291-49ac-947c-efc2ea7866f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1dcf057b-f3c3-4cbd-9a2a-cfbe98b25100
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 403a5222-32f5-4da1-b368-03db738db276
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4cd6eb3-0447-4e13-a11a-fab45a78f9a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fee425aa-cb7f-4a70-8fde-b48da019949b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38cafacf-9254-4aa3-bbd0-046d563e16c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6dad67fc-5437-4d56-8b35-d73d735a630a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45e78982-49b1-44ed-9d77-d3aa89adf5a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41545ef7-e0e6-4bc8-8039-ea1919796c38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86a4ecac-ceda-4c2a-ab96-a0866f12ccf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf818d39-fb4f-4254-aca9-f8b91bd3b3ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c03bec0f-0e5e-41d0-b16d-a42102520cb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8b5f293-44d5-42b3-a0b9-10d014b6dd42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 663ce584-07c8-4a48-9554-041e916b0230
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9127c30-1a7f-4415-bdfa-5ffb3ff7498b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2960e831-547d-4f9d-94c7-8658fb299f3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ab91231-fe12-4172-ac9c-b63f894dbb31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7c21123-9dcd-48f1-b0a9-8a510240326d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a387ce2-382d-4a7f-89cc-a9bd2e3f9be5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe07804f-6c76-4d3b-91ac-4f83c4c83a6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f31543b7-c46d-4386-a690-4cf6d4cd06cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2983eee2-faba-4e34-afe2-f5cf7351ee06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b446bc81-4f83-4f52-bf8c-33b0338a62c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e90f288e-e4e2-4520-a368-73a65ce0a980
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 985046c5-493b-455f-9c22-ca0147b1bf00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0346ff65-2b01-4cbd-9e35-dd0f4e24f720
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 462cf120-e555-4f87-a24a-378f6646690a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7e0fda0-d729-4005-8309-9554b3fc1a8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a27bdf95-ced2-49f5-9fd1-7c3ff5ec6737
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cda0abc2-ef53-4d81-8dfa-7c9a9cd13ec9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a355f5d8-9b12-49bc-9836-64204795a3c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b29e1e3a-6a0c-41b1-9c9b-e5e7f04d52e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b40e6c8-cd88-45a6-b2c0-b450a4914cc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4df04723-ddf0-4aad-a450-359601b10ef6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51e2844e-1834-41be-af29-a1408bcb5af9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99a5ec13-b57b-4004-bb41-5be637d7ad88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7aae3453-92cb-4075-a982-ed55ea999cc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1f27379-9895-4b39-b9a1-dd84bdeea98f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6637153c-0795-46f6-99c9-8111a6c61688
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05416e6a-233c-40c8-9bdb-6b8064e74671
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f8c01be-9e14-4ce1-a311-6bb3f25a453c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e621bc2-a4ea-4763-94dd-527a86d92209
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55297267-0096-4fa7-a392-69527a70886c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 885c59bd-c412-4077-b1b4-23fa53c65157
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fff001ef-3075-46a8-b00c-e36eeb109aed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db8c2586-cf6d-43f2-b95b-32bf7623fa85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8d9df16-101a-4527-a63c-14f6466d3bed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f49d512f-9d14-4b07-99c9-27239bb15599
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 841d9f2c-eb0d-4e9e-a917-db3a6f2c3f56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6ab7aca-1aab-49f3-ac15-3d9ac9a10e8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec530c0f-b22f-4d4e-8abc-e64d6444dd1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cbbf1dd-683f-4a44-8bcb-790793113f0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4166c27a-8c64-4448-86f0-a1ec7972692c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a40165f5-4252-4926-bb5b-9a49752ce762
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b64ae2c1-628a-4c4f-8e47-4109e278d1f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d05b8621-eb65-4f2b-8e4e-c31de7d99f43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fea2da70-b508-4697-b525-e51030350923
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 094fecf9-0534-4f45-92f1-e70170e51549
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f50ac8c4-c585-41b3-b754-b73d328ed739
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a4325cd-ae08-4589-b491-bd0b58b70e2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 922cc4b3-8a66-461a-81ce-3f5ddefdf7a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4eabef8-14a3-4a5e-a870-0b834a04bc57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c7ba6df-24d6-4d6f-aa7f-b017055f87a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01e368c2-62b1-4fb0-85f7-c8aed3c35435
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae4cc64c-a97a-4bc5-b5fe-c64ed6d694e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7dc2c69-9f84-40ab-adee-c60cae9c5bb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3d94b4d-9ec9-44cc-9a99-b5c1a8946c90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3db13edc-2cc6-4754-bde9-165cb344c3d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c336d2e-3b5c-4e00-975c-f87d5e81f960
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 440757b9-67d2-44fb-8025-eebaed1851e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f7aa881-fd52-4d71-a67a-340ebd464412
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3445b317-62c7-4861-ac89-de0fd24a51a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 688e33fd-8240-4566-8097-363503cb67f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f3db942-fdbc-4f30-924e-1057658c477d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70a5a514-5a79-4937-8a95-abf5b2ae5a18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2a8de4f-4660-42d0-a91e-c07993d36f41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18748937-3172-4a08-bb41-05920a0282cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f510005-6c71-4452-a46d-08cabe01215c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 143c6d24-7f47-4f71-8247-27922de5aa92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f263f4cc-b8b4-471e-97ed-c260a797f6c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55d01850-66cf-429e-a6e7-12965fdb4e02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 498273f6-f06c-458c-89fe-ff0f77220805
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63a77556-5780-4237-8ed6-26ef686c3d81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a6fa2ed-0f77-4350-b853-ae9b5f890a74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 812afc4e-7273-4b5d-a983-d8f4c907f7ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2ac1b75-c28a-4837-be65-48c06f9a3198
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09e0d519-bc98-4350-a72f-4166c1c8ef83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ee6689f-4847-4753-85d8-479654db8e3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef7b29c8-57b5-4b70-bd63-a9c5d8a3312d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27633052-c255-4edf-991b-a58fd21214a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ff790be-c8ef-41a3-99fb-6111e808438d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51f6c7bd-93fe-443b-94aa-8d7f81e24244
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64e5bf72-c4a0-4574-836f-00370e991c3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff68ebe6-6dc0-48b5-97a7-0c6e016815cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 785423eb-851f-45d9-a076-347e87dff8e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b501b52a-810b-4677-bb74-45419e60c3f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f52b7a8-0684-4e61-ae73-3c4a00c4a398
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a94d5e46-5ed6-4073-b22a-20329d7bd32b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e00c712-d969-41a3-9775-12d6d13fff25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25f67616-b7c2-4d39-b41f-5615c89b97cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a35c9c9-0d17-4f64-b88d-86ccf575ed00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f20808f-5024-4c5b-b352-e6eed7d6c2a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f2729c2-c74e-4301-9f18-93d2c3726ffa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77260c59-9365-46f0-92b8-a00abf80552e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4314afb-5d3d-490c-b71d-03f17bc55425
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f732fe9-a2e0-4a39-8206-e1a50318a1e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84e9531d-e715-4539-ae1f-542f1f870494
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e2dfce9-140b-4cc4-b63d-f277318a3626
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89a260c6-d835-4dfd-96c8-46007abe3af4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6aee8ea-00e9-4be6-abb4-54f50bff2c66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ebdb257-2070-475c-8754-00397c861a35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94ac10fc-5418-4dc8-983b-1b3fb0b0cc30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c01293f4-afbf-45f8-9f57-b50f8d21c17a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0913b8a-8df3-4833-9565-a124b3946dcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00acced3-d276-4fff-a3b3-9d5b2502914c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36914414-4387-4718-9238-9d4a1bf27f0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d61064fa-0c28-4907-b9f3-0367ff8401f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18745599-7740-4327-8312-36f4f198bf0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66deb503-333e-4ae6-88dc-b8cd9cb037b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e97f3bf8-5c76-4d01-8125-c4fe1d21745b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e15c4b9-6376-47a9-98ab-795525f7e14b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19fc7b09-e9c7-4a7e-9a0f-38071d708f43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a76cdd31-50ba-434d-8a6a-c6c44213112c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68c69b38-ddbc-4580-a280-4a4a0d0d375d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b8c9932-1aa3-4f9e-b6e8-155beaa9254a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9be3afec-2962-4e9b-ac15-9952a8c0b623
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67d6211e-7844-41ff-967d-0f1b5e1f9881
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 685dc2f1-043b-4fc3-aa5f-da1214839d1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a81267b-eb85-4d39-92f9-3a0566dbdc9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b1c1f65-68aa-4b06-a0ec-05480463fa84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51cd5bfe-785f-428a-a733-34d4c524569c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67376b5a-aee2-4f29-bf1a-8cff201e1867
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f3d0c59-d504-4275-8c7d-dd1e4ab033aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e4e48e5-6511-40c9-a925-2f767e503255
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d670f6e-09d5-4151-aa6c-e82d3e9e6690
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f482ec9b-f17d-46c8-927e-bd3c2ef3d49a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68b3ae3b-d97e-4b09-84f3-43f9c4e09665
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4422eb54-b4ee-4660-a659-3279a1bfbbb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f6df22e-b306-4390-a83a-c4937d134127
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55cb8f53-046c-4a18-8244-87db0fd649c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79ccf49c-4b5e-43ba-8841-7ed1c292ac5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd766003-17fa-4d1b-8195-ee3fa1c86f2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 709a1de6-e535-4812-b157-5d4f7e200488
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11990118-6716-467e-a2fe-e7d6a089d23e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9631f2d9-1355-4012-8b2e-22c341c2b302
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63c5ed4f-02b9-46b7-a690-51d52efaf856
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb7acfb3-648e-4392-9358-ce0256cc9abd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b63e8a8-64c3-40d2-83ca-90e9d7d92629
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc3e51e0-64d0-4995-830f-1cb95f153d61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e5331c6-b04e-4c45-bdae-758a0a7d8adb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7bfecfe-a218-405a-99c1-f3dcb9c10394
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61c2bee3-2f6e-4dbc-bab7-cf1fe93b12ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a73db663-b6e1-482b-a180-5129896bb003
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 957c17cc-b1ad-4f09-9823-36164133a090
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1af3f6a6-883b-4921-a64f-4492c004311a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e27f8a68-ec16-4191-878f-68ee0bc8a0b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90b5a7b3-d0ca-45cb-ab57-914e13a86d27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edb00518-6788-47a6-a047-48bcab3a2b8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a8d0217-a4f4-4b98-b05f-22ef0d8a3a80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd7d7b9f-29c1-4fcb-b66a-0d229389cb9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22553d72-de93-4858-bcf6-7f097957c234
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 420e1246-ed28-49fc-8c29-0e5a33e9a904
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6636ee6a-53bf-4d12-8995-63fd9e898f7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cc4638f-8e52-4f70-9b81-0a04a9273d69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a155dd1-6cae-4ee1-9088-af1ebff5befa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01f981f7-be35-4ac2-94ed-2755457ef3b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 950a461f-033a-44b8-b866-c4d91381dd07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20a3e58a-cbb7-493e-ac67-f04a969eb6ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 827b0164-36d8-4213-b37b-8c42c75391d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fa8d243-bcee-47b4-8d5c-75b5cf1be884
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 002cf62c-5f72-43ef-a90f-2fbf5f8a179a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c202029c-4807-47b0-8073-134a338cd430
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2b95b69-fa61-4a82-b751-ad542538e624
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a7420e6-be5d-4b6a-b489-e8042fc0c9be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20b2a16f-b432-4955-beaf-7e9e3b8c9483
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 936094fd-3532-4898-8ed4-8476317e4840
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f0e6e97-c891-4c58-a26a-290bc2be3ee2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 371e84b1-d221-47ca-be07-166484798128
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fa42326-7f89-49c8-8291-9a32a338eb9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b594be2-75c5-49e6-8fd4-89a3bdff058b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89e1121e-91a3-49b1-aeaa-82eb54449e35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ab5da12-fb4b-4054-9970-71652edf650b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84215e1c-8a01-4c5d-ab46-f856c374596b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0eadc378-eec7-4cca-b8d1-d035cd880c78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd888866-7c2c-45c1-b1d9-b2778549381d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e35315e3-a242-4f13-873d-afce161d45ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72a203a7-28cd-494f-abff-c1e0c8f3898e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5ad8547-e2fc-4148-9790-f6cf1f9d9a90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99f842d9-bbd6-4869-af6a-671c02dfb52d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ee61feb-b7ea-45d8-85fc-3dfd34ac1ae6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5236f50-828c-47f3-9995-91e69e105aa4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a565382-d5f4-4e0f-9635-d5de1fa4126d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d07bdca-0be6-49eb-a08d-108a83a3b4a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dec145bf-88c5-4b5c-b0c3-55f4868992a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dea3e719-fcc9-4c8b-a5a9-e69b5513ddce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ba683a7-82be-44e9-b500-fd726f5ffe9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4bd604d-c934-4677-b485-57dbfe999ba9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f9e5adc-dbba-4850-9943-c9cda6d1bd2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c553541-70b4-4944-a8bc-74b3a0a73384
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eaa92deb-792f-4ffe-8d14-8a71b15c597d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 507a43e9-4012-4fdb-9002-69a6dd60ba3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59e00cf4-8e65-4453-96ce-a22410cdbdce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76e6cb4f-aea9-435f-97a9-bdd574c0e208
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b864fe75-0d85-406c-a616-249e9707c792
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7892c84c-62a6-4c53-b952-4ac24068c846
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9cca6d0f-8a7c-4db2-ba5b-f461f5728dff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 620b4da8-7581-4fcf-912e-8f8c0278eb5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd42e314-b350-47b0-93ae-75aab1f7f865
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2065f721-ee23-4aa9-8672-0a715d6ef28e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6110a7d2-cc9d-4bdc-a5a5-4c16e0378135
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8208aa7-fb71-4cc3-ab03-a5f96a447ba1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b77dd6f-4e74-4443-a72d-12cc84142a69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86e13417-8010-446a-ba6f-85a2018a2ceb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46e9a5ce-591d-4965-9709-281f59e2de2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 302e64b2-2a5e-402e-983d-7557ab549641
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afd6224d-ac2f-4e34-ba13-080e3490e149
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d0fd6bc-4f8c-4d7b-bcf2-facad90a7be4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b7add59-be0e-4712-8f0e-9a0c803033c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7824631c-7d0c-4022-bac1-5dd1b0ba6fc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca61615c-91bb-4eb4-b05a-73d96aed42b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3900cd25-cbbc-4248-9f22-9269679b6e52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1d8e765-3045-420a-bbfa-565fba13535e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bb7eb8e-b85c-454a-87b5-c598df2939f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4018e3ed-4d49-4423-bf89-a076bb0f714a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eee6cc21-9d3c-4412-b7b8-85cf9a2de616
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e613c1dd-7457-4731-b191-30bd8e000112
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c9eeeed-2461-41bd-88ca-21008c86b177
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97399dee-46aa-4c59-8b46-de2b2666157c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df4f2d7e-5a1e-4972-8cc8-aa9e5a8d7466
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b488c00-39a7-4ba0-8204-30b1dd2f74d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a23ea088-f4aa-42c2-8422-27e059606743
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 126a1650-28f8-42b5-9210-bb1fb97f66d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c84c83b5-0c98-4ad7-9ad7-73e451e6dab5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c292381f-00be-46f0-a950-cd65df42f57f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c25f9c46-347b-49d7-8bd2-793c9e9af789
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2b53281-5a7e-430d-ab6c-adcdd953ae34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfa8e83f-5e1a-4572-a12d-35b2c44f9d75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d57bb282-c360-4007-95e8-53ec1d4309e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46ce8f52-1582-46b2-b980-41bd918ea972
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31b779ff-57e2-4131-97aa-dfd78a9c8640
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22b60956-3657-453d-ae5f-3ba54db75a4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 843c1b6e-de62-44fb-ab92-26e5ad856742
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 636f2663-5244-4f51-ba6d-40596367456e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35ec6673-5ade-4111-8149-026254b23c7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 899fb307-9d16-46fe-a869-6aa2444e192e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d03f42c2-1883-454f-8e69-41364ad994bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9209f5af-12b0-496f-afe3-6a4388c07193
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e665fab-3a6c-4f78-9873-f2268e32f84b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fcb01d4-8687-43a8-af9a-e0020225fae1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aeb12435-373f-4c5e-8251-a55d19562cb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5e0046d-5532-407e-b817-9dd6635b058c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d6198b7-9bd9-42d9-80a3-3dfe6e27c298
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d43dc41b-84a2-4a8d-8e9c-7ff081a193fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca6fed10-7b26-41df-a779-855bf7e15ea0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb05aeb2-3ca0-4b49-b8ac-429fbaf04e28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37199cb5-26b3-48c8-87f6-18af486dc9ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c193f7a-1afa-4be5-9c44-c1f8f02e826c
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_21
Server: localhost:8686
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_21
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_21/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_21/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_21/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_21/test_labels.txt

📊 Raw data loaded:
   Train: X=(4800, 24), y=(4800,)
   Test:  X=(1200, 24), y=(1200,)

⚠️  Limiting training data: 4800 → 800 samples
⚠️  Limiting test data: 1200 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_21 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 1 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.2289, val=0.0956 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0924, val=0.0845 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0780, val=0.0795 (↓), lr=0.001000
   • Epoch   4/100: train=0.0760, val=0.0797, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0768, val=0.0797, patience=2/15, lr=0.001000
   📉 Epoch 9: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0746, val=0.0799, patience=8/15, lr=0.000500
   📉 Epoch 17: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 1 Summary - Client client_21
   Epochs: 18/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0756, RMSE=0.2749, R²=0.0096
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0092
============================================================


📊 Round 1 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2420, R²: -0.0002

============================================================
🔄 Round 2 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0809 (↓), lr=0.000250
   • Epoch   2/100: train=0.0754, val=0.0810, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0753, val=0.0809, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0752, val=0.0810, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0752, val=0.0810, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0747, val=0.0812, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 2 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0755, RMSE=0.2748, R²=0.0031
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0025
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2415, R²: 0.0017

============================================================
🔄 Round 4 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0783 (↓), lr=0.000063
   • Epoch   2/100: train=0.0763, val=0.0785, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0762, val=0.0785, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0762, val=0.0784, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0762, val=0.0784, patience=4/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0760, val=0.0784, patience=10/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 4 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=0.0032
   Val:   Loss=0.0783, RMSE=0.2799, R²=-0.0230
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2413, R²: 0.0022

============================================================
🔄 Round 9 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0785 (↓), lr=0.000016
   • Epoch   2/100: train=0.0758, val=0.0785, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0758, val=0.0785, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0758, val=0.0786, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0758, val=0.0786, patience=4/15, lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0757, val=0.0787, patience=10/15, lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 9 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0757, RMSE=0.2752, R²=0.0078
   Val:   Loss=0.0785, RMSE=0.2801, R²=-0.0008
============================================================


============================================================
🔄 Round 11 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0748 (↓), lr=0.000004
   • Epoch   2/100: train=0.0769, val=0.0748, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0769, val=0.0749, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0769, val=0.0749, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0769, val=0.0749, patience=4/15, lr=0.000004
   📉 Epoch 7: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0769, val=0.0749, patience=10/15, lr=0.000002
   📉 Epoch 15: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 11 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0076
   Val:   Loss=0.0748, RMSE=0.2735, R²=-0.0070
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2413, R²: 0.0044

📊 Round 11 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0041

📊 Round 11 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 16 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 16 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0060
   Val:   Loss=0.0746, RMSE=0.2732, R²=0.0014
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0041

============================================================
🔄 Round 17 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 17 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2744, R²=0.0017
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0000
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0041

📊 Round 17 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0041

============================================================
🔄 Round 21 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 21 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2749, R²=0.0053
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0049
============================================================


============================================================
🔄 Round 22 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 22 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0045
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0048
============================================================


============================================================
🔄 Round 23 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 23 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2738, R²=0.0045
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0042
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0041

============================================================
🔄 Round 25 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 25 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2770, R²=0.0046
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0123
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 30 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 30 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0073
   Val:   Loss=0.0709, RMSE=0.2663, R²=-0.0002
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 31 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0673 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0673, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0673, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0673, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0673, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0673, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0673)

============================================================
📊 Round 31 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0067
   Val:   Loss=0.0673, RMSE=0.2595, R²=0.0034
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 32 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 32 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2763, R²=0.0061
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0057
============================================================


============================================================
🔄 Round 33 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 33 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0077
   Val:   Loss=0.0730, RMSE=0.2703, R²=-0.0020
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 36 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 36 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2748, R²=0.0067
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0006
============================================================


============================================================
🔄 Round 38 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 38 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2767, R²=0.0029
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0122
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

📊 Round 38 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

📊 Round 38 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 44 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 44 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2765, R²=0.0058
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0021
============================================================


============================================================
🔄 Round 45 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 45 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2752, R²=0.0084
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0038
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

📊 Round 45 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

📊 Round 45 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 51 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 51 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2743, R²=0.0077
   Val:   Loss=0.0806, RMSE=0.2840, R²=-0.0121
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 54 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 54 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0058
   Val:   Loss=0.0775, RMSE=0.2785, R²=0.0023
============================================================


============================================================
🔄 Round 58 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 58 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=0.0039
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0073
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

📊 Round 58 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 61 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 61 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2765, R²=0.0023
   Val:   Loss=0.0759, RMSE=0.2754, R²=-0.0362
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

📊 Round 61 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

📊 Round 61 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 66 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 66 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2767, R²=0.0039
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0159
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 69 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0746, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0746, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0746, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 69 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0747, RMSE=0.2733, R²=0.0089
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0084
============================================================


============================================================
🔄 Round 70 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 70 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0061
   Val:   Loss=0.0744, RMSE=0.2727, R²=0.0005
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 71 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 71 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0052
   Val:   Loss=0.0776, RMSE=0.2785, R²=0.0008
============================================================


============================================================
🔄 Round 73 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 73 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2776, R²=0.0038
   Val:   Loss=0.0734, RMSE=0.2709, R²=0.0069
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 80 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 80 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.0045
   Val:   Loss=0.0722, RMSE=0.2686, R²=-0.0021
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 83 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 83 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0070
   Val:   Loss=0.0723, RMSE=0.2690, R²=0.0016
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

📊 Round 83 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 86 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 86 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2756, R²=0.0039
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0115
============================================================


============================================================
🔄 Round 87 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 87 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0065
   Val:   Loss=0.0789, RMSE=0.2810, R²=-0.0011
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 88 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 88 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2756, R²=0.0051
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0218
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 89 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 89 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0067
   Val:   Loss=0.0751, RMSE=0.2741, R²=-0.0024
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 92 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 92 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0072
   Val:   Loss=0.0765, RMSE=0.2765, R²=0.0006
============================================================


============================================================
🔄 Round 93 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 93 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0063
   Val:   Loss=0.0730, RMSE=0.2703, R²=-0.0019
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

📊 Round 93 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

📊 Round 93 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 97 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0699 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0699, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0699, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0699, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 97 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0076
   Val:   Loss=0.0699, RMSE=0.2643, R²=0.0004
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

📊 Round 97 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

📊 Round 97 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

📊 Round 97 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

📊 Round 97 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

📊 Round 97 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 107 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 107 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2744, R²=0.0032
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0359
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 110 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 110 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2765, R²=0.0059
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0053
============================================================


============================================================
🔄 Round 112 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 112 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0073
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0159
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

📊 Round 112 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

📊 Round 112 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 116 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 116 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2738, R²=0.0045
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0119
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0044

📊 Round 116 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0044

📊 Round 116 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0044

============================================================
🔄 Round 122 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 122 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2741, R²=0.0066
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0056
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0044

📊 Round 122 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0044

============================================================
🔄 Round 131 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 131 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0066
   Val:   Loss=0.0732, RMSE=0.2705, R²=-0.0025
============================================================


============================================================
🔄 Round 133 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 133 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0070
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0256
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0044

📊 Round 133 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0044

============================================================
🔄 Round 141 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0712 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 141 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0061
   Val:   Loss=0.0712, RMSE=0.2669, R²=-0.0008
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0044

📊 Round 141 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0044

============================================================
🔄 Round 143 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 143 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=0.0051
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0025
============================================================


============================================================
🔄 Round 144 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 144 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=0.0082
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0081
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0044

📊 Round 144 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 149 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0739, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0739, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0739, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0739, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0739, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0739, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 149 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0739, RMSE=0.2718, R²=0.0068
   Val:   Loss=0.0860, RMSE=0.2932, R²=0.0028
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 150 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 150 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0034
   Val:   Loss=0.0776, RMSE=0.2785, R²=0.0148
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 151 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0684 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0684, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0684, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0684, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0684, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0685, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0684)

============================================================
📊 Round 151 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0077
   Val:   Loss=0.0684, RMSE=0.2616, R²=-0.0051
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

📊 Round 151 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 154 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 154 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0059
   Val:   Loss=0.0759, RMSE=0.2756, R²=0.0083
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

📊 Round 154 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 158 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0733, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0733, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0733, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0733, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0732, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0732, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 158 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0734, RMSE=0.2709, R²=0.0056
   Val:   Loss=0.0880, RMSE=0.2967, R²=0.0092
============================================================


============================================================
🔄 Round 160 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0671 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0671, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0671, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0671, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0671, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0671, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0671)

============================================================
📊 Round 160 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0086
   Val:   Loss=0.0671, RMSE=0.2590, R²=-0.0048
============================================================


============================================================
🔄 Round 162 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0698 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0698, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0698, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0698, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0698, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0698, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0698)

============================================================
📊 Round 162 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2792, R²=0.0071
   Val:   Loss=0.0698, RMSE=0.2641, R²=0.0019
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 163 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0687 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0687, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0687, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0687, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0687, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0687, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0687)

============================================================
📊 Round 163 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0064
   Val:   Loss=0.0687, RMSE=0.2621, R²=-0.0001
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 166 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 166 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2756, R²=0.0066
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0043
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 168 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0685 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0685, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0685, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0685, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0685, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0685, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0685)

============================================================
📊 Round 168 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2797, R²=0.0072
   Val:   Loss=0.0685, RMSE=0.2617, R²=0.0021
============================================================


============================================================
🔄 Round 169 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0592 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0592, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0592, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0592, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0592, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0593, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0592)

============================================================
📊 Round 169 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0060
   Val:   Loss=0.0592, RMSE=0.2434, R²=0.0062
============================================================


============================================================
🔄 Round 170 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 170 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2742, R²=0.0075
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0025
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

📊 Round 170 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 172 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 172 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2748, R²=0.0067
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0049
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

📊 Round 172 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

📊 Round 172 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

📊 Round 172 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 177 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 177 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2754, R²=0.0071
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0038
============================================================


============================================================
🔄 Round 178 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 178 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2739, R²=0.0066
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0056
============================================================


============================================================
🔄 Round 180 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0680 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0680, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0680, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0680, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0681, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0681, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0680)

============================================================
📊 Round 180 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=0.0070
   Val:   Loss=0.0680, RMSE=0.2608, R²=-0.0176
============================================================


============================================================
🔄 Round 181 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 181 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2763, R²=0.0079
   Val:   Loss=0.0762, RMSE=0.2761, R²=-0.0038
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 182 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0690 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0690, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0690, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0690, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0690, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0690, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0690)

============================================================
📊 Round 182 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0056
   Val:   Loss=0.0690, RMSE=0.2626, R²=0.0091
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

📊 Round 182 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 185 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0707, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0707, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0707, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 185 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0043
   Val:   Loss=0.0707, RMSE=0.2659, R²=0.0100
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 190 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0742, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0742, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0742, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0742, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0742, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0742, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 190 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0743, RMSE=0.2726, R²=0.0078
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0074
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 191 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 191 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2778, R²=0.0063
   Val:   Loss=0.0729, RMSE=0.2700, R²=0.0068
============================================================


============================================================
🔄 Round 192 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0670 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0670, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0670, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0670, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0670, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0670, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0670)

============================================================
📊 Round 192 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0052
   Val:   Loss=0.0670, RMSE=0.2588, R²=0.0012
============================================================


============================================================
🔄 Round 194 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 194 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=0.0064
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0100
============================================================


============================================================
🔄 Round 196 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 196 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0056
   Val:   Loss=0.0730, RMSE=0.2703, R²=0.0079
============================================================


============================================================
🔄 Round 198 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0737, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0737, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0737, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0737, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0737, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0736, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 198 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0739, RMSE=0.2718, R²=0.0073
   Val:   Loss=0.0861, RMSE=0.2933, R²=-0.0177
============================================================


============================================================
🔄 Round 200 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 200 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2744, R²=0.0086
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0016
============================================================


============================================================
🔄 Round 201 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 201 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0054
   Val:   Loss=0.0778, RMSE=0.2790, R²=-0.0021
============================================================


============================================================
🔄 Round 203 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 203 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0078
   Val:   Loss=0.0758, RMSE=0.2754, R²=0.0007
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 206 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 206 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2737, R²=0.0050
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0120
============================================================


============================================================
🔄 Round 207 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 207 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.0058
   Val:   Loss=0.0722, RMSE=0.2688, R²=0.0053
============================================================


============================================================
🔄 Round 208 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 208 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2737, R²=0.0049
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0120
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

📊 Round 208 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 213 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0736, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0736, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0736, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0736, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0736, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0736, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 213 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0738, RMSE=0.2716, R²=0.0053
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0193
============================================================


📊 Round 213 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

📊 Round 213 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 216 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 216 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2747, R²=0.0051
   Val:   Loss=0.0798, RMSE=0.2824, R²=0.0105
============================================================


📊 Round 216 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

📊 Round 216 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 221 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0697 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0697, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0697, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0697, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0697, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0697)

============================================================
📊 Round 221 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2792, R²=0.0086
   Val:   Loss=0.0697, RMSE=0.2641, R²=-0.0044
============================================================


📊 Round 221 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

📊 Round 221 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

📊 Round 221 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

📊 Round 221 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 230 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0745, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 230 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0745, RMSE=0.2730, R²=0.0101
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0104
============================================================


============================================================
🔄 Round 231 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0693 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0693, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0693, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0693, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0693, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0694, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0693)

============================================================
📊 Round 231 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2794, R²=0.0054
   Val:   Loss=0.0693, RMSE=0.2633, R²=0.0007
============================================================


============================================================
🔄 Round 232 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 232 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=0.0069
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0044
============================================================


📊 Round 232 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 236 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 236 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2740, R²=0.0085
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0036
============================================================


📊 Round 236 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 238 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 238 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0047
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0133
============================================================


📊 Round 238 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 239 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0749, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 239 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2737, R²=0.0061
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0025
============================================================


📊 Round 239 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 241 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0736, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0736, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0736, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0736, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0736, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0736, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 241 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0735, RMSE=0.2711, R²=0.0078
   Val:   Loss=0.0876, RMSE=0.2959, R²=0.0018
============================================================


============================================================
🔄 Round 244 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0745, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 244 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0743, RMSE=0.2726, R²=0.0072
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0015
============================================================


📊 Round 244 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 245 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 245 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0062
   Val:   Loss=0.0784, RMSE=0.2799, R²=0.0049
============================================================


📊 Round 245 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

📊 Round 245 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

📊 Round 245 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 249 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 249 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0047
   Val:   Loss=0.0724, RMSE=0.2691, R²=0.0138
============================================================


============================================================
🔄 Round 252 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0704, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0704, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0704, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0705, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 252 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0061
   Val:   Loss=0.0704, RMSE=0.2654, R²=-0.0078
============================================================


📊 Round 252 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

📊 Round 252 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

📊 Round 252 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 259 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 259 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0070
   Val:   Loss=0.0731, RMSE=0.2703, R²=-0.0014
============================================================


============================================================
🔄 Round 261 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0748, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0748, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0748, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0748, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 261 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2737, R²=0.0064
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0039
============================================================


============================================================
🔄 Round 265 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 265 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2761, R²=0.0069
   Val:   Loss=0.0766, RMSE=0.2767, R²=0.0033
============================================================


📊 Round 265 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

📊 Round 265 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

📊 Round 265 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 270 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 270 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2754, R²=0.0081
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0044
============================================================


📊 Round 270 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 272 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0681 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0681, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0681, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0681, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0681, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0681, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0681)

============================================================
📊 Round 272 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0075
   Val:   Loss=0.0681, RMSE=0.2609, R²=0.0002
============================================================


📊 Round 272 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 275 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 275 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=0.0034
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0108
============================================================


📊 Round 275 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 279 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 279 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0051
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0039
============================================================


============================================================
🔄 Round 280 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 280 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0058
   Val:   Loss=0.0779, RMSE=0.2790, R²=-0.0005
============================================================


============================================================
🔄 Round 282 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 282 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0084
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0009
============================================================


📊 Round 282 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

📊 Round 282 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

📊 Round 282 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 288 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 288 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2744, R²=0.0054
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0105
============================================================


============================================================
🔄 Round 289 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 289 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2754, R²=0.0062
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0078
============================================================


============================================================
🔄 Round 290 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0694 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0694, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0694, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0695, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0695, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0695, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0694)

============================================================
📊 Round 290 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0066
   Val:   Loss=0.0694, RMSE=0.2635, R²=-0.0016
============================================================


📊 Round 290 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 291 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 291 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0069
   Val:   Loss=0.0768, RMSE=0.2770, R²=0.0027
============================================================


📊 Round 291 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 292 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0748, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0748, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0748, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0748, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 292 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2737, R²=0.0078
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0002
============================================================


============================================================
🔄 Round 293 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 293 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0071
   Val:   Loss=0.0713, RMSE=0.2671, R²=0.0040
============================================================


============================================================
🔄 Round 294 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 294 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2744, R²=0.0063
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0050
============================================================


📊 Round 294 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 296 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 296 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2746, R²=0.0066
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0014
============================================================


============================================================
🔄 Round 297 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 297 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0060
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0009
============================================================


📊 Round 297 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 300 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0693 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0693, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0693, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0693, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0694, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0694, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0693)

============================================================
📊 Round 300 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0055
   Val:   Loss=0.0693, RMSE=0.2633, R²=-0.0074
============================================================


============================================================
🔄 Round 301 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 301 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2774, R²=0.0075
   Val:   Loss=0.0737, RMSE=0.2714, R²=-0.0240
============================================================


📊 Round 301 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 305 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 305 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2742, R²=0.0062
   Val:   Loss=0.0806, RMSE=0.2840, R²=-0.0029
============================================================


📊 Round 305 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

📊 Round 305 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

📊 Round 305 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 314 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 314 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0079
   Val:   Loss=0.0726, RMSE=0.2695, R²=-0.0003
============================================================


📊 Round 314 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 315 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 315 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=0.0058
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0096
============================================================


📊 Round 315 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 317 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0693 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0693, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0693, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0693, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0693, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0693, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0693)

============================================================
📊 Round 317 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2794, R²=0.0075
   Val:   Loss=0.0693, RMSE=0.2632, R²=0.0022
============================================================


📊 Round 317 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

📊 Round 317 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 322 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 322 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0057
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0102
============================================================


============================================================
🔄 Round 323 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0739, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0739, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0739, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0739, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0739, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0739, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 323 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0738, RMSE=0.2716, R²=0.0054
   Val:   Loss=0.0863, RMSE=0.2939, R²=0.0102
============================================================


📊 Round 323 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 328 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0687 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0687, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0688, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0688, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0688, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0690, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0687)

============================================================
📊 Round 328 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0055
   Val:   Loss=0.0687, RMSE=0.2621, R²=-0.0425
============================================================


============================================================
🔄 Round 330 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 330 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2742, R²=0.0093
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0038
============================================================


📊 Round 330 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 331 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 331 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2744, R²=0.0080
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0006
============================================================


============================================================
🔄 Round 332 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 332 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2739, R²=0.0050
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0121
============================================================


📊 Round 332 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 333 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 333 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0048
   Val:   Loss=0.0745, RMSE=0.2729, R²=0.0039
============================================================


============================================================
🔄 Round 334 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0603 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0603, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0603, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0603, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0603, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0603, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0603)

============================================================
📊 Round 334 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0089
   Val:   Loss=0.0603, RMSE=0.2456, R²=-0.0059
============================================================


📊 Round 334 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 338 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 338 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0745, RMSE=0.2730, R²=0.0063
   Val:   Loss=0.0833, RMSE=0.2887, R²=0.0064
============================================================


============================================================
🔄 Round 339 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 339 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0070
   Val:   Loss=0.0778, RMSE=0.2790, R²=-0.0076
============================================================


📊 Round 339 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0041

============================================================
🔄 Round 340 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 340 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0043
   Val:   Loss=0.0749, RMSE=0.2737, R²=0.0145
============================================================


📊 Round 340 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

📊 Round 340 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

📊 Round 340 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0041

============================================================
🔄 Round 343 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 343 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2741, R²=0.0057
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0036
============================================================


============================================================
🔄 Round 344 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 344 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2745, R²=0.0068
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0042
============================================================


============================================================
🔄 Round 345 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 345 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0057
   Val:   Loss=0.0724, RMSE=0.2690, R²=-0.0030
============================================================


============================================================
🔄 Round 346 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 346 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0072
   Val:   Loss=0.0743, RMSE=0.2727, R²=-0.0028
============================================================


📊 Round 346 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0041

============================================================
🔄 Round 347 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 347 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2743, R²=0.0087
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0013
============================================================


📊 Round 347 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0041

📊 Round 347 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 351 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 351 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0061
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0060
============================================================


📊 Round 351 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 353 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0739, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0739, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0739, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0739, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0739, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0739, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 353 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0742, RMSE=0.2724, R²=0.0085
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0002
============================================================


============================================================
🔄 Round 354 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 354 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0747, RMSE=0.2733, R²=0.0059
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0048
============================================================


============================================================
🔄 Round 356 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 356 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0064
   Val:   Loss=0.0747, RMSE=0.2734, R²=0.0028
============================================================


📊 Round 356 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 360 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 360 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0086
   Val:   Loss=0.0738, RMSE=0.2716, R²=-0.0077
============================================================


📊 Round 360 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 361 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 361 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0064
   Val:   Loss=0.0729, RMSE=0.2699, R²=-0.0091
============================================================


📊 Round 361 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

📊 Round 361 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

📊 Round 361 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

📊 Round 361 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 369 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 369 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2765, R²=0.0066
   Val:   Loss=0.0756, RMSE=0.2749, R²=0.0036
============================================================


📊 Round 369 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 370 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 370 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0046
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0141
============================================================


📊 Round 370 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 372 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 372 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0074
   Val:   Loss=0.0745, RMSE=0.2729, R²=0.0029
============================================================


📊 Round 372 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

📊 Round 372 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 375 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0703 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0703, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0703, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0703, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0703)

============================================================
📊 Round 375 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0059
   Val:   Loss=0.0703, RMSE=0.2651, R²=0.0093
============================================================


============================================================
🔄 Round 376 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 376 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0064
   Val:   Loss=0.0730, RMSE=0.2701, R²=0.0031
============================================================


============================================================
🔄 Round 377 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0732, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0732, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0732, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0732, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0732, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0732, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 377 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0727, RMSE=0.2697, R²=0.0029
   Val:   Loss=0.0906, RMSE=0.3009, R²=-0.0116
============================================================


📊 Round 377 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 378 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0692 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0692, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0692, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0693, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0693, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0693, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0692)

============================================================
📊 Round 378 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0071
   Val:   Loss=0.0692, RMSE=0.2631, R²=-0.0128
============================================================


📊 Round 378 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

📊 Round 378 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

📊 Round 378 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 383 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 383 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0056
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0082
============================================================


============================================================
🔄 Round 384 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 384 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0073
   Val:   Loss=0.0711, RMSE=0.2667, R²=0.0024
============================================================


📊 Round 384 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 386 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 386 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0051
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0125
============================================================


============================================================
🔄 Round 387 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 387 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0066
   Val:   Loss=0.0747, RMSE=0.2733, R²=-0.0004
============================================================


📊 Round 387 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 390 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 390 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0076
   Val:   Loss=0.0743, RMSE=0.2726, R²=-0.0128
============================================================


📊 Round 390 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

📊 Round 390 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 393 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 393 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0076
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0035
============================================================


📊 Round 393 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

📊 Round 393 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 400 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 400 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0067
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.0061
============================================================


📊 Round 400 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 403 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 403 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0063
   Val:   Loss=0.0741, RMSE=0.2723, R²=-0.0161
============================================================


📊 Round 403 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 405 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 405 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0058
   Val:   Loss=0.0754, RMSE=0.2745, R²=0.0084
============================================================


============================================================
🔄 Round 406 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 406 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2745, R²=0.0072
   Val:   Loss=0.0799, RMSE=0.2828, R²=0.0043
============================================================


📊 Round 406 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

📊 Round 406 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 410 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 410 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0082
   Val:   Loss=0.0725, RMSE=0.2693, R²=-0.0014
============================================================


📊 Round 410 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 411 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 411 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2767, R²=0.0047
   Val:   Loss=0.0752, RMSE=0.2743, R²=-0.0333
============================================================


📊 Round 411 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 413 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0704, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0704, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0704, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0704, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0704, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 413 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0066
   Val:   Loss=0.0704, RMSE=0.2653, R²=-0.0032
============================================================


📊 Round 413 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

📊 Round 413 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

📊 Round 413 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

📊 Round 413 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 418 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 418 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2743, R²=0.0063
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0043
============================================================


📊 Round 418 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 419 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 419 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2783, R²=0.0064
   Val:   Loss=0.0717, RMSE=0.2678, R²=0.0018
============================================================


============================================================
🔄 Round 422 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 422 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0059
   Val:   Loss=0.0738, RMSE=0.2717, R²=0.0082
============================================================


============================================================
🔄 Round 423 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0694 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0694, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0694, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0694, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0694, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0694, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0694)

============================================================
📊 Round 423 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0066
   Val:   Loss=0.0694, RMSE=0.2634, R²=0.0068
============================================================


📊 Round 423 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 427 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 427 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=0.0085
   Val:   Loss=0.0788, RMSE=0.2808, R²=-0.0005
============================================================


📊 Round 427 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

📊 Round 427 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

📊 Round 427 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

📊 Round 427 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 431 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 431 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2774, R²=0.0068
   Val:   Loss=0.0736, RMSE=0.2713, R²=0.0013
============================================================


📊 Round 431 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 432 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 432 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0056
   Val:   Loss=0.0732, RMSE=0.2705, R²=0.0083
============================================================


============================================================
🔄 Round 435 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 435 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2750, R²=0.0056
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0084
============================================================


📊 Round 435 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

📊 Round 435 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 438 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 438 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0049
   Val:   Loss=0.0751, RMSE=0.2741, R²=0.0100
============================================================


📊 Round 438 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

📊 Round 438 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

📊 Round 438 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 448 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 448 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2743, R²=0.0072
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0028
============================================================


📊 Round 448 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0044

============================================================
🔄 Round 451 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 451 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2774, R²=0.0073
   Val:   Loss=0.0737, RMSE=0.2714, R²=-0.0080
============================================================


============================================================
🔄 Round 452 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 452 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2748, R²=0.0084
   Val:   Loss=0.0793, RMSE=0.2817, R²=-0.0147
============================================================


📊 Round 452 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0044

============================================================
🔄 Round 454 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 454 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0075
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0034
============================================================


============================================================
🔄 Round 455 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 455 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2747, R²=0.0065
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0062
============================================================


📊 Round 455 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0044

📊 Round 455 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2413, R²: 0.0044

============================================================
🔄 Round 459 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 459 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2767, R²=0.0051
   Val:   Loss=0.0752, RMSE=0.2743, R²=0.0130
============================================================


📊 Round 459 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0044

============================================================
🔄 Round 462 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0701, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0701, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0701, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0701, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 462 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0077
   Val:   Loss=0.0702, RMSE=0.2649, R²=0.0022
============================================================


============================================================
🔄 Round 464 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 464 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0070
   Val:   Loss=0.0779, RMSE=0.2790, R²=0.0049
============================================================


📊 Round 464 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2413, R²: 0.0044

============================================================
🔄 Round 470 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 470 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0080
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0044
============================================================


📊 Round 470 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2413, R²: 0.0044

============================================================
🔄 Round 473 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 473 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2746, R²=0.0071
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0052
============================================================


📊 Round 473 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2413, R²: 0.0044

============================================================
🔄 Round 475 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 475 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2752, R²=0.0065
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0075
============================================================


📊 Round 475 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2413, R²: 0.0044

📊 Round 475 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2413, R²: 0.0044

============================================================
🔄 Round 478 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0701 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0701, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0701, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0701, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0701, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0701, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0701)

============================================================
📊 Round 478 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=0.0061
   Val:   Loss=0.0701, RMSE=0.2647, R²=0.0018
============================================================


📊 Round 478 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0044

============================================================
🔄 Round 482 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 482 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2774, R²=0.0071
   Val:   Loss=0.0736, RMSE=0.2712, R²=0.0011
============================================================


============================================================
🔄 Round 485 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 485 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0046
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0152
============================================================


📊 Round 485 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0044

============================================================
🔄 Round 487 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0745, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 487 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0746, RMSE=0.2731, R²=0.0083
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0004
============================================================


📊 Round 487 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

📊 Round 487 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 490 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 490 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0065
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0069
============================================================


📊 Round 490 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 491 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 491 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2749, R²=0.0045
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0024
============================================================


============================================================
🔄 Round 493 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 493 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0072
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0022
============================================================


📊 Round 493 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 494 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 494 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0058
   Val:   Loss=0.0726, RMSE=0.2695, R²=0.0085
============================================================


============================================================
🔄 Round 496 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 496 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0070
   Val:   Loss=0.0743, RMSE=0.2725, R²=0.0058
============================================================


📊 Round 496 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 497 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0704, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0704, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0704, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0704, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0704, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 497 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0076
   Val:   Loss=0.0704, RMSE=0.2653, R²=0.0021
============================================================


📊 Round 497 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

📊 Round 497 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 503 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 503 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=0.0046
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0147
============================================================


📊 Round 503 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

📊 Round 503 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

📊 Round 503 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

📊 Round 503 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

📊 Round 503 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

📊 Round 503 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

📊 Round 503 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 518 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 518 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2739, R²=0.0042
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0124
============================================================


📊 Round 518 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 520 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 520 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2752, R²=0.0060
   Val:   Loss=0.0784, RMSE=0.2799, R²=0.0074
============================================================


📊 Round 520 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 524 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0749, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 524 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2739, R²=0.0058
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0101
============================================================


============================================================
🔄 Round 526 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 526 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0054
   Val:   Loss=0.0742, RMSE=0.2724, R²=-0.0188
============================================================


📊 Round 526 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

📊 Round 526 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 529 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 529 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2761, R²=0.0075
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0022
============================================================


📊 Round 529 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 531 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 531 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0066
   Val:   Loss=0.0734, RMSE=0.2708, R²=0.0053
============================================================


============================================================
🔄 Round 532 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 532 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=0.0072
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0049
============================================================


📊 Round 532 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

📊 Round 532 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

📊 Round 532 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

📊 Round 532 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 544 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 544 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0747, RMSE=0.2734, R²=0.0039
   Val:   Loss=0.0825, RMSE=0.2871, R²=0.0169
============================================================


📊 Round 544 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

📊 Round 544 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 548 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 548 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2758, R²=0.0078
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0091
============================================================


📊 Round 548 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

📊 Round 548 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

📊 Round 548 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 556 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 556 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0747, RMSE=0.2732, R²=0.0067
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0071
============================================================


📊 Round 556 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 557 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0700 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0700, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0700, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0700, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0700)

============================================================
📊 Round 557 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2790, R²=0.0071
   Val:   Loss=0.0700, RMSE=0.2645, R²=-0.0117
============================================================


📊 Round 557 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

📊 Round 557 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

📊 Round 557 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

📊 Round 557 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

📊 Round 557 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 562 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 562 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0065
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0054
============================================================


📊 Round 562 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

📊 Round 562 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 565 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 565 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2767, R²=0.0074
   Val:   Loss=0.0752, RMSE=0.2743, R²=0.0038
============================================================


📊 Round 565 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

📊 Round 565 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 569 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 569 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2756, R²=0.0069
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0063
============================================================


============================================================
🔄 Round 570 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 570 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=0.0060
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0093
============================================================


============================================================
🔄 Round 571 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 571 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0063
   Val:   Loss=0.0729, RMSE=0.2700, R²=0.0087
============================================================


============================================================
🔄 Round 572 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 572 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0080
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0057
============================================================


============================================================
🔄 Round 573 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0749, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 573 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2736, R²=0.0072
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0020
============================================================


📊 Round 573 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 574 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 574 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0057
   Val:   Loss=0.0717, RMSE=0.2678, R²=0.0113
============================================================


📊 Round 574 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 576 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 576 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0071
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0051
============================================================


📊 Round 576 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

📊 Round 576 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

📊 Round 576 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

📊 Round 576 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 584 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0681 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0681, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0681, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0681, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0681, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0681, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0681)

============================================================
📊 Round 584 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0071
   Val:   Loss=0.0681, RMSE=0.2610, R²=0.0049
============================================================


📊 Round 584 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 589 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 589 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2756, R²=0.0068
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0260
============================================================


============================================================
🔄 Round 590 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0701 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0701, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0701, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0701, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0701, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0701, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0701)

============================================================
📊 Round 590 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=0.0072
   Val:   Loss=0.0701, RMSE=0.2647, R²=0.0016
============================================================


============================================================
🔄 Round 593 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 593 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0060
   Val:   Loss=0.0750, RMSE=0.2739, R²=-0.0099
============================================================


📊 Round 593 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

📊 Round 593 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 597 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 597 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0060
   Val:   Loss=0.0725, RMSE=0.2693, R²=0.0100
============================================================


📊 Round 597 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 598 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 598 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0090
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0068
============================================================


📊 Round 598 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

📊 Round 598 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 602 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 602 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0069
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0057
============================================================


📊 Round 602 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 605 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 605 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0071
   Val:   Loss=0.0726, RMSE=0.2694, R²=0.0052
============================================================


============================================================
🔄 Round 606 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 606 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0062
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0100
============================================================


============================================================
🔄 Round 607 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 607 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2746, R²=0.0058
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0088
============================================================


============================================================
🔄 Round 608 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 608 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2781, R²=0.0057
   Val:   Loss=0.0719, RMSE=0.2682, R²=0.0007
============================================================


============================================================
🔄 Round 610 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 610 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2745, R²=0.0055
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0106
============================================================


📊 Round 610 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

📊 Round 610 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

📊 Round 610 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 613 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 613 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2745, R²=0.0064
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0035
============================================================


============================================================
🔄 Round 616 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0744, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0744, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0744, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0744, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0744, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0744, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 616 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0744, RMSE=0.2727, R²=0.0075
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0072
============================================================


============================================================
🔄 Round 617 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0692 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0692, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0692, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0692, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0692, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0693, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0692)

============================================================
📊 Round 617 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0070
   Val:   Loss=0.0692, RMSE=0.2631, R²=-0.0010
============================================================


============================================================
🔄 Round 618 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 618 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0049
   Val:   Loss=0.0733, RMSE=0.2708, R²=-0.0067
============================================================


📊 Round 618 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 619 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 619 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2772, R²=0.0061
   Val:   Loss=0.0739, RMSE=0.2719, R²=0.0091
============================================================


📊 Round 619 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 624 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 624 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0062
   Val:   Loss=0.0729, RMSE=0.2700, R²=0.0091
============================================================


============================================================
🔄 Round 625 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 625 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2740, R²=0.0074
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0032
============================================================


📊 Round 625 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

📊 Round 625 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

📊 Round 625 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

📊 Round 625 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

📊 Round 625 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 635 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 635 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2758, R²=0.0067
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0053
============================================================


============================================================
🔄 Round 636 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 636 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0041
   Val:   Loss=0.0713, RMSE=0.2671, R²=-0.0045
============================================================


📊 Round 636 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 637 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 637 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0059
   Val:   Loss=0.0718, RMSE=0.2680, R²=-0.0081
============================================================


📊 Round 637 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0042

============================================================
🔄 Round 640 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 640 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0055
   Val:   Loss=0.0787, RMSE=0.2806, R²=0.0112
============================================================


============================================================
🔄 Round 641 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0690 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0690, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0690, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0690, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0690, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0690, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0690)

============================================================
📊 Round 641 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0074
   Val:   Loss=0.0690, RMSE=0.2626, R²=-0.0158
============================================================


📊 Round 641 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0044

============================================================
🔄 Round 642 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 642 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=0.0050
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0036
============================================================


📊 Round 642 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0044

📊 Round 642 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0044

============================================================
🔄 Round 645 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 645 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0070
   Val:   Loss=0.0733, RMSE=0.2707, R²=-0.0036
============================================================


============================================================
🔄 Round 648 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 648 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0063
   Val:   Loss=0.0734, RMSE=0.2710, R²=0.0058
============================================================


============================================================
🔄 Round 649 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0650 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0651, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0651, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0651, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0651, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0651, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0650)

============================================================
📊 Round 649 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0071
   Val:   Loss=0.0650, RMSE=0.2550, R²=0.0051
============================================================


📊 Round 649 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2413, R²: 0.0044

============================================================
🔄 Round 653 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 653 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0069
   Val:   Loss=0.0723, RMSE=0.2689, R²=-0.0048
============================================================


📊 Round 653 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0044

============================================================
🔄 Round 654 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 654 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2761, R²=0.0087
   Val:   Loss=0.0763, RMSE=0.2763, R²=-0.0006
============================================================


📊 Round 654 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0044

============================================================
🔄 Round 657 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 657 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0081
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0001
============================================================


============================================================
🔄 Round 659 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0745, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 659 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0745, RMSE=0.2729, R²=0.0048
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0005
============================================================


============================================================
🔄 Round 660 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 660 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0082
   Val:   Loss=0.0746, RMSE=0.2731, R²=-0.0023
============================================================


============================================================
🔄 Round 661 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0687 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0687, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0687, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0688, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0688, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0688, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0687)

============================================================
📊 Round 661 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0060
   Val:   Loss=0.0687, RMSE=0.2622, R²=0.0006
============================================================


📊 Round 661 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 662 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0690 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0690, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0690, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0690, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0690, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0690, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0690)

============================================================
📊 Round 662 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0059
   Val:   Loss=0.0690, RMSE=0.2626, R²=0.0104
============================================================


============================================================
🔄 Round 664 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0666 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0666, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0666, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0666, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0666, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0666, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0666)

============================================================
📊 Round 664 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0051
   Val:   Loss=0.0666, RMSE=0.2581, R²=0.0145
============================================================


============================================================
🔄 Round 665 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 665 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0067
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0009
============================================================


📊 Round 665 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0044

============================================================
🔄 Round 668 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 668 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0060
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0067
============================================================


📊 Round 668 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0044

============================================================
🔄 Round 669 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 669 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0037
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0043
============================================================


📊 Round 669 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 672 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0662 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0662, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0662, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0662, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0662, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0662, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0662)

============================================================
📊 Round 672 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0039
   Val:   Loss=0.0662, RMSE=0.2573, R²=0.0196
============================================================


📊 Round 672 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

📊 Round 672 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 675 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 675 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2765, R²=0.0059
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0097
============================================================


============================================================
🔄 Round 676 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 676 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0076
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0038
============================================================


📊 Round 676 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

📊 Round 676 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

📊 Round 676 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 681 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 681 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0040
   Val:   Loss=0.0762, RMSE=0.2761, R²=-0.0045
============================================================


📊 Round 681 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 683 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0696 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0696, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0696, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0696, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0696, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0696, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0696)

============================================================
📊 Round 683 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2792, R²=0.0057
   Val:   Loss=0.0696, RMSE=0.2637, R²=0.0114
============================================================


📊 Round 683 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 684 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 684 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0064
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0082
============================================================


📊 Round 684 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

📊 Round 684 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 690 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 690 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0080
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0024
============================================================


📊 Round 690 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 691 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0749, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 691 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2739, R²=0.0060
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0013
============================================================


📊 Round 691 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 693 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 693 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0054
   Val:   Loss=0.0737, RMSE=0.2715, R²=0.0107
============================================================


📊 Round 693 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 694 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 694 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2743, R²=0.0075
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0039
============================================================


📊 Round 694 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 696 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0707, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0707, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0707, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0707, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 696 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0066
   Val:   Loss=0.0707, RMSE=0.2660, R²=0.0071
============================================================


============================================================
🔄 Round 697 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 697 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0056
   Val:   Loss=0.0774, RMSE=0.2781, R²=0.0100
============================================================


📊 Round 697 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0044

============================================================
🔄 Round 700 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 700 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2765, R²=0.0091
   Val:   Loss=0.0756, RMSE=0.2749, R²=-0.0226
============================================================


============================================================
🔄 Round 701 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 701 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0047
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0082
============================================================


📊 Round 701 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0044

📊 Round 701 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0044

📊 Round 701 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0044

============================================================
🔄 Round 705 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0650 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0650, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0650, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0651, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0651, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0651, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0650)

============================================================
📊 Round 705 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0075
   Val:   Loss=0.0650, RMSE=0.2550, R²=-0.0000
============================================================


============================================================
🔄 Round 706 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 706 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0070
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0063
============================================================


📊 Round 706 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0044

============================================================
🔄 Round 711 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 711 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0052
   Val:   Loss=0.0787, RMSE=0.2804, R²=0.0133
============================================================


📊 Round 711 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0044

📊 Round 711 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0044

📊 Round 711 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0044

📊 Round 711 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0044

📊 Round 711 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

📊 Round 711 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 721 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 721 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0070
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0062
============================================================


📊 Round 721 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

📊 Round 721 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

📊 Round 721 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 725 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0675 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0675, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0675, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0675, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0675, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0675, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0675)

============================================================
📊 Round 725 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0069
   Val:   Loss=0.0675, RMSE=0.2598, R²=-0.0059
============================================================


📊 Round 725 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 727 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 727 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0062
   Val:   Loss=0.0744, RMSE=0.2727, R²=0.0086
============================================================


============================================================
🔄 Round 728 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0746, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0746, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0746, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0745, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 728 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0745, RMSE=0.2730, R²=0.0059
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0094
============================================================


📊 Round 728 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 729 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 729 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2754, R²=0.0031
   Val:   Loss=0.0779, RMSE=0.2792, R²=0.0071
============================================================


📊 Round 729 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 731 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 731 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2761, R²=0.0056
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0016
============================================================


📊 Round 731 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 734 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0739, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0739, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0739, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0739, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0739, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0738, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 734 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0737, RMSE=0.2715, R²=0.0059
   Val:   Loss=0.0865, RMSE=0.2940, R²=-0.0002
============================================================


============================================================
🔄 Round 736 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 736 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0051
   Val:   Loss=0.0731, RMSE=0.2703, R²=0.0074
============================================================


📊 Round 736 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0043

============================================================
🔄 Round 738 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 738 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2742, R²=0.0083
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0034
============================================================


============================================================
🔄 Round 739 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0737, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0737, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0737, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0737, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0737, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0737, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 739 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0735, RMSE=0.2710, R²=0.0057
   Val:   Loss=0.0875, RMSE=0.2959, R²=0.0046
============================================================


============================================================
🔄 Round 740 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0707, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0707, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0707, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0707, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 740 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0049
   Val:   Loss=0.0707, RMSE=0.2659, R²=0.0089
============================================================


📊 Round 740 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0044

📊 Round 740 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0044

============================================================
🔄 Round 746 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 746 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2748, R²=0.0055
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0121
============================================================


📊 Round 746 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0044

============================================================
🔄 Round 751 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 751 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2746, R²=0.0071
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0050
============================================================


📊 Round 751 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0044

============================================================
🔄 Round 754 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 754 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0067
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0066
============================================================


📊 Round 754 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0044

============================================================
🔄 Round 757 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0743, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0743, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0742, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0742, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0742, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0742, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 757 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0741, RMSE=0.2723, R²=0.0064
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0013
============================================================


📊 Round 757 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0044

============================================================
🔄 Round 760 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0706 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0706, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0706, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0706, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0707, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0706)

============================================================
📊 Round 760 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0063
   Val:   Loss=0.0706, RMSE=0.2657, R²=-0.0088
============================================================


📊 Round 760 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0044

============================================================
🔄 Round 761 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0715, val=0.0948 (↓), lr=0.000001
   • Epoch   2/100: train=0.0715, val=0.0948, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0715, val=0.0948, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0715, val=0.0948, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0715, val=0.0948, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0715, val=0.0948, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0948)

============================================================
📊 Round 761 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0717, RMSE=0.2677, R²=0.0064
   Val:   Loss=0.0948, RMSE=0.3079, R²=0.0047
============================================================


📊 Round 761 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0044

============================================================
🔄 Round 762 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 762 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2748, R²=0.0059
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0042
============================================================


📊 Round 762 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2413, R²: 0.0044

📊 Round 762 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2413, R²: 0.0044

📊 Round 762 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2413, R²: 0.0044

============================================================
🔄 Round 767 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0698 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0698, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0699, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0699, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0698)

============================================================
📊 Round 767 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0069
   Val:   Loss=0.0698, RMSE=0.2643, R²=-0.0112
============================================================


============================================================
🔄 Round 770 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 770 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2736, R²=0.0087
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0012
============================================================


📊 Round 770 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2413, R²: 0.0044

📊 Round 770 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2413, R²: 0.0045

📊 Round 770 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2413, R²: 0.0045

📊 Round 770 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2413, R²: 0.0045

📊 Round 770 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2413, R²: 0.0045

============================================================
🔄 Round 780 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 780 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0068
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0057
============================================================


============================================================
🔄 Round 781 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 781 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=0.0076
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0065
============================================================


📊 Round 781 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2413, R²: 0.0045

============================================================
🔄 Round 782 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 782 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2740, R²=0.0018
   Val:   Loss=0.0810, RMSE=0.2845, R²=-0.0735
============================================================


📊 Round 782 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2413, R²: 0.0045

============================================================
🔄 Round 783 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 783 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0056
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0101
============================================================


📊 Round 783 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2413, R²: 0.0045

============================================================
🔄 Round 784 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 784 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0047
   Val:   Loss=0.0767, RMSE=0.2770, R²=0.0152
============================================================


📊 Round 784 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2413, R²: 0.0045

============================================================
🔄 Round 785 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 785 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2739, R²=0.0078
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0025
============================================================


📊 Round 785 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2413, R²: 0.0045

============================================================
🔄 Round 786 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 786 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2761, R²=0.0064
   Val:   Loss=0.0764, RMSE=0.2765, R²=0.0088
============================================================


📊 Round 786 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2413, R²: 0.0045

============================================================
🔄 Round 789 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 789 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0083
   Val:   Loss=0.0717, RMSE=0.2678, R²=-0.0006
============================================================


============================================================
🔄 Round 790 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0749, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 790 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2743, R²=0.0073
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0046
============================================================


📊 Round 790 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2413, R²: 0.0045

============================================================
🔄 Round 795 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 795 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0057
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0067
============================================================


============================================================
🔄 Round 796 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0664 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0664, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0664, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0664, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0664, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0665, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0664)

============================================================
📊 Round 796 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0049
   Val:   Loss=0.0664, RMSE=0.2576, R²=-0.0003
============================================================


============================================================
🔄 Round 797 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0745, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 797 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0747, RMSE=0.2733, R²=0.0061
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0090
============================================================


============================================================
🔄 Round 799 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 799 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0076
   Val:   Loss=0.0758, RMSE=0.2754, R²=-0.0159
============================================================


📊 Round 799 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2413, R²: 0.0045

============================================================
🔄 Round 800 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 800 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2765, R²=0.0058
   Val:   Loss=0.0756, RMSE=0.2749, R²=0.0039
============================================================


📊 Round 800 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2413, R²: 0.0046

============================================================
🔄 Round 802 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 802 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2749, R²=0.0055
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0121
============================================================


============================================================
🔄 Round 803 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0746, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0746, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0746, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 803 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2736, R²=0.0070
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0062
============================================================


📊 Round 803 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2413, R²: 0.0046

============================================================
🔄 Round 805 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 805 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0061
   Val:   Loss=0.0730, RMSE=0.2702, R²=0.0046
============================================================


============================================================
🔄 Round 806 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0744, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0744, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0744, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0744, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0744, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0744, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 806 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0743, RMSE=0.2725, R²=0.0076
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0046
============================================================


❌ Client client_21 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_status:14, grpc_message:"Socket closed"}"
>
