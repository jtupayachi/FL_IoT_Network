[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d651e1d3-db53-4369-a427-147fa5368e7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 755ca286-6cea-4430-b2a3-dd93cf604e95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ee0eb3b-e663-4655-95bd-ffddc79ca249
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3092b5d9-4abe-4964-8c01-8f9467d3086a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6da9bced-f9bc-46ea-91f6-144516725af5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0ad81ce-2896-47a1-b199-4d620362d1a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06ef7fd8-5f21-4f72-85f5-0be1008bdd2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dba82361-2be7-47ea-b1fc-a4cc017dff05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd24db3a-06d6-4bc4-b20b-af238d114ed3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94f76d63-b184-4da4-894f-2caab8d6c14c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8dddb0b7-b578-48db-8eb3-cdb9bb3ca2f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75fdc8c2-80ab-4e2b-a45e-514ecbd54262
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c9cfd35-0e0e-4de3-9b45-76c27f020985
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b97b87b9-2474-46a3-a22c-7cbce97be0ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f162e47-472e-48c8-b1c7-dd55e7a04e2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e680620c-6d8a-47e5-9494-323894dc6b87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd2d0c81-c81e-42cf-aaa7-dd57c5f6447f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45748032-d9d7-4c4a-8237-c804a2821d82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffc8b8b2-905f-4972-9e48-ae73d9870310
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14bf12fe-ae29-49c2-8dbc-61021e776f12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b54b2999-63b1-4c1b-9e13-ba94e783d30b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16f1f698-1bb6-4f21-825f-fabe1efe0311
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96d4ae7c-fe09-4550-a5df-52d63777c261
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db42b2b3-928a-4179-8b54-8a65c057613f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cc2e0e6-0243-42a8-bdd2-54ba31c19819
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f47033b-19b4-4d1e-8de9-15926240661f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5dd3d366-0898-41ef-97c6-008096702680
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e30d39c-be56-4f9c-b31b-3e0f75e0ac73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4e3af00-fd20-4855-8ddc-0d58ce663a35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8f30039-b83e-4007-b98c-649326c2bd26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b40ed58c-27b1-4a85-9cc9-c28f14becddd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b88139e-68c5-40da-8d96-b7400194e231
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52abf885-70dc-4e5b-b560-f95e5c165f22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a02a5989-26a6-42cc-92ce-3300022f631e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4fd3d56-7ac4-409f-8a2a-623c6ce38860
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bbfdcde-eab0-4db3-9690-e1d7b801cc54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60e8e64d-7b74-4b1a-abb5-a6f281261fb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7965780f-75d3-4b6a-bcb3-08dbf7cf41ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bdf89dc-fd43-42a3-9561-cc14c6f6525e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message effc386d-6ee2-49bb-a3ca-8ce8e1326c94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ecfda47-11de-404b-af51-0f49b742b418
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8da0fcb9-48ad-441a-b77e-8cf37a30e1f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bafa4af-8aa2-49d4-a0d7-e295dba6710f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 513bb5a5-cb12-4896-8877-926731cb6988
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f9584dc-1e82-49b8-8153-9e327623a007
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20117831-bd43-4daa-87b1-0b032698cb17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 229c5282-316b-4a93-882d-840d0cb614c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec44bd36-0ff1-4f26-8714-4db98901c236
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a32b996d-1f19-4aa4-a866-0756e2fa8d1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7f11001-cbc6-4332-9afd-5ecc33df371e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 800d3d69-7ebe-4921-b8ec-e5294b48e599
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b2d0201-eafc-4cae-b363-c78b3a4bdd86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e95f9868-ac52-4f85-bb57-1640f31c7fe5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f80056b5-6521-449c-95a2-f21f746e6098
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df40152c-6317-41a7-b1ba-31e1b7f78ce2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb0f50f3-fac0-44e8-bbe4-419d858c749c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fddbd72-0864-42d2-ab0f-6643a6e90bcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb5d3319-2546-43ea-89ed-262222e4592f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1cdb149-e405-4631-8f1d-b7abd9eabd0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d291d4db-8be3-42ed-9bd9-01807287dcec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cc4c62d-1560-4bac-ba86-bed9fb2aed46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7d18ea5-d780-4f5c-a442-db350d968e8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e46735a-f9d4-4157-b168-1b38317d75e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90e5dda6-6ae9-4fda-b44d-c208e15182eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 748c7831-6c6f-48c3-ab65-24c0782b5611
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2710e218-f4a0-4fbd-99bf-672e44d5cf42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c53f3555-16de-416f-866c-6f55ee1d00d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e749d16-5a14-48c9-b9d6-fca61372a0ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0cb6ceb-2820-4529-891b-8c533ebac12a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fe97d54-b158-4f2e-bcda-0eea91fd46fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc5ac1f1-4510-4228-8f89-13b2066f6875
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a72531e-3d75-4bf4-bcbe-ebf40c86d24f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9d6248d-166f-4131-b984-8508dcf347ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18a2ad0f-bd80-49df-97c8-2b827fc65339
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee9afbd7-9ce1-4c44-baaa-63787c25e230
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd45fa24-7b9e-4741-b929-3c39cf066b5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5918e13-6604-43ab-9c1c-1420bc46e12f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65b6209f-1b3f-4bae-979d-7b33abaec8be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 059b235e-d5be-4c72-a227-019738a34c39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb3159ba-e3a0-4785-aa4e-3376c6655cff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16d7000d-9d13-41ff-a2ee-fc00e857aa10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 634e3d75-f889-4adc-88b0-7204a936e600
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bdc44a18-40d6-4bfd-9387-d1e41a21fc64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9093c768-4de0-4627-8dbd-47e81539e407
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b05514c8-ba43-47c2-a995-80788ff38edd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f50b1bc-feae-40c1-ba07-88584462e39d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dcaa4ee9-9e16-4d9f-b11d-d58efcf9bdb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bef854ad-7b2b-498b-9ce2-eff81a1a3288
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d9a9d88-5df8-43b0-b2bf-3ae676aa128c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 963d7b97-fc2a-4c39-961b-2f4b489d7400
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 827f38b2-2a51-4b04-9150-44f7d960d411
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31c3485c-fcf4-47c6-9acb-b924ba519e66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74aff2d7-95ef-4148-be9f-4db37dd38979
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fd86320-02fb-476e-8208-f251172b5e69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5e67c4d-9adb-45e6-9e9e-75a67bd22caa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b883ebd-d8a8-494a-91bd-e0853dd54d00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd971e80-127d-4e39-827e-a1b609021711
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59024350-2310-40bb-9017-b6f3ddf5aac3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03d3709e-057d-4f5d-af3b-a3f748557170
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dafd25bc-7eb4-4d55-9d7a-9ea17be2358a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a41543bf-6b4f-4c9a-9c48-b2c8715248c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 651add6c-9d76-4a72-8a5d-3d1936dec835
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 026a32be-58c0-4b92-a495-cb3f18f535d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a06e58b4-2b38-4815-ac15-2ea820c03d00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1e76525-6ba4-49e1-a092-346f11a82cf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb7633c4-f56b-4cb0-b18c-d0e37c08e13e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92ab5732-191a-4edb-a023-5fdfec695056
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d77ae74-dcbb-41af-94af-edad512e28a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b9766d6-f56c-4af7-9b6f-f169af6cf5dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ece6ae7f-ee8d-488b-8e71-7e2230080ae6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed30022b-c640-45e9-9146-2549b220532a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f815f241-5c35-47dd-90bc-5219aaeeba1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eba27bf7-b204-4af3-b2bf-393936ac67da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01af38e1-5adf-40a5-aea5-7e442fec8292
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99f1cb20-0c24-4fc7-9e4b-e61315486feb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0db343ad-6073-400e-94d7-60064b081de3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b838d79d-7b8b-4784-93b4-eaf7a0a73927
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35948152-6dcc-42ef-a9d9-a99921b35be5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17413109-0f1a-483a-a182-ab2c7a733cd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a364aa3-14b6-4d07-9520-1b4e9a96a081
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7f2c1ac-f3d5-4f49-bca3-422c2905f78a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e55b78e-2f01-4fe5-976b-e59fde094bee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f53d99a-8869-4fa4-bb0e-91c70e3c76c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53d1cb4f-298b-471f-bdd5-0334ba4078ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d7898e7-a5a0-40ca-9074-24184b9046fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f821559-f3dd-4907-a299-2978f59b2a01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12201e11-47a1-49b0-a9f7-a140434e6e3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f458e0e4-c408-490d-a6fd-133a32ab2bad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13045610-178e-471b-8065-b95be4647ddc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f52bb44-2c67-40f6-a142-b8541cc23a5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93bce6dd-acf8-4b0f-98c3-abd07a0c8ba7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d93ce838-793c-4190-ac5c-91318e03872b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bbbc4b8-13a9-4231-98ec-3102ab58b73b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e4e5f8b-644b-4874-b7ae-90a9260666a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03fdd466-aaaa-4f86-bccb-b6adb214f3eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81632020-d8ee-4a43-9c2f-9bb1f6bbda62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee872c51-7c45-4683-aba7-23d04745e955
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6615a60-aef9-4300-aaf0-c061b0484ca6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8572c19-132b-4064-a7d0-b29dcddd5581
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be3bea21-76b4-481d-832f-e099b69b660e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93c9e8aa-5b5b-4aee-b19b-2a563546dddd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a4f962a-ebac-4e4a-89b0-8fc37dd14f47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7e6ad7d-b9c5-43cf-be94-aa3917a4ff5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61c4ebef-0206-437d-aa63-7eaf38032065
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12d94fc9-738b-4e3e-b309-6697ce8ce5a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f20c176-3cef-4d49-9b9b-67a6b41e3952
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33df13a5-f85d-44f2-b7fb-51d4fbecc530
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9577b21-2e76-4f52-b704-61c1c7f062c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4087aa65-6acb-4e2f-b117-e0d8bc964550
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 742d5264-1e5e-4429-ba14-90c759b5c2b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff484761-e74d-42bb-b399-75dc1bc32a70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a999221d-22f8-4371-bd10-8564291227de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11258201-3699-4fc3-8c65-bad550a3238f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e75cf1af-732e-4ff6-b345-e7a4e9122bee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1f2e429-e889-4041-9912-6ca6a7d03707
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee455bbc-838e-431f-a3b0-6b5fc7dfc347
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e714703a-9dc4-4d82-abb3-88e70f60735c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ca9e0b9-565c-411a-9d1e-06b6e0a781b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2531786f-393b-46d9-8ade-4a8e57950552
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09abb131-ec0b-419f-8bf4-f9409f7ed3d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db55860e-d522-4698-9fda-7ebe2b183a4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2ca24b4-94ae-4a68-ab96-5721886a2aaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6aed83f-ca8c-461b-9c1d-0764e46ff4ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ece2fffc-9127-42d2-9481-0b2e2a009ed3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fa2b47f-24ee-41df-8844-e7b341f88f44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ceb6880-bcb8-46f9-a22d-dc76811eea9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c8bf14b-f6f4-4beb-83a8-c62582672683
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea16022e-3c0e-4b53-9c58-bd06f659ceab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d3e62a3-5d03-41ea-80db-60d0debd8709
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05a9359d-7dfe-4288-8952-b5c93761f8d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d00289d-4e48-4b54-b735-00da0a687901
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36a9e543-b8be-49d3-84a4-a3fdd2d99142
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 311cdc0c-f591-47e3-8e2a-a740af5c181f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f76771fb-09fa-4982-bdba-ef7474851fb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8eb3bb6-2a82-4646-b4ed-1937e25c5b43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72366d1d-d0bc-4c36-94cf-e43aee0b23d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c127e4a6-0c7e-40f8-bb8d-2301f39891b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd4a2d12-7aa5-469f-b7a3-86b56e631408
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27ec49d2-8b9a-49a5-8444-b3f816f9a9d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 921e504e-4e5d-4450-9ecf-f8cf173f4d2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c09400fb-9b9f-40f9-97d6-0f736f17e3d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6887e759-f396-4c62-8ff4-58260473a740
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46bfe0e5-516b-4f1b-aea5-9a1d345c2032
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25414663-0678-4098-bd9f-3ebdf101620a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e0ec869-fd4d-4d0a-a13b-ae35eb4bc616
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e860242-9e12-4720-b8fb-e42b84730b34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfe5f453-1636-417c-88ca-4aba75a46329
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f58cd4c-c7f9-4d85-84be-0631f073fd37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16445d9f-fba2-44d2-a583-894d243ee5d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71c01292-c8ac-424e-b37d-74de9ae1fe41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 101e63be-8f8c-4a1d-9512-ecf164f64f28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5fb6202-5dd2-4d93-a854-6c2fb809cebb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5d7aed1-1063-48a1-afbb-445dcbaa2c93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c552542b-273e-472f-bc91-0ac1b6e67dd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19529672-c080-49c2-8471-b25c08305cc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10d911b0-faeb-490b-b6b5-1cc6423af52d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ecbf9270-4521-4d43-9521-dafe2b52622f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4bd4386-9651-4481-9976-d5a39276543e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 056e0b2d-0a9a-4c2e-a64f-1de26c3e5105
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44ec5cb1-a02c-4877-9c6b-5aa6212a96ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99eec28e-326b-431f-81c4-c586d7cdd26e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c6149cc-5281-4d51-a116-d7910b7e4db4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77d72889-ce34-4932-880d-d722624d18f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7996eb2-1b46-4b76-8266-3e746c1b57d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4e62000-e013-4462-8a66-2421fe665ce8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e37c5b4a-876c-475d-9c01-11b5ae781fa3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0c5a907-a9a2-44d0-bc8b-dc039901b548
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ebc762d-2309-463a-81ab-320f536d8fd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ed5b0f5-70c6-42b5-aabd-9fd70c1e3fff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0a2cb33-2163-4f6e-a0d8-bd29b4019a39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49b1d5f7-7e81-4d2c-a43a-afb67d02cb4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 333043e2-63ad-4b68-99ab-10e8406981a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8b38d9b-2aa6-4822-99da-661405a3b4bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa83b81f-f845-4d18-84ad-436f45389335
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3af1689c-9326-4c59-be63-e409064bef2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84d28a03-1b85-40f8-9ab7-8c7fb08f0fda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea485c6e-60c4-4680-b1d2-c8c120efdead
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41465d24-c39c-4f65-9a2b-11272a6dbfcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6922c6d5-3a27-4cfd-9be3-56a1a37b59c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d18c7278-567d-42e6-94b0-67785a26f2c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9382880-60a1-489e-9ac5-a811852c2334
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d3a5647-f42e-480e-8ac6-f933b18f8d69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9eaf2d05-f841-4f37-9dd9-e24f491c8d20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 900b8fb8-d856-4e54-af44-8c84231687f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4140542e-6f1c-4167-b0d8-c346f57f7221
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 015b1914-e3b4-4ca0-96c3-1dfed1a9b530
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 581bf16d-64dc-4b57-b605-6b6073aefe12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6524e089-eb90-4be2-9c86-4390b5e2b7c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2a728b6-8234-428a-987f-eee928b6b03c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 192eb4d9-fef1-460e-b171-b69f08b1af45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf95bf5b-f676-4f58-8e92-e3c76ed741fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d023941-028c-402e-a66d-bf8121beba05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40697505-bbe3-49cf-869c-c6fb923c5452
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8cbc7fad-092c-46f9-8c0c-5dc1035ecb4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef5d1cec-1d67-429e-bb57-9fdb6d8bdfc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b20c4dc-ef67-44f5-8f5e-00dec5116770
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ec21126-9f43-4959-ae46-b9c1657704d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bf5c1d8-287c-4a21-9096-d2dc50bad613
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b87c78e1-68de-46db-9d9b-f72145815ca2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 862841a7-b8c2-4ef7-9d5e-583014af317a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f198e6f-08a1-4ee7-bd62-239057166b2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53977d89-45e4-4f22-8478-d7599c52f9ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 617aedd1-25d6-4a52-939c-e58664f5e246
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c29de5e1-2cb7-4499-9abb-5d822d961dff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b86e26c5-4bf0-4019-a5ee-c7edc1bf6c3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c021546c-6d4a-4a08-8cf8-c6204a72ebd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf11568e-8431-44a4-b15b-38c118c20059
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 654a7df6-96a4-4833-9aae-2cbb8ce92092
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0cffeee-82eb-40a1-83c7-9f4e469d2a60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 593405fe-f964-473f-a60b-d4e9492ab389
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 319fb284-0c32-4a3e-9df6-e265c794b77f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c50de7e-a281-4c43-af0a-5155bd924694
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59cd9b09-dd05-4454-96c6-0bfeec00bb60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d2ab592-30b7-4a61-b69b-33cda4ace28a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 399290b8-ad31-4fa0-8c35-9cdbf266b627
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9569793-79ea-44f9-a9c5-e622692e027e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf9bb7c5-00f6-43c0-97ad-a348223e7d15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3b9b4f3-d0cc-40b5-b119-5ae42e3a953e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7468de7e-f8cc-4fac-9606-0351f446f9eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1067b504-2670-4bfc-b556-b04211918bf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 063b8f23-d806-48e9-8b07-ed86ae3095a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62825d34-79c1-4251-b2d8-6b5b163010c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e2c6d19-8849-44d1-9b11-e3ddd120d8cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76e919fe-7a3f-41ca-852c-8c0d31a56bcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b79018c-bd0f-4835-a3a9-3a4f19e9bc7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95d95167-3a87-41e5-a99e-c3f7eae2a9d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f032ef6b-91cb-4a85-9c3a-68e484e5d1f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4e548ed-af80-48b8-a6b4-e088f7c311c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64227e5d-16ad-4b76-a84e-568d745084ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e54d5076-210e-4f90-bf92-e7a0aa41af61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de6413c7-bdbd-4fec-9a6b-060d7aa8c32c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63923d16-1e1b-4ffb-93c6-6126389b0e37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a984d3ae-3836-41be-ba84-45ab00b3f791
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de05da44-c80d-47c5-bdbc-05bd1bfed96c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02743b24-75c0-4fc9-b3bf-f9287a888bb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f370ee28-8909-4740-891c-7f947177db6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4fa022cc-9eda-44b3-814a-e1b1ceb4aed6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7559622a-ec05-4ce7-99a7-226b166ffaf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfaa8503-add8-41bc-a899-57104cf246c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ed9abec-eb9c-41b3-ad53-7cf26793341b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c949dc74-9f25-46de-9e56-cfd96cff6700
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 478a3cfa-d55e-44cf-a4f8-1d1d73544b46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a75ca59b-a857-477a-895c-b4951a282693
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5516930-0531-43b8-ae21-ea904f875791
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd6d7485-4904-41bb-8138-57b117c9231c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67209616-a8ea-44fb-aa80-ff56085272af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d7b69e4-0a67-47f8-86f5-b834d62ec2d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fde67eec-66a2-42ca-a026-6ad8b943df32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 782ad2ab-3019-4d41-b517-2e93982a7b6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36b92657-7c47-4899-a97b-ca72e505d214
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f59d143-ce1c-41a7-9579-f4dd21388e66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe554892-1f74-4821-91a9-17856fa897da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5931b1a9-ab36-42ae-971d-72a4ac75cc9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb97fc5d-ac40-4dac-88ac-564705e9312a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92d51253-f519-4a1d-ace7-2d81d114b938
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c40e0834-57a2-46f0-86e1-02cabf24f7b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e3dbf15-983a-430b-ad59-1532efbeadda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2009925-5244-46f2-a1d3-d9ced9d0ae37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a4a1b65-1364-4720-97d5-dd78c424f28d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fb0c662-b56a-46de-a5b3-d3de41e273b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f8ac025-31e7-4f11-9d70-70fdfc335af6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a192f163-eee4-4d4a-a1c2-ac372d255003
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cd88101-95cc-4dbf-93b1-96fbaa680886
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c12538d5-f305-4530-9124-dc5a8986ef11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae928a9a-3b8b-48eb-9646-e059e790823a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4159221a-b14a-4068-a345-9024883a7f7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 586da905-06ef-4bec-bf20-4ebd0abc7ad3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c09ad15-9529-4473-9a66-c7af95b3c085
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f35361e-5742-4646-b842-08e058b3dfe9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c2c0e7c-9cf2-45fa-baa6-60656f11a8e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aeab830d-911f-4cbb-90c7-44f0fa769598
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c2ed856-3ef2-4a2d-a359-a6eb46fc57c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98eeed60-68b8-4701-b66c-460ea2e164fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 102b666d-ae68-48f5-9a1f-5577efa0d217
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf68243b-baec-4313-8ca5-76dd1d3c506b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8bad39b4-a2b7-47f2-9ede-c811b2c3b7b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 018f2b3e-7e94-43ec-b0f4-cc539c2d100d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 141ce5fb-23fc-4181-b04b-5349bd088ec3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 556fced4-bd7a-41ef-8c53-9df7d81af5ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7cf4a474-00b9-40b7-a5fa-1349382e64e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b514a3a3-5cb1-4600-a61c-bfb7f4eb7494
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26c5c490-3870-4c54-b9bb-81fb323360f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9c8d262-2f87-4be3-b4f2-3cd93b99fab5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8df79c8c-bb2f-4451-a42e-ab533f5e5c34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e65139b-0923-4a1d-87a2-d0967928461e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 486c215b-1842-424b-832d-37e96acaa6d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f27a0280-6684-4cb0-a7f2-ec0f01aaf5d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81ad1f9f-1452-4342-83b7-28bf4b003924
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06091015-5024-401e-ae76-b4bdaa8d2ada
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30f88e8a-1206-438f-a7fe-6577d943e134
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75571200-2088-4440-ba8b-2a0f60bcf1df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 485dfe2b-2b6d-4078-a8ce-fd936615e36a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c728e39f-79fa-49af-b5d3-54a2a05f592c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83ccb77a-81eb-4a8f-9d3a-24d4fe0a9def
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81624a70-8596-4f39-a6d4-a85d10f1602c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac9e1093-53c2-4d86-a2d7-0f427908a253
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e705c485-4041-4503-be7d-20aca62498cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59320396-b55f-406e-949c-14cdff674f42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82c593c8-6aa2-46e9-91cf-dcc8ef133d4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a827873-8633-4387-8b69-37026bcf7968
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97657414-8758-46a8-b5b3-9b2bdebfbb20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 585581d9-ec19-4590-8ccb-7b906df706f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f2f07f4-5e5b-4ea4-95e9-ad8073708e60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e3b32ff-2086-4a7b-8f27-d595e85f6cdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95b99eb0-211b-4ee6-936f-d80b2d1d2f4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9762995e-81c6-421e-983a-48b832e395e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a89198a0-b648-4d6b-a82c-af5d08a98f92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9192e692-44d5-4041-9ba6-352dbab7e51c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d40d98cc-0eb4-465f-bdd7-ae96fb85fcc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e38fae39-01d5-4903-bbfd-5ac45abb3769
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99f67ec7-f61f-4efb-b8ca-7d69fc33e9ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b4e4b8d-3d6e-4130-a2c6-8c4cc1eb788c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73a10d01-d457-43f5-a70d-9dc2a983bd17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06f55ec7-dbfe-4b03-8251-6b8bf6769bd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62f97a9f-b5ac-4109-a0fa-762a653d359f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b0af4b1-53fe-4680-a8cb-c86c7f39d168
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22636eed-0a2d-4a10-93bb-8c4ad688e87c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9e3ed6f-5779-40b3-9772-a52424a6536d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9afd027-0d84-4cde-9eef-725d8887a98b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 658157ff-b3da-4f19-9d24-c79deadc1a48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63438346-0ff2-4755-a161-1aabb3be1bd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 549f5b31-4fac-4adf-8f71-d07877c58ac8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c351dac5-b9e0-4aa2-99c0-c5c6a0fba581
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d56aa617-bc47-496a-9161-07d8332e8021
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aba85557-23a0-4ee3-b8ac-fac6ca6fdfba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0cb28aa-ce3c-4c7d-8265-914e5f075bff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d7e85af-e2a6-4065-8bd2-99a6cec55f6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d76286e-b50f-4fe9-b4b4-2de15b6fba71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0398db43-49e5-4045-b81a-50659b378a2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40027b2d-0589-4034-908f-2bc4d198c21c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a5083ea-80cb-4045-afee-83b9506d097c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69ab7559-8d12-4201-bfb2-08b87b5dfc44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b577037-efb9-47df-b0a8-a43ec51b04a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 640b49fb-ba72-46c0-b033-2d181d8b5f42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a5090c4-d4fa-4fb1-b0fd-b07665b6c288
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bd2f803-fbd2-4453-b619-823e0879b1dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91928fe9-d3f5-402b-a188-5b1ed3dc27e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ddf9e33-1d1e-4fde-801f-88c4564c2d29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e663673e-889c-4fd9-b71f-9ecead6fb42c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bef1402f-b88f-492a-a814-ba1baa3a9f27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fafec7f2-35ee-4a43-896f-111324c6482d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8510736-def3-4e15-9ca1-10b823f3fd51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c94b0861-7e5f-49c4-9501-26c9fff38d98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d730be1-d0a3-4544-9f3e-dd9c910e623a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 299e2fea-ed32-4f0c-b8b4-8a7ecf88f166
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a67f7a3-24f3-47b6-a124-0c3f32be94c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dffb614b-f7a0-42f9-9ec1-cf40bf6b5e10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebe7e910-bc79-4208-afb1-3f1c24aa787e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c63ce758-a470-4b3f-bb88-ab3fc3d018ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ba8bcd9-e6e7-4359-8058-239f9ff14a48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82ad2796-ff90-49fa-8d55-226b179e8d3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e92e4b36-85cb-4f81-80d7-e296314a54bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fda0cd35-a199-46bd-9885-924a4162cda9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 590eb69e-501b-4fa3-9f0e-ee81d2e5f27a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0523c42f-f9a5-4ba0-80f0-595f9218955f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55152714-c3a7-43ac-8c57-9d55f5d69594
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f21fe253-32db-4a65-9ee4-567daeaac049
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ad817e8-4a37-4cde-ac35-429a1f668b3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 778d5686-054a-43aa-af58-f7efe548577a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a5a945e-850e-40db-9e9d-61c0384926fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6160bdc0-3829-4daa-b5cc-40b2eda3e509
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a5109c0-5790-4521-ab39-b9bf27bbe0eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1406a816-b80f-4c4a-a1ef-fe30a61064c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de3b4d6b-3bc2-4ef8-bf93-2bc2ab1eaeb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd6cd818-f50c-4254-a187-ee0f82699f99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6674033f-03db-4937-8f63-83ff55776229
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e76017bf-418b-48ae-a3fb-a65a119f782f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 620cac08-5cb6-400c-a522-24963a3cd519
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a65371ca-c5cc-4a4e-8e55-6a8e2df42155
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fcb2969-69ae-4cda-b136-3add327f96ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94be0792-d01c-48e6-a523-e50dd1898cd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95287f30-5696-45b3-8f6a-974005a5b5f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2906b40e-89d2-476d-a18a-242624633f8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8c0f38e-3dbe-46c2-8906-2bf5ed83f8d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33495ea1-71d3-4c89-954a-e0965898fe27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 717f5cce-5f81-4221-a9c2-ff79c1dca6e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3289f5e-473d-4c9b-bac4-c3533232bafb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05cc7e32-03f6-459f-b0c9-8278f2a49d28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f548b010-f98a-4873-8625-3579979e6d4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a0183b3-bc8a-4208-8421-29f46dde0f5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 238e8b4e-d627-4416-adad-01e896d53c82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d538083-9f59-42ec-a03c-89b43d37a02f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6cf3a07-1020-44b1-99e3-bfc9d6933871
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e926e97a-a7db-4430-9093-e7e007c98bb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c211f546-157e-4a91-8737-14606d7b463b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08334547-dd9b-42e2-9466-a008f601b128
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fda7840a-d10a-45d7-bd45-910c98328091
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15b4b69c-5112-4609-9a93-705cb5c2ea97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35fab95c-1682-4e75-9e5e-02518325c9c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bd38d8c-0448-4d9d-b68e-c3d99fddae37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e114460-043e-498f-ae70-66edd257d373
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 672b91d0-518a-4227-a957-4c62aa3d7ad4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b326ea6-f490-494f-9936-a641038823ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3835fb5-60ee-447d-b39c-b025c27aa441
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1697f8bb-e53c-4205-9738-f2123e4051a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 906c6dd5-3452-4b39-adcb-6ac2c086e478
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c66917e6-d428-4c04-ae0b-8d75bd4eff8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81a8ddc2-e365-442c-a6ad-55e879b132de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4c8bf18-dcac-46e2-b122-781e7c502ea0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7aa7fac-9e73-447a-a06e-bc959d8e8dc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b01b505-7cab-41f9-9d4b-5a6278fc72d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61e1f198-207b-494f-88ac-4270fb4f4feb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5aa23948-b143-4c5a-8a82-5f523f64226e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a16f8559-9e56-4985-8c04-fb0ff963665b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01d2c425-7a07-45c0-b6ac-e8731ecd9e9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 066b98c5-113a-41bb-bc58-87456d444dfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5c2b40f-5b2b-4a55-b143-b667a3b145d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dacda977-074f-4bdf-bfb9-42d117c09152
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef5ba73e-3921-48c3-bcfa-dbcb1587639c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83ce5574-d67e-4f21-b55c-4f8c89728eee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1cdab505-b6d9-4c21-a1e7-b146bac66a0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54412492-59cb-4f5f-a726-074554c10c92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab0606ef-37a3-4037-ad2a-50a23ec57f3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60f3d282-a148-4042-bcb9-bfd746589d8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26ac95df-418c-4b89-98f6-dbe92e61e8ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ed4bcaf-e9d4-4770-907e-19d857b54685
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ce264e5-30c4-464d-a4b7-385b87988848
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5eb47caf-e4c1-4505-a50d-63dca24c4567
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c90dfef-cac6-4e4f-aa0a-7c073e7db10b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c622fb15-0745-4183-8719-e91f9ea3a940
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee78a72a-170d-4742-9f85-248729222a95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4298a7da-07ec-4791-a758-3c3870449115
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f5ca9b2-d2e3-4d99-976e-493a74631315
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2856e35d-d09d-4080-8e88-fd1dc20e10fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb424aaf-52e8-4cf7-a95d-dd2c0e1b6aab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 452c26b8-d128-4ceb-ac2a-8bb68b91b911
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 228cd0a0-081f-478a-a24c-2317e3860d91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edecda86-0735-4409-b86c-60e23635ba3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a3001b0-2067-469f-8afb-09f5131c7694
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99075152-90ac-450b-b611-f271336908fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d48fa906-7844-4904-84f2-18afdf2fa026
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24e43c5e-c72f-48fc-b64e-fd57b6fbedbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5559cc6-d429-4c10-9e9c-299f8b1ec314
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e68a42b7-861d-448f-a0b6-f08ef136b8f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55d9d318-5f3f-4fc6-a624-b67d79e48fb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60087f18-e849-404d-abf6-c1e001ae8f30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f6ee399-d33c-49ab-b313-977ce85e1f25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 817c4f54-bc63-486b-8c49-9f0ffd0adfa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58fd347a-4d26-4f82-be6f-4eafbfc0372e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6282700e-9b39-4184-9a3b-57bd4278fc03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dafffebb-bfec-42bd-b9e0-e8f2e65bbaeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db235d2f-816d-4521-9ed0-5897bdc3f176
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e09a7993-3430-4263-b048-ad505ab3623b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e2e4173-b111-4902-b361-a3de061caa0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0abf1d24-7acf-4d80-afe7-bbd596884eaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1fbf924-aacc-4977-b505-0a4c754c54b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f72ec1b-ae01-44eb-ab3d-c3ba6974304c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da04c64e-6d7f-43ac-aab3-6ba65cbb72d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f5a8c2b-984f-486e-af82-c8f5e1a24e86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85f45722-6626-438f-b4c9-0ce1764a88a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d648f270-0ae6-4471-8b2c-b804b3e2eff1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67ddbbd7-98b7-48cb-bbd0-46d00b0cc753
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cec7556d-7f76-48e0-b3ab-c09572187c2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message becfd362-49e1-4b77-8bc9-dae02a82c41d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33b34e41-7908-42b1-bda4-b64896224317
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0f01dd7-8ae6-495f-bf66-ba86f5900ecd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1d668b9-39a4-42cf-a404-0f9585670b53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5202cc52-5293-4f83-81bd-edcf197a310f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b0a8165-30a0-4dbd-b066-492e82119742
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 624eb6eb-955f-4d5b-b294-a4ad2f401e6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d32c79b-a8b1-4376-96bf-3a877514b112
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03f8cff9-4fc6-4819-8687-e9f35a415d16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c7f4034-92ab-49e7-9c79-099841f7a9d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 942e137e-a3ff-4835-a0a0-a0982620d26c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28ead383-90c6-4c57-9ee4-e13577dbe3f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bae2a315-7eaf-4af1-90e2-c945053c1f97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fc60955-cca3-443b-b1a4-969ebf01165b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24f2dee5-ad69-40af-9f91-30e058869251
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1da6039-98ac-49a5-b263-5105193d631e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cca0fd43-08eb-4d29-a60a-73ec4d7125d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c59ca415-0ca9-42a0-9e4a-34ff52c3c92a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08387125-1f99-48b4-8cd1-bc951c174238
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c80965ff-ffa4-4989-8db0-a9a0035fd0d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message adc134a4-1375-4ebd-a9a6-045c3d1fb156
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc552240-5091-496a-a73f-fb8c77b3aea4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ef71772-14ec-4af2-848d-a09be8ed003e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f3c2aa9-c1b0-43c7-9392-ff65042b13f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e840d803-ae0f-4791-ae33-910cd81e2edb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95e610c0-baaa-4c51-a853-c27ca6f028c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b78660fe-cc38-47f2-b815-883185ffe0cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16542b6a-db39-4e2f-bd4d-bd28093729d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54bd187c-185e-4c2a-926e-621382d32cab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9c111b3-201d-46ed-8a5a-232b87c1cc09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a97c0e0e-a9f3-4c95-b877-5c6c848d3b5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2aef5e32-027b-4e3b-8cde-c794d1feebd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe524aaf-b609-435c-a6fe-610434e750bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d5ac60e-d123-4577-bc00-c3bb4bd17642
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c938c601-30c0-49c8-945d-7a6dfad0dde0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cffc88f6-e41f-459d-83e5-1ee3e8bf2c83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1469de45-d989-4d15-b0db-444680c35ab7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf963fe6-4ae7-4aa1-ac25-08d87dfa5b5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ad727bc-1bc2-4896-bc5b-404bf5728270
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5957c778-f41b-45cd-adeb-b12baff81e64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1876199a-c369-49df-a48c-ec41f5f65e77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a06d9f89-ff37-4bed-99d3-f0f9339e5212
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eeec22a8-03f9-4511-9618-a6ca95209298
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0348301b-ec34-49b7-bbbe-c526f0a99f64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6b99644-79b2-4139-a643-db71432a7277
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30c3b1e8-a5d2-448e-99d0-d2c3787500e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f67a4991-6a23-48ed-b15c-6b3ca0f34e7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 569a94f7-6505-4efd-a879-d49a7e75f5e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c15b968-9409-4642-a2b2-378064a41273
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9264ac8a-e2b0-4e57-91a7-93ac7100ba88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9efbc072-f8d3-4289-abd3-12acef72157a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 469db8e3-0dd3-43d2-abb4-dd8d932f5919
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e341c542-8b02-48b3-b479-8e57bac16f81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53a76aad-b8c3-48f9-9ced-a8cc66b96cd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02d586ab-c3e4-41f0-b855-627b1066ad99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65fda109-c86c-4921-a542-0236ce157fa6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9433c386-9fdf-4b0b-838a-376436a55d16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df6a20a8-c9d6-4ad6-a4da-bee380d400f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcf6f45c-f45b-4cc4-8af8-67d73a7e0e91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51479e9c-c2e8-4a69-bc7d-f871c6c133d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33ceb7aa-4612-4bb5-9349-554c71e5d8a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c987f069-3de3-4029-9fd3-2e630afaa56f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb092083-7b41-4849-a2eb-52c1c8bb0a9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00d2023b-ded0-4894-979f-2380a3469785
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49262903-30e6-47d6-b38c-50da6450679d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4b4cb6d-ab8a-4b49-b95f-8baf9f364852
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 187092be-bcbc-4ba5-8ccd-209f42095203
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4e8fbd9-0012-4534-bb1d-58646018acbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb6bf914-a661-45bf-b53b-593e37eb4e66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77652a93-3259-4ea1-9ff7-11efa6f4bf4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26d68d1b-6bb5-487a-9a22-959382b8f82b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38365a37-798c-4c65-9528-30bf28d03968
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb0afff5-41f2-4872-861d-e185dbb1e53d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 203b1211-0a8c-4de9-94dc-35d55f29737d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56c16d52-d431-4268-ba0a-276fc6dd80b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cae3a892-8ebd-4233-baa1-64d035e5df68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3e73808-a66d-4a37-9b28-1cb6678cb3fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 931eed64-9fc9-4cbc-aaf7-0f833690d4aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6cff21d8-e5ce-41da-b25d-ae727486490e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message adf62570-dbc1-422f-bd0c-3e5f44815bf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba332b9e-c2fd-46ff-84bf-cfa4280de5ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2147543d-07cc-4282-ada5-0530f4defda0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50a4da60-53cf-4d5c-ba56-5d1160c8d9f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 824aa247-916d-4ec0-83b6-fc674bc99ef8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67fff40f-962a-4c57-8d2b-9c5631e3f7e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f82b9e5b-a95b-44c6-ab1d-0c8d8796e791
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02834679-b0c0-41a9-a163-560737436b76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32cd54f5-a308-4959-a80f-151510a8f3cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a23d465-bc48-44ab-88b2-6337dcce6b97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df653d99-52b1-4545-8071-c3c64ce2a24f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 432a87ab-0716-4dbb-8f37-98992c59f76e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17fe819e-07ae-48ac-b52b-9e7da1f2383e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba95d2e0-3f7f-43c1-be83-905246ae5667
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbbc24dd-f874-4894-a91c-7bc710f0e6a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6cfd833f-ced0-41af-96d0-cc528cfe9194
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ead68af6-344d-4322-827d-f9002f58fb68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fd9501c-be7b-4ab4-ac93-3cf422be13d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a7fe43c-12ad-41f8-b75b-b36187ef2221
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8744348a-8ed4-4a11-8d9e-f7a5b82f59c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79475f1a-a387-4042-9711-9bbbda837ad3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5297c572-81fe-4027-8679-5cb69f1f238b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14cf4c16-a132-4ca9-91bf-3be2761c04f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5093e7e1-2862-41e8-a11e-6da3a171abb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36cc34aa-dadc-4afb-a222-8e76eaba6c55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9029e35b-680e-41c1-83ae-9224dfdfc6e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90bb6905-1e2b-4fee-a511-661e821561dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12b5455c-9822-44ce-8fc3-489b89f0307b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b95b3fc-ff03-420c-a7f6-4d46f744fb6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d0266a3-c8b7-422e-b54d-9a3def9bda28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 588770cd-6508-48af-ad98-6acd00d1361c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad28a10b-cda2-4eca-b38d-72a8ea63bf57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17a26cb5-501f-45fd-80f0-31c11a7b8045
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1abc19f2-bcf5-4bc7-b585-e9c73bf92340
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98401dc3-fab5-43ac-adcd-83ac1cea6fa7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62713d6f-eb45-4ad0-9909-55b896a5d542
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d02ee4be-1403-411e-a22f-bf7ab2bf0a66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba0a078a-de92-4738-ab4e-707f5aecb763
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 186aea0d-25d9-4961-832b-f4de1be83475
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc04bd62-a0a9-4fb3-878d-91a330ff5dca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76e63855-1d17-4097-9a57-01edffb96180
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ebadc90-0943-4b80-b3ec-2acc2545008d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6809f1de-995f-41b4-b630-01ff0994dc76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fe7aff4-b35c-4f67-9c3d-c9ad42c73d71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2d8c4ca-cf0b-4923-92b7-3c16daf306e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36d24dbe-9a35-4e65-a318-d2c884abd442
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0df1e69a-d458-447f-85e9-3021febcddff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f53271f-9361-4ea4-9ce4-83689a17092a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 357ed20f-0759-4d13-b15e-914dbf5a7c0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 644fede6-b45d-443a-86fc-5a87bdbd4444
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca2f7ce6-5687-4fe5-9e79-3cc9732cea72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0a62351-b85f-4ac8-be29-99d92a0194c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e348b55-3c9d-453d-8b6d-78c4d62e1533
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 863356a2-ee26-422b-a0ca-d578da5a521e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e0dfcd7-6ffa-4b6b-b4a4-7e7151c2f31b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1eacfa4d-dc10-41d1-a3b6-2b06d0433158
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4874abe-99f5-45a5-ba94-69635ac03759
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e04cf063-a499-4695-9f65-92d8dbee30fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 132ab41e-2f3f-4113-8e8a-f978b6869ccf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a114a62-1b66-4cdc-9504-7f640e09007f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e479c174-3f50-4552-b5c6-77b2749aec28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c813e948-26be-4b07-9895-b61700ad8c11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 384b5d07-1a81-49f0-90f3-8c6f4691e905
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b360511b-d2af-4f53-9573-b4a16bf88902
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51ee51b8-c6a0-4ac0-afae-e1237f9cdd00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ce749a7-b535-489e-921e-0e3227a878c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50ef4199-8462-43d5-8a8a-5d09c267a7e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2b15749-8d78-4449-ad42-b4160dae7189
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53dad018-7447-4854-8e98-97b98ba48bd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4071d64d-cc2a-47e0-a141-39b18e2cb1cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message deb6148b-18f7-4957-9eef-8aaf4a9e427c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55e2b329-45c0-453c-9424-3099170c48aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 406cf27a-74e4-4a29-aa87-baedff595c1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6d2a248-0ddc-46c7-81c2-c9066328c3b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60ed74b2-1cf2-4e87-8677-490afdd5a933
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c2f39c9-24fc-4fc8-bb7b-ac8f3cd44b9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8cfb25f5-10bb-47f5-9594-df493b25d808
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8dc5a171-d752-4959-9bb9-6dc4d61d1196
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55b82dba-4ad7-4adc-90ee-e04e3334151f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 706f27c0-e882-4acd-9bee-a124fb09b972
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bea8900c-e18a-4f65-9113-8896327b1624
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fceb482-c0d2-4387-9cad-c37aabcb71a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84766248-91f6-4b36-9942-a69b7c17bc8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 685c24c8-8ac7-4b3b-baff-4b02e340b096
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d4e8004-3c24-4a6a-877a-f7c97ce597e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86be273b-9abb-472e-af75-1791bc9b2884
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_22
Server: localhost:8686
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_22
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_22/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_22/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_22/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_22/test_labels.txt

📊 Raw data loaded:
   Train: X=(3694, 24), y=(3694,)
   Test:  X=(924, 24), y=(924,)

⚠️  Limiting training data: 3694 → 800 samples
⚠️  Limiting test data: 924 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_22 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2426, R²: -0.0062

============================================================
🔄 Round 3 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.1024 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0830, val=0.0957 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0826, val=0.0937 (↓), lr=0.001000
   • Epoch   4/100: train=0.0795, val=0.0934, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0790, val=0.0935, patience=2/15, lr=0.001000
   📉 Epoch 10: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0770, val=0.0940, patience=8/15, lr=0.000500
   📉 Epoch 18: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 3 Summary - Client client_22
   Epochs: 18/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0774, RMSE=0.2783, R²=0.0128
   Val:   Loss=0.0937, RMSE=0.3061, R²=-0.0186
============================================================


============================================================
🔄 Round 4 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0836 (↓), lr=0.000250
   • Epoch   2/100: train=0.0802, val=0.0833, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0801, val=0.0835, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0800, val=0.0835, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0799, val=0.0835, patience=4/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0795, val=0.0837, patience=10/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 4 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0026
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0093
============================================================


============================================================
🔄 Round 5 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0787 (↓), lr=0.000063
   • Epoch   2/100: train=0.0815, val=0.0785, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0815, val=0.0784, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0814, val=0.0784, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0814, val=0.0784, patience=4/15, lr=0.000063
   📉 Epoch 9: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0812, val=0.0784, patience=10/15, lr=0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 5 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000031 (1 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0025
   Val:   Loss=0.0787, RMSE=0.2804, R²=-0.0101
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2417, R²: 0.0011

📊 Round 5 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2423, R²: -0.0043

============================================================
🔄 Round 8 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0796 (↓), lr=0.000031
   • Epoch   2/100: train=0.0814, val=0.0796, patience=1/15, lr=0.000031
   📉 Epoch 3: LR reduced 0.000031 → 0.000016
   • Epoch   3/100: train=0.0814, val=0.0796, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0813, val=0.0796, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0813, val=0.0796, patience=4/15, lr=0.000016
   📉 Epoch 11: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0813, val=0.0796, patience=10/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 8 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0006
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0069
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0004

📊 Round 8 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2418, R²: 0.0000

📊 Round 8 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2418, R²: 0.0000

============================================================
🔄 Round 20 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0827 (↓), lr=0.000008
   • Epoch   2/100: train=0.0806, val=0.0827, patience=1/15, lr=0.000008
   📉 Epoch 3: LR reduced 0.000008 → 0.000004
   • Epoch   3/100: train=0.0806, val=0.0826, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0806, val=0.0826, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0806, val=0.0826, patience=4/15, lr=0.000004
   📉 Epoch 11: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0805, val=0.0826, patience=10/15, lr=0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 20 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0031
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0139
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2418, R²: -0.0000

============================================================
🔄 Round 21 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0818 (↓), lr=0.000002
   • Epoch   2/100: train=0.0807, val=0.0818, patience=1/15, lr=0.000002
   📉 Epoch 3: LR reduced 0.000002 → 0.000001
   • Epoch   3/100: train=0.0807, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 21 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0809, RMSE=0.2843, R²=0.0014
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0016
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2418, R²: 0.0000

📊 Round 21 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2418, R²: -0.0000

============================================================
🔄 Round 23 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 23 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=-0.0004
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0070
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2418, R²: -0.0000

============================================================
🔄 Round 24 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 24 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0010
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0002
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0001

============================================================
🔄 Round 27 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 27 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0007
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0009
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0001

📊 Round 27 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0001

============================================================
🔄 Round 31 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 31 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2836, R²=0.0023
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0036
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0001

============================================================
🔄 Round 32 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 32 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0004
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0049
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0001

📊 Round 32 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0001

============================================================
🔄 Round 34 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 34 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0011
   Val:   Loss=0.0834, RMSE=0.2887, R²=-0.0025
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0001

📊 Round 34 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0001

============================================================
🔄 Round 37 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 37 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0022
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0036
============================================================


============================================================
🔄 Round 43 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 43 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0030
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0034
============================================================


============================================================
🔄 Round 44 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 44 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0016
   Val:   Loss=0.0732, RMSE=0.2706, R²=0.0026
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0001

============================================================
🔄 Round 46 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 46 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0031
   Val:   Loss=0.0745, RMSE=0.2729, R²=-0.0076
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0001

============================================================
🔄 Round 47 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 47 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0014
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0006
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0002

============================================================
🔄 Round 48 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 48 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0005
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0025
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0001

============================================================
🔄 Round 49 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 49 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=0.0013
   Val:   Loss=0.0822, RMSE=0.2868, R²=0.0005
============================================================


============================================================
🔄 Round 50 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 50 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0023
   Val:   Loss=0.0736, RMSE=0.2713, R²=-0.0048
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0001

============================================================
🔄 Round 52 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 52 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0014
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0056
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0001

============================================================
🔄 Round 54 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 54 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0033
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0142
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0001

============================================================
🔄 Round 56 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 56 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0008
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0019
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0001

============================================================
🔄 Round 58 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 58 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0004
   Val:   Loss=0.0934, RMSE=0.3056, R²=0.0031
============================================================


============================================================
🔄 Round 60 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 60 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0004
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0003
============================================================


============================================================
🔄 Round 61 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 61 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0005
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0038
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0001

============================================================
🔄 Round 63 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 63 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0015
   Val:   Loss=0.0728, RMSE=0.2698, R²=-0.0021
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0001

============================================================
🔄 Round 64 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 64 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0003
   Val:   Loss=0.0872, RMSE=0.2953, R²=0.0058
============================================================


============================================================
🔄 Round 65 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 65 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0009
   Val:   Loss=0.0744, RMSE=0.2727, R²=0.0020
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0001

============================================================
🔄 Round 66 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 66 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0019
   Val:   Loss=0.0909, RMSE=0.3014, R²=-0.0217
============================================================


============================================================
🔄 Round 67 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 67 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0023
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0070
============================================================


============================================================
🔄 Round 68 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 68 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0005
   Val:   Loss=0.0785, RMSE=0.2801, R²=-0.0051
============================================================


============================================================
🔄 Round 69 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 69 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0002
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0044
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0002

============================================================
🔄 Round 71 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 71 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0002
   Val:   Loss=0.0717, RMSE=0.2677, R²=0.0017
============================================================


============================================================
🔄 Round 72 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 72 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0003
   Val:   Loss=0.0713, RMSE=0.2671, R²=-0.0155
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0001

============================================================
🔄 Round 73 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 73 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=-0.0002
   Val:   Loss=0.0862, RMSE=0.2935, R²=0.0017
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0002

============================================================
🔄 Round 76 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 76 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0016
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0088
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0002

============================================================
🔄 Round 78 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 78 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0001
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0059
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0002

============================================================
🔄 Round 81 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 81 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0019
   Val:   Loss=0.0740, RMSE=0.2721, R²=-0.0022
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0002

📊 Round 81 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0002

============================================================
🔄 Round 87 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 87 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=-0.0007
   Val:   Loss=0.0898, RMSE=0.2997, R²=-0.0017
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0002

============================================================
🔄 Round 89 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 89 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0013
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0194
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0002

============================================================
🔄 Round 90 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 90 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0014
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0005
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0002

============================================================
🔄 Round 92 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 92 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0002
   Val:   Loss=0.0749, RMSE=0.2736, R²=0.0054
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0002

============================================================
🔄 Round 94 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 94 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0002
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0057
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0002

============================================================
🔄 Round 97 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 97 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0021
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0096
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0002

📊 Round 97 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0002

📊 Round 97 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0002

============================================================
🔄 Round 104 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 104 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0002
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0059
============================================================


============================================================
🔄 Round 105 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 105 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0020
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0122
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0002

============================================================
🔄 Round 109 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0700 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0700, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0700, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0700, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0700)

============================================================
📊 Round 109 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0019
   Val:   Loss=0.0700, RMSE=0.2646, R²=-0.0031
============================================================


============================================================
🔄 Round 110 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 110 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0009
   Val:   Loss=0.0869, RMSE=0.2949, R²=0.0020
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0001

============================================================
🔄 Round 111 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 111 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0012
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0098
============================================================


============================================================
🔄 Round 112 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 112 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0019
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0030
============================================================


============================================================
🔄 Round 113 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0933, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 113 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2794, R²=-0.0029
   Val:   Loss=0.0931, RMSE=0.3051, R²=-0.0109
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0002

📊 Round 113 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0003

📊 Round 113 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0003

============================================================
🔄 Round 119 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0694 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0695, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0695, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0695, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0695, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0695, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0694)

============================================================
📊 Round 119 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0019
   Val:   Loss=0.0694, RMSE=0.2635, R²=-0.0118
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0003

============================================================
🔄 Round 122 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 122 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=-0.0012
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0012
============================================================


============================================================
🔄 Round 123 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 123 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0006
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0038
============================================================


============================================================
🔄 Round 124 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 124 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0023
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0032
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0003

============================================================
🔄 Round 125 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 125 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0012
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0037
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0003

📊 Round 125 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0003

============================================================
🔄 Round 127 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 127 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=-0.0013
   Val:   Loss=0.0891, RMSE=0.2984, R²=0.0054
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0003

📊 Round 127 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0003

📊 Round 127 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0003

============================================================
🔄 Round 133 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 133 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0016
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0062
============================================================


============================================================
🔄 Round 134 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 134 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=0.0016
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0062
============================================================


============================================================
🔄 Round 136 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 136 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0024
   Val:   Loss=0.0715, RMSE=0.2673, R²=-0.0060
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0002

📊 Round 136 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0002

============================================================
🔄 Round 141 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 141 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0008
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0023
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0002

============================================================
🔄 Round 142 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 142 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0006
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0003
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0002

============================================================
🔄 Round 145 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 145 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0021
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0048
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0002

============================================================
🔄 Round 146 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 146 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0029
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0112
============================================================


============================================================
🔄 Round 147 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 147 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0023
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0076
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0002

============================================================
🔄 Round 150 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 150 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0015
   Val:   Loss=0.0757, RMSE=0.2752, R²=-0.0132
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0002

============================================================
🔄 Round 151 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 151 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0023
   Val:   Loss=0.0903, RMSE=0.3004, R²=-0.0055
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0002

============================================================
🔄 Round 152 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 152 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0029
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0051
============================================================


============================================================
🔄 Round 154 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 154 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0007
   Val:   Loss=0.0919, RMSE=0.3031, R²=-0.0065
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0002

============================================================
🔄 Round 156 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0703 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0703, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0703, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0703, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0703)

============================================================
📊 Round 156 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0013
   Val:   Loss=0.0703, RMSE=0.2652, R²=-0.0049
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0001

============================================================
🔄 Round 158 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 158 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0015
   Val:   Loss=0.0751, RMSE=0.2740, R²=-0.0075
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0001

============================================================
🔄 Round 161 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 161 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0010
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0018
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0002

============================================================
🔄 Round 162 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 162 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0015
   Val:   Loss=0.0851, RMSE=0.2918, R²=0.0002
============================================================


============================================================
🔄 Round 163 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 163 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0016
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0132
============================================================


============================================================
🔄 Round 166 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 166 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0014
   Val:   Loss=0.0811, RMSE=0.2849, R²=0.0115
============================================================


============================================================
🔄 Round 167 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 167 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0004
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0018
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0001

============================================================
🔄 Round 170 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 170 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0019
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0017
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0001

============================================================
🔄 Round 171 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 171 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0009
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0016
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0001

📊 Round 171 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0001

============================================================
🔄 Round 175 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 175 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0016
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0025
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0001

📊 Round 175 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0001

============================================================
🔄 Round 178 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0944 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0944, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0944, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0944, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0944, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0944, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0944)

============================================================
📊 Round 178 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0005
   Val:   Loss=0.0944, RMSE=0.3072, R²=0.0012
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0001

============================================================
🔄 Round 180 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 180 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0001
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0120
============================================================


============================================================
🔄 Round 181 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 181 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0014
   Val:   Loss=0.0748, RMSE=0.2735, R²=-0.0017
============================================================


============================================================
🔄 Round 182 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 182 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0029
   Val:   Loss=0.0868, RMSE=0.2945, R²=-0.0052
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0001

📊 Round 182 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0001

============================================================
🔄 Round 188 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 188 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0015
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0001
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0001

============================================================
🔄 Round 193 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 193 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0034
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0214
============================================================


============================================================
🔄 Round 194 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 194 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2864, R²=-0.0003
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0069
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0001

============================================================
🔄 Round 196 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 196 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0007
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0019
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0001

============================================================
🔄 Round 197 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 197 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0028
   Val:   Loss=0.0833, RMSE=0.2885, R²=-0.0055
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0001

📊 Round 197 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0001

============================================================
🔄 Round 203 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 203 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0004
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0016
============================================================


============================================================
🔄 Round 204 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 204 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0009
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0085
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2418, R²: -0.0000

📊 Round 204 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2418, R²: -0.0000

============================================================
🔄 Round 208 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 208 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0013
   Val:   Loss=0.0792, RMSE=0.2815, R²=-0.0155
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2418, R²: 0.0000

📊 Round 208 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2418, R²: 0.0001

📊 Round 208 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2418, R²: 0.0000

============================================================
🔄 Round 211 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 211 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0025
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0039
============================================================


📊 Round 211 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2418, R²: 0.0001

============================================================
🔄 Round 213 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 213 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0013
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0001
============================================================


📊 Round 213 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2418, R²: 0.0001

============================================================
🔄 Round 216 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 216 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0023
   Val:   Loss=0.0862, RMSE=0.2937, R²=-0.0065
============================================================


============================================================
🔄 Round 217 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 217 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0013
   Val:   Loss=0.0902, RMSE=0.3003, R²=0.0006
============================================================


📊 Round 217 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2418, R²: 0.0002

============================================================
🔄 Round 219 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 219 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0030
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0098
============================================================


📊 Round 219 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2418, R²: 0.0002

============================================================
🔄 Round 221 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0942, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0942, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0942, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 221 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2788, R²=0.0015
   Val:   Loss=0.0942, RMSE=0.3070, R²=-0.0002
============================================================


============================================================
🔄 Round 222 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 222 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0011
   Val:   Loss=0.0794, RMSE=0.2819, R²=-0.0034
============================================================


============================================================
🔄 Round 223 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 223 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0010
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0014
============================================================


============================================================
🔄 Round 224 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0697 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0697, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0697, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0697, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0697, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0697)

============================================================
📊 Round 224 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0021
   Val:   Loss=0.0697, RMSE=0.2639, R²=-0.0059
============================================================


📊 Round 224 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2418, R²: 0.0001

============================================================
🔄 Round 227 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 227 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0007
   Val:   Loss=0.0730, RMSE=0.2701, R²=0.0023
============================================================


📊 Round 227 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2418, R²: 0.0002

============================================================
🔄 Round 229 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 229 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0023
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0036
============================================================


📊 Round 229 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2418, R²: 0.0002

📊 Round 229 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2418, R²: 0.0002

📊 Round 229 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2418, R²: 0.0002

============================================================
🔄 Round 232 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 232 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0023
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0039
============================================================


============================================================
🔄 Round 233 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 233 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0016
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0057
============================================================


============================================================
🔄 Round 235 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 235 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0011
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0132
============================================================


============================================================
🔄 Round 237 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 237 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0010
   Val:   Loss=0.0778, RMSE=0.2790, R²=-0.0134
============================================================


============================================================
🔄 Round 238 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 238 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0019
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0093
============================================================


============================================================
🔄 Round 239 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 239 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0013
   Val:   Loss=0.0875, RMSE=0.2959, R²=0.0097
============================================================


📊 Round 239 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2418, R²: 0.0003

📊 Round 239 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2418, R²: 0.0002

============================================================
🔄 Round 241 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 241 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0019
   Val:   Loss=0.0940, RMSE=0.3066, R²=-0.0014
============================================================


📊 Round 241 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2418, R²: 0.0002

============================================================
🔄 Round 242 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 242 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0011
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0036
============================================================


📊 Round 242 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2418, R²: 0.0002

============================================================
🔄 Round 243 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 243 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0007
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0038
============================================================


📊 Round 243 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2418, R²: 0.0002

📊 Round 243 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2418, R²: 0.0002

📊 Round 243 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2418, R²: 0.0002

============================================================
🔄 Round 251 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 251 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0001
   Val:   Loss=0.0815, RMSE=0.2854, R²=0.0013
============================================================


📊 Round 251 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2418, R²: 0.0002

============================================================
🔄 Round 256 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 256 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0002
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0053
============================================================


============================================================
🔄 Round 257 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 257 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0012
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0010
============================================================


📊 Round 257 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2418, R²: 0.0001

📊 Round 257 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2418, R²: 0.0002

============================================================
🔄 Round 261 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0654 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0654, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0654, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0654, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0654, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0654, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0654)

============================================================
📊 Round 261 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0020
   Val:   Loss=0.0654, RMSE=0.2557, R²=-0.0048
============================================================


============================================================
🔄 Round 262 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 262 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0003
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0066
============================================================


============================================================
🔄 Round 263 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 263 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0010
   Val:   Loss=0.0840, RMSE=0.2899, R²=0.0079
============================================================


📊 Round 263 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2418, R²: 0.0002

============================================================
🔄 Round 264 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0685 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0685, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0685, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0685, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0685, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0685, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0685)

============================================================
📊 Round 264 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0006
   Val:   Loss=0.0685, RMSE=0.2617, R²=0.0038
============================================================


📊 Round 264 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2418, R²: 0.0002

📊 Round 264 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2418, R²: 0.0002

============================================================
🔄 Round 267 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 267 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0007
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0030
============================================================


============================================================
🔄 Round 269 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 269 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0011
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0008
============================================================


📊 Round 269 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2418, R²: 0.0001

============================================================
🔄 Round 270 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 270 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0030
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0103
============================================================


📊 Round 270 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2418, R²: 0.0001

📊 Round 270 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2418, R²: 0.0001

============================================================
🔄 Round 276 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 276 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0015
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0011
============================================================


============================================================
🔄 Round 278 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 278 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0002
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0009
============================================================


📊 Round 278 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2418, R²: 0.0002

📊 Round 278 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2418, R²: 0.0002

📊 Round 278 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2418, R²: 0.0002

📊 Round 278 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2418, R²: 0.0002

============================================================
🔄 Round 285 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 285 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0033
   Val:   Loss=0.0752, RMSE=0.2743, R²=-0.0085
============================================================


📊 Round 285 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2418, R²: 0.0003

============================================================
🔄 Round 289 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 289 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0030
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0084
============================================================


============================================================
🔄 Round 290 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 290 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0026
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0261
============================================================


📊 Round 290 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2418, R²: 0.0003

============================================================
🔄 Round 292 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 292 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0009
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0019
============================================================


📊 Round 292 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2418, R²: 0.0003

📊 Round 292 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2418, R²: 0.0003

============================================================
🔄 Round 294 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 294 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0016
   Val:   Loss=0.0778, RMSE=0.2790, R²=-0.0016
============================================================


📊 Round 294 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2418, R²: 0.0003

============================================================
🔄 Round 295 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 295 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0003
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0039
============================================================


📊 Round 295 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2418, R²: 0.0002

============================================================
🔄 Round 296 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 296 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0019
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0086
============================================================


============================================================
🔄 Round 300 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 300 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0017
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0131
============================================================


📊 Round 300 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2418, R²: 0.0002

============================================================
🔄 Round 304 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 304 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=-0.0016
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0105
============================================================


📊 Round 304 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2418, R²: 0.0003

============================================================
🔄 Round 305 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 305 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0011
   Val:   Loss=0.0788, RMSE=0.2808, R²=0.0026
============================================================


============================================================
🔄 Round 306 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 306 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0018
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0107
============================================================


📊 Round 306 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2418, R²: 0.0002

============================================================
🔄 Round 308 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 308 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=-0.0029
   Val:   Loss=0.0889, RMSE=0.2981, R²=-0.0052
============================================================


📊 Round 308 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2418, R²: 0.0002

📊 Round 308 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2418, R²: 0.0001

============================================================
🔄 Round 312 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 312 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0009
   Val:   Loss=0.0731, RMSE=0.2704, R²=-0.0092
============================================================


📊 Round 312 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2418, R²: 0.0001

============================================================
🔄 Round 313 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 313 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0003
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0011
============================================================


📊 Round 313 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2418, R²: 0.0001

============================================================
🔄 Round 317 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 317 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0007
   Val:   Loss=0.0780, RMSE=0.2794, R²=-0.0075
============================================================


📊 Round 317 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2418, R²: 0.0001

📊 Round 317 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2418, R²: 0.0001

============================================================
🔄 Round 320 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 320 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0003
   Val:   Loss=0.0739, RMSE=0.2718, R²=-0.0083
============================================================


📊 Round 320 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2418, R²: 0.0001

============================================================
🔄 Round 322 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 322 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0023
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0101
============================================================


============================================================
🔄 Round 323 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 323 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0023
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0215
============================================================


📊 Round 323 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2418, R²: 0.0002

============================================================
🔄 Round 326 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0682 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0682, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0682, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0682, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0682, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0682, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0682)

============================================================
📊 Round 326 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2903, R²=0.0008
   Val:   Loss=0.0682, RMSE=0.2612, R²=-0.0081
============================================================


📊 Round 326 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2418, R²: 0.0003

📊 Round 326 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2418, R²: 0.0003

============================================================
🔄 Round 330 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 330 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0005
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0011
============================================================


📊 Round 330 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0003

============================================================
🔄 Round 333 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 333 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0009
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0015
============================================================


📊 Round 333 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0003

📊 Round 333 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0004

============================================================
🔄 Round 335 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 335 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0011
   Val:   Loss=0.0891, RMSE=0.2985, R²=0.0003
============================================================


📊 Round 335 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0004

📊 Round 335 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0004

📊 Round 335 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0004

📊 Round 335 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0004

📊 Round 335 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0004

============================================================
🔄 Round 343 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 343 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0022
   Val:   Loss=0.0758, RMSE=0.2753, R²=-0.0191
============================================================


============================================================
🔄 Round 344 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 344 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0009
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0128
============================================================


📊 Round 344 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0004

============================================================
🔄 Round 346 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0707, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0707, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0707, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0707, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 346 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0002
   Val:   Loss=0.0707, RMSE=0.2659, R²=0.0051
============================================================


📊 Round 346 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0004

📊 Round 346 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0005

============================================================
🔄 Round 349 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 349 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=0.0010
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0009
============================================================


📊 Round 349 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0004

============================================================
🔄 Round 350 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 350 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0012
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0060
============================================================


📊 Round 350 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0004

📊 Round 350 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0004

📊 Round 350 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0004

📊 Round 350 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0004

============================================================
🔄 Round 355 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 355 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0008
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0032
============================================================


📊 Round 355 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0004

============================================================
🔄 Round 356 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 356 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0003
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0033
============================================================


📊 Round 356 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0003

📊 Round 356 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2418, R²: 0.0003

📊 Round 356 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0003

📊 Round 356 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0003

📊 Round 356 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2418, R²: 0.0003

============================================================
🔄 Round 365 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 365 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0003
   Val:   Loss=0.0794, RMSE=0.2817, R²=-0.0136
============================================================


📊 Round 365 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2418, R²: 0.0003

============================================================
🔄 Round 367 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 367 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=-0.0002
   Val:   Loss=0.0891, RMSE=0.2985, R²=0.0058
============================================================


📊 Round 367 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2418, R²: 0.0003

📊 Round 367 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0003

📊 Round 367 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0004

📊 Round 367 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2418, R²: 0.0003

============================================================
🔄 Round 375 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 375 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=-0.0002
   Val:   Loss=0.0798, RMSE=0.2824, R²=0.0063
============================================================


============================================================
🔄 Round 377 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 377 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0034
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0106
============================================================


📊 Round 377 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2418, R²: 0.0003

============================================================
🔄 Round 379 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 379 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=0.0015
   Val:   Loss=0.0918, RMSE=0.3030, R²=-0.0011
============================================================


============================================================
🔄 Round 380 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 380 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0013
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0028
============================================================


============================================================
🔄 Round 382 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 382 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0005
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0013
============================================================


📊 Round 382 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0003

============================================================
🔄 Round 384 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 384 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0017
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0016
============================================================


============================================================
🔄 Round 386 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 386 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0015
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0009
============================================================


============================================================
🔄 Round 387 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 387 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=-0.0014
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0081
============================================================


📊 Round 387 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0004

============================================================
🔄 Round 389 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 389 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0007
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0132
============================================================


📊 Round 389 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0004

============================================================
🔄 Round 390 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 390 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0017
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0014
============================================================


📊 Round 390 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0004

============================================================
🔄 Round 392 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 392 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0034
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0169
============================================================


📊 Round 392 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0004

============================================================
🔄 Round 395 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 395 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0008
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0022
============================================================


📊 Round 395 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0004

📊 Round 395 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0004

============================================================
🔄 Round 398 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 398 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0005
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0044
============================================================


📊 Round 398 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0004

============================================================
🔄 Round 399 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 399 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0005
   Val:   Loss=0.0852, RMSE=0.2920, R²=0.0068
============================================================


============================================================
🔄 Round 405 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 405 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=-0.0001
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0021
============================================================


============================================================
🔄 Round 406 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 406 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0016
   Val:   Loss=0.0749, RMSE=0.2737, R²=-0.0071
============================================================


📊 Round 406 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0004

============================================================
🔄 Round 407 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 407 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0007
   Val:   Loss=0.0902, RMSE=0.3004, R²=0.0009
============================================================


📊 Round 407 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0004

============================================================
🔄 Round 409 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 409 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0043
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0185
============================================================


============================================================
🔄 Round 410 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 410 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0000
   Val:   Loss=0.0797, RMSE=0.2822, R²=-0.0030
============================================================


============================================================
🔄 Round 413 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 413 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=-0.0030
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0077
============================================================


📊 Round 413 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2418, R²: 0.0002

============================================================
🔄 Round 414 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 414 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0003
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0045
============================================================


============================================================
🔄 Round 415 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 415 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0001
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0061
============================================================


============================================================
🔄 Round 416 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 416 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0011
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0006
============================================================


============================================================
🔄 Round 418 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 418 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0020
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0023
============================================================


📊 Round 418 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2418, R²: 0.0002

============================================================
🔄 Round 421 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 421 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0023
   Val:   Loss=0.0797, RMSE=0.2822, R²=-0.0068
============================================================


============================================================
🔄 Round 423 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 423 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0003
   Val:   Loss=0.0890, RMSE=0.2984, R²=0.0038
============================================================


📊 Round 423 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2418, R²: 0.0003

============================================================
🔄 Round 424 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 424 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0031
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0067
============================================================


============================================================
🔄 Round 425 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 425 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0008
   Val:   Loss=0.0745, RMSE=0.2729, R²=0.0024
============================================================


📊 Round 425 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2418, R²: 0.0003

📊 Round 425 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2418, R²: 0.0003

============================================================
🔄 Round 435 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 435 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0034
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0154
============================================================


📊 Round 435 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2418, R²: 0.0003

============================================================
🔄 Round 439 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 439 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0003
   Val:   Loss=0.0741, RMSE=0.2723, R²=0.0044
============================================================


============================================================
🔄 Round 440 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 440 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0030
   Val:   Loss=0.0907, RMSE=0.3012, R²=-0.0113
============================================================


📊 Round 440 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2418, R²: 0.0003

============================================================
🔄 Round 442 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 442 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0019
   Val:   Loss=0.0752, RMSE=0.2742, R²=0.0080
============================================================


📊 Round 442 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2418, R²: 0.0003

============================================================
🔄 Round 443 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 443 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0014
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0058
============================================================


📊 Round 443 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2418, R²: 0.0002

============================================================
🔄 Round 444 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 444 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0000
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0219
============================================================


📊 Round 444 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2418, R²: 0.0002

============================================================
🔄 Round 446 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 446 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0019
   Val:   Loss=0.0827, RMSE=0.2877, R²=-0.0022
============================================================


📊 Round 446 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2418, R²: 0.0002

============================================================
🔄 Round 447 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 447 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0024
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0060
============================================================


============================================================
🔄 Round 448 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 448 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0003
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.0036
============================================================


============================================================
🔄 Round 451 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 451 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0013
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0080
============================================================


============================================================
🔄 Round 455 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 455 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0007
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0027
============================================================


============================================================
🔄 Round 456 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 456 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0008
   Val:   Loss=0.0754, RMSE=0.2747, R²=-0.0053
============================================================


📊 Round 456 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2418, R²: 0.0002

============================================================
🔄 Round 458 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 458 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0026
   Val:   Loss=0.0826, RMSE=0.2873, R²=-0.0162
============================================================


📊 Round 458 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2418, R²: 0.0001

📊 Round 458 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2418, R²: 0.0002

============================================================
🔄 Round 461 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 461 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0016
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0053
============================================================


📊 Round 461 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2418, R²: 0.0002

📊 Round 461 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2418, R²: 0.0002

============================================================
🔄 Round 467 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 467 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0004
   Val:   Loss=0.0752, RMSE=0.2742, R²=0.0031
============================================================


============================================================
🔄 Round 469 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 469 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0003
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0023
============================================================


📊 Round 469 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2418, R²: 0.0001

📊 Round 469 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2418, R²: 0.0001

============================================================
🔄 Round 472 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 472 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0039
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0224
============================================================


============================================================
🔄 Round 474 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 474 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0031
   Val:   Loss=0.0763, RMSE=0.2762, R²=-0.0074
============================================================


============================================================
🔄 Round 475 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 475 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0034
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0173
============================================================


============================================================
🔄 Round 476 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 476 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0018
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0074
============================================================


📊 Round 476 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2418, R²: 0.0001

📊 Round 476 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2418, R²: 0.0001

📊 Round 476 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2418, R²: 0.0002

============================================================
🔄 Round 481 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 481 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0023
   Val:   Loss=0.0770, RMSE=0.2774, R²=-0.0107
============================================================


============================================================
🔄 Round 482 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 482 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0032
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0111
============================================================


📊 Round 482 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2418, R²: 0.0003

📊 Round 482 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2418, R²: 0.0003

============================================================
🔄 Round 492 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 492 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0000
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0137
============================================================


📊 Round 492 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2418, R²: 0.0003

============================================================
🔄 Round 494 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 494 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0032
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0109
============================================================


============================================================
🔄 Round 495 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 495 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0013
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0376
============================================================


============================================================
🔄 Round 496 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 496 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0018
   Val:   Loss=0.0742, RMSE=0.2724, R²=-0.0247
============================================================


📊 Round 496 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0004

============================================================
🔄 Round 497 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 497 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0020
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0034
============================================================


📊 Round 497 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0004

============================================================
🔄 Round 501 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 501 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0004
   Val:   Loss=0.0780, RMSE=0.2794, R²=0.0064
============================================================


============================================================
🔄 Round 502 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 502 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0014
   Val:   Loss=0.0759, RMSE=0.2756, R²=-0.0005
============================================================


============================================================
🔄 Round 503 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 503 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0012
   Val:   Loss=0.0882, RMSE=0.2969, R²=-0.0121
============================================================


📊 Round 503 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0004

============================================================
🔄 Round 504 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 504 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0000
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0052
============================================================


============================================================
🔄 Round 505 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 505 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0010
   Val:   Loss=0.0904, RMSE=0.3007, R²=0.0004
============================================================


📊 Round 505 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0004

📊 Round 505 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0004

============================================================
🔄 Round 508 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 508 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0001
   Val:   Loss=0.0873, RMSE=0.2955, R²=0.0051
============================================================


📊 Round 508 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0004

📊 Round 508 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0004

📊 Round 508 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0004

============================================================
🔄 Round 514 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 514 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0013
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0052
============================================================


📊 Round 514 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0004

============================================================
🔄 Round 516 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 516 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0005
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0111
============================================================


📊 Round 516 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0003

📊 Round 516 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0004

📊 Round 516 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0004

============================================================
🔄 Round 521 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 521 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0004
   Val:   Loss=0.0801, RMSE=0.2829, R²=-0.0106
============================================================


📊 Round 521 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0004

============================================================
🔄 Round 523 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 523 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0032
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0092
============================================================


============================================================
🔄 Round 526 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 526 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0043
   Val:   Loss=0.0834, RMSE=0.2887, R²=-0.0118
============================================================


============================================================
🔄 Round 527 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 527 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0020
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0163
============================================================


📊 Round 527 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0005

============================================================
🔄 Round 529 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 529 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0010
   Val:   Loss=0.0826, RMSE=0.2875, R²=-0.0038
============================================================


📊 Round 529 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0005

📊 Round 529 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0005

📊 Round 529 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0005

============================================================
🔄 Round 534 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 534 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0014
   Val:   Loss=0.0726, RMSE=0.2694, R²=-0.0026
============================================================


📊 Round 534 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0005

📊 Round 534 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0005

📊 Round 534 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0005

📊 Round 534 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0005

📊 Round 534 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0005

============================================================
🔄 Round 542 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 542 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0009
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0057
============================================================


📊 Round 542 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0006

============================================================
🔄 Round 545 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 545 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0023
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0079
============================================================


============================================================
🔄 Round 548 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 548 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0036
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0183
============================================================


📊 Round 548 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0006

============================================================
🔄 Round 553 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 553 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0021
   Val:   Loss=0.0874, RMSE=0.2957, R²=0.0046
============================================================


📊 Round 553 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0005

============================================================
🔄 Round 555 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 555 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0005
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0023
============================================================


📊 Round 555 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0006

📊 Round 555 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0006

============================================================
🔄 Round 559 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 559 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0002
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0044
============================================================


============================================================
🔄 Round 560 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 560 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0008
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0121
============================================================


============================================================
🔄 Round 562 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 562 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0000
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0048
============================================================


📊 Round 562 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0005

📊 Round 562 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0006

📊 Round 562 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0006

📊 Round 562 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0006

📊 Round 562 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0006

📊 Round 562 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0006

📊 Round 562 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0006

============================================================
🔄 Round 570 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0956 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0956, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0956, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0956, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0956, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0956, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0956)

============================================================
📊 Round 570 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0019
   Val:   Loss=0.0956, RMSE=0.3092, R²=-0.0020
============================================================


============================================================
🔄 Round 573 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 573 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0001
   Val:   Loss=0.0826, RMSE=0.2873, R²=0.0044
============================================================


============================================================
🔄 Round 575 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 575 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0007
   Val:   Loss=0.0733, RMSE=0.2707, R²=0.0019
============================================================


📊 Round 575 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0006

📊 Round 575 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0006

============================================================
🔄 Round 577 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 577 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2792, R²=0.0007
   Val:   Loss=0.0936, RMSE=0.3059, R²=0.0019
============================================================


============================================================
🔄 Round 578 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 578 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0011
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0008
============================================================


============================================================
🔄 Round 581 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 581 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0023
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0044
============================================================


📊 Round 581 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0006

📊 Round 581 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0006

============================================================
🔄 Round 583 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 583 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0016
   Val:   Loss=0.0862, RMSE=0.2937, R²=-0.0011
============================================================


📊 Round 583 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0006

============================================================
🔄 Round 585 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 585 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0028
   Val:   Loss=0.0714, RMSE=0.2671, R²=-0.0078
============================================================


📊 Round 585 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0007

📊 Round 585 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0007

============================================================
🔄 Round 590 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 590 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0020
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0096
============================================================


📊 Round 590 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0007

============================================================
🔄 Round 591 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 591 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0010
   Val:   Loss=0.0801, RMSE=0.2829, R²=0.0046
============================================================


============================================================
🔄 Round 594 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 594 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0006
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0015
============================================================


📊 Round 594 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0007

📊 Round 594 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0007

📊 Round 594 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0007

============================================================
🔄 Round 599 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 599 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0009
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0182
============================================================


============================================================
🔄 Round 600 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 600 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0016
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0034
============================================================


============================================================
🔄 Round 602 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 602 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=-0.0003
   Val:   Loss=0.0879, RMSE=0.2964, R²=0.0053
============================================================


📊 Round 602 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0007

============================================================
🔄 Round 604 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 604 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0006
   Val:   Loss=0.0864, RMSE=0.2940, R²=0.0024
============================================================


📊 Round 604 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0007

============================================================
🔄 Round 605 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 605 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0009
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0190
============================================================


============================================================
🔄 Round 607 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 607 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0037
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0105
============================================================


📊 Round 607 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0007

============================================================
🔄 Round 608 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 608 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0022
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0139
============================================================


============================================================
🔄 Round 610 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 610 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0000
   Val:   Loss=0.0727, RMSE=0.2697, R²=0.0056
============================================================


============================================================
🔄 Round 612 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 612 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=-0.0051
   Val:   Loss=0.0917, RMSE=0.3028, R²=-0.0231
============================================================


📊 Round 612 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0007

📊 Round 612 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0007

============================================================
🔄 Round 615 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 615 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0015
   Val:   Loss=0.0740, RMSE=0.2719, R²=0.0069
============================================================


📊 Round 615 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0007

📊 Round 615 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0006

📊 Round 615 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0007

📊 Round 615 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0007

============================================================
🔄 Round 621 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 621 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0013
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0097
============================================================


📊 Round 621 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0006

📊 Round 621 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0006

============================================================
🔄 Round 625 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 625 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0025
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0139
============================================================


📊 Round 625 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0006

============================================================
🔄 Round 627 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 627 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0007
   Val:   Loss=0.0849, RMSE=0.2913, R²=0.0019
============================================================


📊 Round 627 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0007

📊 Round 627 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0007

============================================================
🔄 Round 636 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 636 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0039
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0250
============================================================


============================================================
🔄 Round 638 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 638 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0029
   Val:   Loss=0.0797, RMSE=0.2824, R²=-0.0086
============================================================


============================================================
🔄 Round 639 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 639 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0031
   Val:   Loss=0.0905, RMSE=0.3009, R²=-0.0065
============================================================


============================================================
🔄 Round 641 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 641 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0006
   Val:   Loss=0.0711, RMSE=0.2666, R²=0.0027
============================================================


📊 Round 641 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0004

============================================================
🔄 Round 642 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 642 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0013
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0104
============================================================


📊 Round 642 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0004

📊 Round 642 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0004

============================================================
🔄 Round 646 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 646 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0021
   Val:   Loss=0.0778, RMSE=0.2790, R²=-0.0034
============================================================


📊 Round 646 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0004

📊 Round 646 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0003

============================================================
🔄 Round 648 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 648 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0006
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0077
============================================================


📊 Round 648 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2418, R²: 0.0003

============================================================
🔄 Round 650 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 650 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0003
   Val:   Loss=0.0889, RMSE=0.2981, R²=-0.0121
============================================================


📊 Round 650 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0003

============================================================
🔄 Round 653 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 653 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0034
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0114
============================================================


📊 Round 653 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0004

============================================================
🔄 Round 654 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 654 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0001
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0045
============================================================


============================================================
🔄 Round 657 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 657 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0003
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0030
============================================================


📊 Round 657 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0004

============================================================
🔄 Round 658 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 658 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0029
   Val:   Loss=0.0882, RMSE=0.2969, R²=-0.0070
============================================================


📊 Round 658 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0004

📊 Round 658 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0005

============================================================
🔄 Round 663 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 663 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0028
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0137
============================================================


============================================================
🔄 Round 664 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 664 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0038
   Val:   Loss=0.0725, RMSE=0.2693, R²=-0.0272
============================================================


📊 Round 664 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0005

📊 Round 664 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0004

📊 Round 664 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0004

============================================================
🔄 Round 670 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 670 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0018
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0297
============================================================


📊 Round 670 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0005

============================================================
🔄 Round 672 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 672 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0023
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0051
============================================================


📊 Round 672 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0005

📊 Round 672 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0005

📊 Round 672 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0005

📊 Round 672 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0005

============================================================
🔄 Round 678 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 678 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0015
   Val:   Loss=0.0862, RMSE=0.2935, R²=-0.0008
============================================================


📊 Round 678 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0005

============================================================
🔄 Round 680 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 680 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0000
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0036
============================================================


📊 Round 680 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0005

📊 Round 680 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0005

📊 Round 680 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0006

📊 Round 680 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0006

============================================================
🔄 Round 687 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 687 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0012
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0071
============================================================


============================================================
🔄 Round 688 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 688 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0020
   Val:   Loss=0.0765, RMSE=0.2765, R²=-0.0076
============================================================


📊 Round 688 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0005

============================================================
🔄 Round 690 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 690 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0003
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0145
============================================================


============================================================
🔄 Round 692 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 692 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0015
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0014
============================================================


📊 Round 692 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0005

📊 Round 692 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0005

============================================================
🔄 Round 695 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 695 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0012
   Val:   Loss=0.0737, RMSE=0.2716, R²=-0.0006
============================================================


📊 Round 695 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0005

============================================================
🔄 Round 699 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 699 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0002
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0007
============================================================


📊 Round 699 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0005

📊 Round 699 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0005

============================================================
🔄 Round 704 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 704 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0020
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0084
============================================================


📊 Round 704 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0005

============================================================
🔄 Round 707 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 707 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0012
   Val:   Loss=0.0745, RMSE=0.2730, R²=0.0054
============================================================


📊 Round 707 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0005

============================================================
🔄 Round 709 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 709 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0023
   Val:   Loss=0.0732, RMSE=0.2706, R²=-0.0077
============================================================


============================================================
🔄 Round 711 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 711 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0023
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0037
============================================================


📊 Round 711 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0005

📊 Round 711 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0005

============================================================
🔄 Round 716 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 716 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0020
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0032
============================================================


============================================================
🔄 Round 718 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 718 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0010
   Val:   Loss=0.0732, RMSE=0.2706, R²=-0.0032
============================================================


📊 Round 718 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0005

📊 Round 718 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0006

============================================================
🔄 Round 721 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 721 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0008
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0006
============================================================


📊 Round 721 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0006

============================================================
🔄 Round 722 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 722 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0015
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0053
============================================================


📊 Round 722 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0006

============================================================
🔄 Round 724 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0685 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0685, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0685, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0685, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0685, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0685, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0685)

============================================================
📊 Round 724 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0005
   Val:   Loss=0.0685, RMSE=0.2618, R²=0.0031
============================================================


📊 Round 724 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0006

============================================================
🔄 Round 726 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 726 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0002
   Val:   Loss=0.0758, RMSE=0.2753, R²=-0.0105
============================================================


============================================================
🔄 Round 727 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 727 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0025
   Val:   Loss=0.0788, RMSE=0.2806, R²=-0.0067
============================================================


============================================================
🔄 Round 729 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 729 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0016
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0037
============================================================


📊 Round 729 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0006

============================================================
🔄 Round 731 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 731 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=-0.0020
   Val:   Loss=0.0926, RMSE=0.3042, R²=-0.0456
============================================================


📊 Round 731 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0006

📊 Round 731 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0006

📊 Round 731 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0006

============================================================
🔄 Round 737 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 737 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0020
   Val:   Loss=0.0785, RMSE=0.2801, R²=-0.0057
============================================================


📊 Round 737 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0006

============================================================
🔄 Round 739 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 739 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0027
   Val:   Loss=0.0793, RMSE=0.2815, R²=0.0113
============================================================


📊 Round 739 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0005

📊 Round 739 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0005

============================================================
🔄 Round 741 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 741 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=0.0005
   Val:   Loss=0.0866, RMSE=0.2944, R²=0.0019
============================================================


============================================================
🔄 Round 742 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 742 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0008
   Val:   Loss=0.0871, RMSE=0.2951, R²=0.0076
============================================================


📊 Round 742 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0005

📊 Round 742 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0005

📊 Round 742 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0005

============================================================
🔄 Round 745 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 745 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=0.0014
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0019
============================================================


============================================================
🔄 Round 747 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 747 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=-0.0008
   Val:   Loss=0.0830, RMSE=0.2882, R²=0.0001
============================================================


📊 Round 747 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0005

============================================================
🔄 Round 748 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 748 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0007
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0013
============================================================


📊 Round 748 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0005

📊 Round 748 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0005

============================================================
🔄 Round 750 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 750 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0027
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0094
============================================================


📊 Round 750 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0005

============================================================
🔄 Round 751 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 751 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0002
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0421
============================================================


============================================================
🔄 Round 753 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 753 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2871, R²=0.0009
   Val:   Loss=0.0755, RMSE=0.2747, R²=0.0013
============================================================


============================================================
🔄 Round 754 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 754 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0006
   Val:   Loss=0.0726, RMSE=0.2694, R²=0.0061
============================================================


============================================================
🔄 Round 759 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 759 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=-0.0012
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0039
============================================================


📊 Round 759 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0005

============================================================
🔄 Round 761 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 761 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0010
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0069
============================================================


============================================================
🔄 Round 762 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 762 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0006
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0226
============================================================


============================================================
🔄 Round 763 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 763 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0008
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0019
============================================================


📊 Round 763 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0005

📊 Round 763 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0005

============================================================
🔄 Round 765 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 765 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0004
   Val:   Loss=0.0785, RMSE=0.2801, R²=0.0027
============================================================


============================================================
🔄 Round 766 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 766 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0012
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0005
============================================================


============================================================
🔄 Round 768 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 768 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0010
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0053
============================================================


📊 Round 768 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0004

============================================================
🔄 Round 769 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 769 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0017
   Val:   Loss=0.0802, RMSE=0.2831, R²=-0.0054
============================================================


📊 Round 769 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0004

============================================================
🔄 Round 770 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 770 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0015
   Val:   Loss=0.0895, RMSE=0.2991, R²=-0.0047
============================================================


📊 Round 770 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0004

============================================================
🔄 Round 772 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 772 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0007
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0024
============================================================


============================================================
🔄 Round 774 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 774 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0022
   Val:   Loss=0.0750, RMSE=0.2738, R²=-0.0089
============================================================


📊 Round 774 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0004

📊 Round 774 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0004

============================================================
🔄 Round 776 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 776 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0017
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0034
============================================================


============================================================
🔄 Round 777 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 777 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0001
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0009
============================================================


📊 Round 777 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0004

============================================================
🔄 Round 779 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 779 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0039
   Val:   Loss=0.0908, RMSE=0.3014, R²=-0.0090
============================================================


📊 Round 779 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: 0.0004

============================================================
🔄 Round 781 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 781 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0019
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0088
============================================================


============================================================
🔄 Round 784 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 784 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0004
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0004
============================================================


📊 Round 784 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2418, R²: 0.0003

============================================================
🔄 Round 785 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 785 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0004
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0072
============================================================


============================================================
🔄 Round 788 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 788 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0013
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0098
============================================================


============================================================
🔄 Round 790 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 790 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0020
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0022
============================================================


============================================================
🔄 Round 791 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 791 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0003
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0025
============================================================


============================================================
🔄 Round 792 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 792 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0021
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0066
============================================================


📊 Round 792 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2418, R²: 0.0003

📊 Round 792 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2418, R²: 0.0003

============================================================
🔄 Round 795 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 795 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0008
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0018
============================================================


📊 Round 795 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2418, R²: 0.0003

📊 Round 795 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2418, R²: 0.0003

============================================================
🔄 Round 798 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 798 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0002
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0120
============================================================


📊 Round 798 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2418, R²: 0.0002

============================================================
🔄 Round 802 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 802 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0011
   Val:   Loss=0.0789, RMSE=0.2808, R²=0.0052
============================================================


📊 Round 802 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2418, R²: 0.0003

📊 Round 802 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2418, R²: 0.0003

============================================================
🔄 Round 807 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 807 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0027
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0050
============================================================


📊 Round 807 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2418, R²: 0.0002

============================================================
🔄 Round 808 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 808 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0007
   Val:   Loss=0.0735, RMSE=0.2710, R²=0.0003
============================================================


❌ Client client_22 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_status:14, grpc_message:"Socket closed"}"
>
