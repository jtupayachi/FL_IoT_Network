[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d48a0ce-4db1-459e-9d52-d1a573113d87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 050943f9-df82-42e2-bc19-ae08b681543b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95a4322a-d912-4cb6-a137-d72f4420de84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c359b555-0325-4a0d-97a0-60fb3d40a4d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7cf89d7c-c12a-4843-a9a3-caa8d2ced190
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a06ed1d9-d35e-4f16-91c8-7cc9146aac52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 833506d3-f9d2-4c81-8532-81ee0bd9cc6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad97aa65-d60b-4043-b41e-95c1bd4a8982
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b661a7dd-a646-47f7-841f-147725b3b30d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 203a9819-e73d-4d10-ad7e-fa20093d0c2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d52d553-f029-4964-9d8e-e729faa0d8dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63557df2-4173-4170-9c9e-b1043fee9c26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b370372a-42f5-428e-86ca-993dd64b62e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b91dba82-ce65-42f7-9d67-1ef91cbc422b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1f01128-3b39-4e3a-ba91-c367877d51e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84ba8882-1be9-4658-878a-71d626c030d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8285ff19-a045-48bc-bb3a-13295c544af5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8894d4d3-160c-4930-989d-3c4d1d4a5193
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe81fb54-2f5f-4391-8331-f6230e043817
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7096fdcc-28fd-4a83-9331-8f45a6a6805c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a825b264-f519-4e79-a6b8-6fb45b472dab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e931806-5394-469f-8fba-49bb74f5aa0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 729be13e-3618-47ac-8a64-3707e11ed864
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa577da0-db5b-4c75-be12-dda1ba0a5601
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bf85391-4b68-45f9-83b4-32cafab6a3bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 520c7f0b-4f25-4da9-9ece-d45bae0bd686
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 614126f7-6c66-4390-952f-67b168e9121a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d77bfbd-622a-46eb-b4a0-e02f2a2ba28c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6153cfc-b788-4dc4-88c0-f0743b7d404f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33f07cba-4d9f-4a0c-a385-366bd1f2f34e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e578af1-615c-4bcd-81d2-a47358ddd5ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d177ce4-4fa0-48c4-89eb-091f0260f728
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33c8ebcf-e462-4c83-8616-bf5d712ce841
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23ddd224-dd75-49fe-b46a-4059900b4719
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc514a6d-aa71-4c2c-a604-f3c3707ea02e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 421434e1-d745-46de-8600-91152ae3b476
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c4e67d4-f8f6-40e7-bb24-b4d937d00d88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fee634b5-124e-4dde-9e23-20d24ef72365
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ce6ba6c-788e-426c-bf91-10ec080e08a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe8ccc81-d649-45ed-b373-0b38a9a63617
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbfa7244-e30e-45fe-a173-4c2273e259b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1076789d-2823-4b89-9c07-38394739dbba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f780a514-038d-4ae9-871a-3af45317e9b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8acf2a34-1367-490f-8497-4f1b363fdb0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 734a7a9c-edc4-489e-8610-75f67ff887ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbded8cd-0cda-4bb6-9d4c-bad92388fe15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 533a77c9-d174-49c7-9d5f-a1f31409f221
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b900e89-6b7e-40ce-ab4a-174b11c93ec0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9dda995d-94a3-4dcc-87a9-86a422d1926b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 949bd953-a45d-4696-a081-2ca72cc211c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 481984ca-8ea1-4db8-abc2-4c5eeff129eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 292b6dd0-3cae-41a5-beca-d5328742967b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ba5d3fb-fde2-4f54-a00b-8599fc0b4882
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd2f4bbf-d2b2-4f01-9054-6a6326f53305
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f421ef85-3f26-461e-86f1-78124d0a6777
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc0166dd-79ad-4866-8e93-0c87da2a5d62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ba09b14-d7dc-453b-a653-083e3c383a4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae9724c3-c76f-41cd-9e9b-d685a8401978
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 783f75ec-e018-46ea-a11c-b29521432360
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e007da3b-91f7-496a-a6b1-b7d06d68ed77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 253eee46-20c6-49fd-9cf6-67ec05e5214a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67579899-6bfe-4252-891d-cb91b385faac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d10c44b5-71d6-45ff-ae10-61486daea6ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88b5996f-f34f-402d-992a-d284250237d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9caf493f-0902-4d86-b2ab-eb039bbfc5a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e72c263c-50f6-45ec-a17d-df9c063bd15c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6ed7d55-3e9c-4cc9-886a-a118ceecb6a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03d146ba-c440-4243-b364-98bb41e3bea3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8c18fbd-bbbc-462c-85d9-8e86e5d889c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12219159-efac-42ec-9f27-218101620fed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b6b5a11-9ba2-496a-8e75-e8af7e0ec97d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2240de65-464c-4b9d-b662-f2d76723b424
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7387990e-841c-42a6-bf2b-d42c2458d2c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f7402d2-75a9-4021-b59e-8c16f7134e11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f353ad44-5da9-4d4c-9167-a3094d15a6f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e05a226-3fb1-4bc7-ab42-ed2e7d59f9de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f29e61c-2bd0-4c28-b274-8e13d67fffb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8616716-c48b-4199-b2df-e2d5b6cb6546
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83cca135-6876-4766-b73e-94a47cb792f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3ecaeef-3895-4f7f-889f-f7e2debd5399
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57c6d806-4e3f-4c34-8a92-12f253c167bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46f276c9-1072-4873-bd25-c56b3e33de82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e859142-b879-400e-b253-ba07ccd8931d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a8278ad-ce03-4935-b4fd-7c63ba7d7afc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e3ec8e9-c71b-4602-ad69-d25f626601e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57eaec68-2b53-4f57-aaab-808c9e77e588
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5004f04a-48c1-489c-a8bf-424672e19735
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d44cdf32-ffee-4cfd-9ae6-7a183038f93f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5409aa3f-c8eb-468a-8656-37e6324d0fe7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fa4d90f-2a78-4ea7-9aee-0ac1a0bad887
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e3668e2-0d6e-425d-88d6-10fd2aaa4bd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 414d38ed-b1ee-414a-874f-d118cdcc9605
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e97b71e8-6dfe-4646-a218-3cca9cc619ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3b2eb10-4acc-4186-9f24-f4a3f66898ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4d4d17f-be60-4a5c-bd02-c5f841c5a6d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9088b247-531c-4fb6-816a-ba7f0e5cb7ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7732f5c7-7f64-44e2-8818-3137d15ea0f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6ab2189-c04a-4133-81a0-d8ee42bb86a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d4404c3-d475-4e97-9afa-23e5e612f143
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24e5a842-2f16-46d9-800a-6dc89fe012e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59dbd69f-b033-4eaf-8b3c-820bf88dce39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3369ffd-32f6-4a70-974f-3eea7d46cd5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ab874e7-0c0e-4f4a-bd1e-8f4d0eb9955f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba141059-a089-4979-ac4d-eaa1b35610a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44b150b2-33f0-42ae-bc7f-ade98fe45f3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8edcb65d-9be3-4bd9-baa1-5fdfd0f39031
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ebb1c23-fe30-4f00-98ff-84ddfc5396f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1cc02fc8-d6a5-4a8d-a3b8-7e065fb56002
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d94756b-547a-4946-8d62-16f8684a1c98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58c65fbf-210d-4e69-9f52-2070ed349488
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fdfad5a-cd26-4564-9141-3078836c3aa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2808d324-2e1f-4559-9b87-cf05f979eb0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08ab522f-7c43-4cd0-8107-393f8ac3994e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad50b79b-d786-4df1-86ab-73643904a7cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6de7a30-1aa5-419e-96aa-66569429fc5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6464ce3d-9298-465a-bd69-01eefdef840f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c459ddba-4759-46d5-885e-33fbc9d99f73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b2a4d08-e985-4076-b2d7-6e10e540352d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1970a23c-1ab2-487d-9e95-23129de9d8d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab7e95c6-7618-4611-be29-42af067e8403
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e57aaaa-d92c-4c24-9cec-2b81c767a6d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39dda249-bc7f-4d76-9a20-375bc77efe1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10bd0342-0310-4e2e-99ee-dc798abc9584
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b39df628-93e0-4000-a4c8-6aa496dddc42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e690142-58a9-4f04-8da4-f7cd415af7a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e00f6ae8-b735-45c8-8c87-59a342097e48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb53bfbe-d90a-47cb-a1e7-336d9cfb08ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 941669a4-8663-4d07-8580-4756da4febab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7615979f-acb8-4054-b178-b9fcec04e258
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 961c6c77-dd10-4259-8b21-43ea704559d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48eb5661-456b-4483-b1ed-fcdc4a396d6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8eb92a2-9cb2-4347-b71e-a104fa383670
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f52ae1fc-5127-495f-bc53-e7e176a7f1a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2dec0ca8-6a41-4c62-bc41-91240ff3c0cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1811a4ce-1688-43c9-8f7d-859c59789a9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 395f5654-e1a9-4ba3-80d9-6b796a74b824
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 402132d2-9cc9-49f4-9725-a3275778e451
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2110a4fc-62ef-4ff4-9a6e-d3d969bf506b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b82d5e6-5c3e-4b7e-864c-5d0c8a64ef3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67dcd422-3727-411b-88f1-99b4af7e7d52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba52be9b-d821-461a-b860-52d3fd28d027
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1322751e-d920-4cb0-924d-4ef4b6669c71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 597d6e0c-b9fa-415b-93ec-0c943ff530c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d74774d0-bacc-4389-be0a-a5c6181d6847
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d78fb719-08e1-40e6-9aa8-1a504148879c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ea5066c-629a-45f5-bc08-89441c03afd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75787a76-8312-4193-90a3-4375a97874cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f40bf1fd-fabc-45ee-b291-b55971adc390
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ad90443-7e63-461f-b535-52971d145392
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c22edbea-3fbf-495e-b20e-085372574b9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9d14e32-1e61-4e2e-88f2-d6a7c519735b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad22cdef-a65c-42f9-92a6-4c2402b60c1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62378979-7291-409d-a58a-50e8766b405b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c91e6f04-62a3-43b4-9465-eb67f2368db7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 992c58c1-0c1b-4f73-8497-d05f851ff1f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37572dd7-7c35-4fbb-a787-e381bdd3c3fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d50f2af-734c-4bf2-92a4-e7e99a2b3da0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98888216-e1e8-4343-8c23-831b4f53230d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d249632-25c0-4833-8085-9de0f6b0c55b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50a307aa-f63c-4599-927f-2294a65db058
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a39abeaa-2c70-4724-91c6-d6b196ff676a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed58a1a8-9639-4c13-90dc-496558e7c8b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 590f48bb-0aa1-4359-abe9-0b053df0e040
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3160fb0-d95d-44f4-816a-840b20a41b37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73298f87-90a2-4e27-a260-2c593a472048
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a00a111c-486f-4be4-bb25-a45767cf3840
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c60e1b94-32ad-4989-ac4d-f3424b984c7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b0a3fec-5235-498d-aac3-45fcf749f0e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 700755f0-5776-4a31-a9ad-87771eec9554
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee7889b7-f908-4880-a5e8-d2c81ff515e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc3660a9-f361-4744-bae9-e7eb6d856516
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9aa068d-302a-43a5-9f4f-7ea5e62ff94f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eacbcdaf-0747-461d-ba25-c329bc866bc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0909e66-b05d-47cc-badf-df19be7d5995
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 127f4e47-246e-4620-bff6-8451c2074578
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9623c7de-6cdf-467f-8373-ad60f0ae0fd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfa87330-b450-420f-905a-df014a0e6c0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ca10a70-6c7f-489c-9a39-56b00634cb40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e6f8966-ed9e-40d8-8443-4f1b74be99f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb0f2cfb-4817-43e6-8c9f-bf4b6491b61e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 760a350a-5b22-4ad1-865c-c11d5c316820
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75954bb0-d864-4c1b-bfc8-b5e9f4c407d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e27923c-8a4b-4443-8ab3-b1a5ca0f9f9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b9356fd-403b-49ca-b8fc-61dc2eca12de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3eab699-8745-4add-a015-86bda50b6293
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2ddbb5d-b065-4193-a90c-c9b03c5050c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf7bf65c-9238-4859-b90e-20b1e19916d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04079919-b12f-4705-aac1-f552b4349f48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0718e446-c624-46c0-b245-f338906f3731
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1e680ba-16ce-4372-a086-7b69b78d9f15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fec6765c-fdd0-4689-a9d7-4e08a667c781
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c55f421-0d32-40c3-ae52-a4578f9e7eae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c2139da-0dbe-41bd-9f8b-195f1489264a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13240c78-db8f-48eb-92d2-6bca25615a0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d0741e1-f0ad-40b0-9d33-9c0bcb5699d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69a6fd28-ac70-4f51-bcc8-5bc3e359e440
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbe60c40-110e-48f0-846d-863a253f7e43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 102a8a2d-88c1-49c2-9a5e-a4b8769384d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eeb61995-f9a3-43d7-92b6-65de91d1decd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 617fd20e-0ec4-4562-a8f1-e6d6451785d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bdc35960-881f-488d-8ad2-15bb0a03e146
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3abb4298-ba4e-498f-b06a-ebe4ebb69573
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06de8a47-e85b-4b31-8873-06dd93dd5111
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3df91744-b9c9-47c4-8cf5-f7773ee8b4c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b84fb1b-862c-402b-bbab-6cd3d86d4489
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 869d8d73-3a42-4a40-b145-6550689b939c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95af8002-47da-4ef9-8bd1-8ac768ba443e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7bb9351-37ea-4384-ac41-507b3e2c0427
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8333f69-57c5-4442-b212-0c4d72b7cb26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a077c2f-19aa-49c8-9573-47efd103c29d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a904adba-3685-4fdc-b87a-91ecb68322b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d46708eb-7c6c-43dc-ac62-9636ae486f91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8397900-5c94-4e76-84c2-c0ba80bf279e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8f4824e-f057-4205-b148-608a19399907
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9a5f692-4fa5-4f22-a20c-ae7a0e685b7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91d92a0b-8f8b-457e-8970-92f578065985
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9d3dd77-83e5-4082-8b14-b1bf7628ac2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a2e7378-0634-4767-8bda-d380ecd8ad0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11d3983f-7daf-4059-b98d-0a0d82d83ab9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98f71ab1-3822-4e14-868f-c98e3fade796
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8904a09-03c2-4045-bb85-f2f08a909807
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d380ac87-0876-40d1-b467-061bb7f46040
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1624ab98-3d63-4526-a243-3b77977cea2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d617452-cc18-4218-9cc5-303e00b055b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 986e1ca8-0113-48d5-a57a-c4b5fd164c02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10b62751-86d2-4fd5-8d9d-a764ac4e5383
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 751df088-8ffa-49bd-8147-90b4e49b3451
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70e29fad-a6fb-44c6-916d-be517c38c5fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0b5d846-d2c9-4d1a-9d6b-a5f8d344f76b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e2432ed-1e91-46cc-b0bb-aa67b604b06b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26ee9811-27c0-4caf-af88-4eb9107eee6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46c5195e-a69b-4903-83cc-3dfcd114e10b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b0f2c1a-a2a8-47a9-85de-010dcc650ffc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e50b143e-a5a3-483b-b09d-f1c21b8c77cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef77a429-1330-4b22-b949-d917681e84ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06c8948e-3f7e-4f13-ba0e-f6967d20b11e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 639e2cf2-7ea4-474f-85ac-6be012223715
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87f57ef4-71f3-459c-bfea-bd8ac4365c31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9bd1d7e-4c29-4d58-b0d0-7446ea3b5bb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f6660f8-265d-4fad-ac42-d05342dcdf76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1f22bb3-1c51-4f43-8e9e-db5f2ae47f1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a529a4dc-fdb4-4557-87bc-e99543b19794
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bfd455a-26e8-4f91-9efc-1583797a9f1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72b8e699-2f51-4650-889c-89045ee20647
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b99640b3-9e73-42cd-bafb-dcf0d8b53221
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3848dd3c-a99b-4086-9034-792ab19d3bf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0150c446-df8c-4dd8-872a-9bd0af7c8739
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71b844e7-3523-48f3-8deb-6e504aaa8a69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d4602b3-00c3-4fed-a320-e0a3fad03d32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04f1e128-76d9-49f6-8598-aa728c097aed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c06b1777-fba5-4cdb-99ed-a991d6266b40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4f2b072-0bda-46d3-bc21-e3983de4268b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96839719-3c82-4668-889e-20a245b4c794
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69d4b6a6-36cf-4b4a-964e-18b64bf41704
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffac8b91-afd4-465b-a613-4f99e2a9e0d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32e124a5-86e5-40ec-bfce-32d43fdb6d7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87fb7b5d-1a0f-4966-abba-02d65ef90e80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19a2e83f-a3c4-4ac6-934d-b08cf9838b6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ba473a0-f721-40e7-b59d-c7d35c513884
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 562cf7a3-85b7-4c42-9827-7304486ef193
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7070eaa1-a755-44f5-ba59-5898f804bc01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5026f9f5-7598-4f8e-a702-e02952b197e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3fe9505-2996-43f3-9622-1806d2817fb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message daf625d7-903f-4c41-aa47-a16a7cb25837
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3519d730-3ea6-451c-9360-31f7986c1542
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81f42f9b-b0a6-43ab-9901-604c0a78fce9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f1cd14a-deab-42a1-81bc-fa2589461153
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 825c2472-86ea-46d2-ba56-10c5c937952d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7680db5d-a7b5-4f35-915b-de228c0e23aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b997084-b2e2-4727-ad2a-19dad30c6231
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4faa8c6a-f04b-47d0-b572-6140486717e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ac58bde-4de1-4db6-9325-fd4d500d20c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba6173d4-e7a1-4fce-87cc-7b2adc08fda6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e59b78c-86ca-4f5a-9d69-ace748296227
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87739e63-5ab0-46ca-b4ab-b061f6319daf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 272b7c6c-6524-4871-acc9-9b0e56a5bf90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38ab9121-7ff0-46fa-898e-7a7913b7d37d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b513fb3e-4abc-488c-a8e8-46648421e1e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4b923dc-6e3c-4527-ae8b-62f513448147
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b0ee859-24d2-4b91-aef8-d766133690c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f1996de-43ea-4810-954f-79bed43a4a12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ef9d05d-d38e-4689-a2df-f25228532da0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 409316af-96b9-4a67-a306-bcdac7c1083b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 726de383-d97f-47cc-8a70-e0c79c6108c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c18c24b3-8659-4ee5-98af-8ea3b6f12e7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a640805-0d3d-44ac-afbc-664fc2450132
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e19fc4c0-f75a-4d5d-9caa-d38941ea8cfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 454b8465-8dee-4e5c-afd0-1d7c11b136da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 959b166e-6dcf-445f-8b3d-4f4607d45c61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38bc55bb-91eb-4f94-986a-d8db8f8baac9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 545e2218-8fcd-488f-acff-56e422815890
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25d4706a-6b1d-434e-932e-b27e1197ca06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 975f8bf3-8731-4294-9c53-4bb96186ff8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de2d4005-65ad-4a3e-be01-fc32c6d4c1ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63973b12-4df0-4ec9-9acf-f8467164b344
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f23eff98-9f71-4759-95e2-2d45743e197c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41edceed-8a0c-4a4f-a293-f1313788f0b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41969f4f-348b-479c-8d00-a7655313e275
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2379766-af2b-47de-a07b-915d6299b7ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c61e54c-22fa-419b-9335-31cccff97ddf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba066284-0d33-449e-912c-bc0d13a20e8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b369a86-79dc-4752-8e33-a043572652c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ce10784-5b7b-4397-976d-c70aed34db3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9764f083-5c25-44e7-af99-d1478422b770
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61226aaa-377d-4ded-9aac-f1ca94e97606
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03f1fd84-b3b2-4243-91cf-ef285a20c25d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85dbf810-c709-4dc2-ba8f-f55bc2d0e0f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7db823a7-21af-40a5-85c0-2f86cdbac5c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc20f8b2-36e6-4e93-9ae1-4dc0ccf0dc74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e4b8724-dc56-4528-8825-e3998a8008ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c847ef7-6de3-476e-86aa-a78c0677ba99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d4d6854-fa43-484a-bd6b-bce7e11b7c27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00f8c40b-1748-4137-8c30-bcd87f271fff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6631ee28-c81f-4a49-ad02-b6ce17b9ced6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a577c074-caaa-4803-8653-2033d8297000
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e9a40da-eeb7-485a-8667-80f0157cc043
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 803e678e-d58e-43ed-b039-a6a7b2980fc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29d2a1f3-a3dd-4e04-bcb6-e74e05d50630
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f000286-da3b-4268-963d-edbc2adff80d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 749e32dd-3b5d-483e-bd5b-b28755b15ddf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8caa9461-980a-455d-958c-bfbaad6b1c2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 227c8459-a69f-424a-91e2-ba841cf38268
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc5a207b-a788-4554-863b-f6792f65b1b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fedb113e-3e7c-4496-b282-70d8fc122506
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edc782b0-e064-48b0-bf56-d6880413a9c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 614bd6f4-d821-48bb-8ff8-57575164a006
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de9db974-5fc5-4a78-a360-8db431ec57c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51f3067e-8c7c-4b84-93ac-62c9341afb87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b271c10-c20b-4a25-9c56-f823f1595b30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8078e845-8282-4ea4-a69f-d0d80cc5ebf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a90cdd0b-5e60-4d68-9626-f5319bb0ddf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d54e264d-cff3-4741-a672-2625453c2e79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 031572d8-1f62-47d6-a750-2efcc6e5185a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d91bcae9-5ed4-437f-8770-bb6c5e424f2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe861c45-d1fe-4460-ab7c-6d47fd148d1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cda05ae7-aede-4c26-90de-9d2ac9ff3376
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06a47a13-196f-4c98-8723-b7c80e1c816e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb4f944c-4f0b-46de-9f79-98740c96f947
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d84231c9-4d46-4153-8aea-f4e44a2a296e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9cc3c1fa-2a60-477a-aaad-e170b9673622
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c426f3c-e807-4c06-90d2-f245649d89ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c9ba54b-50fe-4024-b5fd-99f5e23af39c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2d90b65-167c-41fa-b875-5d912ce6dcae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3787226-ff35-4b24-92f7-01cdc4680a93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2cb74abd-2b5f-4ec6-9673-c4d94022fccd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8b49e54-c560-449e-a031-430aeaf844d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 200cfadd-feb9-4d83-ac2a-4ec6f0dc924a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1f62d8c-2ea7-4d43-a8c8-c4fb9b800c00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ae4e7f4-02c6-446a-ad7f-158a44be644e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0b63f6d-b2ae-46ce-8882-92774c6336bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9c04aff-0bb9-4cc6-8613-40414379abda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba73afef-3167-4d8e-a77b-c7a4545dc39d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf27acde-0562-4174-b8c8-541f811dd163
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33bcca66-1bca-49ce-9d5c-25f8afe72c61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5d89f01-2426-40a8-a262-3f8c27bf833f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8255cf4a-278f-4f69-8a19-d62cbc8e78f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a58faf0d-a74f-41d2-a2ce-e49401e31e04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a62a60e5-6c3d-4f82-ab95-135df8b0efeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e611aee3-ba01-4fa1-a471-5195f9900709
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 085a2a48-0763-41d2-88c1-3dc4150a3308
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e40046fe-8a61-4a57-8359-18a329b7484f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5eb75503-8eb5-4205-8b51-f57b3126b94f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91b5a260-c607-4e79-a3e5-3bc039ff63d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de3ef20a-b9d6-4a7c-8dbb-8ed4501513d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61adc3bf-8c23-4e87-bef9-e3c8d477194a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab766194-f3f2-4a31-9560-0ac861b49364
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ee04603-5e81-4960-a185-5a1a9d2865a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e631d568-a568-40ea-9cba-dbb90ff78071
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a522fd2-073e-4bd2-8ade-03276fdc73a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ab68328-2aef-4859-9adb-bfdad14c6aad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35bb06e5-84f0-42a5-bf80-6e224d870001
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1add4e1a-82c9-48a3-9434-65962ce04636
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f9dca96-8f3b-4300-a9be-278090e6bd46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 620e38f4-3e25-4e38-919b-6633e16b9f8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fe4bf48-8097-4abe-8c03-bd924ac144f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b5f575d-667d-427b-ad08-c421f5bca5e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efdd2d3d-f4df-4a0a-b66d-fb74cb328118
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4923f1b-5ae8-4576-b083-681b68e90f2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6b94d60-8986-4988-a0bf-093f9ab377cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e97aaa54-cda7-404b-b018-ba8c7f7699b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0464e9a-0617-433f-88f6-954a4474adb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9238b7ea-9bee-46df-8059-1693f6480b14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2940d598-1c1c-48a3-9928-03bed2dd2661
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e309444-0746-43e4-9abb-193c7ee3d86b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b144390e-1e30-4159-9c13-799f60b7e03c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6af75a39-4927-44bb-b74e-0b31d0cd492c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6c9ea2c-5ad8-4b9f-9253-d312fcd428a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bb8512e-8dae-4d9d-bb9e-7dad8ec9b858
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd2a3e36-9326-4459-8c2d-1df93f796ffe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 871750f1-62d5-48fb-a5a7-3ac655fac8cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8adb5805-4cd7-42d4-9175-f85e87f56fc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f21fc5c-6d6e-4e80-be3d-92daebaa2cee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c36bc6a-2d4a-42ad-b0c2-7ff553d62e01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1a9a7e9-7f52-453a-a613-2363a0472bb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81ad36bf-74f7-49b6-ad57-289b6dbe5ec0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a7cacc4-a969-4122-a894-306918980a76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7964b0a2-5aeb-4914-82a4-dd38da2eb6ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34f16e54-6cf8-4ff6-bab1-567d4d21dedd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d0c0ef6-f56c-442f-ba54-99720aae7b06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba7de860-d7ee-4ca8-b979-eda3e01946a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43aca63e-927b-440f-91b4-4cfd0682b34e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 487918e9-02b9-4d9b-a6e9-c3a8da3dfd9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c631ee7-3b10-4cd8-8f2b-9e8c28d36b8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62155f65-b8c6-4d30-923b-973fddf51510
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df5d95c2-0b61-4af5-99ad-3d370e8c2b51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5e07c6c-55be-48ec-a1f7-d3e29c7aa23c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0184bb9-149c-4f7a-ac00-d8a1efbe09cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1a78bea-90ed-48f5-91b3-93bcc807d2b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fee8cd61-a06e-4373-915a-c7392aa6016f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b958dbc3-617a-4fae-ada4-afa7e25622da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0fcd6e4-4c75-4334-b15f-5c134e08351b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74eecff6-0c5c-4271-bf91-3ef45883d623
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01aa4c0e-70cc-41e1-8c86-b6f1ef239766
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0674397-405c-44fd-9f68-18640247f1e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a87a2c39-e884-4a0d-ab34-0e1f1eee19f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d79de42-90e4-40a0-a83b-636766634ecf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83d254de-2b4d-4718-a266-42c09864577b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65f80464-6607-44aa-848c-62661b140620
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19353e33-25c0-4420-8d96-812dc210cba4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31dd7286-0354-47d3-8613-768acc309b54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6cd9db8d-bc30-40ec-b20e-9ed460c4290a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fae82e42-fd44-463e-af2e-dcd4c2689584
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c8d1397-915f-47ad-8023-9317a8c059c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eadc4bb4-9317-43eb-a60c-59e419ae30e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b815143e-d333-4892-a5b8-4f1664a44bc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1595adc0-4b4e-4986-b5ca-986194051832
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd531466-efcb-46d0-881c-e0d6e5cd829c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a39c1685-f99a-4570-96ad-4445bf81e9e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95f56a78-f120-42e7-b352-212b71eace8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c528b3a-fe22-45bd-9fd3-c99c4fccbe46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19871020-680a-44e5-878e-0f752b499f1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc773796-55f0-4830-b40a-173beeabaa74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f0aec44-d275-4ebe-822d-01141e514f55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1f73064-dc8a-430f-b297-61fd401e9b37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84c9ffc9-19bc-4f0d-a5ee-89c2450c128b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e895cd00-edf0-471d-b76f-351a01c28fc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87383454-b5e6-4924-b091-4a10080d58e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39d76355-fe5c-4af1-8f4e-b3b16343d9ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5679b2f1-0e6a-4d11-ae63-4d2a698e75ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c6fbc48-1204-4b89-a94e-e1f550de91c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 177364ea-cfc0-4f4d-8c14-6041c303f7f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1183b6b5-8bdf-4af7-9d1d-1548c22d5298
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44f5868f-cf9f-4787-9a4c-be7a4cac7537
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1716505a-7151-4128-a0f2-3683b6742640
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0c6f699-6fd5-40fe-87cc-a8c4fe8e5908
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75add054-7c16-4c9d-ae5d-e459cbf4259b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edfc77f9-207d-4610-bfce-184d562f2850
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf22a2ff-07a3-498a-9422-aa74d8296937
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8321de6f-2e64-4490-abda-9161c05a7e07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd3bdf58-79f1-4514-a946-0798c7a57950
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18526148-ba0f-4157-bc13-c9c8af006dd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 353bd843-b9c0-45b1-9918-7d90955411b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b05bb87-f66c-4da7-8317-ca4d8bf60ef5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aee9dd0d-cb6c-4b8d-a1e3-465c2de231e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48bbb6de-e46b-4257-a381-197c5b5c33d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ab7d863-ca60-4c67-b290-4b8353130c08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd563221-4a99-4340-a021-412a59d3e546
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a96400bd-a2dd-416e-b366-dddd864c4639
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efd1d7f2-728d-46fd-b5b2-ce88de271fa0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a1dd6a1-6581-474b-b562-84b7047dff01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98654da6-fbe4-4d8e-8e1c-47bd11c7c990
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17777ae8-86c9-4ed2-8dd7-c2eb6f27a6e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8f13b60-dec2-416e-b5ba-798c81b33d91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5a455cc-1c3e-4a6e-bdca-57a0ba41ac38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d54dc67-d64c-479e-8477-d33b83565876
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 870db3a6-bdcf-442b-b751-27eb188bb908
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c8caaaf-fc28-480f-aea8-d73194015677
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8500327b-fe47-400f-a772-e44e9dd88d7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91ba4036-7763-4b88-be4f-9564fb205903
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31597c74-09c6-4700-9fc1-c3f8ea345b63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e37e60ef-a27b-4013-8aee-fb9051e67352
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 318bd525-5f93-4705-bfea-aa4ba44130fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bbce733-c680-4e82-b87f-4a47f43fb023
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message daa0f96e-19cc-4e78-9f07-4e8e1dd5bb6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3a0a6a7-919a-4907-9bb7-87cbf4168023
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2eb96540-47bb-418f-94d0-6b2b99d7d969
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 438406c3-65ee-473d-bc33-194bb8b836fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13a157e0-cf80-4b73-a1c3-0eacd7098d63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61cf1029-2af6-4d2f-ada4-8acedb0179b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e3d1d2c-da27-40c5-9f52-63f3deae80ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 961c5c51-ca36-4bf9-b3a2-459f59122d8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d07568d3-63f3-40ec-80f8-fbc6fadc1537
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b62e1035-9c63-4d50-841c-6bbd8f831657
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01f3edec-8431-48d4-9f78-27e386754ffb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac7e5313-42cc-43d1-919e-77fcbe33db4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2b230d6-1bf1-4aba-923a-7bbd4d092ea0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4da2f346-3ec5-4823-a12b-1c36f7140704
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89eeb9e0-3365-463f-9909-d7fa4609688b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 718e15bc-8462-48c5-bdb0-37923e8acfb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d21f63ea-73e1-4109-a1c2-c4b1d918e01c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 324a607d-3d1f-4aea-8a6c-f93102094673
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc9ff5e5-9952-4e44-a442-7dd2e8acfd9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b15e55f5-0887-493d-a215-abfd1532dd30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22fee9ef-4518-4277-b248-413fbcd04111
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 971a3c05-1c37-4f92-a2a1-60944fc166db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 445739e8-40d6-48f8-904b-e2bd6f08c56a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ac5a4cc-9322-4784-88c2-c39a657d70cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f64ced5-1b12-4238-9275-c9f98062e835
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfdd0614-6650-4abb-b0e8-b3c1c916b0e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa1efac7-a5bb-4858-b12d-e601bca57b5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 179996a0-c949-46f3-94a8-92783da158ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7eb1cdef-945f-4eec-8e2b-c32e040bf121
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a07754c1-2416-414d-93dd-b95a1caad9a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7743e056-92c1-4fa8-9551-423b9b1f8f88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c94e9a00-7e23-4882-bbea-04c11816a884
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e163d7d-57bc-4e3f-bd2a-b97705d810fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbbe7e94-b7fa-4068-bc4d-202a295523bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63ae7355-c9be-48f9-9ce6-d6ffc03704b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 621e0742-0476-40de-b8e1-80cbbe627731
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e900640-8a51-452b-a480-a7e614dbd14b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34197979-7d21-4ead-a067-02e053989a89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d794b90-4995-49c7-8d7c-4c65cbddfb22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9e46d26-ef31-434e-ad81-b98de8f305dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3555e7b-278f-47b3-ad88-bf8c22d701ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc111dd6-3c21-425c-b660-14d56742921e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f315a38-769f-4a32-8c49-fbfb8ceebc87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 010bdd97-b01b-46ca-8e26-03195931b931
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message badce249-8e8f-4491-ba3e-139c92e31164
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15e5cad6-27aa-4629-a3d7-1a5b1d418034
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc544949-500d-4adb-9ac4-ff4dc201b1f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a7995ce-26bf-49a5-8dad-2ed2bc5d0082
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30b4eda3-0482-492f-88ea-1c35d6cdb98d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49f42796-1bb3-4ca2-afc7-f5bacfbb6683
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4e2d5ca-b04c-4352-b742-5c0a76ee30f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0a04007-0e7d-4db5-93e0-03c79cc8b75c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2692a767-727b-45e7-b5e4-ff1790552ec9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b81ace93-2aff-41ba-a2b4-a198853ffb10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4fc73c66-8089-4e87-ac0a-96a9230e09f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31a52ced-6d21-4c0f-b3a8-ee46b256b6e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb66434f-71f4-4e7f-9e74-296a1ed81f77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9495259-7b64-4f60-9e35-672f467494f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a1c0127-95ab-4fe7-b023-25ddece49b51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 418335db-2839-40bc-8ff3-cf8bf9c2eb55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03475e50-d249-4437-8e23-c99d1ffee89b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92922db4-facd-43c4-a544-a5149653bb8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8e05cc9-06b7-424e-ba18-86ef22f6a936
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8de7f3b8-3007-4c9b-9571-21ee06521d3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19a176df-7967-4042-a174-28a6fddb932b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4187960-231e-4414-8248-4e8b76575d34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b92e68ab-8bbe-48b0-8944-6b1e92f0ed88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d03b6a2-8f10-480e-b012-c778168101ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75872d6b-e535-44ac-90e1-20627a9e5aac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cb806fb-214f-494e-b48f-3f97643a8c9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61731d65-f12c-4607-9b0a-d1534fb498ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 227a4d1d-d597-4ec3-9fca-7fce128c79c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5108e947-c240-4752-9e70-6dfa6ab778ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1929a940-6ddb-4d83-838d-76aad30bfa5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba132123-bb26-457c-8ce1-d8183d0f3e97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3819e52c-8f92-477c-947b-49aee19321b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 188c6ef3-e2d0-4aae-aceb-edc043ba906a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7df631e8-023b-4cbe-83a7-b7c208a96190
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee59b10c-fd9b-433d-9b48-b51ce04a8e57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cee3990f-03ad-4073-bc88-3fa9a02ef0f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3f3e367-7b8d-4eab-9449-c87a3b57afd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 643a4e9b-1af9-455c-a622-bdde56796e60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bdb717fd-cb83-4b81-90a1-14815d7578f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b2fd5ca-034a-46eb-98a1-42551b1d7996
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3848493b-7048-4b94-93b5-956b237a6b8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 536fd1a8-105d-4c9a-a4c4-5bac9b94ef11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78f4a47d-ce91-4fa1-a1e8-529b49bfbcc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43cf164d-cadd-42ba-b1c9-4d0a8ecbccf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4899b983-17c2-4037-b166-e3be7ae27c2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9bf23e33-123f-41a6-885b-893fb36ccd53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01285942-3c7d-4e02-90a3-fb3c97a423de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb3cf8b9-e26b-4a91-8b38-201acddbe23f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61c1f8a7-f992-40c8-b992-ee240e1bb330
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0aa9af37-3084-4e72-8823-bfa75a7c03fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f08c3abb-6c84-4c2a-9b25-eb23106f88c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f92d2e30-9013-4114-93fa-51eeb872bd4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 325ba554-4101-429b-a009-e45ebb2558d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b9ae123-eee1-4bd5-b101-30d609ac3317
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c9ea942-cd1a-46f0-bbf4-02d2492e3623
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe94bd24-e791-4534-b0fd-736b48433390
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a032c73-bddb-4791-be7b-d4675ab05890
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c31edf6-b371-4b56-911d-ad6f1c137590
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6218dc4b-360c-42df-8513-96dda760f514
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b53139b-98da-4b5d-a7b0-17ac7cfd98a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c86b54b3-534e-4cca-b834-9ca41f8b08bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f776fe94-de74-42f8-8881-865414ef7daa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 008827da-b4a9-4f93-b13a-7882d23d4ff8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6f1ce65-623d-4dc4-afcd-c059e15c3a30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d24d3c74-05cc-47fa-a079-3f84dcf3c19a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3975c55-7213-4f05-b855-bf731e9aaa21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74d6f891-224f-4d1b-8490-7ed8719366c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12fe711e-ae17-4a2e-b42f-65897a415294
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8178b138-255e-4f54-b419-20c60659ea0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd114d8f-3911-4ca7-a6a2-6f2f377f2f2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5dbfbda0-6e63-4324-a870-026229f98b0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddc1b114-ba17-4154-8b92-f24df1701204
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ba58073-94f0-4c8e-87b8-afeb62718c32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b154ea7a-a4d6-47ff-96e1-60ecbed46b44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d1c4a2c-e67f-4739-9614-3e67390eddf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79935729-1558-4fa6-ac0d-2095af321438
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 227d7769-ea29-4366-b159-78c3bd1d7eeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cbe815e-d565-44e8-b412-7faafff4302a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 461d59d9-bf10-4ae6-8f3d-6718e82a7b70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c296a529-1c1a-497b-bb42-00092b3e9fd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ac5f720-0ae3-4514-976e-c759c585cfde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 023c4b3f-c483-4ad1-a08c-d45e47e988ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91cd0bbf-6e9e-43d8-89ac-b92e29f022c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ea3c7ea-b926-4ef3-a67f-cdf256a28c66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 353de305-eb4f-4b60-915b-66d925317d81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36fc3fcc-f2ff-47af-87b0-24e1ab6b48c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5f6a59c-7696-485c-a1fb-2ae459028701
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7887f313-43aa-448f-9dae-216b70aacac2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed7ed144-ff0c-4981-b351-1904604eed2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a78e8d2f-2a0a-4890-810b-ac2b1ba6c4f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e5f6354-e44d-45f6-9709-814bd435995f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92214b05-ceb4-4ac2-ba41-ff005ce8738d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 194306a5-5fdf-4e58-a429-73110dd35164
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ae5f9c1-3bdb-41ed-9686-d1b011a885b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14bb14d9-4992-4eb1-94e0-d5d61ad27fb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9afe2fa7-cbc4-4ddf-9f9f-b5d8c47353a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fd2ccb8-0f24-46ba-a5f8-8d0420b18ad0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d36d8cea-0cee-4cd3-ba5d-1057261fbd23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ba8ca8f-8c6f-48ef-826b-db61c4280885
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3d20343-f813-4156-9089-7a954736b702
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 545a787f-2b70-457c-bbf4-7714e6f7435d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acd06158-e6de-4580-9e50-ef82d8934178
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4859dee4-18cf-4803-8df3-7b58545d1234
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 608e5a4e-723d-41aa-84ab-882a45ecc2cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23fff218-08e7-4dce-8e83-d63370f2cef1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d60e209f-2d1e-4d5e-bcbf-9565051b186d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa9d0223-077a-4bff-a3c1-a01d16614dcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8542e95f-5ddb-472c-9178-b8b6c4a1bf41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c08a559d-5b8c-41fc-9ed4-d2f98789ba3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c881ecd9-503c-4154-9d67-358113d7f9ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 550cc58d-ea45-41ce-aebe-231d10259f7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52b56db8-bc27-418a-beda-49f97e5d9437
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff172bbe-3195-4d68-a93a-ff1282e80390
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7917bd69-3c60-41fa-9393-bfea9ccf51a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e702e7e-ff43-4030-8f37-ed48abe29491
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04d3a46b-e771-440a-a21e-6438270fa484
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9e87dc7-a377-4350-81c2-4d3754f7c907
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b150416-9d35-4320-a6be-d03a788144ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2dc025e3-e7a6-4d76-8dd2-396959f5e908
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3bf9bf0-31c3-45ac-b43a-c161b0ff24c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0933869d-8f79-4ef8-b716-11ce1d9e5155
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b4f9751-0aa2-480c-88f9-80feff04c29c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c25b03c-0054-4cf0-8188-b90dc69093f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ec98a3b-f740-4d42-9d3c-e036506f21cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33a16743-e17e-40da-9fd5-ccd360353195
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 294bff0c-b91b-459e-a5e7-5edd2cac005e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cf40545-bf95-4330-8fe3-8fc82ef0520b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 385f2470-ab68-40ea-a7e6-e34df309878e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a8a272e-8e3f-48d9-b086-74ea8eb50715
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0f9b78d-e255-470d-bf00-5fb9d04f54d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0dd3ae4-e471-4c09-b68a-1daddd7a17f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 302bba5d-0e19-4d4f-84b3-85a4acc39fbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ea8b965-5f69-4a3c-8978-3901cc22a2f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6480ce5f-864f-4eda-b09b-6f11f5d77a34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a20e6afd-fe3b-4be6-b876-26d2634d582a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eab73655-7252-499c-b243-aeab61900669
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b017c54-5294-4927-8b11-135169f4c9f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61769325-fc7c-4ac6-b5fe-c475211e800f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41684cb5-4c0f-4c2c-b293-daa67a1b6a23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b8df34d-4b3f-4cee-b521-45d0d073d95e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ef4c773-412b-4ccd-b908-2cacc51e8cad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a28faaf1-f880-4355-b1f1-3f7e672584e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f70280a7-255c-4652-a931-83a8b5206645
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8771463e-1a8a-4ecc-a22e-7a909772ae7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2bacf32-d476-4c89-bfeb-0ddb57dda2f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06f742b3-d3a5-4b56-934e-5f76943a4f7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7cde0a6-139a-4909-a522-eaa726665334
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e7a372d-3ed6-4463-8378-7ec882252654
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b36baa6-8922-4319-b262-2b1bb8f83225
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1acf3f9d-340e-48c7-812e-d7066c07158a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa1327a8-b74a-47c1-b7e3-c0153da6be51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d55c25d-2ec1-40c1-ad62-63df3b950b33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d50f426-9ef4-4f6f-90d2-afe0b7654277
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26e88735-926e-410b-bed9-9ab6efeda642
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 221e0b06-65ab-487b-8f6c-ce5305cac339
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_23
Server: localhost:8686
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_23
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_23/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_23/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_23/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_23/test_labels.txt

📊 Raw data loaded:
   Train: X=(7224, 24), y=(7224,)
   Test:  X=(1806, 24), y=(1806,)

⚠️  Limiting training data: 7224 → 800 samples
⚠️  Limiting test data: 1806 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_23 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 3 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0879 (↓), lr=0.001000
   • Epoch   2/100: train=0.0836, val=0.0886, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0837, val=0.0885, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0836, val=0.0881, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0834, val=0.0876, patience=4/15, lr=0.001000
   • Epoch  11/100: train=0.0817, val=0.0874, patience=3/15, lr=0.001000
   📉 Epoch 18: LR reduced 0.001000 → 0.000500
   • Epoch  21/100: train=0.0769, val=0.0893, patience=13/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 3 Summary - Client client_23
   Epochs: 23/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0117
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0099
============================================================


============================================================
🔄 Round 5 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0886 (↓), lr=0.000500
   ✓ Epoch   2/100: train=0.0832, val=0.0878 (↓), lr=0.000500
   📉 Epoch 3: LR reduced 0.000500 → 0.000250
   • Epoch   3/100: train=0.0829, val=0.0879, patience=1/15, lr=0.000250
   ✓ Epoch   4/100: train=0.0827, val=0.0872 (↓), lr=0.000250
   • Epoch   5/100: train=0.0826, val=0.0874, patience=1/15, lr=0.000250
   📉 Epoch 11: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0823, val=0.0877, patience=7/15, lr=0.000125
   📉 Epoch 19: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 5 Summary - Client client_23
   Epochs: 19/100 (early stopped)
   LR: 0.000500 → 0.000063 (3 reductions)
   Train: Loss=0.0825, RMSE=0.2871, R²=0.0059
   Val:   Loss=0.0872, RMSE=0.2952, R²=-0.0291
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2432, R²: 0.0005

============================================================
🔄 Round 8 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0879 (↓), lr=0.000063
   • Epoch   2/100: train=0.0827, val=0.0879, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0827, val=0.0879, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0826, val=0.0879, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0826, val=0.0879, patience=4/15, lr=0.000063
   📉 Epoch 8: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0824, val=0.0880, patience=10/15, lr=0.000031
   📉 Epoch 16: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 8 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0017
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0017
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0815, RMSE: 0.2856, MAE: 0.2436, R²: 0.0010

============================================================
🔄 Round 9 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0857 (↓), lr=0.000016
   • Epoch   2/100: train=0.0832, val=0.0858, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0832, val=0.0858, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0832, val=0.0858, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0832, val=0.0859, patience=4/15, lr=0.000016
   📉 Epoch 8: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0831, val=0.0859, patience=10/15, lr=0.000008
   📉 Epoch 16: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 9 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0006
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0094
============================================================


============================================================
🔄 Round 10 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0766 (↓), lr=0.000004
   • Epoch   2/100: train=0.0856, val=0.0766, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0856, val=0.0766, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0855, val=0.0766, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0855, val=0.0766, patience=4/15, lr=0.000004
   📉 Epoch 8: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0855, val=0.0766, patience=10/15, lr=0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 10 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000002 (1 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0010
   Val:   Loss=0.0766, RMSE=0.2767, R²=-0.0118
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0012

============================================================
🔄 Round 12 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0862 (↓), lr=0.000002
   • Epoch   2/100: train=0.0833, val=0.0862, patience=1/15, lr=0.000002
   📉 Epoch 3: LR reduced 0.000002 → 0.000001
   • Epoch   3/100: train=0.0833, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 12 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0011
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0034
============================================================


============================================================
🔄 Round 13 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 13 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0008
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0009
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2436, R²: 0.0010

============================================================
🔄 Round 18 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 18 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0011
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0213
============================================================


============================================================
🔄 Round 19 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 19 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0016
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0039
============================================================


============================================================
🔄 Round 20 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 20 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0008
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0010
============================================================


============================================================
🔄 Round 21 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 21 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0043
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0131
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2436, R²: 0.0010

============================================================
🔄 Round 24 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 24 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=-0.0011
   Val:   Loss=0.0770, RMSE=0.2774, R²=0.0002
============================================================


============================================================
🔄 Round 25 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 25 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0010
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0007
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2435, R²: 0.0010

============================================================
🔄 Round 26 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 26 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0001
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0057
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2435, R²: 0.0010

📊 Round 26 Test Metrics:
   Loss: 0.0815, RMSE: 0.2856, MAE: 0.2435, R²: 0.0010

📊 Round 26 Test Metrics:
   Loss: 0.0815, RMSE: 0.2856, MAE: 0.2435, R²: 0.0011

============================================================
🔄 Round 32 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 32 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0017
   Val:   Loss=0.0830, RMSE=0.2880, R²=-0.0137
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0815, RMSE: 0.2856, MAE: 0.2435, R²: 0.0011

============================================================
🔄 Round 35 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 35 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0023
   Val:   Loss=0.0903, RMSE=0.3005, R²=0.0049
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0815, RMSE: 0.2856, MAE: 0.2435, R²: 0.0011

📊 Round 35 Test Metrics:
   Loss: 0.0815, RMSE: 0.2856, MAE: 0.2435, R²: 0.0011

📊 Round 35 Test Metrics:
   Loss: 0.0815, RMSE: 0.2856, MAE: 0.2435, R²: 0.0011

============================================================
🔄 Round 38 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 38 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0008
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0085
============================================================


============================================================
🔄 Round 39 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 39 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0039
   Val:   Loss=0.0910, RMSE=0.3016, R²=0.0104
============================================================


============================================================
🔄 Round 40 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 40 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0015
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0020
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0815, RMSE: 0.2856, MAE: 0.2435, R²: 0.0011

============================================================
🔄 Round 41 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 41 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0011
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0034
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0815, RMSE: 0.2856, MAE: 0.2435, R²: 0.0011

📊 Round 41 Test Metrics:
   Loss: 0.0815, RMSE: 0.2856, MAE: 0.2435, R²: 0.0011

============================================================
🔄 Round 43 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 43 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0002
   Val:   Loss=0.0914, RMSE=0.3023, R²=-0.0100
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0815, RMSE: 0.2856, MAE: 0.2435, R²: 0.0011

============================================================
🔄 Round 44 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 44 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0023
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0289
============================================================


============================================================
🔄 Round 46 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 46 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0004
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0025
============================================================


============================================================
🔄 Round 47 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 47 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0014
   Val:   Loss=0.0859, RMSE=0.2932, R²=0.0016
============================================================


============================================================
🔄 Round 48 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 48 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0002
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0056
============================================================


============================================================
🔄 Round 49 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 49 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0021
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0039
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0815, RMSE: 0.2856, MAE: 0.2435, R²: 0.0011

============================================================
🔄 Round 50 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 50 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0018
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0023
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0815, RMSE: 0.2856, MAE: 0.2435, R²: 0.0011

============================================================
🔄 Round 52 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 52 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0022
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0126
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0815, RMSE: 0.2856, MAE: 0.2435, R²: 0.0011

============================================================
🔄 Round 54 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 54 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0005
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0025
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0815, RMSE: 0.2856, MAE: 0.2435, R²: 0.0011

============================================================
🔄 Round 57 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 57 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0000
   Val:   Loss=0.0822, RMSE=0.2868, R²=-0.0113
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0815, RMSE: 0.2856, MAE: 0.2435, R²: 0.0011

📊 Round 57 Test Metrics:
   Loss: 0.0815, RMSE: 0.2856, MAE: 0.2435, R²: 0.0011

============================================================
🔄 Round 59 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 59 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0028
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0050
============================================================


============================================================
🔄 Round 60 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 60 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0036
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0063
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0815, RMSE: 0.2856, MAE: 0.2435, R²: 0.0011

📊 Round 60 Test Metrics:
   Loss: 0.0815, RMSE: 0.2856, MAE: 0.2435, R²: 0.0011

============================================================
🔄 Round 64 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 64 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0027
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0121
============================================================


============================================================
🔄 Round 65 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 65 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=-0.0037
   Val:   Loss=0.0894, RMSE=0.2991, R²=-0.0112
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0815, RMSE: 0.2856, MAE: 0.2435, R²: 0.0011

============================================================
🔄 Round 69 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 69 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0018
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0034
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0815, RMSE: 0.2856, MAE: 0.2435, R²: 0.0011

============================================================
🔄 Round 70 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 70 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=0.0006
   Val:   Loss=0.0741, RMSE=0.2723, R²=-0.0126
============================================================


============================================================
🔄 Round 72 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 72 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0003
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0080
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0815, RMSE: 0.2856, MAE: 0.2435, R²: 0.0011

📊 Round 72 Test Metrics:
   Loss: 0.0815, RMSE: 0.2856, MAE: 0.2435, R²: 0.0011

============================================================
🔄 Round 74 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 74 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0022
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0059
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0815, RMSE: 0.2856, MAE: 0.2435, R²: 0.0011

📊 Round 74 Test Metrics:
   Loss: 0.0815, RMSE: 0.2856, MAE: 0.2435, R²: 0.0011

📊 Round 74 Test Metrics:
   Loss: 0.0815, RMSE: 0.2856, MAE: 0.2435, R²: 0.0011

============================================================
🔄 Round 78 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 78 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0007
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0048
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0815, RMSE: 0.2856, MAE: 0.2435, R²: 0.0011

============================================================
🔄 Round 82 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 82 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0012
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0093
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0815, RMSE: 0.2856, MAE: 0.2435, R²: 0.0011

📊 Round 82 Test Metrics:
   Loss: 0.0815, RMSE: 0.2856, MAE: 0.2435, R²: 0.0011

============================================================
🔄 Round 85 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 85 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0005
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0056
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0815, RMSE: 0.2856, MAE: 0.2435, R²: 0.0011

============================================================
🔄 Round 87 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 87 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0028
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0062
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0815, RMSE: 0.2856, MAE: 0.2435, R²: 0.0012

============================================================
🔄 Round 89 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 89 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0014
   Val:   Loss=0.0940, RMSE=0.3065, R²=-0.0046
============================================================


============================================================
🔄 Round 91 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 91 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0003
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0048
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0815, RMSE: 0.2856, MAE: 0.2435, R²: 0.0012

📊 Round 91 Test Metrics:
   Loss: 0.0815, RMSE: 0.2856, MAE: 0.2435, R²: 0.0011

📊 Round 91 Test Metrics:
   Loss: 0.0815, RMSE: 0.2856, MAE: 0.2435, R²: 0.0012

============================================================
🔄 Round 95 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 95 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0006
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0080
============================================================


============================================================
🔄 Round 96 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 96 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0021
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0049
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0815, RMSE: 0.2856, MAE: 0.2435, R²: 0.0012

============================================================
🔄 Round 101 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 101 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0010
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0078
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0012

============================================================
🔄 Round 103 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 103 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0012
   Val:   Loss=0.0872, RMSE=0.2952, R²=-0.0022
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0012

============================================================
🔄 Round 104 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 104 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0021
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0007
============================================================


============================================================
🔄 Round 106 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 106 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0014
   Val:   Loss=0.0907, RMSE=0.3012, R²=0.0008
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0815, RMSE: 0.2856, MAE: 0.2435, R²: 0.0012

============================================================
🔄 Round 107 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 107 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0010
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0060
============================================================


============================================================
🔄 Round 108 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 108 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0013
   Val:   Loss=0.0919, RMSE=0.3031, R²=0.0014
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0815, RMSE: 0.2856, MAE: 0.2435, R²: 0.0012

============================================================
🔄 Round 109 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 109 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0019
   Val:   Loss=0.0746, RMSE=0.2732, R²=0.0015
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0815, RMSE: 0.2856, MAE: 0.2435, R²: 0.0012

📊 Round 109 Test Metrics:
   Loss: 0.0815, RMSE: 0.2856, MAE: 0.2435, R²: 0.0012

============================================================
🔄 Round 112 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 112 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0020
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0184
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0012

============================================================
🔄 Round 113 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 113 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0025
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0048
============================================================


============================================================
🔄 Round 114 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 114 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0012
   Val:   Loss=0.0889, RMSE=0.2981, R²=0.0010
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0012

============================================================
🔄 Round 116 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 116 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0030
   Val:   Loss=0.0785, RMSE=0.2801, R²=-0.0238
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0012

============================================================
🔄 Round 118 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 118 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0011
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0082
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0012

📊 Round 118 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0012

============================================================
🔄 Round 121 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 121 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0002
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0146
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0012

============================================================
🔄 Round 124 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 124 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0021
   Val:   Loss=0.0848, RMSE=0.2911, R²=-0.0040
============================================================


============================================================
🔄 Round 125 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 125 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0017
   Val:   Loss=0.0927, RMSE=0.3045, R²=-0.0081
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0012

📊 Round 125 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0012

============================================================
🔄 Round 130 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 130 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0030
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0055
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0012

============================================================
🔄 Round 132 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 132 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0018
   Val:   Loss=0.0913, RMSE=0.3021, R²=-0.0046
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0012

============================================================
🔄 Round 133 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 133 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0013
   Val:   Loss=0.0760, RMSE=0.2756, R²=-0.0155
============================================================


============================================================
🔄 Round 134 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 134 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0007
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0068
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0012

📊 Round 134 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0012

📊 Round 134 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0012

============================================================
🔄 Round 138 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 138 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0008
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0076
============================================================


============================================================
🔄 Round 141 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 141 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0002
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0084
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0012

============================================================
🔄 Round 143 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 143 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0005
   Val:   Loss=0.0917, RMSE=0.3029, R²=-0.0045
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0012

📊 Round 143 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0012

📊 Round 143 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0012

📊 Round 143 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0012

============================================================
🔄 Round 147 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 147 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0004
   Val:   Loss=0.0925, RMSE=0.3041, R²=-0.0064
============================================================


============================================================
🔄 Round 148 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 148 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0010
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0000
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0012

📊 Round 148 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0012

📊 Round 148 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0012

============================================================
🔄 Round 154 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 154 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0009
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0132
============================================================


============================================================
🔄 Round 156 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 156 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0003
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0122
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0012

============================================================
🔄 Round 159 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 159 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0004
   Val:   Loss=0.0728, RMSE=0.2698, R²=-0.0051
============================================================


============================================================
🔄 Round 160 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 160 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0000
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0060
============================================================


============================================================
🔄 Round 161 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 161 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0020
   Val:   Loss=0.0749, RMSE=0.2736, R²=0.0050
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0012

📊 Round 161 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0012

📊 Round 161 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0012

============================================================
🔄 Round 165 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 165 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=0.0007
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0087
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0012

📊 Round 165 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0012

📊 Round 165 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0012

📊 Round 165 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0012

============================================================
🔄 Round 171 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 171 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0017
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0030
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0012

============================================================
🔄 Round 172 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 172 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0017
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0002
============================================================


============================================================
🔄 Round 174 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 174 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0024
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0058
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0013

============================================================
🔄 Round 176 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 176 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0007
   Val:   Loss=0.0924, RMSE=0.3039, R²=-0.0063
============================================================


============================================================
🔄 Round 179 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 179 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0012
   Val:   Loss=0.0898, RMSE=0.2997, R²=-0.0005
============================================================


============================================================
🔄 Round 182 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 182 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0025
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0028
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0013

============================================================
🔄 Round 183 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 183 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0029
   Val:   Loss=0.0715, RMSE=0.2674, R²=0.0059
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0013

============================================================
🔄 Round 184 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 184 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0009
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0083
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0013

📊 Round 184 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0013

============================================================
🔄 Round 187 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 187 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0005
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0117
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0013

============================================================
🔄 Round 188 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0704, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0704, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0704, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0704, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0704, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 188 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0008
   Val:   Loss=0.0704, RMSE=0.2654, R²=-0.0046
============================================================


============================================================
🔄 Round 189 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 189 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0008
   Val:   Loss=0.0932, RMSE=0.3053, R²=-0.0041
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0013

📊 Round 189 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0013

============================================================
🔄 Round 194 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 194 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0020
   Val:   Loss=0.0934, RMSE=0.3057, R²=0.0034
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0013

============================================================
🔄 Round 195 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 195 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2916, R²=-0.0043
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0018
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0013

============================================================
🔄 Round 196 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 196 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0017
   Val:   Loss=0.0729, RMSE=0.2699, R²=0.0037
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0013

============================================================
🔄 Round 197 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 197 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0038
   Val:   Loss=0.0837, RMSE=0.2894, R²=0.0050
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0013

============================================================
🔄 Round 200 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 200 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0006
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0077
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0013

============================================================
🔄 Round 201 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 201 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0032
   Val:   Loss=0.0856, RMSE=0.2927, R²=0.0055
============================================================


============================================================
🔄 Round 202 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 202 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0013
   Val:   Loss=0.0907, RMSE=0.3011, R²=-0.0087
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0013

============================================================
🔄 Round 203 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 203 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0002
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0054
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0013

============================================================
🔄 Round 204 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 204 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0015
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0002
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0013

============================================================
🔄 Round 206 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 206 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0007
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0136
============================================================


============================================================
🔄 Round 207 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 207 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0004
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0025
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0013

============================================================
🔄 Round 210 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 210 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0008
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0003
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0013

📊 Round 210 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0013

============================================================
🔄 Round 213 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 213 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2915, R²=-0.0009
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0003
============================================================


============================================================
🔄 Round 214 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 214 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0010
   Val:   Loss=0.0801, RMSE=0.2829, R²=0.0005
============================================================


📊 Round 214 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0013

============================================================
🔄 Round 215 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 215 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0009
   Val:   Loss=0.0724, RMSE=0.2691, R²=-0.0039
============================================================


📊 Round 215 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0013

📊 Round 215 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0013

============================================================
🔄 Round 218 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 218 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0001
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0149
============================================================


============================================================
🔄 Round 220 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 220 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0002
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0126
============================================================


============================================================
🔄 Round 222 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 222 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0000
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0039
============================================================


📊 Round 222 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0013

📊 Round 222 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0013

============================================================
🔄 Round 225 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 225 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0012
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0124
============================================================


📊 Round 225 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0012

============================================================
🔄 Round 232 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 232 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=-0.0027
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0080
============================================================


📊 Round 232 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0012

============================================================
🔄 Round 234 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 234 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0009
   Val:   Loss=0.0732, RMSE=0.2706, R²=-0.0002
============================================================


📊 Round 234 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0012

📊 Round 234 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0013

📊 Round 234 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0013

============================================================
🔄 Round 245 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0960 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0960, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0961, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0961, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0961, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0961, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0960)

============================================================
📊 Round 245 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0007
   Val:   Loss=0.0960, RMSE=0.3099, R²=-0.0158
============================================================


📊 Round 245 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0013

============================================================
🔄 Round 247 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 247 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0010
   Val:   Loss=0.0855, RMSE=0.2925, R²=-0.0127
============================================================


============================================================
🔄 Round 248 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 248 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0005
   Val:   Loss=0.0826, RMSE=0.2873, R²=-0.0103
============================================================


📊 Round 248 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0013

============================================================
🔄 Round 251 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 251 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=-0.0006
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0013
============================================================


📊 Round 251 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0013

📊 Round 251 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0013

============================================================
🔄 Round 254 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 254 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0003
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0024
============================================================


📊 Round 254 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0013

📊 Round 254 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0013

============================================================
🔄 Round 257 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 257 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0003
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0023
============================================================


============================================================
🔄 Round 258 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 258 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0001
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0084
============================================================


📊 Round 258 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0013

============================================================
🔄 Round 260 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 260 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0001
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0027
============================================================


📊 Round 260 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0013

📊 Round 260 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0013

📊 Round 260 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0013

============================================================
🔄 Round 264 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 264 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0017
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0023
============================================================


============================================================
🔄 Round 266 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 266 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0001
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0306
============================================================


============================================================
🔄 Round 268 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 268 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0034
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0081
============================================================


============================================================
🔄 Round 272 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 272 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0004
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0025
============================================================


📊 Round 272 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0013

============================================================
🔄 Round 273 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 273 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0004
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0050
============================================================


📊 Round 273 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0013

============================================================
🔄 Round 274 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 274 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0019
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0099
============================================================


============================================================
🔄 Round 276 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0708, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0708, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0708, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 276 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0008
   Val:   Loss=0.0707, RMSE=0.2660, R²=-0.0224
============================================================


📊 Round 276 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0013

============================================================
🔄 Round 281 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 281 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0019
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0292
============================================================


📊 Round 281 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0013

============================================================
🔄 Round 284 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 284 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0001
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0083
============================================================


============================================================
🔄 Round 285 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 285 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0012
   Val:   Loss=0.0895, RMSE=0.2992, R²=0.0011
============================================================


📊 Round 285 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0013

============================================================
🔄 Round 288 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 288 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0003
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0023
============================================================


📊 Round 288 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0013

📊 Round 288 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0013

============================================================
🔄 Round 292 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 292 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0006
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0099
============================================================


📊 Round 292 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0013

📊 Round 292 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0013

============================================================
🔄 Round 294 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 294 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=0.0001
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0059
============================================================


📊 Round 294 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0013

============================================================
🔄 Round 298 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 298 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0015
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0013
============================================================


============================================================
🔄 Round 300 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 300 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0032
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0054
============================================================


📊 Round 300 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0013

============================================================
🔄 Round 302 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 302 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0002
   Val:   Loss=0.0753, RMSE=0.2745, R²=-0.0036
============================================================


📊 Round 302 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0013

============================================================
🔄 Round 305 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 305 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0005
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0015
============================================================


============================================================
🔄 Round 306 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 306 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0005
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0086
============================================================


============================================================
🔄 Round 307 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 307 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=-0.0008
   Val:   Loss=0.0806, RMSE=0.2840, R²=-0.0033
============================================================


============================================================
🔄 Round 308 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 308 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0003
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0044
============================================================


📊 Round 308 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0014

============================================================
🔄 Round 309 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 309 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0016
   Val:   Loss=0.0889, RMSE=0.2981, R²=-0.0067
============================================================


============================================================
🔄 Round 310 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 310 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0026
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0077
============================================================


📊 Round 310 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0014

============================================================
🔄 Round 312 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 312 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0004
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0025
============================================================


📊 Round 312 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0014

============================================================
🔄 Round 316 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 316 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0017
   Val:   Loss=0.0734, RMSE=0.2710, R²=0.0019
============================================================


📊 Round 316 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0014

============================================================
🔄 Round 318 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 318 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0007
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0059
============================================================


============================================================
🔄 Round 319 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 319 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0002
   Val:   Loss=0.0917, RMSE=0.3028, R²=-0.0111
============================================================


📊 Round 319 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0014

📊 Round 319 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0014

============================================================
🔄 Round 322 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 322 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0017
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0121
============================================================


📊 Round 322 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0014

📊 Round 322 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0014

📊 Round 322 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0014

============================================================
🔄 Round 325 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 325 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0001
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0039
============================================================


📊 Round 325 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0014

============================================================
🔄 Round 327 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 327 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0001
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0041
============================================================


============================================================
🔄 Round 328 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 328 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=0.0003
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0070
============================================================


📊 Round 328 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0014

📊 Round 328 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0014

📊 Round 328 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0014

📊 Round 328 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0014

============================================================
🔄 Round 334 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 334 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0004
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0027
============================================================


📊 Round 334 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0014

============================================================
🔄 Round 335 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 335 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0022
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0056
============================================================


📊 Round 335 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0014

📊 Round 335 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0013

============================================================
🔄 Round 338 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 338 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0005
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0231
============================================================


📊 Round 338 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0014

============================================================
🔄 Round 342 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 342 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0003
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0049
============================================================


============================================================
🔄 Round 343 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 343 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0015
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0280
============================================================


============================================================
🔄 Round 344 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 344 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0015
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0123
============================================================


📊 Round 344 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0013

📊 Round 344 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2436, R²: 0.0013

============================================================
🔄 Round 346 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 346 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=-0.0021
   Val:   Loss=0.0910, RMSE=0.3017, R²=-0.0059
============================================================


============================================================
🔄 Round 347 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 347 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0019
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0012
============================================================


============================================================
🔄 Round 349 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 349 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0007
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0005
============================================================


============================================================
🔄 Round 352 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 352 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0018
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0072
============================================================


📊 Round 352 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0014

📊 Round 352 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0014

📊 Round 352 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0014

============================================================
🔄 Round 359 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 359 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0006
   Val:   Loss=0.0775, RMSE=0.2785, R²=-0.0087
============================================================


============================================================
🔄 Round 362 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 362 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0012
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0116
============================================================


📊 Round 362 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0014

============================================================
🔄 Round 365 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 365 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0012
   Val:   Loss=0.0919, RMSE=0.3031, R²=0.0010
============================================================


============================================================
🔄 Round 366 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 366 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0008
   Val:   Loss=0.0840, RMSE=0.2897, R²=-0.0007
============================================================


📊 Round 366 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0014

📊 Round 366 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0014

============================================================
🔄 Round 371 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 371 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0016
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0028
============================================================


📊 Round 371 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0014

============================================================
🔄 Round 376 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 376 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0000
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0036
============================================================


📊 Round 376 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0014

📊 Round 376 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0014

============================================================
🔄 Round 378 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 378 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0012
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0001
============================================================


============================================================
🔄 Round 381 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 381 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0001
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0042
============================================================


============================================================
🔄 Round 382 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 382 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0004
   Val:   Loss=0.0915, RMSE=0.3025, R²=-0.0022
============================================================


============================================================
🔄 Round 384 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 384 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0014
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0046
============================================================


📊 Round 384 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0014

📊 Round 384 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0014

📊 Round 384 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0014

============================================================
🔄 Round 388 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 388 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0027
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0035
============================================================


============================================================
🔄 Round 389 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 389 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0001
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0039
============================================================


============================================================
🔄 Round 390 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 390 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0004
   Val:   Loss=0.0889, RMSE=0.2981, R²=-0.0046
============================================================


📊 Round 390 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0014

============================================================
🔄 Round 394 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 394 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2933, R²=-0.0011
   Val:   Loss=0.0746, RMSE=0.2730, R²=-0.0028
============================================================


📊 Round 394 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0014

📊 Round 394 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0014

============================================================
🔄 Round 397 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 397 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0001
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0152
============================================================


📊 Round 397 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0014

============================================================
🔄 Round 399 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 399 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0024
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0045
============================================================


📊 Round 399 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0014

============================================================
🔄 Round 401 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 401 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0002
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0072
============================================================


============================================================
🔄 Round 402 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 402 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0025
   Val:   Loss=0.0849, RMSE=0.2913, R²=0.0068
============================================================


============================================================
🔄 Round 403 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 403 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0025
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0087
============================================================


📊 Round 403 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0014

============================================================
🔄 Round 406 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 406 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0009
   Val:   Loss=0.0851, RMSE=0.2918, R²=0.0000
============================================================


============================================================
🔄 Round 407 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 407 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0014
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0022
============================================================


📊 Round 407 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0014

============================================================
🔄 Round 411 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 411 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0006
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0091
============================================================


============================================================
🔄 Round 413 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 413 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0000
   Val:   Loss=0.0785, RMSE=0.2801, R²=-0.0063
============================================================


📊 Round 413 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

============================================================
🔄 Round 416 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 416 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0009
   Val:   Loss=0.0904, RMSE=0.3007, R²=0.0000
============================================================


📊 Round 416 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

📊 Round 416 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

============================================================
🔄 Round 419 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 419 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0000
   Val:   Loss=0.0919, RMSE=0.3031, R²=-0.0071
============================================================


📊 Round 419 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

============================================================
🔄 Round 420 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 420 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0007
   Val:   Loss=0.0929, RMSE=0.3048, R²=-0.0010
============================================================


============================================================
🔄 Round 421 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 421 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0008
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0244
============================================================


📊 Round 421 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

============================================================
🔄 Round 424 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 424 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0001
   Val:   Loss=0.0745, RMSE=0.2730, R²=-0.0064
============================================================


============================================================
🔄 Round 425 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 425 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0002
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0078
============================================================


📊 Round 425 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

============================================================
🔄 Round 428 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 428 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0008
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0150
============================================================


============================================================
🔄 Round 431 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 431 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0040
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0276
============================================================


📊 Round 431 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

============================================================
🔄 Round 433 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 433 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0002
   Val:   Loss=0.0768, RMSE=0.2772, R²=-0.0052
============================================================


📊 Round 433 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

📊 Round 433 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

📊 Round 433 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

============================================================
🔄 Round 439 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 439 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0021
   Val:   Loss=0.0763, RMSE=0.2763, R²=-0.0184
============================================================


📊 Round 439 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

============================================================
🔄 Round 442 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 442 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2916, R²=-0.0017
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0023
============================================================


============================================================
🔄 Round 443 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 443 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0001
   Val:   Loss=0.0769, RMSE=0.2773, R²=-0.0035
============================================================


============================================================
🔄 Round 445 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 445 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0004
   Val:   Loss=0.0900, RMSE=0.3001, R²=-0.0027
============================================================


📊 Round 445 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

============================================================
🔄 Round 447 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 447 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0008
   Val:   Loss=0.0915, RMSE=0.3025, R²=-0.0021
============================================================


============================================================
🔄 Round 448 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 448 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0002
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0042
============================================================


============================================================
🔄 Round 452 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 452 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0006
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0005
============================================================


📊 Round 452 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

📊 Round 452 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

📊 Round 452 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

============================================================
🔄 Round 457 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 457 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0021
   Val:   Loss=0.0731, RMSE=0.2705, R²=0.0065
============================================================


📊 Round 457 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

============================================================
🔄 Round 458 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 458 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0024
   Val:   Loss=0.0898, RMSE=0.2997, R²=-0.0119
============================================================


============================================================
🔄 Round 459 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0654 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0654, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0654, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0654, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0654, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0654, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0654)

============================================================
📊 Round 459 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=-0.0017
   Val:   Loss=0.0654, RMSE=0.2557, R²=0.0048
============================================================


📊 Round 459 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

============================================================
🔄 Round 461 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 461 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0008
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0002
============================================================


📊 Round 461 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

📊 Round 461 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

============================================================
🔄 Round 464 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 464 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0013
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0011
============================================================


📊 Round 464 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

============================================================
🔄 Round 467 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 467 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0018
   Val:   Loss=0.0866, RMSE=0.2942, R²=0.0003
============================================================


📊 Round 467 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

============================================================
🔄 Round 468 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 468 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0018
   Val:   Loss=0.0879, RMSE=0.2966, R²=-0.0095
============================================================


============================================================
🔄 Round 470 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 470 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0019
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0049
============================================================


📊 Round 470 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

📊 Round 470 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

============================================================
🔄 Round 476 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 476 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0011
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0083
============================================================


📊 Round 476 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

============================================================
🔄 Round 479 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 479 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0011
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0082
============================================================


📊 Round 479 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

============================================================
🔄 Round 481 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 481 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0009
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0011
============================================================


📊 Round 481 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

📊 Round 481 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

============================================================
🔄 Round 483 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 483 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0023
   Val:   Loss=0.0730, RMSE=0.2701, R²=0.0076
============================================================


📊 Round 483 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

============================================================
🔄 Round 484 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 484 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0017
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0027
============================================================


============================================================
🔄 Round 485 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 485 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0035
   Val:   Loss=0.0785, RMSE=0.2801, R²=0.0117
============================================================


📊 Round 485 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

📊 Round 485 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

📊 Round 485 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

📊 Round 485 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

============================================================
🔄 Round 495 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 495 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0002
   Val:   Loss=0.0763, RMSE=0.2763, R²=-0.0052
============================================================


📊 Round 495 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

============================================================
🔄 Round 498 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 498 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0004
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0015
============================================================


📊 Round 498 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

============================================================
🔄 Round 500 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 500 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=-0.0005
   Val:   Loss=0.0841, RMSE=0.2901, R²=-0.0018
============================================================


📊 Round 500 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

============================================================
🔄 Round 502 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 502 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0010
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0011
============================================================


📊 Round 502 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

============================================================
🔄 Round 505 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 505 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0005
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0066
============================================================


📊 Round 505 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

============================================================
🔄 Round 507 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 507 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0001
   Val:   Loss=0.0838, RMSE=0.2896, R²=-0.0135
============================================================


============================================================
🔄 Round 508 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 508 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0017
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0029
============================================================


============================================================
🔄 Round 510 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 510 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0006
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0210
============================================================


============================================================
🔄 Round 511 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 511 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0012
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0090
============================================================


📊 Round 511 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

📊 Round 511 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

📊 Round 511 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

📊 Round 511 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

📊 Round 511 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

📊 Round 511 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

============================================================
🔄 Round 522 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 522 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0015
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0023
============================================================


📊 Round 522 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

============================================================
🔄 Round 523 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 523 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0022
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0012
============================================================


📊 Round 523 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

📊 Round 523 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

============================================================
🔄 Round 525 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 525 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0023
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0048
============================================================


📊 Round 525 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

============================================================
🔄 Round 528 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 528 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=0.0009
   Val:   Loss=0.0769, RMSE=0.2773, R²=-0.0072
============================================================


📊 Round 528 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

============================================================
🔄 Round 530 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 530 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0010
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0170
============================================================


============================================================
🔄 Round 533 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 533 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0007
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0021
============================================================


============================================================
🔄 Round 534 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 534 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0002
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0041
============================================================


📊 Round 534 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

============================================================
🔄 Round 535 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 535 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0001
   Val:   Loss=0.0897, RMSE=0.2996, R²=-0.0066
============================================================


📊 Round 535 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

============================================================
🔄 Round 536 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 536 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0000
   Val:   Loss=0.0747, RMSE=0.2732, R²=-0.0116
============================================================


============================================================
🔄 Round 538 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 538 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0004
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0034
============================================================


📊 Round 538 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

============================================================
🔄 Round 539 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 539 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0014
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0018
============================================================


📊 Round 539 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

============================================================
🔄 Round 543 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 543 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0012
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0106
============================================================


📊 Round 543 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

============================================================
🔄 Round 546 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 546 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0008
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0033
============================================================


📊 Round 546 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

📊 Round 546 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

============================================================
🔄 Round 555 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 555 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0024
   Val:   Loss=0.0792, RMSE=0.2815, R²=0.0014
============================================================


📊 Round 555 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

============================================================
🔄 Round 557 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 557 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0002
   Val:   Loss=0.0726, RMSE=0.2694, R²=-0.0054
============================================================


📊 Round 557 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

============================================================
🔄 Round 558 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 558 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0026
   Val:   Loss=0.0784, RMSE=0.2799, R²=-0.0106
============================================================


📊 Round 558 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

📊 Round 558 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

============================================================
🔄 Round 560 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 560 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0012
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0016
============================================================


============================================================
🔄 Round 561 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 561 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0021
   Val:   Loss=0.0780, RMSE=0.2792, R²=0.0058
============================================================


📊 Round 561 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

============================================================
🔄 Round 563 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 563 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0005
   Val:   Loss=0.0925, RMSE=0.3041, R²=-0.0011
============================================================


📊 Round 563 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

============================================================
🔄 Round 566 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 566 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0010
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0165
============================================================


📊 Round 566 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

============================================================
🔄 Round 567 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 567 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0010
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0065
============================================================


============================================================
🔄 Round 568 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 568 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0009
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0165
============================================================


============================================================
🔄 Round 569 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 569 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0001
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0030
============================================================


📊 Round 569 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

============================================================
🔄 Round 570 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 570 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0031
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0078
============================================================


📊 Round 570 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

📊 Round 570 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

📊 Round 570 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

📊 Round 570 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

============================================================
🔄 Round 574 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 574 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0006
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0028
============================================================


📊 Round 574 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

📊 Round 574 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

📊 Round 574 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

============================================================
🔄 Round 578 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 578 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0008
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0087
============================================================


📊 Round 578 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

============================================================
🔄 Round 579 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 579 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0036
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0100
============================================================


📊 Round 579 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

📊 Round 579 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

============================================================
🔄 Round 581 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 581 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0003
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0037
============================================================


📊 Round 581 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

============================================================
🔄 Round 582 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 582 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0019
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0018
============================================================


📊 Round 582 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

============================================================
🔄 Round 585 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 585 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0006
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0021
============================================================


📊 Round 585 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

============================================================
🔄 Round 587 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 587 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0008
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0172
============================================================


============================================================
🔄 Round 589 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 589 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0013
   Val:   Loss=0.0893, RMSE=0.2989, R²=0.0022
============================================================


📊 Round 589 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2436, R²: 0.0015

📊 Round 589 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2436, R²: 0.0015

============================================================
🔄 Round 591 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 591 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0005
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0348
============================================================


============================================================
🔄 Round 592 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 592 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0003
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0067
============================================================


📊 Round 592 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2436, R²: 0.0015

============================================================
🔄 Round 594 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 594 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0018
   Val:   Loss=0.0769, RMSE=0.2774, R²=-0.0117
============================================================


📊 Round 594 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2436, R²: 0.0015

📊 Round 594 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2436, R²: 0.0015

📊 Round 594 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2436, R²: 0.0015

📊 Round 594 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2436, R²: 0.0015

============================================================
🔄 Round 602 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 602 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0028
   Val:   Loss=0.0892, RMSE=0.2986, R²=-0.0348
============================================================


============================================================
🔄 Round 604 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 604 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0002
   Val:   Loss=0.0907, RMSE=0.3012, R²=-0.0050
============================================================


📊 Round 604 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2436, R²: 0.0015

📊 Round 604 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2436, R²: 0.0015

============================================================
🔄 Round 611 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 611 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=-0.0009
   Val:   Loss=0.0738, RMSE=0.2716, R²=0.0009
============================================================


============================================================
🔄 Round 612 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 612 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0003
   Val:   Loss=0.0793, RMSE=0.2817, R²=-0.0036
============================================================


============================================================
🔄 Round 613 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 613 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0029
   Val:   Loss=0.0895, RMSE=0.2992, R²=0.0007
============================================================


📊 Round 613 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

============================================================
🔄 Round 614 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 614 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0020
   Val:   Loss=0.0926, RMSE=0.3044, R²=0.0024
============================================================


📊 Round 614 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

📊 Round 614 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

============================================================
🔄 Round 621 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 621 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0006
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0012
============================================================


📊 Round 621 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

📊 Round 621 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

📊 Round 621 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

============================================================
🔄 Round 625 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 625 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0008
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0004
============================================================


📊 Round 625 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

============================================================
🔄 Round 628 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0941 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0941, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0941, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0941, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0941, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0941, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0941)

============================================================
📊 Round 628 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0003
   Val:   Loss=0.0941, RMSE=0.3067, R²=-0.0153
============================================================


📊 Round 628 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

============================================================
🔄 Round 629 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 629 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0019
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0046
============================================================


📊 Round 629 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

============================================================
🔄 Round 631 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 631 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0009
   Val:   Loss=0.0890, RMSE=0.2982, R²=-0.0002
============================================================


📊 Round 631 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2436, R²: 0.0015

============================================================
🔄 Round 633 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 633 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0003
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0055
============================================================


📊 Round 633 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

📊 Round 633 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0015

============================================================
🔄 Round 637 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 637 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0011
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0011
============================================================


============================================================
🔄 Round 640 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0691 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0691, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0691, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0691, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0691, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0691, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0691)

============================================================
📊 Round 640 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0017
   Val:   Loss=0.0691, RMSE=0.2629, R²=0.0043
============================================================


📊 Round 640 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0016

============================================================
🔄 Round 641 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0712 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 641 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=-0.0025
   Val:   Loss=0.0712, RMSE=0.2669, R²=0.0090
============================================================


============================================================
🔄 Round 642 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 642 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0018
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0018
============================================================


============================================================
🔄 Round 643 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 643 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0034
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0078
============================================================


============================================================
🔄 Round 644 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 644 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0007
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0245
============================================================


============================================================
🔄 Round 645 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 645 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0008
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0068
============================================================


📊 Round 645 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0016

============================================================
🔄 Round 647 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 647 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0001
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0161
============================================================


📊 Round 647 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0016

============================================================
🔄 Round 650 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 650 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0021
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0073
============================================================


============================================================
🔄 Round 651 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 651 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0018
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0048
============================================================


============================================================
🔄 Round 652 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 652 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0004
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0384
============================================================


📊 Round 652 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0016

============================================================
🔄 Round 653 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 653 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0015
   Val:   Loss=0.0927, RMSE=0.3045, R²=-0.0142
============================================================


📊 Round 653 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0016

📊 Round 653 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0016

📊 Round 653 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0016

============================================================
🔄 Round 658 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 658 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0003
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0078
============================================================


============================================================
🔄 Round 659 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 659 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=-0.0018
   Val:   Loss=0.0797, RMSE=0.2822, R²=-0.0027
============================================================


📊 Round 659 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0016

============================================================
🔄 Round 661 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 661 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0011
   Val:   Loss=0.0847, RMSE=0.2911, R²=0.0016
============================================================


============================================================
🔄 Round 663 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 663 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0018
   Val:   Loss=0.0871, RMSE=0.2952, R²=0.0042
============================================================


📊 Round 663 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0016

============================================================
🔄 Round 664 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 664 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0009
   Val:   Loss=0.0735, RMSE=0.2711, R²=-0.0073
============================================================


📊 Round 664 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0016

📊 Round 664 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0016

📊 Round 664 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0016

============================================================
🔄 Round 669 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 669 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0004
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0046
============================================================


📊 Round 669 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0016

============================================================
🔄 Round 671 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 671 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0038
   Val:   Loss=0.0897, RMSE=0.2994, R²=0.0063
============================================================


============================================================
🔄 Round 672 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 672 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0017
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0028
============================================================


============================================================
🔄 Round 674 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 674 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0007
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0005
============================================================


📊 Round 674 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0016

============================================================
🔄 Round 675 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 675 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0015
   Val:   Loss=0.0907, RMSE=0.3012, R²=-0.0020
============================================================


📊 Round 675 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0016

📊 Round 675 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0016

============================================================
🔄 Round 680 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0961 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0961, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0961, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0961, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0961, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0961, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0961)

============================================================
📊 Round 680 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0025
   Val:   Loss=0.0961, RMSE=0.3099, R²=0.0051
============================================================


============================================================
🔄 Round 681 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 681 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0023
   Val:   Loss=0.0865, RMSE=0.2942, R²=0.0063
============================================================


============================================================
🔄 Round 682 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 682 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0019
   Val:   Loss=0.0767, RMSE=0.2769, R²=-0.0107
============================================================


📊 Round 682 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0016

📊 Round 682 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0016

📊 Round 682 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0016

============================================================
🔄 Round 689 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 689 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0012
   Val:   Loss=0.0865, RMSE=0.2942, R²=-0.0038
============================================================


📊 Round 689 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0016

📊 Round 689 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0016

📊 Round 689 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0016

============================================================
🔄 Round 696 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 696 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0002
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0060
============================================================


============================================================
🔄 Round 698 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0947 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0947, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0947, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0947, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0947, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0947, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0947)

============================================================
📊 Round 698 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0007
   Val:   Loss=0.0947, RMSE=0.3078, R²=-0.0069
============================================================


📊 Round 698 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0016

📊 Round 698 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0016

📊 Round 698 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0016

============================================================
🔄 Round 702 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 702 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0010
   Val:   Loss=0.0743, RMSE=0.2726, R²=0.0008
============================================================


📊 Round 702 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0016

============================================================
🔄 Round 703 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 703 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0014
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0083
============================================================


📊 Round 703 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0016

============================================================
🔄 Round 704 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 704 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0001
   Val:   Loss=0.0884, RMSE=0.2972, R²=-0.0096
============================================================


📊 Round 704 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0016

============================================================
🔄 Round 705 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 705 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0028
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0107
============================================================


============================================================
🔄 Round 706 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 706 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0010
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0004
============================================================


============================================================
🔄 Round 709 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 709 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0004
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0034
============================================================


📊 Round 709 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0016

📊 Round 709 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0016

============================================================
🔄 Round 712 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 712 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2885, R²=-0.0007
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0156
============================================================


📊 Round 712 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0016

📊 Round 712 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0016

📊 Round 712 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0016

============================================================
🔄 Round 718 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 718 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0007
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0061
============================================================


📊 Round 718 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0016

📊 Round 718 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0016

============================================================
🔄 Round 724 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 724 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0006
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0001
============================================================


📊 Round 724 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0016

📊 Round 724 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0016

============================================================
🔄 Round 728 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 728 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0002
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0160
============================================================


📊 Round 728 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0016

============================================================
🔄 Round 731 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 731 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0020
   Val:   Loss=0.0766, RMSE=0.2767, R²=0.0035
============================================================


📊 Round 731 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0016

============================================================
🔄 Round 732 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 732 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0001
   Val:   Loss=0.0898, RMSE=0.2997, R²=-0.0033
============================================================


============================================================
🔄 Round 733 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 733 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0011
   Val:   Loss=0.0733, RMSE=0.2708, R²=-0.0168
============================================================


📊 Round 733 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0016

============================================================
🔄 Round 736 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 736 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0005
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0057
============================================================


📊 Round 736 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0016

============================================================
🔄 Round 741 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 741 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0025
   Val:   Loss=0.0873, RMSE=0.2955, R²=0.0062
============================================================


📊 Round 741 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0016

============================================================
🔄 Round 745 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 745 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0014
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0215
============================================================


📊 Round 745 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0016

============================================================
🔄 Round 749 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 749 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0005
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0011
============================================================


📊 Round 749 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0017

============================================================
🔄 Round 751 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 751 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0022
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0000
============================================================


============================================================
🔄 Round 752 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 752 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0016
   Val:   Loss=0.0871, RMSE=0.2951, R²=0.0023
============================================================


📊 Round 752 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0017

============================================================
🔄 Round 755 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 755 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0009
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0081
============================================================


============================================================
🔄 Round 756 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 756 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0003
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0031
============================================================


📊 Round 756 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0016

📊 Round 756 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0016

============================================================
🔄 Round 759 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 759 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0008
   Val:   Loss=0.0907, RMSE=0.3011, R²=-0.0071
============================================================


============================================================
🔄 Round 760 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 760 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0009
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0011
============================================================


📊 Round 760 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0017

============================================================
🔄 Round 762 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 762 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0009
   Val:   Loss=0.0872, RMSE=0.2952, R²=-0.0098
============================================================


📊 Round 762 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0017

============================================================
🔄 Round 764 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 764 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0003
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0055
============================================================


📊 Round 764 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0017

📊 Round 764 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0017

📊 Round 764 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0017

📊 Round 764 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0017

📊 Round 764 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0017

============================================================
🔄 Round 770 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0980 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0981, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0981, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0981, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0981, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0981, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0980)

============================================================
📊 Round 770 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=-0.0016
   Val:   Loss=0.0980, RMSE=0.3131, R²=-0.0041
============================================================


============================================================
🔄 Round 772 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 772 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0013
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0016
============================================================


📊 Round 772 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0017

📊 Round 772 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0017

============================================================
🔄 Round 776 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 776 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0010
   Val:   Loss=0.0855, RMSE=0.2925, R²=0.0011
============================================================


📊 Round 776 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0017

============================================================
🔄 Round 777 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 777 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0001
   Val:   Loss=0.0762, RMSE=0.2761, R²=-0.0101
============================================================


============================================================
🔄 Round 778 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 778 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0011
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0020
============================================================


============================================================
🔄 Round 779 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 779 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0011
   Val:   Loss=0.0775, RMSE=0.2785, R²=-0.0056
============================================================


📊 Round 779 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0017

📊 Round 779 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0017

============================================================
🔄 Round 784 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 784 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0026
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0070
============================================================


📊 Round 784 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0017

============================================================
🔄 Round 785 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 785 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0009
   Val:   Loss=0.0803, RMSE=0.2835, R²=0.0012
============================================================


📊 Round 785 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0017

============================================================
🔄 Round 787 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 787 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0009
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0062
============================================================


📊 Round 787 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0017

📊 Round 787 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0017

============================================================
🔄 Round 789 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 789 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0014
   Val:   Loss=0.0897, RMSE=0.2994, R²=-0.0096
============================================================


============================================================
🔄 Round 790 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 790 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0012
   Val:   Loss=0.0849, RMSE=0.2913, R²=0.0007
============================================================


📊 Round 790 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0017

📊 Round 790 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0017

============================================================
🔄 Round 794 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 794 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0022
   Val:   Loss=0.0783, RMSE=0.2797, R²=-0.0121
============================================================


📊 Round 794 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0017

============================================================
🔄 Round 795 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 795 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0007
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0145
============================================================


📊 Round 795 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0017

============================================================
🔄 Round 798 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 798 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0007
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0032
============================================================


============================================================
🔄 Round 799 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 799 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0001
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0041
============================================================


📊 Round 799 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0017

============================================================
🔄 Round 800 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0999 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0999, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0999, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0999, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0999, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.1000, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0999)

============================================================
📊 Round 800 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0002
   Val:   Loss=0.0999, RMSE=0.3161, R²=-0.0074
============================================================


============================================================
🔄 Round 801 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 801 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0002
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0039
============================================================


📊 Round 801 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0017

============================================================
🔄 Round 802 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 802 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=0.0005
   Val:   Loss=0.0917, RMSE=0.3028, R²=-0.0181
============================================================


📊 Round 802 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0017

📊 Round 802 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2435, R²: 0.0017

============================================================
🔄 Round 807 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 807 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0011
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0050
============================================================


❌ Client client_23 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_status:14, grpc_message:"Socket closed"}"
>
