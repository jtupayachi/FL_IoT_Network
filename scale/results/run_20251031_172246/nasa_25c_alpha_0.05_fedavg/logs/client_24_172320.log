[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3450237b-de98-4dc8-88aa-105f3566097d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2db8373-bf35-4994-9c98-dcf66288b96e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21d72665-2a43-4108-9df2-519782d3624b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32a115f6-2932-40d1-8e01-0a360258b27e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45118dcb-f8b5-46a5-9a70-45297929d584
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d68d8dda-7910-40e5-8ae9-d55941c72226
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 315cb61e-da47-4698-a4ed-97ba0f44ff3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d6e4946-75d8-456a-b8d2-66ce675b8f20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac913c1e-56bf-4425-b5b6-0bdb2f949b82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9023550-48d6-486c-a1e7-328ba95ebe25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be419606-b4f6-491d-8339-13ef2211f9af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5de66b0c-f541-4ccc-abea-42df766e0d34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d47b34f6-0c99-495c-958a-2d91f734902b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abf132b7-fa90-4a1a-b6a4-dacee7c6a661
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 396178c9-2706-43da-b665-56dcc32468b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9aa5307-6a50-426c-b414-5cb92ad11f62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b8ce10d-a081-4071-80da-e4d80c9b8f14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ac1b9d9-dfc7-45ad-9c15-cb8417120bcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f9d2a33-517d-48a5-9dac-05d1074d65cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3f043fd-28e9-425c-9282-f984ec907cfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cf33fcf-18df-4728-a71b-17ff3864ac7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35ce727a-fca6-42b3-82bf-a86673fe49fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18a6c43b-f18e-4b57-b1d5-54f892b826f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 689d4797-d437-4770-b9b3-4943d10f3a13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45ed6f57-5f13-49d9-b52f-c5fa4ab8476f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 822af103-2596-4524-98b2-ef71ce43751d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26d021f9-074c-4337-ac13-14b8492fd2f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5563575a-ce23-4903-80ae-457582a7d493
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5773e30d-3aa6-46ea-a185-bd5b9e15168f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16063125-bdf3-4f30-9590-d5e5c4068de4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0542c08-05ea-43db-83e3-3a25858a4245
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de49fecb-462f-43f5-be44-9ccf5fe2db0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d7ffc19-2fcf-405e-811e-edbbc30693b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3800af13-6cf7-4920-a328-dbb7986ef08b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3217103-eb2e-462a-8d27-5f0d12c71eda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 399afa9f-38bd-4829-95a7-ccd6d91b578f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9065d882-ae13-4cf3-97e7-9cfc1881f930
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8bbafa3d-a07e-4c20-9a0c-31e10c10c713
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8cbd037-a9e2-4094-965d-55452661d460
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbabca30-3e24-4c34-8139-8e3c2c9062fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9dfea527-03cd-4260-82ec-a0bbc2c778c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23802e49-22e5-4dae-9518-96012133e5b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91e7013f-190f-4c9a-8519-7f683e061a11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4eb42c4e-3891-40e9-bceb-7edbf4a21fcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08693ecd-8e91-4857-9455-b3ed5c876c37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ec7cfae-fbfd-41f1-a231-73cf995c8cc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec002ec4-cc5c-4f7d-9897-578e3efe8a8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b5aa433-36cc-4c61-bbbc-cb9c2c8d3540
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5240b58d-c5fd-4544-84f4-0f6551850302
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8a837f6-7b90-41f1-9bb6-adb2378dea7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b77cb75-c648-42ad-bf48-7d314d409ade
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72e0d86f-51ec-4a10-be5d-ea8430b6d397
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec26d12e-777e-4aeb-868e-1280f7a12fd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ad462c0-3c47-4b3a-a393-74dd11d42294
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88bd9fbb-0654-4cc3-b792-5859ecbdfaa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 650d2d41-566d-4992-8423-bd05c5aac195
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1021ed44-3ab9-42fa-9af7-49d9427b8038
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86af6ccb-dc80-4f50-925f-5518a65ed1e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e692bdf-3e72-4e2a-aa57-ea6deaf43c80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57263b9d-2fc1-4ca2-a74a-26844bb1a104
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae69df16-7d5f-42f1-baad-e369146916b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a411ffb-ddb9-414d-8cde-da86303fa9f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db88e749-683b-44f4-9542-5efcfa64fffd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ded7661-9a62-4ff7-9e9c-70eed075c7a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87fb8ea7-c00e-4c1f-afc5-eb0ae4249e4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc22bf7f-d7e1-4e7a-898c-02765f2abda7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b316f0e-7e89-4a52-acfd-170d43f67809
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 827f34ed-fe39-4738-be23-a89531aad3d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e192f025-3197-4e3d-a30f-bb00b14f9a45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 425f98be-3702-4483-9292-49f9e9bf1ab4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89accf88-a1b0-4301-9eb4-94ccaa0171db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a3ffa38-6642-4503-9d3c-f7780357a32b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce9933c5-603e-472b-9ea7-bf9f1b3f4fb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0076edf9-f8c8-43d5-92d7-bb5fbddec715
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87ea2ba6-f83c-4b6c-9a21-c7237d7a512c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62e28be2-a33f-4a0d-89ed-bb1871abee5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea3579bf-6c8c-4ba4-9567-260328f2db7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56f9641b-1c52-443f-9ae6-c5914b2bad46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4caaa61a-43e2-453f-b292-561fad785f6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f125d093-daf6-45eb-be18-34a88ecab2af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efbb3a98-ed53-457b-b8a6-92f020f3deaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24e67a9b-151e-4c86-8698-0f5170610249
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e5f7a86-b96c-494e-9557-7bd5e9254891
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d93a4df-98af-4fde-8681-d4539c598629
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2431ba43-0edc-4592-b517-bfb0461c0cc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7d6ec0c-b3d5-4cc3-b16a-3aaf0980c75b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4598d6b2-8864-4a64-8295-814b511fdaca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4188405e-7fd3-4871-9ca9-5772a0585f83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b1c21ca-e1d9-4b84-832a-b3ba1b21e57d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e22c1b32-8f8c-4c23-9039-2d034932fd5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd87af9d-e887-4ceb-8995-5e74a7ee17ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7597eb86-e0dd-42df-95f1-cb5911477c76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c30a5b8-9ee8-4bd3-9186-bf821152b470
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67c06698-f1dc-4bba-a549-dddf8595d6bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2c73cd9-e6ef-4c24-88ab-df2e93386e23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca9c0305-3d10-4e15-bcf1-fcac291c65cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e62490d-a849-4487-8496-2fa6dbc74234
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d314f156-a62e-4317-a6d5-d09509a1d0f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf0b6423-c5d7-4752-b93e-e6e68980fbe8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4b56cf3-078a-4dbd-b67b-782d59d4fe55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7f724a8-15a1-46d0-aba8-c118e651940c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b3829a7-c0db-4b9e-bf73-44bf351b8dfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f346ba21-faca-4454-8964-19ea312a59b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f35ff94e-698e-404f-b55b-e2cd24b5f827
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cd9fc9b-65bc-4d54-8eca-4cf432b1ce2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56a62262-749e-49a6-afd9-3544e5532a68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc89340d-0b90-4118-af62-ec9326f05e9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fc8ba8a-a682-4853-8856-6e83f393a65d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 567e6a16-c0ac-4ae9-aaec-d04e78ea0b86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccbd8fad-3a11-4cde-829b-58fa472ba0a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e035fda5-ff43-44e5-9f7a-790b387a07be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 488f60d5-42ce-4c5a-8aaa-0a7a3ee6ec26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12d9b883-da3c-4da6-9b53-75f92a536291
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75c9c135-090d-409a-b30d-44a6530fd662
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33dd6475-f643-412f-8be5-66a03b06bd64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3972f2b-bbe7-4da3-ad61-728227539e4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d39218b-b582-40a3-b00a-5981e0cb677f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f6cae6c-f8df-40e6-a395-06298fddbeb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb958b2a-3fb3-4b34-b8ad-3b2b460c1703
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d9dd409-176a-4d4c-82dd-0a0ac795d73f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bb7970b-8c5d-43c6-b3ac-362535d0d5a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14dfe20f-0fa1-45e6-a8bb-b5122d0dc8b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df144868-12f4-4443-aa2e-50d9fc182d89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 439a2422-84e2-494c-85db-ac0d76f7ccfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68136a90-decc-497e-8afb-0354d7fa8b50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e8fe9ee-4465-49c9-b791-d3ca0fc6f119
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd6b8ccf-223a-40fc-acdd-44349e412499
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eef31a3a-aff4-4768-a530-7313f7dc7f25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e2fbf05-aace-4a0a-8646-3aa4d63a29b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70e63665-3e2d-4e6d-9808-b72dc1a6ce04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59da1937-1e89-4684-bd85-fe029f1da91f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c94a6bdb-d6cb-4ec5-959a-a5015faecfbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0377e284-07a2-4ab2-8234-e931547f1017
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f02b3d62-4768-4db6-975c-030761317b5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9af843b2-4d65-47de-ab48-a3f5252d873d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9a5358a-e00b-46aa-967a-e81472f3b684
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 436bf2b1-fd08-46a1-8b5b-ec4f15283ccd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d3667f6-fcdf-48c9-ad17-4a64fec63e60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0925cc1-e2f8-41c8-a810-ea1ca61e7e67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d44a5544-5333-4971-b58c-59a4b0e09578
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d33f7be7-e5d6-4aa6-94f2-882cbb2fe0e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8149399-ac21-4d82-a295-053d4a97683f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6be762ec-a419-401b-a84b-53e524e099b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82c26fb1-5a7f-437b-bfec-0b281da5c11f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e9a895c-9e34-4a78-a205-186b50090932
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message baad9074-3a47-4621-b0a1-095e38d78f2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83e32b22-c620-48e0-9e65-e9d791dea325
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee0146ef-0f5f-4dd3-ab93-ff0a590a15f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 055db6d7-0a2f-45ee-bed3-59304507688a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3defe10f-3624-4d6d-9787-2fa1a9b98baa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 917581d3-d9b2-4445-9e82-f2e4bc1fd4f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 334cce49-2ce5-4699-99c0-c8c140a835a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d207992b-be72-4e7c-939e-5c1f3fd2e751
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40bed4d7-2dae-4c18-908e-676299654697
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b177525-4557-49ef-8b67-4a7b0bec18cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 527dc087-75b6-4907-a767-1c1479fcd657
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 749f1161-3ed8-4f65-8aad-52f12bd9f54c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84a550dc-8f44-40b3-b0b7-77134dee15c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9447668-cb20-4682-bacd-d391903242b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60b241df-ea1e-4a38-9131-2ae6d0d23156
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcf73151-74da-47a5-b407-550f8457f5b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f623eb3-3390-4953-a14f-6730f1a9be3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f27308f7-caca-4f87-92ef-65c62351ebd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 302b1eff-a6e6-4f76-b83b-1163f39e8f26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 287d75a9-0073-4c87-8ec2-22b3edd96c2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66200621-9e92-40b8-9c9a-7a789eaf1336
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9e96397-2243-49f1-b897-ecd440b60ad4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6235dae4-c413-4c11-8ddd-57f203b4cc85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0cc98e1d-161c-4223-9bc4-7005912e50cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b61d026c-698f-42a1-8a35-8636100dbcd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 981435fe-fb99-418c-9603-4193afbbc06c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c166fa64-0408-4da1-8890-8a6ee649e2c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4567936d-d3ec-4dba-bdae-06e60e0a935b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05ca39f3-7e0e-40b5-a371-a8c3a27a4c4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae05aada-cc1b-4331-972b-43178cfaff4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6441b875-879f-4109-84d9-d1f9088756a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e0b41a8-196e-4e2d-8afb-064abbdfdfd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 858dfad5-9570-4091-ae00-ac84abdbdc11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28e060e9-53d1-4437-a2fc-71904a721213
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a7d950e-19c4-4724-bea4-390caa0dcd67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8af1bf2-c7da-4d03-b5cd-36f3a4f5435b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a869eacd-38de-4e31-b9f3-7ec9fdb5e32e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdf88904-0110-4037-9bfc-6e1f1af91c2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cf731a8-f74a-4b5e-a556-894c756d7cb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 670639f0-87f2-4ddc-8111-29c26decda76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 522a9bc9-1a9b-4a1e-a7ef-933ada70a55e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68fc14b0-1e04-4bbf-ba13-deeba177c70d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6436c5d-f7a9-4cd9-82b6-97da263e9479
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fbe1cfc-b306-4557-bfb2-69cc9dab4b8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c67803f-7aed-48c1-abb9-870570c7acdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14ec3a0f-21a2-470e-a787-6cbbd9ff0544
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7b4d4e3-11b3-4795-8e0b-b6c4aad0e460
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 421aa987-e33f-4d7f-91e9-5054fb6037e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8eb5bf9e-d246-4a7a-97d0-fb9f890fdad8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c2aca7b-b977-41ed-a053-da3d63be049b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2816e3f-4923-42f0-a4d5-e3e01fee7e3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4910b2c4-2ffc-46ab-9584-ede30793fea4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff2506ec-7e99-4c15-905e-4ba53f2037cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9be59284-def5-47ad-a6bf-55f5368784aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 792f4850-6734-46ea-abfa-1dd98b192b3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2247c82-65af-4228-904c-e645c1bbe233
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a546e96-2568-4a1a-aa68-ca666ca3debd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e783f6e4-6b33-4249-8f2a-28b31911fe63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df538182-0822-4d88-ab2b-63a4089d35b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9823fff-bb2b-4070-8446-daf36f2dbef0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e31a4ac-9106-4bdc-9932-77ebe444dd2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fae8a80-de30-4e1c-9c1e-04d29f75fe18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 966337fd-d38e-471c-8383-8f1593c0472a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5c9d11e-bdbc-4a05-a2f5-f6ca7d40c585
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdf52c19-573a-4450-89fb-0b3551a57591
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82f4b156-4b6a-405b-99d0-414538804e4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1e80f58-7f30-475b-8d40-bc13832dbe77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd591c58-063b-4252-920c-f67da075a916
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06aa332c-b9a7-4a1c-96eb-902f919cfb70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message adcf0b9b-7427-43ba-ac3c-65d6ef60f28e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f9288fb-de13-460e-ac0c-85c0eb37d10a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d453aa39-18af-4f3c-917d-7444d141e4d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfb2de1b-a245-42da-b00b-473631dcb574
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f8c0736-1ca8-4e71-ac36-e7096a4bebda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 802300c9-ad86-4c63-a76c-7659979a57b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 345de3a2-0cf8-49b1-8ad9-36eda75fe5de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9db4316-b924-478c-b752-68032b9e39fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a588bad9-fe20-4e1d-ade6-4a5b80752e3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d1a86c7-d0e4-4f66-a7cd-491301a2543f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c94ff10-fa39-4aa2-bffa-f46c613c0549
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e534d75c-a149-4e8d-8cb6-042b2a91a859
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 467aa609-7d2f-40ec-a316-67ad7f1a8018
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98c785d9-b50f-40bd-b646-984d170ce25e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7305893d-ccec-4a6c-a066-b4d31e98a6f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f89bbf42-0652-4269-9da1-0eb44caf548a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 313088b5-e02e-4b2a-a6c3-3efb7d95adb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b53e8f2-ec06-421b-88a6-3684294ea128
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f33cdda-fe34-429a-b32f-7087d7530668
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 582be553-e6cc-4274-b87a-3959fdb68942
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83e6a047-51cd-4d09-93eb-674396616ed9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24ec383d-2d04-4493-8092-acdec714ee4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e92ec2b7-b746-40f9-a554-307ea16d6f44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2612c4a-9746-4c0e-b950-299f8f66133d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cbf5404-9f36-4e07-a17e-415ba598d9e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60bb3998-060a-4752-914f-8d56f545b3f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5998eb00-5536-4ae5-a013-eeae91e72d69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ccfde0e6-5d27-4294-a8ad-fbdc2334d5d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 727e8590-fbc4-45cc-9af7-1e38d1ca1008
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0ba39c6-9611-401d-828f-1b2cbf940063
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92970bce-8ecd-48b0-9c2f-e7988017b14b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 141f8f72-4b8c-48de-bc24-fa5d9ae786f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0e66130-fc0d-4f31-9231-2d2e3c90cda6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4973ade5-0f34-4032-96ec-8382a3c49c31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8a6a39d-4944-4a29-b33c-921f92fb3921
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fd5485d-d421-4a52-a1f0-4242b967cab5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fd3a127-d9ab-487d-a4d4-60f97d37b813
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d88fd56-95d2-467d-9b8b-36bda28f8147
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc0cb539-171d-4593-8fc0-beb323288ec3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eddde784-0438-4466-abc7-f07f72f18e61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1065d00c-a65b-4da6-ab56-9672491e2491
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b26a9e91-d060-4d97-9797-65928a0fc668
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9da49293-42fa-4e4f-899d-45aeb55fe500
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f5da758-3b03-4622-be20-e42ab3526603
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f07b689-deb9-421e-bf57-3b46a5c85526
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61a0e1b1-b129-4ac3-97bd-07e6aeac36d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c83e70ab-4c7c-4a9d-985e-8941b555b758
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f5d106d-c808-404c-801d-63bd2c4bf1e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a13246da-cb00-478b-abae-b5b525fff192
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c95f95c3-74fd-4faa-a6e1-8c3e696a99ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77da4d27-7abb-4369-9b8d-146fdd894fae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e132942-b664-4fe5-9075-6cb10c060641
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc2125c6-07d9-4749-824e-310dbb1d5368
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e03bd03-797d-4e01-a185-fad2d3930a7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31d9340f-a0e3-4180-a871-83e29bf99a81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 481483b1-8008-4724-b1a1-55480b6c43ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df28778e-35e2-4bb6-a6f6-c0ddcedb672a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be01d914-0d99-47cc-adb9-177b30f7bff6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c0718de-21e9-4e02-8076-a70458635e6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8aaa18f0-a31a-4faa-9a28-8b99788e3595
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd0d9b23-0ace-4191-a0f1-f14533abf55f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82762169-7041-404f-a47a-79d7d1788726
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2934b26-0a65-46ef-babd-d9c306291660
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d9fd552-099c-4f81-a3de-d131efb95cd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92f1b709-87e7-47d3-9336-0bea8725ae9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12a715b0-c9df-4139-898b-8032ea2c8df1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d21f2cb-3410-48d8-a687-aeac0d287462
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe5dd26c-4ed7-4f2c-b3d3-34a6757651d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0872d484-af91-4061-97b8-9806bf0f06fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1a703a3-9109-43be-bf8f-1c0e554576e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61a2e457-58c6-47cb-b0c3-1099644970c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae0efd5b-5c62-4b5b-a076-2f84870038d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25395599-5672-420a-9add-d27536db2ea8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 941d4b7f-89c7-449a-a5bc-e614f6c63b36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 269b281b-8622-4f48-9b6a-1081ba59d3f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2760beb-7c8c-4687-9b58-496211437cd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b66078fe-f426-4a49-b09d-dacb4e820ad4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d9bf6ee-e810-4117-ae14-8fade2778bae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f94f6fc5-f88d-43f3-9add-ba32e945718d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9cecd1c8-614f-4ba9-ae70-39ed8ae41798
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e33af08-4df2-47b1-bbee-d100a3c000f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7747ac4a-0066-4cb2-a136-86ab8b7c7684
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cab02fe3-a75b-48c0-bf92-eb3169c67c45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b97a09b-44d6-4763-a988-a1ae460b2820
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5434f5dd-bcbd-4654-8bf0-c9b3a9ac75ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19e0e0a9-be74-405c-9df7-8a04d4ca1891
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b6e6399-9537-44ee-b90f-f6d8b3e3ec25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c9cdb65-3940-4f82-875a-2582b0462f1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3930dca5-9683-4c35-9cea-32fdbb86057d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e56a7577-b1b2-45c2-8252-123ec8252aa7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b1beeb1-440b-41e2-84fb-52af9b923946
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a4bc28d-7f28-4356-81bf-24917983b8ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5dad7c99-5c2b-438a-9122-bd272303873f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b521c02-b9f2-4901-91db-9a5a84fb5356
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fce13949-66c5-41c1-ac84-c1a299e54ca9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f8f64ad-875b-4c96-be44-ca60bbe956a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b894e1e3-1552-4c7c-81d3-58116dc3f285
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d729171-e3cb-42ca-9e81-6a2d1e977a5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 208e4ca9-fbc3-410c-b2e3-28b595e499e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d1027fe-860f-4387-9b39-b8930c22bd3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea705054-43fe-4705-a233-1f87922c4738
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33fe1447-bc69-4a91-a8d3-cea65c275db6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91f30cdb-df49-4798-95b0-bae0415ef290
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86fe4ffa-f03c-4fa5-8a59-e91431ad3541
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba47425f-bbeb-41fd-a6c0-34558d7c66f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 633b0e89-d7ff-4561-acd4-d94fcf70659a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 293fc9ab-ca26-4044-9d41-09343da87872
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a7d63e0-ffed-440b-b4c7-96217a5b296d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f916e58-b32a-4ee3-91ab-691dc47bf28d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 012ccda4-bed9-4085-834a-9885d100e8f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 915a6e8b-c0ad-4855-9fa5-8a20e6e3801d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8be8fb25-99aa-40f5-8c58-2f9f8c07d11b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfd10d17-94fc-4579-81cd-55d1afbb6b99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d109864e-94e9-4660-b8da-d59e0c32e6c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 742dfe29-9e55-481e-b5f0-a628d5a207ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c27a74f-c936-41df-a731-4a24767edb8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ec5daca-57c9-4fc0-8096-b01feb41c2a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6f419a4-cb04-460e-a77c-5568335698ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19e6b725-3876-41c4-bd27-069637529938
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb1e658c-c925-486d-ab09-4df46d1b6c2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65bea823-c2fa-42ec-bdc4-f7ab48499a75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d2dc231-ed14-4e9d-9941-1a1b25a58e6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95e6d732-4cbd-4fb4-b262-d4eb96fccc97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8bbdcaf-1337-470b-8c63-232de6ce9544
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce58b6cd-e148-4b7d-b022-b2d686e85f99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cab8b494-b4c2-4e9b-a2ee-d6db5bdd6573
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09b21fd6-7cc7-47ca-89ca-9d6157f10a38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4dd36411-f3a2-4a1c-81df-6ca17b76a710
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72f38ca7-3797-4631-89df-eebe8c3e3ed4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5907395a-de97-4309-879e-10fb5636ec0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d6a89e9-76c0-4520-b67d-8cde26741618
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91cb2e06-3c82-4699-9b89-815040220e90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43571b2e-439e-4d01-98d3-02d886814cbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5169d80d-4a83-49a0-ac33-60083cb68a6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0b59364-6a47-4af6-9b85-a1fac25bd580
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de09bf77-4d6d-44c5-b891-3d548416a4af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2274c147-9705-4f0d-95f6-409c8a84c120
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e401f425-ef5e-428b-a7d5-95fbf87c8f98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df5d557c-4687-437b-9003-3636d7a3ee7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fba2c46-b2ab-4cda-857f-bece92691120
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad663383-7486-4946-b1bc-2f299bfe5963
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f5cd213-e46b-4dee-83fe-2061d8d9a7c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91a7ef76-bb34-4b1a-80bb-523cbb0b8775
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5d77e1b-8399-43b4-909e-f565f4a6b774
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01cb6124-5b3c-40dc-85ac-189957bdb337
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68fcf22f-2840-4c53-9340-829fd456ebe3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 225216cb-495e-4304-979c-09c24cabf9c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8abc5b7e-5643-4334-ae75-be07511c114c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6dfdfea-e33c-4db8-9d53-a9bfabe62865
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0075d4db-b26c-4ac9-b807-ba1ee9dec0f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 547946b0-09d8-4325-ac7c-0394863503db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ea2f9c4-1f59-4287-be07-897403ad3fac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54970883-ef3f-4c6f-afe0-7bf69d017479
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40297491-2ba5-417e-88bb-163f58040e0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c94cfe4-4e95-4242-84c4-259d7e19a0f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6eeceb29-5902-42e5-8e49-c45d05df4398
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e5816da-710a-4475-b5d0-9c901d3addf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1198afc8-e94a-42a9-ad65-6a44f19c548d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83151fcf-01a9-4346-9326-9919035c1636
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7f198b4-9e69-493b-9f37-adf0b70ed470
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d372f8d-8095-4f59-b94f-282a5f5b25bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ff3e4be-715e-4260-b0c0-4dcac51dc4a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23d17363-df30-40a2-85e9-106f4752a1cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e7a0d3b-63d1-4f22-9833-9a13223996fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02fa7c18-b83d-49c5-adf9-d20ea6852798
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdcaa5b5-0b2a-4919-8a5a-9e30083f43f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 524f6b74-28e1-4f62-ab3a-6d58fa86660a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99a7a8a1-8e89-4545-a6e2-def0e042337c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57ea5874-a802-4e0e-a5ea-fb3fb97cf330
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c54b6aba-f606-43ec-9cde-11c3139fcfa6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ca2388f-96fa-464b-b79a-850d25092c44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80ed64b7-7e4c-426e-991d-01666fa74dc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14191459-0804-4685-b77c-28ed5c5ee25a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0da56275-4eba-4425-a70e-c2dfe28a3700
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 096134d5-2771-4db2-8ee3-d271ced5ce12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed81ba50-996f-45db-b83f-fa7e1cc8e0a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e29a9a24-c4c6-4668-a610-a152f65bd045
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfcaf386-6a81-45cb-883d-792753e35a5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06d50417-9c78-48ae-94c3-734344b8504e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b08e946-2947-416b-a8f8-9c5bfe48250b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b32ebc58-e144-40f8-bd0e-a6f1e1eb26b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44d8e56f-4b6b-41f0-a111-be264ff1f277
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29328887-8b01-4809-b86b-6f3461db18c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e48439d-4329-4a08-85a7-ab7600adbd56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 666b8865-33a3-4636-9a9a-d19b746d31aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 220f48ca-a87f-4100-a830-c3e1e29a2b0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9039146a-78df-43e5-937e-7ae87deb5b4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df76ac87-4eeb-4ee4-bf11-400d43bdd732
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e7c5eff-535f-4308-8d27-b5d43b31332c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4c5a04d-742e-4845-8dde-066b46441872
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9ae10bb-dd50-41c4-82f9-84f210ff525c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5042449-fdbc-4868-b3ea-7262d12f89c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8578953d-9c22-447a-aec6-b2c82943d7d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51f5426c-23ab-4e36-8541-55247f510e88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9308ef79-0d7f-4f48-8c22-d2a6e141ce19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52fb1c84-c718-4b74-82b8-29b514ba2ec7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ca2c93d-0bb5-4e89-a157-1e60113e6d08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6569744-ae9f-485a-aeaf-94f597e7a461
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79603dc2-26d4-485a-837b-8f690cc5cea6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92dc0505-3b59-499d-8970-b5b87f43cc92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e045729f-6a5f-4e86-8add-13db12764f57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e221f115-9b19-49cf-9eff-a39439d47bde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e1c3d78-757f-4ffb-b3b7-190535ea14ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 196ec0dd-6a0f-435f-a8e3-9db7da8fb3b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc01fbd7-1175-413f-b893-617a414da489
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8ca7145-ea77-4fe1-96c2-626a03800f82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc55d078-9659-4d1e-a38f-4afd0b863f16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb85060e-68a8-4754-a4f5-396210203dd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b40ed68-666d-41d2-8a8a-ef97036d7e91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ca20834-2838-4661-8408-5289bca52028
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 537a3323-0b6d-4dbb-a8b8-69bc8a96b8b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a02531d4-6f07-481b-8924-fce813cbc09b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12f8d9db-0bd2-44e6-afa7-023abe05e53e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 121d4d4c-767a-408a-b474-874e282f88a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e826be05-d658-4f98-83e6-01d9ba3a5677
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a06433ad-f7f0-4ead-88a3-47b97f04f819
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6b7e9df-e306-4f62-8f4a-6fe3691b6ec3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 556a903d-e84d-4e3f-9ca4-943f8e56569b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9c82503-32d2-416f-bdc2-ee9581aefc35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 457cc21f-b0f5-437c-9f76-e21d0636f860
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db65ed29-804e-4f16-8d2b-bb8db0fa0671
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66ba9c3c-2d14-485d-9efe-c2dd2d06de1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14ef48d9-fa64-48fa-9162-99bfbcbaf817
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18302332-b210-437e-abe0-d549f3063bb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 650d83ea-ea22-49e1-ab8a-168b1997ea0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48dbcda6-69ba-457b-a862-9a17fea92199
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d92895fe-ad72-4fa8-8278-465126811486
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbf7ca2f-ae24-4fad-bf96-d8a7840db22e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b29ca7f8-6b52-4ff5-bdeb-9818735932db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6b1ebef-aee5-438b-8190-6787b2da0f2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ad679b6-2bf1-4038-94ef-ba7d9feb5f55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ca0f52c-5bb5-477e-9ec5-4bfe37414e14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bded00e-19fb-403e-9bae-e66e0e2863b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5752481d-6985-418b-806a-efe25d1b2849
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99b7d7e9-9f43-453b-b6aa-88c209fe562e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58e56b12-6e20-4a6c-be8b-be2171ce6eeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fc490ef-5239-4dbc-84c2-4f3070109eb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b519e109-2c65-4881-b363-486e6f53ea8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 687e56a1-adc6-4272-ad8c-e43a3fd15857
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8261f3d9-ef57-4246-8022-96f1326c652f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ef1eef5-cf83-44b3-863f-713a0b5e09fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fa857e8-8455-46e1-a80f-d461b3ea63eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a549fdce-8be7-410e-82c6-52c57313fe03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e44f954-e840-4669-9534-409b8dceca7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c000a76e-d4f4-41aa-b2ee-9a4dfec1892b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f018b9a-8878-43d3-a545-f127a0fd6526
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7dda7fe-bf9b-4e46-8224-1aa04a000853
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b876f192-f896-4263-be06-46b82e85c641
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 601ed41e-8ca9-4181-9613-2bc60b628eb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28017b42-00e2-4358-974f-65bc1b1b5fd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbe61dbd-c7b7-4bba-9302-99eebab270a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be0e0a31-e1d2-4a88-acfb-5a49bb2d75b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cc8d7e7-55a3-414e-baf8-105899366bb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e90669e4-d567-4d69-8f9c-bb71a5376fba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e343e6d-8c72-4dd5-be56-a4c7065e90ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8ca476d-df54-4342-8c26-6885dc230842
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a0bdede-f95a-49a7-8e5a-589c8d6413f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8596f697-35c2-4630-94c7-1a7218ea1566
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e86439d2-b5f7-4de3-8e82-9c08635970f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a36c769-1d28-4b7a-88a8-bfbf1ea9137e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d8e8037-c1d1-438f-8199-e86c9b5c3d87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f25527bc-a17c-49f0-bb82-3ce5e5cf01f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a069c4a1-e8ad-4501-8b77-7b2219289636
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a2b07b5-1155-4519-955d-cc2f4945dbf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0884f338-d4ac-4a54-89c5-2673ebae40b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c630852-f567-44f6-83e6-0f90d530b26f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01148ca4-0322-4989-8d83-7ff79aa4122c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ac5e1d2-a219-4fe6-a848-6a846227abb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8dfb900d-6a3f-4ad6-9826-348f3a9d04a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c0baa08-c065-48a0-bfe7-f909b5553a64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 276e6c12-9851-4d0a-b2a9-ea2794c61f5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cea3da9b-c994-44a3-8432-ec5b1548f743
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70022d61-e59e-47e6-bb85-e6ae903e693a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0545cbf6-0846-408e-aeda-95b0bcac5848
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c734a4b8-a894-4c30-a907-0aee186450d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6269d82d-06ac-4283-ad4a-ff6f50c704b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25e28cf3-a6d9-412c-abe4-7b881e70ccc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d521989a-921b-4dea-a87e-5e38d72bfdd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc02f576-fc67-4183-8eeb-3b6d4b98c2df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57df1130-613a-4af6-b2f9-725c84441400
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbf71cdb-c3c3-4260-9c89-6409e12962ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9172447-3f5d-4a3f-81e7-f863a53f5527
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 740c75dd-6111-46ab-ac57-bac700777086
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a49f9e5b-789b-4109-97af-5b764b4675b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d475545-95ec-4849-b99a-e2e93c8445ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 561321b6-a2f3-4fdf-ab58-44a4b3b5e456
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a7ab0ac-32d3-4cd4-a7d2-05533cc7ff00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e07c23d-0e72-45ac-92a2-25d954891e18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba385f8b-3b48-4454-a3ab-e371207d8751
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f94840f-8790-4e12-b76e-45e4989be827
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a68b4c17-9126-4502-b0b1-a29d9706a50c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83c2a88c-8d1f-4e7b-99f6-303808a37f7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c016711-4437-4fd3-8c4e-d83136f1bdf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9ef5572-70b2-41cf-8c43-2be948fb9b11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96719253-b631-4cf6-b3ec-26a4cdcb7332
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f334b4a8-f298-4040-ae71-56040f84dd3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80ff2827-9999-4faf-9883-b55f106d4cfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 812a456d-91ac-4f5d-9d61-5f23a3800b7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35a9023b-9b45-4039-b17c-97a83e7ce768
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e706a5c-e5d9-4a09-899f-17ae701debda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 592b0b4d-8fc7-49db-ad8d-d2340a98559a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21835476-c465-4db9-bade-1a87fb9ab2e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dad9e182-aa9a-48aa-b10c-b87823c12ac6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20ab7009-a7b9-49b0-bfb3-8b29b6d3f62a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd4ea5ae-bc64-4237-95f0-8c941e047ec2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3584f56-47a7-4ad3-8801-972cebcdd5ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76d53f3d-bcbd-414b-b2e4-34924b49cdcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message deed2f81-525c-4321-b7aa-f92da494facf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d211831-8ed6-4739-89b5-012604925118
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f615b567-b84c-4765-ab74-2ba27a9aa41c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae57d518-a211-4399-8349-65f170d5fb69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56039eb8-c982-4333-9424-1fd78bdc8e4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0107f92d-1df0-49cd-8c7e-3e388383ff26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68e1fa81-adcd-4c50-b477-889dbe77e6cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 214878c3-3700-4a17-933f-b25ba9509513
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 733dc141-bc90-4669-bc55-e67f5ed4941e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eab661a2-5a8c-4c75-adbb-5b0557368855
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46c4164a-e134-4a39-b09f-696676f18867
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de4d8a17-9f67-499f-befa-490d98bd0cf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73ccf780-f650-4c39-b740-c1c2b5c121a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1be1bb13-018b-4a78-b9f3-2a057ba8e7e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a80fc239-7e4f-4108-907e-4b24194eef52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 814c3b9e-8a53-43b7-b018-2e9fac5707dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29b0f952-ccee-4949-8b73-c8956e27e7e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 075496e0-8ce2-4cb4-900e-091805ef0de7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cae292d7-716e-4d3c-84d0-734756173a8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c253a502-c886-4dac-95b8-debccb7b2d31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83f6d337-96cf-4bea-9423-df1e1a382fab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07b31b47-9598-494b-b130-77920157d54e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 149420d5-0986-4a2f-b85c-fb62ce319f9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a8bf941-6df3-47f4-bb78-d59690180dd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c05427d6-0fc5-42fb-8a74-66a1bd28ad40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2ff44c1-769e-453b-b0a7-044a9896f0fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c5d5d23-961f-4e35-8c3f-9acc6e8d540b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb3a3416-d1ce-4ffa-a7e3-4b7c51091213
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ac906a8-28d7-4d4b-b5b7-f882974b5924
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28413422-4538-4c20-beb4-1d518721bdbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a0dd8b4-a3c5-4885-8010-abd3b2156106
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2a07375-4eaa-4959-9ed5-3d99a46ef6d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ca211a7-3b57-4208-bcbd-04c9003c0d78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad9cbcef-4777-4a40-a810-aa27f770c0f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fb88bc4-fac6-48ce-8e23-bc31c00d8021
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 745e0d5e-bc67-467f-b934-60a4f22fbe5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b7c2811-72ad-41c3-ac53-93ccca893b0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b59ed31b-71dd-497b-8115-978a6a4a6c29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbf0ee3a-582b-413c-a022-c04442d9cbfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa089283-d7e6-449a-b56c-dd75127693ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afe9d655-0028-4e0e-927d-af8f2a9bb82d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f681c146-1960-438f-83e0-481a6cd14e58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3791544-247e-4578-8c46-da2e11d0ffc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fb4d8d6-4c0b-4ee8-8f25-05797bc898c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e463d47-70db-45f9-bf4c-dd84928da950
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7b6ce5d-dc37-43d1-a4af-54a98036d2c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f357ce56-c749-42b6-a0e9-15e5e8ad4512
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70f326d5-2b78-4d9a-a602-5945623070d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9662a4d3-4605-45c7-b906-d5d01ab92e47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44f38156-b0dc-47b2-8fef-b8111c0c8c8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3319946-b961-4ec2-9ff9-296c4d305787
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6be50a3-448e-4398-be0e-69ceb17aed2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b807a53-7d28-419d-9ee9-7de00eaae739
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c7649a2-f2ba-415c-b591-357c6f5745c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a12ec27-65ba-42f1-a57d-a7d0df9e30e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09ef4d48-62c8-4a86-b82f-b92255a2da55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98962c8f-0a7f-418f-8262-fd4b8a55c6cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13e025db-fee8-4928-95ea-9c706940f085
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3ff5380-9531-48e7-a1c8-cdcf3e1a9c62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message acc2000f-3b9a-4b12-9e1c-f248fdd1c82f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6ea31a4-1f69-475d-9d7d-14c82f9cfb01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88b7b30e-36a2-482a-af38-fd32a7dff1a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f497520b-a061-472c-9d9a-68beda1c0a51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d208ce3a-d1e0-4e26-bce7-4172cbcf5041
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef0590c8-5ca9-4cba-8ab1-e627678f2824
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d7e9903-7598-4c1e-b2d5-00814846fcb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1f31d50-516d-4324-9e69-44d2969a5d52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17c5e41b-63e5-41eb-a51b-c50973997a68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a5d9927-e951-4afc-8ed5-41f8352b06ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f267f09-7eef-4b93-b718-02734760c229
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44e07ea3-9c6f-4234-98c7-a24cdb4e26a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a642dafa-d378-463c-9daa-667a923631bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message acdf2ac8-bded-43e7-974c-6307b1ec2763
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce386d01-f475-4821-b3d7-1abec7014a02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e0b2e97-ef0b-4da0-abd9-28cdfce53e19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2360debd-98b9-4ba8-b727-52d05586c317
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5a0e410-3355-44e3-961b-1f27d1429e85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66fef8a5-d5d4-49b8-a654-2717ba220718
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 122f82c5-ba39-4f1c-bbed-46a1ac1f5db0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 989d55f8-997e-4d75-9ebf-bb990861519b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa7c5026-5fec-4718-a4a2-fb4e0b58b7fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8f4a63c-0bd1-4ab4-b8f3-a54d7bf607f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a088904-5c1e-4813-9ea0-214f2c7eb413
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa42f21d-4fe3-4487-b345-1f772bb02133
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac1426b1-cfa9-49ad-9e28-fc3fd1be1d3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5f6c2af-f94c-4ceb-a710-84048d3dd4d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c473e387-3e6b-46bd-a606-ef144cca1b1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e4a3d2b-6dac-4ec0-b0ba-8c66d0e663a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message daca18f4-eb44-42df-a671-6c20331d48db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 440f0216-2a17-4145-8746-e56ee8e3614f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43bb1894-57ef-4aab-a0a7-d53578b37e61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75ec1669-60e9-4160-8507-616cc95d8cdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c002339a-39ed-49f0-97ee-c09220e0e4ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 934cfa09-24ca-4be0-b7d0-1c55730df455
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d575b81-1042-4e5e-9cdd-94e1fb3bf00e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bedc0f8-e6a0-4ebf-b9dd-6d2a7b8e7e14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bec2108-4c54-43c4-93c8-734f5c3b2187
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94058cba-23fb-414f-b050-e5ab7aa5d7f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 925669e4-60b4-4c92-9991-68db041f7e92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86a33bf4-5048-4c59-a830-b87232f2f3ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acd3a16e-bdce-4847-9ebc-0a588f115cb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b68b0c1e-380f-4ffe-bed9-38b326ab148e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65270d5d-e2da-4615-becd-379239af6d31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 657a9243-b071-469a-89b2-3747f697cdd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 125ecf03-f8a8-4b02-9873-44021ecc96f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2dc6408-e5e5-4f9f-9588-0fd45c5afb08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00e99280-f97b-4abf-99ee-25d5b54d6839
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4f7ac14-18ae-4846-ac0a-2deb24ee639e
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_24
Server: localhost:8686
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_24
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_24/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_24/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_24/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_24/test_labels.txt

📊 Raw data loaded:
   Train: X=(3897, 24), y=(3897,)
   Test:  X=(975, 24), y=(975,)

⚠️  Limiting training data: 3897 → 800 samples
⚠️  Limiting test data: 975 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_24 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2485, R²: -0.0030

📊 Round 0 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2479, R²: 0.0032

============================================================
🔄 Round 4 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0925 (↓), lr=0.001000
   • Epoch   2/100: train=0.0879, val=0.0936, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0876, val=0.0938, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0872, val=0.0937, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0868, val=0.0937, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0839, val=0.0940, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 4 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=0.0166
   Val:   Loss=0.0925, RMSE=0.3042, R²=-0.0146
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2479, R²: 0.0042

============================================================
🔄 Round 5 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0951 (↓), lr=0.000250
   • Epoch   2/100: train=0.0881, val=0.0948, patience=1/15, lr=0.000250
   ✓ Epoch   3/100: train=0.0880, val=0.0945 (↓), lr=0.000250
   • Epoch   4/100: train=0.0879, val=0.0943, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0879, val=0.0941, patience=2/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0874, val=0.0933, patience=1/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063
   • Epoch  21/100: train=0.0870, val=0.0929, patience=11/15, lr=0.000063
   📉 Epoch 23: LR reduced 0.000063 → 0.000031
   📉 Epoch 31: LR reduced 0.000031 → 0.000016
   • Epoch  31/100: train=0.0868, val=0.0928, patience=7/15, lr=0.000016
   📉 Epoch 39: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 5 Summary - Client client_24
   Epochs: 39/100 (early stopped)
   LR: 0.000250 → 0.000008 (5 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=0.0221
   Val:   Loss=0.0929, RMSE=0.3048, R²=0.0097
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0035

============================================================
🔄 Round 6 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0939 (↓), lr=0.000008
   • Epoch   2/100: train=0.0879, val=0.0940, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0879, val=0.0940, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0879, val=0.0941, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0878, val=0.0941, patience=4/15, lr=0.000008
   📉 Epoch 8: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0878, val=0.0942, patience=10/15, lr=0.000004
   📉 Epoch 16: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 6 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=0.0095
   Val:   Loss=0.0939, RMSE=0.3064, R²=-0.0053
============================================================


============================================================
🔄 Round 7 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0941 (↓), lr=0.000002
   • Epoch   2/100: train=0.0880, val=0.0941, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0880, val=0.0941, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0880, val=0.0941, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0880, val=0.0941, patience=4/15, lr=0.000002
   📉 Epoch 8: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0880, val=0.0941, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0941)

============================================================
📊 Round 7 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=0.0092
   Val:   Loss=0.0941, RMSE=0.3067, R²=-0.0042
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0034

============================================================
🔄 Round 10 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 10 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2990, R²=0.0103
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0029
============================================================


============================================================
🔄 Round 12 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0935 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0935, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0935, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 12 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=0.0081
   Val:   Loss=0.0935, RMSE=0.3058, R²=0.0112
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0035

============================================================
🔄 Round 15 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 15 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2982, R²=0.0094
   Val:   Loss=0.0902, RMSE=0.3003, R²=0.0050
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2482, R²: 0.0033

============================================================
🔄 Round 16 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 16 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2969, R²=0.0099
   Val:   Loss=0.0934, RMSE=0.3056, R²=0.0071
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0035

📊 Round 16 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0035

📊 Round 16 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0035

📊 Round 16 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0035

============================================================
🔄 Round 25 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0956 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0956, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0956, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0956, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0956, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0956, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0956)

============================================================
📊 Round 25 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=0.0077
   Val:   Loss=0.0956, RMSE=0.3092, R²=0.0133
============================================================


============================================================
🔄 Round 26 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0948 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0948, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0948, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0948, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0948, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0949, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0948)

============================================================
📊 Round 26 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=0.0107
   Val:   Loss=0.0948, RMSE=0.3079, R²=-0.0081
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0034

📊 Round 26 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0034

📊 Round 26 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0034

============================================================
🔄 Round 30 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0905, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0905, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0905, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0905, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0905, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0905, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 30 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0906, RMSE=0.3011, R²=0.0089
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0134
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0034

============================================================
🔄 Round 32 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 32 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2992, R²=0.0101
   Val:   Loss=0.0879, RMSE=0.2964, R²=0.0062
============================================================


============================================================
🔄 Round 34 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0904, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0904, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0904, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0904, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0904, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0903, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 34 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0907, RMSE=0.3011, R²=0.0099
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0012
============================================================


============================================================
🔄 Round 37 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0903, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0903, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0903, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0903, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0903, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0903, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 37 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0901, RMSE=0.3001, R²=0.0087
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0134
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0034

============================================================
🔄 Round 38 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0942, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0942, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0942, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 38 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=0.0097
   Val:   Loss=0.0942, RMSE=0.3069, R²=0.0093
============================================================


============================================================
🔄 Round 40 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0902, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0902, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 40 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0906, RMSE=0.3010, R²=0.0080
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0117
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0034

============================================================
🔄 Round 48 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 48 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2986, R²=0.0092
   Val:   Loss=0.0892, RMSE=0.2987, R²=0.0000
============================================================


============================================================
🔄 Round 49 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0938, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 49 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=0.0102
   Val:   Loss=0.0938, RMSE=0.3063, R²=0.0061
============================================================


============================================================
🔄 Round 52 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.1014 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.1014, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.1014, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.1014, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.1014, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.1014, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1014)

============================================================
📊 Round 52 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=0.0095
   Val:   Loss=0.1014, RMSE=0.3184, R²=0.0021
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0034

============================================================
🔄 Round 53 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.1045 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.1045, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.1045, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.1045, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.1045, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.1045, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1045)

============================================================
📊 Round 53 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0118
   Val:   Loss=0.1045, RMSE=0.3233, R²=-0.0025
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0034

============================================================
🔄 Round 57 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0904, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0904, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0904, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0904, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0904, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0904, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 57 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0905, RMSE=0.3008, R²=0.0093
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0097
============================================================


============================================================
🔄 Round 60 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 60 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2990, R²=0.0090
   Val:   Loss=0.0882, RMSE=0.2970, R²=0.0090
============================================================


============================================================
🔄 Round 61 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 61 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2969, R²=0.0093
   Val:   Loss=0.0932, RMSE=0.3053, R²=0.0107
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0034

============================================================
🔄 Round 62 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 62 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=0.0095
   Val:   Loss=0.0910, RMSE=0.3017, R²=0.0008
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0034

📊 Round 62 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0034

============================================================
🔄 Round 67 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0930, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0930, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0930, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0930, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0930, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0930, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 67 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0925, RMSE=0.3041, R²=0.0122
   Val:   Loss=0.0758, RMSE=0.2753, R²=-0.0055
============================================================


============================================================
🔄 Round 70 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 70 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2974, R²=0.0093
   Val:   Loss=0.0921, RMSE=0.3035, R²=0.0086
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0034

============================================================
🔄 Round 73 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 73 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2990, R²=0.0094
   Val:   Loss=0.0881, RMSE=0.2969, R²=-0.0013
============================================================


============================================================
🔄 Round 74 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0952 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0952, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0952, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0952, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0952, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0952, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0952)

============================================================
📊 Round 74 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=0.0111
   Val:   Loss=0.0952, RMSE=0.3086, R²=0.0044
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0034

============================================================
🔄 Round 76 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 76 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2979, R²=0.0085
   Val:   Loss=0.0909, RMSE=0.3015, R²=0.0137
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0034

============================================================
🔄 Round 81 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0905, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0905, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0905, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0905, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0905, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0905, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 81 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0905, RMSE=0.3009, R²=0.0101
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0057
============================================================


============================================================
🔄 Round 82 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 82 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2986, R²=0.0079
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0061
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2482, R²: 0.0034

📊 Round 82 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2482, R²: 0.0034

============================================================
🔄 Round 86 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 86 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2984, R²=0.0080
   Val:   Loss=0.0896, RMSE=0.2993, R²=0.0067
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2482, R²: 0.0033

============================================================
🔄 Round 87 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 87 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=0.0120
   Val:   Loss=0.0934, RMSE=0.3056, R²=-0.0050
============================================================


============================================================
🔄 Round 88 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 88 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=0.0088
   Val:   Loss=0.0907, RMSE=0.3011, R²=0.0106
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2482, R²: 0.0033

============================================================
🔄 Round 90 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0993 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0993, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0993, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0993, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0993, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0993, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0993)

============================================================
📊 Round 90 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2944, R²=0.0078
   Val:   Loss=0.0993, RMSE=0.3151, R²=0.0076
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2482, R²: 0.0033

============================================================
🔄 Round 95 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 95 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2981, R²=0.0086
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0090
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2482, R²: 0.0033

============================================================
🔄 Round 96 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 96 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2991, R²=0.0082
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0049
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2482, R²: 0.0033

============================================================
🔄 Round 97 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 97 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=0.0088
   Val:   Loss=0.0917, RMSE=0.3028, R²=-0.0071
============================================================


============================================================
🔄 Round 98 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 98 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.3000, R²=0.0104
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0062
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2482, R²: 0.0033

============================================================
🔄 Round 100 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0912, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0912, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0912, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0911, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0911, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0911, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 100 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0910, RMSE=0.3016, R²=0.0102
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0015
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2482, R²: 0.0033

============================================================
🔄 Round 101 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 101 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2974, R²=0.0089
   Val:   Loss=0.0920, RMSE=0.3034, R²=0.0094
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2482, R²: 0.0033

============================================================
🔄 Round 106 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0903, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0903, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0903, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0903, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0903, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0903, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 106 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0901, RMSE=0.3002, R²=0.0107
   Val:   Loss=0.0854, RMSE=0.2923, R²=0.0034
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2482, R²: 0.0033

============================================================
🔄 Round 107 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 107 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2989, R²=0.0086
   Val:   Loss=0.0885, RMSE=0.2975, R²=0.0107
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2482, R²: 0.0034

📊 Round 107 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0034

============================================================
🔄 Round 114 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 114 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2976, R²=0.0098
   Val:   Loss=0.0916, RMSE=0.3026, R²=0.0055
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2482, R²: 0.0033

📊 Round 114 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2482, R²: 0.0033

============================================================
🔄 Round 120 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 120 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2991, R²=0.0089
   Val:   Loss=0.0880, RMSE=0.2967, R²=0.0127
============================================================


============================================================
🔄 Round 122 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0901, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 122 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0904, RMSE=0.3006, R²=0.0088
   Val:   Loss=0.0844, RMSE=0.2904, R²=0.0054
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2482, R²: 0.0033

📊 Round 122 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2482, R²: 0.0033

📊 Round 122 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2482, R²: 0.0033

============================================================
🔄 Round 125 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0919, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0919, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0919, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0919, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0919, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0919, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 125 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0917, RMSE=0.3028, R²=0.0108
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0012
============================================================


============================================================
🔄 Round 126 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0909, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0909, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0909, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0909, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0909, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0909, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 126 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0907, RMSE=0.3012, R²=0.0101
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0015
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2482, R²: 0.0033

============================================================
🔄 Round 128 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0941 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0941, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0941, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0941, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0941, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0941, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0941)

============================================================
📊 Round 128 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=0.0089
   Val:   Loss=0.0941, RMSE=0.3067, R²=0.0119
============================================================


============================================================
🔄 Round 129 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0909, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0909, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0909, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0909, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0909, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0909, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 129 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0910, RMSE=0.3017, R²=0.0089
   Val:   Loss=0.0818, RMSE=0.2859, R²=0.0006
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2482, R²: 0.0033

📊 Round 129 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2482, R²: 0.0033

📊 Round 129 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2482, R²: 0.0033

📊 Round 129 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2482, R²: 0.0033

============================================================
🔄 Round 136 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 136 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2984, R²=0.0070
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0097
============================================================


============================================================
🔄 Round 137 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 137 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2994, R²=0.0093
   Val:   Loss=0.0873, RMSE=0.2955, R²=0.0052
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2482, R²: 0.0033

📊 Round 137 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2482, R²: 0.0033

============================================================
🔄 Round 141 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 141 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=0.0079
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0298
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2482, R²: 0.0033

============================================================
🔄 Round 144 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 144 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2990, R²=0.0081
   Val:   Loss=0.0883, RMSE=0.2972, R²=0.0094
============================================================


============================================================
🔄 Round 146 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0955 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0955, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0955, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0955, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0955, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0955, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0955)

============================================================
📊 Round 146 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=0.0105
   Val:   Loss=0.0955, RMSE=0.3090, R²=0.0036
============================================================


============================================================
🔄 Round 149 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 149 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2979, R²=0.0094
   Val:   Loss=0.0909, RMSE=0.3016, R²=0.0056
============================================================


============================================================
🔄 Round 152 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 152 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2995, R²=0.0090
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0086
============================================================


============================================================
🔄 Round 153 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0915, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0915, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0915, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0915, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0915, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0915, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 153 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0913, RMSE=0.3021, R²=0.0099
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0011
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2482, R²: 0.0034

📊 Round 153 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0034

📊 Round 153 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2482, R²: 0.0034

============================================================
🔄 Round 162 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 162 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=0.0062
   Val:   Loss=0.0937, RMSE=0.3060, R²=0.0125
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2482, R²: 0.0033

============================================================
🔄 Round 167 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0906, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0906, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0906, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0906, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0906, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0906, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 167 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0903, RMSE=0.3005, R²=0.0082
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0112
============================================================


============================================================
🔄 Round 169 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0908, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0908, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0908, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0908, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0907, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0907, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 169 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0907, RMSE=0.3012, R²=0.0086
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0106
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0034

📊 Round 169 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0034

============================================================
🔄 Round 172 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 172 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2993, R²=0.0112
   Val:   Loss=0.0876, RMSE=0.2959, R²=0.0005
============================================================


============================================================
🔄 Round 173 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 173 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2996, R²=0.0079
   Val:   Loss=0.0867, RMSE=0.2945, R²=0.0159
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0034

============================================================
🔄 Round 175 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 175 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=0.0096
   Val:   Loss=0.0939, RMSE=0.3064, R²=-0.0082
============================================================


============================================================
🔄 Round 176 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.1022 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.1022, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.1022, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.1022, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.1022, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.1022, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1022)

============================================================
📊 Round 176 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0110
   Val:   Loss=0.1022, RMSE=0.3197, R²=0.0045
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0034

📊 Round 176 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0034

============================================================
🔄 Round 184 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0983 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0983, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0983, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0983, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0983, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0983, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0983)

============================================================
📊 Round 184 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=0.0082
   Val:   Loss=0.0983, RMSE=0.3135, R²=0.0105
============================================================


============================================================
🔄 Round 185 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 185 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2990, R²=0.0101
   Val:   Loss=0.0882, RMSE=0.2970, R²=0.0063
============================================================


============================================================
🔄 Round 186 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 186 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2992, R²=0.0106
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0058
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0034

============================================================
🔄 Round 188 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0901, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0901, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 188 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0901, RMSE=0.3002, R²=0.0100
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0075
============================================================


============================================================
🔄 Round 189 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 189 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=0.0109
   Val:   Loss=0.0926, RMSE=0.3043, R²=0.0056
============================================================


============================================================
🔄 Round 190 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 190 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2997, R²=0.0100
   Val:   Loss=0.0866, RMSE=0.2942, R²=0.0085
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0034

============================================================
🔄 Round 196 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 196 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=0.0092
   Val:   Loss=0.0913, RMSE=0.3021, R²=0.0058
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0034

============================================================
🔄 Round 198 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 198 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2976, R²=0.0116
   Val:   Loss=0.0915, RMSE=0.3026, R²=0.0027
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0034

============================================================
🔄 Round 201 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0918, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0918, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0918, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0918, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0918, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0917, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 201 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0920, RMSE=0.3033, R²=0.0112
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0032
============================================================


============================================================
🔄 Round 202 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 202 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2976, R²=0.0100
   Val:   Loss=0.0914, RMSE=0.3023, R²=0.0054
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0034

📊 Round 202 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0034

📊 Round 202 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0034

📊 Round 202 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0035

============================================================
🔄 Round 211 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0941 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0941, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0941, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0941, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0941, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0941, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0941)

============================================================
📊 Round 211 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=0.0107
   Val:   Loss=0.0941, RMSE=0.3068, R²=0.0053
============================================================


📊 Round 211 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0035

============================================================
🔄 Round 212 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0911, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0911, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0911, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0911, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0911, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0911, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 212 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0910, RMSE=0.3017, R²=0.0103
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0076
============================================================


============================================================
🔄 Round 213 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 213 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2977, R²=0.0098
   Val:   Loss=0.0911, RMSE=0.3019, R²=0.0084
============================================================


============================================================
🔄 Round 215 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0933, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 215 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2969, R²=0.0084
   Val:   Loss=0.0932, RMSE=0.3053, R²=-0.0031
============================================================


📊 Round 215 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0035

============================================================
🔄 Round 216 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 216 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2998, R²=0.0095
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0108
============================================================


============================================================
🔄 Round 219 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0911, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0911, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0911, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0911, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0911, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0911, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 219 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0911, RMSE=0.3018, R²=0.0086
   Val:   Loss=0.0814, RMSE=0.2854, R²=0.0133
============================================================


============================================================
🔄 Round 220 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0941 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0941, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0941, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0941, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0941, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0941, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0941)

============================================================
📊 Round 220 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=0.0072
   Val:   Loss=0.0941, RMSE=0.3067, R²=0.0195
============================================================


📊 Round 220 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0035

📊 Round 220 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0035

============================================================
🔄 Round 224 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0953 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0953, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0953, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0953, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0953, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0953, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0953)

============================================================
📊 Round 224 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=0.0098
   Val:   Loss=0.0953, RMSE=0.3087, R²=0.0098
============================================================


📊 Round 224 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0035

============================================================
🔄 Round 225 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 225 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2989, R²=0.0091
   Val:   Loss=0.0884, RMSE=0.2973, R²=0.0131
============================================================


📊 Round 225 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0035

============================================================
🔄 Round 226 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 226 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2974, R²=0.0108
   Val:   Loss=0.0919, RMSE=0.3032, R²=-0.0009
============================================================


📊 Round 226 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0035

📊 Round 226 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0035

📊 Round 226 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

============================================================
🔄 Round 230 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0968 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0968, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0968, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0969, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0969, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0970, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0968)

============================================================
📊 Round 230 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2954, R²=0.0066
   Val:   Loss=0.0968, RMSE=0.3111, R²=0.0061
============================================================


📊 Round 230 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

============================================================
🔄 Round 231 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 231 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2981, R²=0.0124
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0010
============================================================


📊 Round 231 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

============================================================
🔄 Round 232 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 232 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2984, R²=0.0078
   Val:   Loss=0.0895, RMSE=0.2991, R²=-0.0172
============================================================


📊 Round 232 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

📊 Round 232 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

📊 Round 232 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

📊 Round 232 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

============================================================
🔄 Round 237 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 237 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=0.0120
   Val:   Loss=0.0929, RMSE=0.3048, R²=0.0002
============================================================


============================================================
🔄 Round 240 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0902, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0902, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 240 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.2999, R²=0.0110
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0050
============================================================


============================================================
🔄 Round 243 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0899, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 243 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.2999, R²=0.0085
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0085
============================================================


📊 Round 243 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

============================================================
🔄 Round 244 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 244 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2991, R²=0.0088
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0107
============================================================


============================================================
🔄 Round 246 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.1005 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.1005, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.1005, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.1005, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.1005, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.1006, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1005)

============================================================
📊 Round 246 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0088
   Val:   Loss=0.1005, RMSE=0.3170, R²=-0.0070
============================================================


📊 Round 246 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

============================================================
🔄 Round 250 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 250 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2991, R²=0.0100
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0033
============================================================


📊 Round 250 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

============================================================
🔄 Round 255 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 255 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2993, R²=0.0094
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0123
============================================================


📊 Round 255 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0035

============================================================
🔄 Round 259 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0953 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0953, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0953, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0953, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0953, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0953, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0953)

============================================================
📊 Round 259 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=0.0101
   Val:   Loss=0.0953, RMSE=0.3087, R²=0.0086
============================================================


📊 Round 259 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

📊 Round 259 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

============================================================
🔄 Round 261 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 261 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=0.0110
   Val:   Loss=0.0934, RMSE=0.3056, R²=0.0056
============================================================


📊 Round 261 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0035

============================================================
🔄 Round 264 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 264 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2993, R²=0.0102
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0076
============================================================


📊 Round 264 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0035

============================================================
🔄 Round 266 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0913, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0913, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0913, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0913, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0913, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0913, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 266 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0911, RMSE=0.3019, R²=0.0124
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0015
============================================================


📊 Round 266 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0035

📊 Round 266 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0035

📊 Round 266 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0035

============================================================
🔄 Round 269 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 269 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2969, R²=0.0109
   Val:   Loss=0.0932, RMSE=0.3053, R²=-0.0177
============================================================


============================================================
🔄 Round 271 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0899, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0899, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0898, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 271 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2994, R²=0.0101
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0089
============================================================


📊 Round 271 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0035

============================================================
🔄 Round 272 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 272 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2979, R²=0.0089
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0078
============================================================


📊 Round 272 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0035

📊 Round 272 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0035

============================================================
🔄 Round 277 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0921, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0920, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0920, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0920, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0920, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0920, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 277 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0920, RMSE=0.3033, R²=0.0084
   Val:   Loss=0.0776, RMSE=0.2787, R²=-0.0027
============================================================


📊 Round 277 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0035

📊 Round 277 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0035

📊 Round 277 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0035

📊 Round 277 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

============================================================
🔄 Round 281 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0942, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0942, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0942, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 281 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=0.0096
   Val:   Loss=0.0942, RMSE=0.3069, R²=0.0113
============================================================


============================================================
🔄 Round 284 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 284 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=0.0093
   Val:   Loss=0.0918, RMSE=0.3029, R²=0.0042
============================================================


📊 Round 284 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

============================================================
🔄 Round 285 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 285 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2989, R²=0.0087
   Val:   Loss=0.0884, RMSE=0.2974, R²=0.0104
============================================================


============================================================
🔄 Round 286 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.1002 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.1002, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.1002, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.1002, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.1002, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.1002, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1002)

============================================================
📊 Round 286 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0131
   Val:   Loss=0.1002, RMSE=0.3165, R²=-0.0027
============================================================


============================================================
🔄 Round 288 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 288 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=0.0082
   Val:   Loss=0.0887, RMSE=0.2978, R²=0.0102
============================================================


📊 Round 288 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

📊 Round 288 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

============================================================
🔄 Round 292 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 292 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2998, R²=0.0107
   Val:   Loss=0.0861, RMSE=0.2935, R²=0.0039
============================================================


📊 Round 292 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

============================================================
🔄 Round 293 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0909, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0909, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0908, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0908, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0908, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0908, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 293 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0908, RMSE=0.3013, R²=0.0077
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0146
============================================================


📊 Round 293 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

============================================================
🔄 Round 296 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 296 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2990, R²=0.0091
   Val:   Loss=0.0881, RMSE=0.2969, R²=0.0109
============================================================


============================================================
🔄 Round 297 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0902, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0902, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 297 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0902, RMSE=0.3003, R²=0.0088
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0020
============================================================


============================================================
🔄 Round 298 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 298 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2992, R²=0.0091
   Val:   Loss=0.0876, RMSE=0.2960, R²=0.0134
============================================================


📊 Round 298 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

📊 Round 298 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

============================================================
🔄 Round 301 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 301 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2988, R²=0.0107
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0043
============================================================


📊 Round 301 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

============================================================
🔄 Round 303 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 303 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2982, R²=0.0095
   Val:   Loss=0.0901, RMSE=0.3002, R²=0.0071
============================================================


📊 Round 303 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

============================================================
🔄 Round 304 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 304 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=0.0110
   Val:   Loss=0.0909, RMSE=0.3015, R²=0.0053
============================================================


📊 Round 304 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

============================================================
🔄 Round 307 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0911, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0911, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0911, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0911, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0911, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0911, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 307 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0911, RMSE=0.3018, R²=0.0093
   Val:   Loss=0.0814, RMSE=0.2852, R²=0.0083
============================================================


📊 Round 307 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0035

============================================================
🔄 Round 309 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0944 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0944, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0944, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0944, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0944, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0944, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0944)

============================================================
📊 Round 309 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2964, R²=0.0096
   Val:   Loss=0.0944, RMSE=0.3072, R²=0.0008
============================================================


============================================================
🔄 Round 311 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0899, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0899, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0899, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 311 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.2999, R²=0.0087
   Val:   Loss=0.0859, RMSE=0.2930, R²=0.0083
============================================================


📊 Round 311 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0035

============================================================
🔄 Round 312 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0901, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0901, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 312 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2999, R²=0.0102
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0073
============================================================


============================================================
🔄 Round 314 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 314 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=0.0071
   Val:   Loss=0.0909, RMSE=0.3016, R²=-0.0068
============================================================


📊 Round 314 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0035

============================================================
🔄 Round 315 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0904, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0904, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0904, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0904, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0904, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0904, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 315 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0904, RMSE=0.3007, R²=0.0097
   Val:   Loss=0.0841, RMSE=0.2899, R²=0.0030
============================================================


📊 Round 315 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0035

============================================================
🔄 Round 317 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 317 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2995, R²=0.0088
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0093
============================================================


📊 Round 317 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0035

============================================================
🔄 Round 321 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 321 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=0.0101
   Val:   Loss=0.0922, RMSE=0.3037, R²=-0.0062
============================================================


📊 Round 321 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0035

============================================================
🔄 Round 323 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 323 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2994, R²=0.0104
   Val:   Loss=0.0871, RMSE=0.2951, R²=0.0079
============================================================


📊 Round 323 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0035

============================================================
🔄 Round 324 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 324 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2985, R²=0.0093
   Val:   Loss=0.0893, RMSE=0.2989, R²=0.0118
============================================================


📊 Round 324 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

============================================================
🔄 Round 326 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 326 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2972, R²=0.0095
   Val:   Loss=0.0923, RMSE=0.3038, R²=0.0111
============================================================


📊 Round 326 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

📊 Round 326 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

============================================================
🔄 Round 329 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0898, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 329 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2996, R²=0.0100
   Val:   Loss=0.0865, RMSE=0.2942, R²=-0.0038
============================================================


============================================================
🔄 Round 330 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0899, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0899, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0899, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 330 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.3000, R²=0.0090
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0099
============================================================


============================================================
🔄 Round 331 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0911, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0911, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0911, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0911, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0911, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0911, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 331 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0911, RMSE=0.3018, R²=0.0087
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0062
============================================================


📊 Round 331 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0037

============================================================
🔄 Round 332 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0905, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0905, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0905, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0905, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0905, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0905, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 332 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0903, RMSE=0.3005, R²=0.0101
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0021
============================================================


============================================================
🔄 Round 334 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 334 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2976, R²=0.0086
   Val:   Loss=0.0915, RMSE=0.3025, R²=0.0136
============================================================


📊 Round 334 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0037

📊 Round 334 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0037

============================================================
🔄 Round 342 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 342 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2993, R²=0.0101
   Val:   Loss=0.0873, RMSE=0.2955, R²=0.0100
============================================================


============================================================
🔄 Round 343 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 343 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=0.0099
   Val:   Loss=0.0916, RMSE=0.3026, R²=0.0103
============================================================


📊 Round 343 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0037

============================================================
🔄 Round 344 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 344 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2979, R²=0.0107
   Val:   Loss=0.0906, RMSE=0.3010, R²=0.0041
============================================================


📊 Round 344 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0037

📊 Round 344 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0037

📊 Round 344 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0037

============================================================
🔄 Round 352 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0922, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0922, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0922, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0922, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0922, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0922, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 352 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0923, RMSE=0.3038, R²=0.0102
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0070
============================================================


📊 Round 352 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0037

📊 Round 352 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

============================================================
🔄 Round 356 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 356 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2993, R²=0.0103
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0090
============================================================


============================================================
🔄 Round 357 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 357 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2990, R²=0.0091
   Val:   Loss=0.0881, RMSE=0.2968, R²=0.0092
============================================================


📊 Round 357 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

============================================================
🔄 Round 358 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 358 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2993, R²=0.0102
   Val:   Loss=0.0875, RMSE=0.2957, R²=0.0057
============================================================


============================================================
🔄 Round 360 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 360 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=0.0101
   Val:   Loss=0.0908, RMSE=0.3013, R²=0.0064
============================================================


============================================================
🔄 Round 361 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 361 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2994, R²=0.0106
   Val:   Loss=0.0871, RMSE=0.2951, R²=0.0080
============================================================


📊 Round 361 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

============================================================
🔄 Round 362 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0996 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0996, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0996, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0996, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0996, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0996, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0996)

============================================================
📊 Round 362 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0110
   Val:   Loss=0.0996, RMSE=0.3156, R²=0.0069
============================================================


============================================================
🔄 Round 363 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0995 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0995, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0996, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0996, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0996, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0996, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0995)

============================================================
📊 Round 363 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=0.0086
   Val:   Loss=0.0995, RMSE=0.3155, R²=0.0036
============================================================


📊 Round 363 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

============================================================
🔄 Round 365 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0907, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0907, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0907, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0907, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0907, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0907, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 365 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0907, RMSE=0.3011, R²=0.0098
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0112
============================================================


📊 Round 365 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

============================================================
🔄 Round 367 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 367 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=0.0089
   Val:   Loss=0.0925, RMSE=0.3042, R²=0.0117
============================================================


📊 Round 367 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

============================================================
🔄 Round 369 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0901, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0901, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 369 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.3001, R²=0.0100
   Val:   Loss=0.0855, RMSE=0.2923, R²=0.0044
============================================================


============================================================
🔄 Round 370 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0951 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0951, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0952, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0952, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0952, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0952, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0951)

============================================================
📊 Round 370 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=0.0084
   Val:   Loss=0.0951, RMSE=0.3085, R²=0.0061
============================================================


📊 Round 370 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0037

============================================================
🔄 Round 371 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0907, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0907, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0907, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0907, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0907, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0907, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 371 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0908, RMSE=0.3013, R²=0.0102
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0017
============================================================


📊 Round 371 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0037

============================================================
🔄 Round 372 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 372 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2986, R²=0.0097
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0128
============================================================


📊 Round 372 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0037

📊 Round 372 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

============================================================
🔄 Round 376 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 376 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2989, R²=0.0085
   Val:   Loss=0.0882, RMSE=0.2970, R²=0.0057
============================================================


📊 Round 376 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

============================================================
🔄 Round 377 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0906, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0906, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0906, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0906, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0906, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0906, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 377 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0905, RMSE=0.3008, R²=0.0087
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0102
============================================================


📊 Round 377 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

============================================================
🔄 Round 379 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0991 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0992, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0992, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0992, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0992, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0994, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0991)

============================================================
📊 Round 379 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0081
   Val:   Loss=0.0991, RMSE=0.3149, R²=-0.0129
============================================================


📊 Round 379 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

============================================================
🔄 Round 381 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 381 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2979, R²=0.0101
   Val:   Loss=0.0907, RMSE=0.3012, R²=0.0031
============================================================


============================================================
🔄 Round 382 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0901, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0901, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 382 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2994, R²=0.0110
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0027
============================================================


============================================================
🔄 Round 384 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 384 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2976, R²=0.0105
   Val:   Loss=0.0913, RMSE=0.3021, R²=0.0085
============================================================


============================================================
🔄 Round 385 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 385 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2969, R²=0.0093
   Val:   Loss=0.0931, RMSE=0.3052, R²=0.0130
============================================================


📊 Round 385 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0037

============================================================
🔄 Round 387 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0946 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0946, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0946, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0946, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0946, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0946)

============================================================
📊 Round 387 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2962, R²=0.0101
   Val:   Loss=0.0946, RMSE=0.3076, R²=0.0100
============================================================


📊 Round 387 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0037

============================================================
🔄 Round 393 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 393 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2994, R²=0.0108
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0249
============================================================


📊 Round 393 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0037

📊 Round 393 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0037

📊 Round 393 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0037

============================================================
🔄 Round 398 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0905, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0905, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0905, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0905, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0905, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0905, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 398 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0905, RMSE=0.3009, R²=0.0101
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0078
============================================================


📊 Round 398 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0037

📊 Round 398 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0037

============================================================
🔄 Round 402 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 402 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2969, R²=0.0107
   Val:   Loss=0.0932, RMSE=0.3052, R²=0.0061
============================================================


============================================================
🔄 Round 404 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0902, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0902, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 404 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2998, R²=0.0114
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0050
============================================================


============================================================
🔄 Round 407 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 407 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2996, R²=0.0098
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0024
============================================================


📊 Round 407 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0037

============================================================
🔄 Round 409 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 409 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=0.0080
   Val:   Loss=0.0921, RMSE=0.3035, R²=-0.0221
============================================================


============================================================
🔄 Round 411 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 411 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2983, R²=0.0092
   Val:   Loss=0.0897, RMSE=0.2995, R²=0.0134
============================================================


📊 Round 411 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

============================================================
🔄 Round 412 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0901, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0901, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 412 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0901, RMSE=0.3002, R²=0.0081
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0181
============================================================


============================================================
🔄 Round 413 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0942, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0942, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0942, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 413 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2964, R²=0.0100
   Val:   Loss=0.0942, RMSE=0.3068, R²=0.0098
============================================================


📊 Round 413 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

📊 Round 413 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

============================================================
🔄 Round 417 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 417 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2974, R²=0.0089
   Val:   Loss=0.0918, RMSE=0.3031, R²=0.0147
============================================================


============================================================
🔄 Round 418 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 418 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2983, R²=0.0102
   Val:   Loss=0.0898, RMSE=0.2996, R²=-0.0042
============================================================


📊 Round 418 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

============================================================
🔄 Round 420 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0902, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 420 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0903, RMSE=0.3004, R²=0.0108
   Val:   Loss=0.0845, RMSE=0.2908, R²=0.0071
============================================================


============================================================
🔄 Round 423 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 423 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2969, R²=0.0102
   Val:   Loss=0.0930, RMSE=0.3049, R²=0.0097
============================================================


📊 Round 423 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

============================================================
🔄 Round 426 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 426 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2995, R²=0.0105
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0045
============================================================


📊 Round 426 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

============================================================
🔄 Round 427 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 427 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2990, R²=0.0102
   Val:   Loss=0.0880, RMSE=0.2966, R²=0.0096
============================================================


📊 Round 427 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

============================================================
🔄 Round 429 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 429 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0903, RMSE=0.3004, R²=0.0105
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0080
============================================================


📊 Round 429 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

📊 Round 429 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

============================================================
🔄 Round 433 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 433 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=0.0077
   Val:   Loss=0.0903, RMSE=0.3005, R²=0.0043
============================================================


============================================================
🔄 Round 434 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0901, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 434 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0903, RMSE=0.3004, R²=0.0080
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0164
============================================================


📊 Round 434 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

============================================================
🔄 Round 436 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 436 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0901, RMSE=0.3002, R²=0.0100
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0083
============================================================


📊 Round 436 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

============================================================
🔄 Round 438 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 438 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2986, R²=0.0108
   Val:   Loss=0.0889, RMSE=0.2982, R²=0.0043
============================================================


📊 Round 438 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

============================================================
🔄 Round 440 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.1013 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.1013, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.1013, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.1013, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.1013, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.1014, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1013)

============================================================
📊 Round 440 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0095
   Val:   Loss=0.1013, RMSE=0.3182, R²=-0.0071
============================================================


============================================================
🔄 Round 441 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 441 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2994, R²=0.0096
   Val:   Loss=0.0869, RMSE=0.2949, R²=0.0023
============================================================


📊 Round 441 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

📊 Round 441 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

============================================================
🔄 Round 445 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0914, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0914, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0914, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0914, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0914, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0914, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 445 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0914, RMSE=0.3024, R²=0.0105
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0084
============================================================


============================================================
🔄 Round 446 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0943 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0943, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0943, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0943, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0943, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0943, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0943)

============================================================
📊 Round 446 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2964, R²=0.0099
   Val:   Loss=0.0943, RMSE=0.3071, R²=0.0081
============================================================


📊 Round 446 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0035

============================================================
🔄 Round 450 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 450 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2991, R²=0.0092
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0031
============================================================


📊 Round 450 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0035

============================================================
🔄 Round 453 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0909, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0909, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0909, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0909, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0909, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0909, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 453 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0908, RMSE=0.3013, R²=0.0097
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0086
============================================================


============================================================
🔄 Round 455 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 455 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=0.0095
   Val:   Loss=0.0936, RMSE=0.3059, R²=-0.0086
============================================================


📊 Round 455 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0035

============================================================
🔄 Round 459 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 459 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2995, R²=0.0101
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0094
============================================================


📊 Round 459 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0035

📊 Round 459 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0035

============================================================
🔄 Round 466 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 466 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2993, R²=0.0109
   Val:   Loss=0.0873, RMSE=0.2955, R²=0.0063
============================================================


📊 Round 466 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0035

📊 Round 466 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0035

============================================================
🔄 Round 472 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0967 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0967, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0967, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0967, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0967, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0967, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0967)

============================================================
📊 Round 472 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=0.0103
   Val:   Loss=0.0967, RMSE=0.3110, R²=0.0098
============================================================


============================================================
🔄 Round 473 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0898, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 473 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2998, R²=0.0086
   Val:   Loss=0.0861, RMSE=0.2935, R²=0.0027
============================================================


📊 Round 473 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0035

============================================================
🔄 Round 474 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0945 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0945, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0945, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0945, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0945)

============================================================
📊 Round 474 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=0.0103
   Val:   Loss=0.0945, RMSE=0.3074, R²=0.0096
============================================================


📊 Round 474 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0035

============================================================
🔄 Round 476 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0911, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0911, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0911, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0911, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0911, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0911, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 476 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0910, RMSE=0.3017, R²=0.0079
   Val:   Loss=0.0815, RMSE=0.2854, R²=0.0087
============================================================


📊 Round 476 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0035

============================================================
🔄 Round 477 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.1012 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.1012, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.1012, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.1012, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.1012, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.1011, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1012)

============================================================
📊 Round 477 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=0.0121
   Val:   Loss=0.1012, RMSE=0.3181, R²=0.0035
============================================================


📊 Round 477 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0035

============================================================
🔄 Round 479 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 479 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2989, R²=0.0075
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0205
============================================================


============================================================
🔄 Round 480 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0903, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0903, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0903, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0903, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0903, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0903, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 480 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0902, RMSE=0.3003, R²=0.0106
   Val:   Loss=0.0849, RMSE=0.2913, R²=0.0012
============================================================


============================================================
🔄 Round 481 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 481 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=0.0113
   Val:   Loss=0.0904, RMSE=0.3006, R²=0.0024
============================================================


📊 Round 481 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

============================================================
🔄 Round 482 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 482 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2984, R²=0.0110
   Val:   Loss=0.0894, RMSE=0.2990, R²=0.0068
============================================================


📊 Round 482 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

📊 Round 482 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

============================================================
🔄 Round 486 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 486 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2985, R²=0.0091
   Val:   Loss=0.0893, RMSE=0.2988, R²=0.0145
============================================================


============================================================
🔄 Round 487 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 487 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=0.0084
   Val:   Loss=0.0925, RMSE=0.3042, R²=0.0143
============================================================


📊 Round 487 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

============================================================
🔄 Round 488 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0910, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0910, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0910, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0910, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0910, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0910, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 488 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0910, RMSE=0.3016, R²=0.0111
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0045
============================================================


📊 Round 488 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

============================================================
🔄 Round 490 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0941, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 490 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=0.0090
   Val:   Loss=0.0940, RMSE=0.3066, R²=0.0061
============================================================


============================================================
🔄 Round 492 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 492 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=0.0120
   Val:   Loss=0.0936, RMSE=0.3059, R²=0.0030
============================================================


📊 Round 492 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

============================================================
🔄 Round 493 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 493 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2985, R²=0.0113
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0101
============================================================


📊 Round 493 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0037

============================================================
🔄 Round 495 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0953 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0953, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0953, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0953, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0953, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0952, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0953)

============================================================
📊 Round 495 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=0.0119
   Val:   Loss=0.0953, RMSE=0.3086, R²=0.0038
============================================================


📊 Round 495 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0037

============================================================
🔄 Round 496 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0963 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0963, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0963, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0963, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0963, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0963, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0963)

============================================================
📊 Round 496 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=0.0106
   Val:   Loss=0.0963, RMSE=0.3104, R²=0.0053
============================================================


📊 Round 496 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0037

📊 Round 496 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0037

📊 Round 496 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0037

============================================================
🔄 Round 502 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0964 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0964, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0964, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0964, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0964, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0965, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0964)

============================================================
📊 Round 502 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=0.0093
   Val:   Loss=0.0964, RMSE=0.3104, R²=-0.0056
============================================================


📊 Round 502 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0037

============================================================
🔄 Round 506 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 506 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2986, R²=0.0106
   Val:   Loss=0.0890, RMSE=0.2984, R²=0.0046
============================================================


📊 Round 506 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0037

📊 Round 506 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

============================================================
🔄 Round 510 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 510 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2995, R²=0.0102
   Val:   Loss=0.0868, RMSE=0.2945, R²=0.0099
============================================================


📊 Round 510 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0037

📊 Round 510 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0037

============================================================
🔄 Round 513 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0913, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0913, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0913, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0913, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0913, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0913, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 513 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0913, RMSE=0.3022, R²=0.0091
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0105
============================================================


📊 Round 513 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0037

============================================================
🔄 Round 514 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0899, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0899, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0898, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 514 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2997, R²=0.0081
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0016
============================================================


📊 Round 514 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0037

============================================================
🔄 Round 517 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0899, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0899, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0899, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 517 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2994, R²=0.0095
   Val:   Loss=0.0871, RMSE=0.2951, R²=0.0055
============================================================


📊 Round 517 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0037

============================================================
🔄 Round 520 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 520 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2988, R²=0.0105
   Val:   Loss=0.0884, RMSE=0.2974, R²=0.0089
============================================================


📊 Round 520 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0037

============================================================
🔄 Round 521 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 521 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2993, R²=0.0107
   Val:   Loss=0.0873, RMSE=0.2954, R²=0.0081
============================================================


📊 Round 521 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0037

📊 Round 521 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0037

📊 Round 521 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0037

============================================================
🔄 Round 525 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 525 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=0.0076
   Val:   Loss=0.0903, RMSE=0.3005, R²=0.0203
============================================================


📊 Round 525 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0037

============================================================
🔄 Round 526 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0913, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0913, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0913, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0913, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0913, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0912, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 526 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0911, RMSE=0.3018, R²=0.0085
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0079
============================================================


============================================================
🔄 Round 527 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0902, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 527 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0902, RMSE=0.3003, R²=0.0070
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0096
============================================================


============================================================
🔄 Round 529 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 529 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=0.0112
   Val:   Loss=0.0925, RMSE=0.3041, R²=0.0043
============================================================


📊 Round 529 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0037

============================================================
🔄 Round 533 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0906, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0906, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0906, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0906, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0905, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0905, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 533 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0906, RMSE=0.3010, R²=0.0086
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0147
============================================================


📊 Round 533 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0037

📊 Round 533 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0037

============================================================
🔄 Round 538 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0915, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0915, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0915, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0915, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0915, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0915, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 538 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0913, RMSE=0.3021, R²=0.0094
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0129
============================================================


============================================================
🔄 Round 539 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0963 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0963, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0963, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0963, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0963, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0963, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0963)

============================================================
📊 Round 539 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=0.0099
   Val:   Loss=0.0963, RMSE=0.3103, R²=0.0115
============================================================


📊 Round 539 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0038

📊 Round 539 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0038

📊 Round 539 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0038

📊 Round 539 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0038

============================================================
🔄 Round 549 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 549 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=0.0097
   Val:   Loss=0.0909, RMSE=0.3015, R²=0.0125
============================================================


📊 Round 549 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0038

============================================================
🔄 Round 550 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0904, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0904, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0904, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0904, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0904, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0904, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 550 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0904, RMSE=0.3006, R²=0.0079
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0165
============================================================


============================================================
🔄 Round 551 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0904, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0904, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0904, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0904, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0904, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0904, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 551 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0903, RMSE=0.3006, R²=0.0120
   Val:   Loss=0.0842, RMSE=0.2901, R²=0.0018
============================================================


============================================================
🔄 Round 552 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 552 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.3000, R²=0.0113
   Val:   Loss=0.0856, RMSE=0.2925, R²=0.0044
============================================================


📊 Round 552 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0038

============================================================
🔄 Round 554 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0899, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0899, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0899, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 554 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.3000, R²=0.0091
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0049
============================================================


============================================================
🔄 Round 557 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0914, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0914, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0914, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0914, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0914, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0914, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 557 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0914, RMSE=0.3024, R²=0.0101
   Val:   Loss=0.0798, RMSE=0.2826, R²=0.0109
============================================================


📊 Round 557 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0038

============================================================
🔄 Round 559 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0969 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0969, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0969, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0969, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0969, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0969, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0969)

============================================================
📊 Round 559 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2952, R²=0.0106
   Val:   Loss=0.0969, RMSE=0.3113, R²=0.0066
============================================================


============================================================
🔄 Round 560 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 560 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2998, R²=0.0111
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0029
============================================================


📊 Round 560 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0038

============================================================
🔄 Round 563 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 563 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2995, R²=0.0085
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0198
============================================================


📊 Round 563 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0038

============================================================
🔄 Round 565 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0903, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0903, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0903, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0902, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 565 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0902, RMSE=0.3004, R²=0.0115
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0030
============================================================


============================================================
🔄 Round 566 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 566 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=0.0128
   Val:   Loss=0.0936, RMSE=0.3060, R²=-0.0049
============================================================


📊 Round 566 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0038

============================================================
🔄 Round 568 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0903, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0903, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0903, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0903, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0903, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0903, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 568 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0901, RMSE=0.3002, R²=0.0113
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0025
============================================================


📊 Round 568 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0038

📊 Round 568 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0038

============================================================
🔄 Round 572 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 572 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2994, R²=0.0103
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0134
============================================================


📊 Round 572 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0038

============================================================
🔄 Round 574 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0919, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0919, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0919, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0919, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0919, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0919, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 574 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0919, RMSE=0.3032, R²=0.0103
   Val:   Loss=0.0778, RMSE=0.2790, R²=0.0006
============================================================


============================================================
🔄 Round 576 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 576 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=0.0118
   Val:   Loss=0.0907, RMSE=0.3012, R²=0.0008
============================================================


============================================================
🔄 Round 577 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0970 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0970, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0970, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0970, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0970, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0970, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0970)

============================================================
📊 Round 577 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2952, R²=0.0103
   Val:   Loss=0.0970, RMSE=0.3114, R²=0.0077
============================================================


============================================================
🔄 Round 578 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 578 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2994, R²=0.0121
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0026
============================================================


📊 Round 578 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0038

============================================================
🔄 Round 579 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 579 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=0.0110
   Val:   Loss=0.0920, RMSE=0.3033, R²=0.0077
============================================================


============================================================
🔄 Round 581 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0911, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0911, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0911, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0911, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0911, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0911, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 581 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0914, RMSE=0.3024, R²=0.0106
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0085
============================================================


📊 Round 581 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0038

============================================================
🔄 Round 582 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 582 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2986, R²=0.0089
   Val:   Loss=0.0888, RMSE=0.2981, R²=0.0162
============================================================


📊 Round 582 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0038

============================================================
🔄 Round 584 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 584 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=0.0087
   Val:   Loss=0.0920, RMSE=0.3032, R²=0.0054
============================================================


📊 Round 584 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0038

============================================================
🔄 Round 585 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 585 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.3001, R²=0.0098
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0025
============================================================


📊 Round 585 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0038

============================================================
🔄 Round 586 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 586 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2991, R²=0.0092
   Val:   Loss=0.0878, RMSE=0.2962, R²=-0.0061
============================================================


📊 Round 586 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0038

============================================================
🔄 Round 588 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 588 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2972, R²=0.0079
   Val:   Loss=0.0921, RMSE=0.3035, R²=0.0026
============================================================


============================================================
🔄 Round 589 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 589 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=0.0097
   Val:   Loss=0.0885, RMSE=0.2976, R²=0.0088
============================================================


============================================================
🔄 Round 592 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 592 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=0.0091
   Val:   Loss=0.0931, RMSE=0.3052, R²=-0.0083
============================================================


============================================================
🔄 Round 593 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 593 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2971, R²=0.0108
   Val:   Loss=0.0926, RMSE=0.3043, R²=0.0084
============================================================


📊 Round 593 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0039

============================================================
🔄 Round 594 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 594 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2984, R²=0.0095
   Val:   Loss=0.0894, RMSE=0.2990, R²=0.0037
============================================================


📊 Round 594 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0039

============================================================
🔄 Round 596 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0948 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0948, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0948, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0948, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0948, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0948, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0948)

============================================================
📊 Round 596 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=0.0111
   Val:   Loss=0.0948, RMSE=0.3079, R²=0.0073
============================================================


============================================================
🔄 Round 598 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 598 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2974, R²=0.0128
   Val:   Loss=0.0917, RMSE=0.3028, R²=-0.0002
============================================================


📊 Round 598 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0039

============================================================
🔄 Round 599 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 599 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2985, R²=0.0096
   Val:   Loss=0.0892, RMSE=0.2986, R²=-0.0008
============================================================


📊 Round 599 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0039

============================================================
🔄 Round 600 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 600 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=0.0091
   Val:   Loss=0.0903, RMSE=0.3004, R²=0.0154
============================================================


============================================================
🔄 Round 601 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 601 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2991, R²=0.0101
   Val:   Loss=0.0876, RMSE=0.2960, R²=0.0020
============================================================


============================================================
🔄 Round 602 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0942, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0942, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0942, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 602 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2964, R²=0.0105
   Val:   Loss=0.0942, RMSE=0.3069, R²=0.0076
============================================================


📊 Round 602 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0039

📊 Round 602 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0039

📊 Round 602 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0039

============================================================
🔄 Round 606 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 606 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2993, R²=0.0118
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0123
============================================================


============================================================
🔄 Round 607 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 607 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=0.0093
   Val:   Loss=0.0910, RMSE=0.3017, R²=-0.0097
============================================================


============================================================
🔄 Round 608 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0920, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0920, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0920, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0920, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0920, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0920, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 608 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0919, RMSE=0.3031, R²=0.0094
   Val:   Loss=0.0780, RMSE=0.2792, R²=-0.0002
============================================================


============================================================
🔄 Round 610 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0918, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0918, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0918, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0918, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0918, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0918, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 610 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0915, RMSE=0.3025, R²=0.0105
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0099
============================================================


📊 Round 610 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0039

============================================================
🔄 Round 613 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0909, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0909, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0909, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0909, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0909, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0909, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 613 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0908, RMSE=0.3014, R²=0.0109
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0045
============================================================


============================================================
🔄 Round 618 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0943 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0943, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0943, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0943, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0943, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0943, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0943)

============================================================
📊 Round 618 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=0.0105
   Val:   Loss=0.0943, RMSE=0.3070, R²=0.0069
============================================================


============================================================
🔄 Round 619 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 619 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.3000, R²=0.0091
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0144
============================================================


📊 Round 619 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0038

📊 Round 619 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0038

============================================================
🔄 Round 623 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 623 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2998, R²=0.0095
   Val:   Loss=0.0860, RMSE=0.2932, R²=0.0021
============================================================


📊 Round 623 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0038

📊 Round 623 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0038

============================================================
🔄 Round 626 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0969 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0969, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0970, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0970, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0970, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0970, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0969)

============================================================
📊 Round 626 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=0.0116
   Val:   Loss=0.0969, RMSE=0.3114, R²=0.0011
============================================================


📊 Round 626 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0038

============================================================
🔄 Round 629 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 629 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2994, R²=0.0090
   Val:   Loss=0.0870, RMSE=0.2949, R²=0.0146
============================================================


============================================================
🔄 Round 631 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 631 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=0.0104
   Val:   Loss=0.0915, RMSE=0.3024, R²=0.0076
============================================================


============================================================
🔄 Round 632 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 632 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2994, R²=0.0080
   Val:   Loss=0.0869, RMSE=0.2947, R²=0.0158
============================================================


============================================================
🔄 Round 635 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 635 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2969, R²=0.0101
   Val:   Loss=0.0928, RMSE=0.3046, R²=0.0098
============================================================


============================================================
🔄 Round 639 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 639 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2994, R²=0.0102
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0075
============================================================


============================================================
🔄 Round 640 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 640 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2982, R²=0.0111
   Val:   Loss=0.0897, RMSE=0.2995, R²=0.0054
============================================================


📊 Round 640 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0037

============================================================
🔄 Round 644 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0938, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 644 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2966, R²=0.0076
   Val:   Loss=0.0937, RMSE=0.3061, R²=-0.0049
============================================================


📊 Round 644 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0037

============================================================
🔄 Round 645 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 645 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=0.0112
   Val:   Loss=0.0904, RMSE=0.3006, R²=-0.0043
============================================================


📊 Round 645 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0037

📊 Round 645 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

📊 Round 645 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

============================================================
🔄 Round 649 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0903, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0903, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0903, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0903, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0903, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0903, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 649 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0903, RMSE=0.3005, R²=0.0113
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0036
============================================================


📊 Round 649 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

============================================================
🔄 Round 651 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0945 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0945, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0945, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0945, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0945)

============================================================
📊 Round 651 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2962, R²=0.0109
   Val:   Loss=0.0945, RMSE=0.3074, R²=0.0066
============================================================


📊 Round 651 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

📊 Round 651 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0037

============================================================
🔄 Round 654 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0933, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 654 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=0.0113
   Val:   Loss=0.0932, RMSE=0.3054, R²=-0.0027
============================================================


📊 Round 654 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0037

============================================================
🔄 Round 655 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 655 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2979, R²=0.0097
   Val:   Loss=0.0904, RMSE=0.3007, R²=0.0101
============================================================


============================================================
🔄 Round 658 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0903, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0903, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0903, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0903, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0903, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0903, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 658 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0903, RMSE=0.3005, R²=0.0082
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0097
============================================================


📊 Round 658 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0037

============================================================
🔄 Round 659 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0953 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0953, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0953, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0953, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0954, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0954, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0953)

============================================================
📊 Round 659 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=0.0099
   Val:   Loss=0.0953, RMSE=0.3087, R²=-0.0049
============================================================


📊 Round 659 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0037

📊 Round 659 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0037

============================================================
🔄 Round 664 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0901, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0901, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 664 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0903, RMSE=0.3004, R²=0.0088
   Val:   Loss=0.0845, RMSE=0.2906, R²=0.0165
============================================================


📊 Round 664 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0037

============================================================
🔄 Round 665 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 665 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2996, R²=0.0102
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0110
============================================================


📊 Round 665 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0037

============================================================
🔄 Round 667 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0958 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0958, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0958, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0958, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0958, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0958, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0958)

============================================================
📊 Round 667 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=0.0118
   Val:   Loss=0.0958, RMSE=0.3095, R²=0.0031
============================================================


📊 Round 667 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0037

============================================================
🔄 Round 669 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0906, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0906, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0906, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0906, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0906, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0905, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 669 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0906, RMSE=0.3011, R²=0.0110
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0032
============================================================


📊 Round 669 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0037

============================================================
🔄 Round 671 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 671 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2990, R²=0.0078
   Val:   Loss=0.0880, RMSE=0.2966, R²=0.0168
============================================================


============================================================
🔄 Round 672 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0909, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0909, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0909, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0909, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0909, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0908, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 672 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0911, RMSE=0.3019, R²=0.0097
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0140
============================================================


📊 Round 672 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0037

📊 Round 672 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0038

📊 Round 672 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0038

============================================================
🔄 Round 676 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0911, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0911, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0911, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0911, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0911, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0911, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 676 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0912, RMSE=0.3019, R²=0.0100
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0093
============================================================


📊 Round 676 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0037

============================================================
🔄 Round 678 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.1057 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.1057, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.1057, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.1057, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.1057, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.1057, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1057)

============================================================
📊 Round 678 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0116
   Val:   Loss=0.1057, RMSE=0.3250, R²=0.0048
============================================================


📊 Round 678 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0037

📊 Round 678 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0037

============================================================
🔄 Round 680 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 680 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2986, R²=0.0096
   Val:   Loss=0.0888, RMSE=0.2980, R²=0.0122
============================================================


============================================================
🔄 Round 681 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.1042 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.1042, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.1042, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.1042, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.1042, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.1042, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1042)

============================================================
📊 Round 681 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0113
   Val:   Loss=0.1042, RMSE=0.3228, R²=0.0075
============================================================


📊 Round 681 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0037

============================================================
🔄 Round 685 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 685 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=0.0120
   Val:   Loss=0.0922, RMSE=0.3036, R²=-0.0007
============================================================


📊 Round 685 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0038

============================================================
🔄 Round 689 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 689 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2995, R²=0.0106
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0096
============================================================


📊 Round 689 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0037

📊 Round 689 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0037

============================================================
🔄 Round 692 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 692 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2964, R²=0.0106
   Val:   Loss=0.0940, RMSE=0.3066, R²=0.0098
============================================================


📊 Round 692 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0038

============================================================
🔄 Round 696 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0941, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 696 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2964, R²=0.0114
   Val:   Loss=0.0940, RMSE=0.3066, R²=-0.0006
============================================================


📊 Round 696 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0037

📊 Round 696 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0037

📊 Round 696 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0037

============================================================
🔄 Round 699 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0907, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0907, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0907, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0907, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0907, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0906, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 699 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0904, RMSE=0.3007, R²=0.0105
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0040
============================================================


============================================================
🔄 Round 701 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 701 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2984, R²=0.0092
   Val:   Loss=0.0892, RMSE=0.2987, R²=0.0000
============================================================


📊 Round 701 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0037

============================================================
🔄 Round 702 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 702 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2984, R²=0.0105
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0022
============================================================


📊 Round 702 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0037

📊 Round 702 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0037

============================================================
🔄 Round 707 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0941, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0941, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0941, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 707 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2964, R²=0.0084
   Val:   Loss=0.0940, RMSE=0.3067, R²=0.0073
============================================================


============================================================
🔄 Round 713 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 713 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2990, R²=0.0083
   Val:   Loss=0.0880, RMSE=0.2966, R²=0.0190
============================================================


============================================================
🔄 Round 714 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 714 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2984, R²=0.0087
   Val:   Loss=0.0892, RMSE=0.2987, R²=0.0150
============================================================


============================================================
🔄 Round 716 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0899, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0899, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0899, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 716 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.2999, R²=0.0104
   Val:   Loss=0.0856, RMSE=0.2927, R²=0.0076
============================================================


📊 Round 716 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0038

📊 Round 716 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0038

============================================================
🔄 Round 721 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 721 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2997, R²=0.0099
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0084
============================================================


============================================================
🔄 Round 722 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0903, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0903, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0903, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0903, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0903, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0902, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 722 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0903, RMSE=0.3005, R²=0.0101
   Val:   Loss=0.0841, RMSE=0.2901, R²=0.0058
============================================================


📊 Round 722 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0038

📊 Round 722 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0038

============================================================
🔄 Round 726 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 726 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=0.0100
   Val:   Loss=0.0936, RMSE=0.3059, R²=0.0105
============================================================


📊 Round 726 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0038

============================================================
🔄 Round 730 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0970 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0970, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0970, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0970, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0970, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0971, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0970)

============================================================
📊 Round 730 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=0.0126
   Val:   Loss=0.0970, RMSE=0.3115, R²=0.0003
============================================================


============================================================
🔄 Round 731 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0908, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0908, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0908, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0908, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0908, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0907, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 731 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0906, RMSE=0.3010, R²=0.0097
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0141
============================================================


📊 Round 731 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0038

📊 Round 731 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0038

📊 Round 731 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0038

📊 Round 731 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0038

📊 Round 731 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0037

============================================================
🔄 Round 744 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0955 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0955, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0955, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0956, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0956, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0956, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0955)

============================================================
📊 Round 744 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=0.0093
   Val:   Loss=0.0955, RMSE=0.3091, R²=0.0024
============================================================


============================================================
🔄 Round 745 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0920, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0920, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0920, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0920, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0920, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0919, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 745 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0919, RMSE=0.3031, R²=0.0089
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0179
============================================================


📊 Round 745 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0037

============================================================
🔄 Round 747 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 747 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2981, R²=0.0111
   Val:   Loss=0.0899, RMSE=0.2999, R²=0.0073
============================================================


📊 Round 747 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0037

============================================================
🔄 Round 748 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 748 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2994, R²=0.0084
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0055
============================================================


============================================================
🔄 Round 751 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0920, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0920, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0920, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0920, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0920, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0920, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 751 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0918, RMSE=0.3030, R²=0.0106
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0087
============================================================


📊 Round 751 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0038

============================================================
🔄 Round 752 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0966 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0966, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0966, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0966, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0966, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0966, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0966)

============================================================
📊 Round 752 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=0.0090
   Val:   Loss=0.0966, RMSE=0.3108, R²=0.0132
============================================================


============================================================
🔄 Round 754 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 754 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2997, R²=0.0104
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0055
============================================================


============================================================
🔄 Round 755 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 755 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=0.0077
   Val:   Loss=0.0919, RMSE=0.3031, R²=0.0209
============================================================


📊 Round 755 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0038

📊 Round 755 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0038

📊 Round 755 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0038

============================================================
🔄 Round 764 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0899, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 764 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0902, RMSE=0.3003, R²=0.0115
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0061
============================================================


📊 Round 764 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0037

============================================================
🔄 Round 770 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0945 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0945, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0945, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0945)

============================================================
📊 Round 770 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=0.0094
   Val:   Loss=0.0945, RMSE=0.3074, R²=-0.0091
============================================================


📊 Round 770 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0037

📊 Round 770 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0037

📊 Round 770 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0037

📊 Round 770 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0037

============================================================
🔄 Round 776 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 776 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2992, R²=0.0100
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0079
============================================================


📊 Round 776 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0037

============================================================
🔄 Round 779 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0965 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0965, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0965, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0965, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0965, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0965, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0965)

============================================================
📊 Round 779 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2954, R²=0.0094
   Val:   Loss=0.0965, RMSE=0.3106, R²=0.0136
============================================================


============================================================
🔄 Round 782 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0922, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0922, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0922, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0922, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0922, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0922, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 782 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0922, RMSE=0.3037, R²=0.0102
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0115
============================================================


============================================================
🔄 Round 783 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0916, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0916, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0915, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0915, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0915, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0915, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 783 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0911, RMSE=0.3018, R²=0.0091
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0011
============================================================


📊 Round 783 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

============================================================
🔄 Round 785 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 785 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=0.0096
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0114
============================================================


📊 Round 785 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

============================================================
🔄 Round 787 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0912, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0912, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0912, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0912, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0912, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0912, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 787 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0912, RMSE=0.3020, R²=0.0101
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0090
============================================================


============================================================
🔄 Round 788 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0946 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0946, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0946, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0946, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0946, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0946)

============================================================
📊 Round 788 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=0.0091
   Val:   Loss=0.0946, RMSE=0.3075, R²=0.0030
============================================================


============================================================
🔄 Round 789 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 789 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2986, R²=0.0102
   Val:   Loss=0.0889, RMSE=0.2981, R²=0.0081
============================================================


📊 Round 789 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

📊 Round 789 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

📊 Round 789 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

============================================================
🔄 Round 793 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 793 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=0.0122
   Val:   Loss=0.0919, RMSE=0.3032, R²=0.0032
============================================================


============================================================
🔄 Round 794 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0903, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0903, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0903, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0903, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0903, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0902, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 794 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0904, RMSE=0.3007, R²=0.0096
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0115
============================================================


📊 Round 794 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

============================================================
🔄 Round 797 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0902, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0902, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 797 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0903, RMSE=0.3006, R²=0.0086
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0084
============================================================


============================================================
🔄 Round 798 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 798 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=0.0096
   Val:   Loss=0.0927, RMSE=0.3045, R²=0.0080
============================================================


📊 Round 798 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

📊 Round 798 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

============================================================
🔄 Round 801 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0899, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 801 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2998, R²=0.0119
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0004
============================================================


============================================================
🔄 Round 803 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 803 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2981, R²=0.0105
   Val:   Loss=0.0900, RMSE=0.3001, R²=0.0101
============================================================


📊 Round 803 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

============================================================
🔄 Round 804 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 804 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=0.0105
   Val:   Loss=0.0926, RMSE=0.3043, R²=-0.0143
============================================================


============================================================
🔄 Round 805 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0898, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 805 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2996, R²=0.0118
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0047
============================================================


📊 Round 805 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

============================================================
🔄 Round 806 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0905, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0905, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0905, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0905, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0905, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0904, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 806 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0904, RMSE=0.3007, R²=0.0079
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0219
============================================================


📊 Round 806 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2481, R²: 0.0036

============================================================
🔄 Round 808 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0903, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0903, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0902, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0902, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 808 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0902, RMSE=0.3003, R²=0.0123
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0011
============================================================


❌ Client client_24 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_message:"Socket closed", grpc_status:14}"
>
