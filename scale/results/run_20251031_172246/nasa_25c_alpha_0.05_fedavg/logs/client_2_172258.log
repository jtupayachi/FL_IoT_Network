[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72cd0edd-aa31-4c5b-99fc-0f6f9a73dc7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ecd9ed8-166a-4b8c-80de-847b40fc600d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd1c0c45-9989-45a7-819e-61b1fe68f971
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ebfcb65-5b19-4c3f-8411-813cfb88207f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a0a7440-13e4-4455-bba1-6b10e4a3c483
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bebb1881-56ff-465d-b2ed-248dd17c092c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91114de3-06d5-472c-99cf-b2568e1cd075
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d69cbd2f-9e88-47d3-9ca0-6ae6ec6377e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff349f86-02f6-4052-b698-9af223337cd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f791670-c78f-46fa-929a-4767a9383382
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53ca3db4-227f-4525-944d-b4575e3d426a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97b2a05e-66c4-4a86-b0a6-d39c5effdfe6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0d79108-87df-4ead-8809-e17c962f2d02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20ff59e0-a44e-4828-be9d-c0a1ead1975a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d23774b9-0795-4a69-963c-ee16a66f3f34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0fa3741-86f5-4847-8fdb-3af8f07147cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa1adfea-1d88-419f-890a-be74c2e0df86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c9df751-73bb-49b1-aa56-89833f3d1764
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2196c111-67b7-4fad-a9ae-8e575d52819e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0aa2cb4-c99a-49ee-af3d-d996ff151286
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d54b604a-e57f-455c-ac01-a18fd1766522
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f98c016f-b2f6-4155-a81f-4b195b9cfed3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c40b8a52-2dcd-4f5a-9eb5-67d88f233d8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76818f6f-82e3-47d7-892f-1cfbdc84369a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c40821e7-f268-4081-b6ef-ebc5fbb2c4ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a529826-ea14-4329-a2c5-e3a8bd6ab82e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e94335b9-d679-4a47-b2bf-7de8fae79f5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cac6cbff-646c-4ceb-b387-4865d7d350c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13bd0d4f-160f-4879-adca-5f64e2d9702e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fee1a2e7-5f39-4e3a-b3b4-53ae22997343
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b08f6d6-63aa-414f-8fb5-d17432cf79ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1c71a84-c878-4bc6-9db5-00db24a9c61b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc08a4bf-b63c-4986-853b-b40678bd7554
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd4c782d-b35b-4838-9823-3799cb45d992
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b65c4f83-8b2b-4c56-8ed4-6ac98e0ecbc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa1d9b0d-8d7e-42d8-a0b5-efb351a1cd76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0e7ea4e-e319-482e-879b-65d1642e2cbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45bd4072-45d1-4cc3-a879-66196d62ec8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d44988b-f408-4f62-a3e0-60ca8ee9ab88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00c8560d-5519-4332-9cd4-d18b118f4c40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f9f7c03-0244-4036-8f4c-1c5998fc12bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d931a50-f1bc-4e17-a519-8dbbc4b030ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2a53195-9340-4102-8045-80fc5ba020ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d544f0a5-c322-4152-8e50-9a7b46fd6e3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cc46016-e544-4d5f-8b16-0e4addc6c2a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d96686b-45be-43eb-a5cb-27f46a60ed06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61798b54-a389-4af7-8ab2-6d26bba983ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50e28b39-07b8-470a-be83-fa2fbfcd8980
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 517237e7-72f5-4f1a-b248-ac19da88b219
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e327461-9e29-4af3-adc8-b9dad5b16d0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a16b334-0b3a-435e-9af7-5b46d3668c84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b0025f7-504d-4c27-b705-b126712583ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ceab6772-4ef1-4a94-af3b-c16d3d24ef06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1736ee7c-ee27-4f14-adab-275411bdc98b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf2c2667-f09a-45c4-84c2-172382b6e956
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dad70d06-e5c8-4201-9d26-4e941fce5d75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e98d2edb-ba0d-44f1-a24b-b77a995e8c31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 125e2c10-a63e-41bf-8d49-7f44b9e67032
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c30cda32-a15b-41ae-a796-1839d68622d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3fb9ac1-fd61-4ba5-8399-59b228653163
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c937e7f1-884f-4bb1-948a-57f04d43b3b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90cfb2ca-503f-4f77-971e-148ea1e52f4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f7572e6-854a-4085-b356-2024345a3d26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d192023-a432-463b-ac92-0030373f946a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86b137d8-9905-45ce-a63a-8e8c64840315
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecda0e43-dcca-47ce-8a67-7a05f4ad9671
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8364f33-63cf-4275-95d4-3381618a3bc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8b1a29f-d967-4b04-873a-07b1773fd25d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9aec212-3d0f-4f23-99fd-e8a6855b7d79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6779c4e-72e7-43f6-ba27-1b24dd3455ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3cdd1a7-bfd4-4c21-b753-1099bdead84d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c26c409-b5f3-46e1-9d1a-9ee5c64a569e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85b629b6-dfb3-4e34-9f8e-202dfd752c38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecaec8cf-6d54-43e1-a6c0-92cbd3c771f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a3a2e0a-6144-47a9-b04c-de19fd93a0e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b8b9ee2-7c22-4c39-9b1a-3d95a2ea5f64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0aaaad16-27c2-4233-9b0d-e4c1e8350a6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd6c9173-157f-4aeb-8163-51846bbf5d3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41a54bce-1863-4f20-8adf-3bb8cd543619
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ae7c5e8-70e2-48a4-b631-d5a750cbc0aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9efdd7c2-1c6d-4bff-b3c2-806bcf17ca5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e093b7b-9f5e-4e92-b37f-46683608a9b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7f002fe-2389-46b3-8228-f2c4861f7331
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d13edff-3fdb-4ad7-b0eb-5f3617c4f39d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3369f41c-46a8-47c4-b51d-91578877761c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3043eeb8-de8a-44d4-8799-bf4556d87154
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffecf17b-4068-4ae4-be67-25ec9dc408fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab6db7bf-5c87-4f0e-b556-86c449a7f7f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b80b121a-cb44-4a94-bc3a-ad097eb33661
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8c95653-f2c3-4542-85c7-602cd891f513
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f22a65a2-d5bb-4106-a322-7ec2f39fbc5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9ef6e05-b5ae-4c32-8b2c-5929c3abb8c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a47a42b-3ecb-4681-96f6-b68141ea0f8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1aeb0bf5-31c5-4118-953c-df47c6dba836
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1589b558-cfe5-4984-a9b9-442460370fab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbff653c-e9b0-4c1c-9012-a6c923fef72c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c633301-cd59-40f7-b0ef-169f6fd7a8d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24debe97-57ae-4598-9e13-bb8ae4008102
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 178ca7ce-4cb5-4a6d-80ea-f8813afff01d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3539aa5-a674-4f4c-8ff7-ef374a1513e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3548bfcc-0c8b-48ac-aa27-007d3b773669
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee612cd9-8cac-4ec7-b9a3-92fba1c2220b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2c004f5-1f35-452b-9b3a-e9083710ae7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7d2b67f-9285-48e0-8dbf-6897467a7f13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51afeac0-aca9-4cfb-b3a3-ce0cadff0310
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8a8a4fd-ba3e-40f3-b592-99a4f85b06f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4dc7b1e-dc2b-4000-b1a0-14014f0dd481
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba330d65-2433-4b09-bbb6-e8b93dca83c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9e77b4f-6046-4f18-bdf1-75cceb7ec3c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a7919ed-d95b-4e99-9364-af8d87ed07ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76a268cd-a930-46bd-9d8b-1202ccc85d44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a283c4c6-c89a-47f9-81db-883c08c2c514
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1770fd2e-dd05-4a5d-9fd3-63092f138b16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c0ad95c-ba50-477c-93a4-faf28dd0aa1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82534b0d-5b52-4507-b672-5ab5e8040d74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43b6d6d2-4234-4d5f-a543-d927c23de798
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8c587fb-d5b2-4fee-9176-6868af25250c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e455fc6-a442-484c-b43e-772a5c71fe9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8cedbf9-698d-4b62-acec-c987c3e274a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1dcd972b-3a84-48fa-bb5b-99decebc2142
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e513d302-2837-4a2e-85b7-86286ffd39f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0510ec3-03ab-4e3e-86b0-b2f8203434f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7dbab438-41dd-48bb-ab76-91959842d1c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04493626-b755-4f6c-82d2-e5b33b23916e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83eb7e4e-1be8-4c54-86a9-a065620ff37c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88985041-e32f-4ac3-9b7f-63629c4dc18a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97e28978-2d85-4585-b019-ce41a1ef5a52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed7ea38b-7a18-4626-877d-da8d7dd50456
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5137e4b-3fd9-4949-b7bc-50b093987aa3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1298c9e3-0968-4d45-a5b1-eb58941e44bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b047517b-638d-469c-9e2b-0bd9d240e5b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9dea4163-5160-4152-a5af-2b2669ab00c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77aebd7c-796d-463b-ad4c-6dfa31d6e6f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8453252-ce20-4d5d-ba29-d09517eed5e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b4d548c-9826-4405-bdd4-c399849a33e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0e645ed-4b69-42da-86f2-1763d1893c12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b84f09c4-1c47-42fc-b53c-a5ab87b94235
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b52fb833-2cb7-4fa1-945c-7febd6f9c5c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cb9aec3-4714-4790-9966-626bb45dd3b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74e3888d-9ee0-44aa-8bb3-ef10169c3148
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 367c1ac8-a5ca-4437-9b86-d7f1af2a5d75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6574c986-f86e-494c-8f5c-90980360869f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 572d1138-f664-4c7c-9188-981bc2aa3dc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da6494d3-8c5c-4b6c-83f7-948c4cb7f96e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59a7c247-4fb0-4a10-a5d3-6c62e7c6ba36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9692ebe-87db-4e22-8624-fd38e874d18c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0400fa8b-9c74-4844-8095-4d32e7ceca69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcff62fe-bd88-4cf2-bab1-d55fa26d6597
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec56009e-c858-45e0-8ee3-250a145d8802
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 406e54d3-0054-49e5-9288-5e674ae5f703
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96325853-17f6-491f-a2e8-9af95f4cc94b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f81b945-8cb2-4492-ab57-4f14f82e4477
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 525aec0e-a3de-466f-bf42-ad60cbde7aab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5e79588-b1af-47a0-ba39-8a50be32723d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4fd97b3-1135-4e90-93a0-133dd0c7b3e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ddfa2de-b668-4725-a423-790427ff70f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 700d7644-afb5-4960-a099-8c41c9a9db18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4edd5bec-5317-4e40-99e5-8340e4f31ac4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7409e809-48bd-4162-a532-dcb9f7b95ba2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eaff3f0d-8f71-4111-ac0b-7351af49f320
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17209ec0-a0e7-42ee-bea2-7a7c3dee3dd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f547014-6a0f-4ba2-a54f-0df6b2b89b68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9942cdfa-99e7-4dbd-b4ae-fa85d3c5fd18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afa12c04-5d86-4bac-939a-00f584527277
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8d7e918-c830-422a-a448-0e7d1c230463
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef726bc6-dbbe-48dc-a6d0-16bb799ad68e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1149178-e04e-4e9f-9cf4-9f713c45f7d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41d200f4-0046-4857-a1f0-046e964c1735
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 952fd452-cc10-46e2-9ade-ddc916e2ab0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b27dfbd8-7d43-45f7-b9b3-6a2a14d65f13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5635415b-f5fc-4713-a406-94393c0089d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de53786a-ebb2-40de-930e-df5179000eb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46f08f20-48e8-4cf2-9825-c86d1fbb2767
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84bd7474-71ae-4f41-8cc5-162582c14089
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75265670-c4e9-4b61-9081-126b9de0e8ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 857c7e48-c2fd-4619-aa5e-ba6e0e4ba108
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b9f144a-d89b-4c5b-bad1-2a45b6d91665
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24534c54-4e1f-4c82-8c91-612c7b98d610
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb08af5d-7f0d-4a56-a91a-d8ed05552cc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b996b28-edfa-43ca-a5e4-013baad04803
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbcfca12-195f-4c38-bbeb-ced2087c0908
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41045675-4a78-48e3-960d-50cd661f8781
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ba7e2e6-4ef2-49ca-ac02-c2260cd97f56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edbae4fd-f8ad-4da2-900d-9d5bbb0b0092
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af3a9721-c043-4033-9dab-e3fe834ae07e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88e778d2-375b-4b44-b204-4e9e59ffc67a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41d01cf0-adc4-49aa-ae0a-ae081fe9d5a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e833e594-d29d-4616-948e-1d661cbf5594
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b227f106-717b-46e2-b0c4-25fd69cadd08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c057a6da-506b-40dc-a4d2-8969ab51204b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d781995e-2a37-40a8-ad44-a367e84a7029
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03aa6570-5cd0-4ea3-b951-55779199c4a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 054233cb-2aaf-4eca-a26b-5f51694a165d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5aecb46d-1434-43fb-8446-5ca7f16fd03e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c2c1995-3e61-48f0-a932-e2fe2a009fa0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72cacb03-ea88-41f3-b230-9077832749c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd61279b-5b3d-43f2-b160-a4b6cfd7ac68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16bfab82-9556-4b93-8f7c-43ab1f5a3c66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fedc6190-bf67-40f6-af38-a6cea7702f33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bb3503f-f963-44f8-a105-de582692e9bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ea6db5c-ec4a-493b-9ad0-d993b448b343
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f381f026-db2d-4706-bfa1-4c8a3c275162
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a89c350f-bb6a-4b1d-8c38-5a9177df04d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8096bef0-bfa2-464b-8114-f52a1d3a703c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26a1cf7f-da76-4573-855e-1f7d41e057f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bb009de-69e3-4aca-81ec-78417ed791f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b64561f9-1c63-458e-aa42-e6bc80f01af9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28f0edd4-2aaa-4030-aabe-be74d543f873
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffc8bbbd-bc68-455c-931a-dbdeec7671ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d3556a6-ea4a-4b81-926b-52603a4d6757
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 321c4c0c-bdee-4d99-b5b4-4f2615b6d54d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10556f47-d44b-40b9-b19a-f232ad2c64b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad25be11-3616-4de3-a340-45a5177150e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 509b4fb6-ea51-460f-b7a3-7b99e9323030
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 577a3ba6-97de-4604-bded-22301b9b5dd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebd75555-19c6-4805-8b9c-f5d23f7e0bcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a888932-1fe8-4c41-a332-a71987c3d9c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef7d2a0c-f042-4026-a32d-0bf9e82b05e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 218e5dc1-66ee-41ce-b1e7-799d956827eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82001175-eaae-4d1a-ad01-7788e5f5651d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a942b4e-f19b-495b-b28c-cdf12fcb1f56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1250c43f-a3e3-4ec6-8de0-1bd5e75c2472
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88303b60-a640-4387-8310-a4423c5aeda7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4def61a-fc3f-4e2a-bf97-760cf08a1fe1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91197f22-bb77-48a7-8940-5df90eedb31c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b8dbc00-7b59-4074-b468-952d5c41d82f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10afc1f5-8d75-408b-9e0f-7faba08361c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e87647b-6be7-4532-a481-dacebc3d9fd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa364488-5787-4c8d-ad90-2f7b3fe5bd6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85321eae-e965-4c06-a653-1c90cf164aee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bee79f53-ce12-4430-bf1f-e471dad13a87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa4175f6-99c9-4a4f-b4c4-fe96eff92bd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99fcd1cc-04f8-4175-b8fe-773fad8e7ff1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6fd9b5d-2257-4a22-9dcc-0ff5bea9285d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85fff0ab-a0be-4b4a-8613-bf52ac616b37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19b478c6-4831-4d0a-99a2-96442ff3681e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a08ca33-6c3a-4261-a6ac-b05a4cad3707
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 161a3ee5-8e4a-48fe-a66c-b2610289c1b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdcd3814-26e6-4621-8e5e-1274b868c6ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b07e5a3-a6b9-45c7-a3fa-ce9025dc0ab9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0e1857d-4924-421e-b620-b212c5890744
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 101cb532-06ef-445b-9c0c-592c3450567b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 163594a2-c32a-4ae0-95dc-93bbf2d03f83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8af66535-7c8a-4072-9a92-28f21ec8b101
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8241e217-c264-4668-bf03-98ef4a76ce29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 386b7169-929d-4bbe-b87e-5aebddb46679
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 968b8520-1047-4743-b6d1-77323acad4ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a658e350-e82c-492f-bca3-d7f7c681399d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6192c21-348d-421a-b79d-cd94d1d5d944
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9166b27-26ca-40e3-a9c4-ee9bc3e415d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f69c4f0-57f2-44a2-9d89-4c6adb3c5c8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab3eb56e-07d1-4c56-8f7c-188529bcb3f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efdb1fa2-4273-4c34-bc8f-b9b4bbc9e366
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ef94863-f904-4704-ba4c-d0fdfe13671e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b58dcffb-ecf0-405b-8096-b94bf6091f55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89ae24af-aac2-43bf-add5-972b4d34d799
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 929c546e-823d-4561-9acc-c5c76d470db0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 700b105c-8ab8-424c-8b0c-a38fa1a5ce3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db95f0ef-a624-4274-92b7-4b18e4410cd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4f2ec53-75b4-413e-ac31-3e158de5ac35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e174ac85-c1ca-4370-8b40-ab366a12806c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5597de3-96cb-4ffa-997a-040a6f0acd7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fba08426-2fc1-441d-9d51-b44d2e612bf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24ddc6c1-35c7-494b-b5a3-bf41d085227d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af587359-793e-4b83-924e-f22070d12a19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a97f8eb-4bdc-438a-b0c6-b0a21825b5e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0257b207-f619-4de0-9e41-bfff8e535908
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05ee1ab4-c198-41d1-87dc-647cb61cad2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fe00820-91d6-4780-9cc5-b3f840b86da5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fca793a-abe9-43e7-a714-858f8ddb5b08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e30e8557-d735-48e1-a307-94c9844b5e86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 273fb175-ab87-4851-801b-cb448b74aa97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6525a33d-c9c9-4c45-b7b5-a4e9f4da7b8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b0c50ba-e029-4f9b-9ebc-d3dec044ce3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c54fb3d6-2f8d-4c70-9170-567c548312ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3c5945b-06d1-4c67-ad3a-894b9159b653
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c7ff689-ee27-4abd-b31a-3ef04ac22780
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c3c45c7-8f0c-4ff7-b9d6-f12e55997fcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 198b58a2-3f09-4bbb-9634-f34ecd220da4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d895ef73-b8d7-49ef-a372-4ab6c15c0395
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 158037cc-e578-4d41-9045-3f51b4b2a4bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff374058-8507-4a16-a69e-8fa642f46a17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca0e6b2c-929d-4397-8d15-6d1e3854a8fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da838e82-095c-4ee3-8d60-4c79464abab6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7b0a6ca-3446-407e-93bf-9ed98a24bf18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b929e691-ff03-4e34-8531-ace79037f62e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c7699bc-bbf8-4259-a3b6-74a02ca5c612
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcd24863-30cd-46e5-b4ab-2cf0a79067c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b1d4f17-6696-458a-861f-175809c43500
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c59479e4-5e35-4d9f-8176-28768eca75c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 188095d3-7086-4e27-9753-3f56ea47b972
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fae9119a-36f2-4155-ad3c-d89776b0850b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd870d66-742f-4816-922e-64ab47138c62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message baa5e645-3e22-4246-ab24-1f44808d0bfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eca33e10-21b8-4c78-8af0-efa4e9ad9de0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfbfbfa7-7841-4a04-9a19-1b0e301d0b93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2dca0f5d-2e4b-4330-8622-c911aa9a8d35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c60600ce-5c6c-4d85-914f-40e53ebbfdd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34f6f01e-e315-42e4-8c5b-8d6ee644809e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02a7705b-5984-4c41-ac63-6789ae522efb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c57e45e-d3ba-4a67-8593-fad4a65f71fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1463325-8d6c-46f2-a05e-1447b9bbae89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87064243-040e-4825-8e7c-210125ebe9ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edb256a3-0ca8-4b2a-9c9d-cbd2deb2cebf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68ed27a8-b538-4473-98c5-4ec41bca4c0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3077a66-45b6-42f3-a71c-671b94360cbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ee97c47-fca4-4815-88cb-e8e5659acef2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7958dd94-f573-4c2e-93a7-c44fae4ed9d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ccd0663-4f09-4820-8c9f-0e56676a4b6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 423e713f-a878-4389-aec0-fb2a8c04b981
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2e43020-5cd1-467e-8277-ef06042a217f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6283de9a-28ca-421a-bd10-9b302936b0db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb9fc28b-3d89-4c89-b2af-3a693a899651
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8665f9dd-db51-428f-b286-a750d63f4cae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4cf9069-1ba7-49d2-82b7-1a57cb1932dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d137604-e76b-4fdc-8eec-89944cea8561
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9380c9d-4389-4564-91b6-7d1fb163d8de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message faebf7ca-caff-4f71-9b88-3eec1a31c251
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cca12f5-bae6-4778-b5cf-eb4bc2c5c082
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b70e08f-6a6f-4116-b20e-1ea205220b56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87dce163-21c5-4a5f-a1c8-2924030817ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f03a25b2-2fdf-4df6-a5e3-6d09e1d8fdfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b48ea2ca-c1ce-453d-819a-7c6dd7d74ea5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 699c026a-187c-4c0c-b1f6-c2154308f590
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b580709c-7a55-456d-bf41-5e26bfaf7652
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8dba9d18-046d-4ee5-8030-03e0e8ca119b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c52961d-04b0-42b5-815a-99edde0aa124
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce6b573c-4bcb-42ab-8132-2c61085e90bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63adaa37-ca07-41c5-865a-2b85bb908044
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14c2f70d-0083-4f8a-8a9a-1eac76b1f5bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9816523c-4c54-429e-a0f5-453b6e0cdef5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c8d74e6-98ae-438b-a772-59c26cf2f61e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13cd5106-af44-45d1-8015-d2fccdf4c59e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 025daec9-81c6-48cb-a6db-5eb37a99446d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06ced372-f254-4ead-b4a6-ade673bb4626
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bd966de-951e-41af-99ab-dda28c753a53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c74a97ab-b1a7-4716-84f6-8a2f23f5f2ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd59bb99-3686-4f06-afeb-7d7cb82f015e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0d9b47a-fc17-4a3c-80bf-0c47ab3cadba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d28363b-8b31-42e6-9bfb-850e16760494
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 191dfa6b-57d1-4fa8-a248-80b4d89c549c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b09dcbcf-2756-400c-a0d2-1c26cb2c2e36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fc44d55-9ac4-4758-9100-42daa5149aa4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2679fc1-767f-4e87-8e36-b2c8bc144106
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14af7023-2ffb-40fd-a0cd-3182f4ea0fb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 027b1160-0f21-4341-81c6-95ac03bb3d2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ce7fe9f-b121-4779-a91c-a4f0b3a6d7af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2b654fa-b86f-40e7-8e3c-e64d910847db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a63b4d9e-173d-4c9d-8ab7-29b6a4264276
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19714f6c-b954-449a-b9c5-58f3788ae2c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18833321-afc3-42e6-87ce-db3f08604aa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1aafe6c-708f-4ee4-b7a8-0c8ad077617f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76356404-b95b-4067-8b52-5b6d8282749c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd534c05-ad93-4959-8f9f-728d9a138305
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aefd5c4f-7383-4d22-af74-d11b2d2b7fae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c52be31-6525-497f-b63e-8f866725f68c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89ff26d6-a618-4a1c-b14c-276d966db3ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62f1f947-c086-4e63-a58d-9604cf4f8a41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b323178c-b583-4647-9679-4770630a260e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fab91d4f-795e-495a-8157-f58d70dbe040
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bca17357-b0b6-423b-b07c-4e42af2db457
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95628675-5fc7-446c-ba44-7bc9b4845371
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24988616-dce9-4048-b939-1c0fa5e0333a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db946231-a891-40b1-8797-626aa8bbf2c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 755be7ed-ab9e-47e7-b1ef-cb22fc06f0f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89554a32-0476-4deb-a0fa-a4f67bece70e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a9ba2a6-55f6-44bd-879b-6c8482284472
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bb70827-b8f9-4280-8325-a0e769a0da13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b338ebc-0a7d-4d91-bc35-4e92357767b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 032b11ec-2b2f-4681-979d-4f4dbbb08d8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f519c24-0b67-46f8-a35e-d92c89d3be6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b083b30c-abdd-49cb-bf55-f62096f9c59d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da553c4a-4c1c-4a43-aad0-3ee740faa197
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05eef21d-c32f-42ee-b714-61fcebe821fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99c2613a-5a18-43f0-af2c-e76fdec89c63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32c4b7be-edba-4cbf-a7d8-138068486899
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 517de43a-a7cd-4b71-bd76-41187c4486ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ae3d274-7474-486f-9d9e-47524b0f100c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 543b4782-c2e5-4bb9-9694-d81e0502eaa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d1884ac-94df-4d60-a463-6de50cfbeff6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e469f480-aa34-4991-a6d7-ada41fcef25a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fad79996-b2dc-4bbc-9ccc-52cdddf6d0ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8f0fae6-0681-4511-8268-7a74648fc3bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58f89bf0-4106-41cf-979f-f2f6fe9e31a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc4568f9-cc69-4053-acd2-1d0336733580
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ad06744-0c3c-4fab-a167-d902afb64856
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 088c1301-1cfe-44f8-b09b-84ae6edbd290
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fec45ac-c0fe-4178-8e17-8b1d3f957e25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ebc5546-81a6-45d5-9a18-0a7522b66a57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e22c3e1-d854-4e29-af49-7e756598652a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54ef5b01-bccf-44d8-b744-c1c8abdae845
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 003d49a5-6647-4f03-8fba-611d369a7b68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4affe75b-6f2d-49f3-b548-2f2d72631aae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85665a78-a68c-4afa-909e-e6d3f624f92b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 458abf19-c263-461d-b661-d51f4c24de14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93511651-18e9-4102-a2c8-9be51b3567f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c969ba4-3389-4df2-ac14-fad9acd8dca1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 019962cf-0f79-470f-8cc6-9ebc46d6a456
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a049519-7937-432d-a22e-785415ddf519
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 186d4d94-e546-4839-b5a8-41e0f4631a98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53ce4fed-860a-472d-a32d-468bd522d79a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd863a60-e5d4-4562-a8f8-e212c7a8084b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72b94e3b-5edd-470b-843a-509d7f5b4a49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2a50fb1-cbfa-4c86-8a21-1a27e25e945a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25536c14-2e5c-40d3-8a70-1c4d996c54b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8753de5-f933-4d76-a76e-834165af5b3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f69dadbb-1b15-42a7-ad51-6900bcc6c49d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4b59daf-6570-43f8-b688-401563b272ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d59c8414-5e5c-4f0c-9104-bb82014991de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8932a8cb-f15f-4ace-8d66-b98858684c70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afa9b811-53da-4de7-bc76-c7f67be01eab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 583ff470-c220-496e-8277-e5f81b676fc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c33cd8a-97f2-4ab5-8a08-ee4486b33547
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0dfe013f-3eb2-4b75-a1f9-3bf3fcb937d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf16f64e-8edb-471a-aac9-a91a18d65ce5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48f8c2a5-0ea0-49f3-b12f-7ffe65c1453e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80507fbf-f629-4ab9-8a6c-31ec6ad6af45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ccf84912-c1af-49ca-a3da-cbc529eabea1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 242d96b6-6fa0-463e-889e-93e8e1d36453
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db89ce47-2098-495a-abe6-9c5db7c38a67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d60a76c-bc99-4c18-ac69-b5564b4dbac3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f794c2a2-fdca-4431-8b7c-0418d3bd40de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa76f361-7ca3-414f-8d88-be1652ae8977
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7feba876-0c21-490d-84b6-d5f8625c0384
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb20c6dc-d295-4730-b8f5-80d43ffea8a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7edefceb-80fb-42d8-86a0-c934957302d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b99e956a-19b4-4a02-ba48-5c558b4e3d08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f29280a8-8923-4883-b199-c7dd9ad313a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bb3bea1-5baf-4b19-8da5-173924c17759
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95540c70-a1c6-4daa-9c20-cf771578af68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f15541b7-1db4-40a9-8759-5234c17cd7ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd1fc192-26bb-48f1-9924-19d7b7d6967b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01e7425f-8831-47c1-9f59-5895026fbaf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc562838-fbea-4de2-9961-452a9fefecfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75161113-6ef9-46c9-8e46-168a9f1d5935
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 797292a5-c6d9-4534-ab86-a0a2a1483142
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0aba56f7-54ee-4169-bf32-674b22b7c0c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9a453fe-9817-46b4-a77c-4d8258d4aebb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a285d240-ee72-40cf-802c-cd3ee01bbafa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba8e7c7b-d201-4f7d-8de8-9c166e282a13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bd199ae-eca7-4f4f-8aff-635078f7be55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f91ccf71-e211-4849-90ed-07c728b52287
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bae9a9b0-6436-4e3c-8be8-86bdcafa82a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9859775-59a9-45c5-87f9-ab37aa674f88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b96bcbe8-fc3b-49cb-9620-c46c53b4f14c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c934433-f1ff-40f1-ab31-b4d84e43eb9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f8162cc-8d59-4dad-a19c-e15f47ac5dbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6736ad8f-861a-4acf-9fbb-8bb5baa334ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ecd536f-0acc-4b7a-a19e-96a038b159a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 794672e7-b292-431f-80f7-50d9d0e20755
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 730110f8-3693-4c3e-8e69-272a8e8cfbdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 972d0774-bf8d-471c-ab8a-9d980fffcb8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a0920f4-a9c6-4eb5-874b-14ba332c4c45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7ff2cd9-f3a3-4cb7-bd95-ab0e9b902a37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 086cdfde-126c-49fb-8729-346c1177a817
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8cfaed6-0010-4b10-b35e-5a9d06329cbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81b6f978-8b1d-4c59-ac23-ca2bfd66a368
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e984dbc5-f340-4bf6-badc-f41b005523c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 140b02bd-9d47-422f-8fb9-b3ae39c007ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44c4848d-42b0-4253-814a-8166930d79b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message babc5f93-b8e1-4008-92ba-12957a9e71b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da7a15ca-374b-4fe5-9811-7bccdb8614bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc5546f2-f0d8-4563-bde5-33f5cd4b0429
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64614b61-783f-4660-a607-42dde34686c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e42e0a22-7e16-41e8-8f02-5bab3bd828c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 758a107b-dee2-4142-ab5e-74aa05424080
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4984db1b-41cc-43fa-b0d6-84d4d8ad07d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db748506-1e24-4592-8c1e-44b65ada50f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54ee0c45-0dc8-441d-a150-bdf4c9327569
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5611373e-6a26-4c38-a41a-1a860a8c83f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87489b1c-d0af-4dfc-b757-3bb972b2c51f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 536e58a8-68d6-42bb-bf8f-f5cb4451147e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf0454af-2020-4b33-8089-19bca0293b18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f788e35c-be1a-46cf-9037-aecc34a89b92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69b54724-7bea-4a96-8487-28bb848e91c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f976b5bf-5ce7-4870-84c5-26e93419fe52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d00da9bb-59d2-49e2-b564-ae001a660d7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 225cb8bc-59fd-439b-9e3c-72e2749008d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c21dec8-bfb7-4af5-a0ca-7f3d252ddde0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 996217d9-5cdd-4cc5-a775-50dce1ca621c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b56a946-6e18-48ea-9062-2f9dd9865f18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85a6d6f2-beec-4db7-b852-6660e4173694
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a13d6a78-6e7b-401c-94b2-f33b74f04db6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3cb3875-f48c-4d78-984d-3e9b86e75bd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d671d09-533b-4e1e-b82b-c162a698ba86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5efb4cf-0408-4076-b67c-eedb40418884
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4289884e-168d-4f88-81d7-5c28aeff1a12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef28f0a9-6d44-41e8-89a5-9ce88db1f8dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64020adf-fac7-473f-85e9-ca11a45709c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9067291a-0b01-4c88-87aa-e6f6709ddb2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 370ae906-047c-4054-b2e4-058694d57835
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 606154ee-f117-47cd-9aee-a859bbf31cda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bdb4408f-1c5c-468f-9798-4b686ded7075
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aba95d37-5b9c-4b36-a578-528ce692dccb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75e86e73-3429-4e6e-bc8a-8c4832dd2c4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10bf8ece-109a-4097-b1cd-7b55dcd4402f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37b3e460-5079-45e1-a609-12d05a3cbcf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38e3f018-0321-474b-b1b1-5c4bc5ad5ec3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e616eb7-0d65-4d95-9187-83da723347a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 718d7e9b-b609-4762-a2ed-c42b4cfe3211
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 929eaafd-f82c-459d-a4e0-26d6f6664a42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd1bdfe3-b3d9-4817-8979-4b36e20d0ef4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae168f4f-b7b2-47eb-a977-f32aeba59cdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84c17f85-2b38-485d-a53f-1e2c11c78ee4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 609f8fac-0d12-41c3-ae65-e73cf1c48411
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9881c0b2-b03d-4ff3-a22a-3c936c65dea5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84cd8fd4-27ad-41ad-a885-13079faa73e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f2f60e8-49bd-42b6-9270-915c16a8448e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ee74792-c972-4d7f-b602-b48641d53d6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f582538-696d-4505-a46e-045784941293
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb5f1efd-f63e-432b-985f-bcf05460efbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8dd26266-de52-4324-a867-69ea3da16fb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbe4b7c8-6d42-4086-9583-b76c6f5a42a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 053ce900-2dd4-419f-b395-53cd3b49def1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f86eec5e-0d59-4671-9490-1651934b9a84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c85e1020-0bb5-4891-929c-323e7a172a92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3e98926-a641-43a9-8d40-584adbb0d73a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be1cb601-dacc-449a-a77c-09ba6b49d759
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8d3202c-60c0-446d-94c1-38c9c5ee0e62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef16d1a8-adee-42b8-bcf2-9b84962dac66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80988988-6068-4e2c-8433-badf005091ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 139e957a-d02c-49b5-a4b3-a8fe89ba44b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3df2d1c1-4f99-41aa-8801-49d0ec88716c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2a3907a-54af-442c-a948-bd728d7ee04b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c57b9d87-243c-4769-9664-98570d9a7135
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6aff2c69-ee8f-4109-8509-b4d7d00d0467
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60ac167a-6893-4205-8d06-2c8e82e22d34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba3bb7bb-362c-4600-815b-10a151372db7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4d8a236-7769-442a-847f-626c32b4c8bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d31d26a-6edc-4f18-b708-cf2f3c88b57a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67078535-23ce-4b33-94af-91a65f4a7b2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad8102b6-664b-4944-bf62-576de5357e53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fe38a18-8045-4391-82ff-c754f6e13936
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b308adf-6fb6-4c79-a0e3-145273690b1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a48e8532-911b-4dc2-94a7-b7cf883512ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8096f80b-3fa9-4488-9ffb-22b39a3a18fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message deceb53b-8d97-4b63-a34f-6c9543a16b82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b004139-885d-4cb6-8f69-bf9b7bd20aee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c84f47ae-c3f2-422a-95ac-3d56d06961f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94d09763-b2f4-4913-b8fc-de290d0776a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c350eb9-6487-44e8-90c5-90216dca28a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 591c3724-51bb-4229-9a1e-685e761a7b23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7501c82d-0acd-4318-84fa-f3d97fb2150a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7bcff51d-7c60-4108-88f0-47b9f1e096ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce1022a2-68fe-480d-b510-e5cea614438c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec0ce3d0-23eb-4302-9422-7c6dcb4b8897
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76652b99-6c24-45ab-a34b-671d34c470df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc154b9e-0d0e-4036-905f-6c829ca7eb87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7d7771f-cc5b-4bea-9c18-a56e80227640
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56d1dc50-07f4-4665-b8b2-67952995a8d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c671180-af2c-4fba-8b4c-ea6abf48ac85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a288ef29-59f2-46f5-8db3-4d5c6725fec3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9da734ab-8e03-423a-9703-6ad2645203b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58dc9818-d7bf-48ea-9ff8-50f043254a73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ca528c1-30ec-41dc-aad1-7e75b5da7887
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eac8e91e-5282-44c6-b8db-eb84c767f933
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27a814ce-d6be-40d1-8b11-cc5b4260ec66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8cae0d7-6fb7-4357-90c1-dcc0920a0ec9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 938c463c-5111-4aa9-a57c-9476a23040ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 625f727a-2c0d-4049-8678-a5b3d12391ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68b7bc2c-5d41-4da4-bfd1-bf51e8641b09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbb4f87b-464b-47aa-9491-1bce0bf83aa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15ceebd6-6b34-493a-82fe-69823fafc91b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1745ff34-18c5-4547-9374-ab0fd9688d19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d635e6fd-e794-47ce-9eaa-863d21909052
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c73ef21a-c7c3-4f73-9334-e22c954a98b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 564410d2-4fd8-45e4-afbb-60b4e6ca8aa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26e1512a-06b2-4120-bb44-f04a4c82c1eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56668c46-51cc-49ca-bb4a-efe4eae98e35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 257aaea0-6fc6-41a5-af67-9546266935ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89872a36-43dc-4cb4-9ce6-0474a712eade
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69df6274-df4e-4520-aa0b-33b9240df17d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e7640c2-b4db-4303-bd05-c765ea2d8c9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39bb14f0-82b5-48cc-a9c0-489f2a19f37b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de47ce69-4240-4940-867f-d6adce7c7896
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ded2f05c-fbc5-4db1-99ef-1c589e1e7df9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a9602c6-7214-4cd8-8a50-b14fd5b15ce7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07fbaed9-8577-45eb-a537-2e3d0f6b99f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 636fc378-0e32-40f9-8c52-5c5c14b6fbc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6699a8d-38cd-476b-b57b-2033d2f23bb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 056034a4-53f6-42bc-a186-a0eae78c546e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fab8aa7-178d-4eb9-b7f2-d7314aa39b7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8299e31-07b1-4379-b5ef-065cf47d5303
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a735ac4-faae-44bd-99b5-8cf2a4f53e8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7a4df72-191e-4cb2-825a-56dd1f69e027
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6c2577d-bdc9-416e-bb73-2c32bb9ffaca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be16ac2e-2d17-4dfe-8168-005c8bfb00b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5acce270-0955-4059-b79d-892232c2055c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb443edb-cbab-45f3-9a57-3e7655c81efa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7df63683-15fd-46ac-bb31-5cdadc72bb23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14e44d25-8c5a-4009-b1a4-be67807f6228
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc0ea0b5-b96a-4a00-a2d2-dbc8465782ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9a7b2ea-e9dd-4234-a5b9-bbcd1065185d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 231e1407-9c9d-4e89-9591-58e2d6890d67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b7e23e1-e8cb-4bf8-977b-9bc36b5693f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4ba214a-5690-4b1b-9829-0318b9139935
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6663d06-6cb0-46cd-bc91-09eb85bdadb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7f84506-43b6-4636-a892-1025f27f5c50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f94830c-365a-401d-8627-c7376db7f3db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfebe9ea-8a3a-45d2-8160-815dbb701b94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d15f8ab2-2209-4656-8089-2d419aa2dcc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a471b3b7-df69-41c5-88f0-885cf4c63afd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b8a19e3-519a-41a6-b917-1258f7e5c7ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fca9d01-8638-4540-89b7-6481f2d87241
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5c5db2b-db6f-4ea4-b153-b6e979290a6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce3ebe90-0f28-4fd5-bed3-8e02ce7e3709
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb5f1099-17a0-4d58-846a-352fe2057473
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2cefc6c5-a19c-4559-b203-c4d1c306f369
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c062f46f-3fff-4f4b-95ae-a894a2a4908a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b567003-adf1-4020-ae0c-8a16bae2681c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 353faa3f-c4fc-4f49-a528-155209dee558
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c90856f8-8b1a-4d04-8838-9308bd1d8b18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7659e51d-2569-4c30-a982-c283ec786059
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e489302-d92c-4fc5-8119-42794f1331fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77874baf-790e-4d77-986f-f60382e29809
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98b76437-fa5d-4fa5-b746-f930d1fdc17c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1a54a4e-b300-4b32-8fd9-819815ac1a25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b83bb615-da83-4c42-a5ee-be3c56058d1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fba3418-35c2-4ca6-a536-8d5aaa7ebc5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b93c2ed5-048b-4c71-80a0-ebffa7733f3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd84d5c3-d34a-45c6-a585-2ad7f7dd76fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7885e6c1-e3cb-4431-919e-9356344823d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61dc7586-830d-41ab-af89-8eee28fa22e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6f6ecec-8e67-4815-a9ae-a050260fe538
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df6a5ad6-ad64-4ffb-aa8f-078a07999f09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0448bcc1-2393-47ee-bd7c-2d49dc75a465
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f00e4e4-9dfd-4b2d-bc7f-05ff53bd6c21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17240ad5-6c15-4e41-a6b3-6747e1b00ded
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 081aeabe-643e-41fe-b605-21c234d82b89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c0c6541-d758-49a3-ad81-f6352b601b1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba7886e7-6fb9-4b35-98e8-1a3597229a30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3694f8c5-d8d7-4e86-9d31-8b593deaa8bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ddeceac-eefb-491c-8b93-6d451fa8aa4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f18132ce-64ff-499b-994b-d86a2311f2a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 406083c9-9905-4fd3-b567-75858d3ace56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ead5b65-0781-4e17-9c2e-df631b4c4a2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3699d89b-a1c9-4501-a54a-ec4da9e05339
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ed27444-f077-47e4-bd91-77241d827104
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04fba368-2700-47be-8d74-8bbb8c87fe49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7120fd54-e74c-42c7-b282-1361b14332e2
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_2
Server: localhost:8686
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_2
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_2/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_2/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_2/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_2/test_labels.txt

📊 Raw data loaded:
   Train: X=(5055, 24), y=(5055,)
   Test:  X=(1264, 24), y=(1264,)

⚠️  Limiting training data: 5055 → 800 samples
⚠️  Limiting test data: 1264 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_2 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2511, R²: -0.0034

📊 Round 0 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2512, R²: -0.0041

📊 Round 0 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2509, R²: -0.0027

📊 Round 0 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2510, R²: -0.0026

============================================================
🔄 Round 6 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0800 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0814, val=0.0780 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0803, val=0.0774 (↓), lr=0.001000
   • Epoch   4/100: train=0.0797, val=0.0771, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0795, val=0.0770, patience=2/15, lr=0.001000
   ✓ Epoch  11/100: train=0.0783, val=0.0762 (↓), lr=0.001000
   📉 Epoch 21: LR reduced 0.001000 → 0.000500
   • Epoch  21/100: train=0.0748, val=0.0767, patience=10/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 6 Summary - Client client_2
   Epochs: 26/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0343
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0349
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2512, R²: -0.0041

============================================================
🔄 Round 7 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0830 (↓), lr=0.000500
   ✓ Epoch   2/100: train=0.0829, val=0.0799 (↓), lr=0.000500
   📉 Epoch 3: LR reduced 0.000500 → 0.000250
   • Epoch   3/100: train=0.0801, val=0.0799, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0796, val=0.0794, patience=2/15, lr=0.000250
   ✓ Epoch   5/100: train=0.0789, val=0.0793 (↓), lr=0.000250
   📉 Epoch 11: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0784, val=0.0794, patience=6/15, lr=0.000125
   📉 Epoch 19: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 7 Summary - Client client_2
   Epochs: 20/100 (early stopped)
   LR: 0.000500 → 0.000063 (3 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0196
   Val:   Loss=0.0793, RMSE=0.2817, R²=-0.0001
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0032

============================================================
🔄 Round 10 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0695 (↓), lr=0.000063
   • Epoch   2/100: train=0.0821, val=0.0695, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0819, val=0.0696, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0817, val=0.0696, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0816, val=0.0697, patience=4/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0811, val=0.0700, patience=10/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0695)

============================================================
📊 Round 10 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0028
   Val:   Loss=0.0695, RMSE=0.2636, R²=-0.0004
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2513, R²: -0.0036

============================================================
🔄 Round 13 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0786 (↓), lr=0.000016
   • Epoch   2/100: train=0.0806, val=0.0784, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0803, val=0.0784, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0802, val=0.0783, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0801, val=0.0783, patience=4/15, lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0798, val=0.0783, patience=10/15, lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 13 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0063
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0023
============================================================


============================================================
🔄 Round 14 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0910 (↓), lr=0.000004
   • Epoch   2/100: train=0.0777, val=0.0909, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0776, val=0.0908, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0776, val=0.0907, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0775, val=0.0906, patience=4/15, lr=0.000004
   📉 Epoch 7: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0774, val=0.0903, patience=4/15, lr=0.000002
   📉 Epoch 15: LR reduced 0.000002 → 0.000001
   • Epoch  21/100: train=0.0773, val=0.0901, patience=14/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 14 Summary - Client client_2
   Epochs: 22/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0775, RMSE=0.2785, R²=-0.0010
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0126
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 20 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 20 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0029
   Val:   Loss=0.0856, RMSE=0.2927, R²=-0.0445
============================================================


============================================================
🔄 Round 22 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 22 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0057
   Val:   Loss=0.0840, RMSE=0.2897, R²=-0.0126
============================================================


============================================================
🔄 Round 23 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 23 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0097
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0012
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0032

📊 Round 23 Test Metrics:
   Loss: 0.0842, RMSE: 0.2903, MAE: 0.2513, R²: -0.0032

============================================================
🔄 Round 26 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 26 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=-0.0103
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0027
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0842, RMSE: 0.2903, MAE: 0.2513, R²: -0.0032

============================================================
🔄 Round 28 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 28 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0115
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0018
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0842, RMSE: 0.2903, MAE: 0.2513, R²: -0.0032

============================================================
🔄 Round 29 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 29 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0023
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0283
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0842, RMSE: 0.2903, MAE: 0.2513, R²: -0.0032

============================================================
🔄 Round 31 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 31 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0046
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0163
============================================================


============================================================
🔄 Round 32 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 32 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0097
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0033
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0842, RMSE: 0.2903, MAE: 0.2513, R²: -0.0032

============================================================
🔄 Round 35 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 35 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0021
   Val:   Loss=0.0722, RMSE=0.2686, R²=-0.0469
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0842, RMSE: 0.2903, MAE: 0.2513, R²: -0.0032

============================================================
🔄 Round 36 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 36 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=-0.0151
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0046
============================================================


============================================================
🔄 Round 37 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 37 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0085
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0019
============================================================


============================================================
🔄 Round 39 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0700 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0701, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0701, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0701, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0701, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0702, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0700)

============================================================
📊 Round 39 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0116
   Val:   Loss=0.0700, RMSE=0.2646, R²=-0.0121
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0842, RMSE: 0.2903, MAE: 0.2513, R²: -0.0032

============================================================
🔄 Round 41 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 41 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0115
   Val:   Loss=0.0756, RMSE=0.2749, R²=0.0030
============================================================


============================================================
🔄 Round 42 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 42 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0054
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0162
============================================================


============================================================
🔄 Round 43 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 43 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0018
   Val:   Loss=0.0733, RMSE=0.2707, R²=-0.0398
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0842, RMSE: 0.2903, MAE: 0.2513, R²: -0.0032

============================================================
🔄 Round 46 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 46 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0061
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0110
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0842, RMSE: 0.2903, MAE: 0.2513, R²: -0.0032

📊 Round 46 Test Metrics:
   Loss: 0.0842, RMSE: 0.2903, MAE: 0.2513, R²: -0.0032

============================================================
🔄 Round 51 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 51 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0080
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0021
============================================================


============================================================
🔄 Round 52 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 52 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0139
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0007
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0842, RMSE: 0.2903, MAE: 0.2513, R²: -0.0032

📊 Round 52 Test Metrics:
   Loss: 0.0842, RMSE: 0.2903, MAE: 0.2513, R²: -0.0032

📊 Round 52 Test Metrics:
   Loss: 0.0842, RMSE: 0.2903, MAE: 0.2513, R²: -0.0032

📊 Round 52 Test Metrics:
   Loss: 0.0842, RMSE: 0.2903, MAE: 0.2513, R²: -0.0032

📊 Round 52 Test Metrics:
   Loss: 0.0842, RMSE: 0.2903, MAE: 0.2513, R²: -0.0032

============================================================
🔄 Round 58 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 58 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0051
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0132
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0842, RMSE: 0.2903, MAE: 0.2513, R²: -0.0032

============================================================
🔄 Round 59 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 59 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0100
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0006
============================================================


============================================================
🔄 Round 60 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 60 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0086
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0028
============================================================


============================================================
🔄 Round 62 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 62 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2806, R²=-0.0010
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0390
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0842, RMSE: 0.2903, MAE: 0.2513, R²: -0.0032

============================================================
🔄 Round 65 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 65 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0057
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0118
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0842, RMSE: 0.2903, MAE: 0.2513, R²: -0.0032

============================================================
🔄 Round 66 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 66 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=-0.0054
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0142
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0842, RMSE: 0.2903, MAE: 0.2513, R²: -0.0032

📊 Round 66 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2513, R²: -0.0033

============================================================
🔄 Round 69 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 69 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0019
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0469
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2513, R²: -0.0033

📊 Round 69 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2513, R²: -0.0033

============================================================
🔄 Round 74 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 74 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0145
   Val:   Loss=0.0818, RMSE=0.2859, R²=0.0108
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2513, R²: -0.0033

============================================================
🔄 Round 76 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 76 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0036
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0299
============================================================


============================================================
🔄 Round 77 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 77 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=-0.0056
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0111
============================================================


============================================================
🔄 Round 78 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 78 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0025
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0300
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0842, RMSE: 0.2903, MAE: 0.2513, R²: -0.0032

📊 Round 78 Test Metrics:
   Loss: 0.0842, RMSE: 0.2903, MAE: 0.2513, R²: -0.0032

📊 Round 78 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2513, R²: -0.0033

============================================================
🔄 Round 83 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 83 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0070
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0047
============================================================


============================================================
🔄 Round 84 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 84 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0087
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0145
============================================================


============================================================
🔄 Round 85 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 85 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0045
   Val:   Loss=0.0819, RMSE=0.2861, R²=-0.0193
============================================================


============================================================
🔄 Round 86 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 86 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0056
   Val:   Loss=0.0823, RMSE=0.2870, R²=-0.0134
============================================================


============================================================
🔄 Round 87 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 87 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=-0.0169
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0026
============================================================


============================================================
🔄 Round 88 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 88 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=-0.0043
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0146
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2513, R²: -0.0033

📊 Round 88 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2513, R²: -0.0033

============================================================
🔄 Round 90 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 90 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0025
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0431
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2513, R²: -0.0033

============================================================
🔄 Round 91 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 91 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0042
   Val:   Loss=0.0741, RMSE=0.2722, R²=-0.0232
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2513, R²: -0.0033

📊 Round 91 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2513, R²: -0.0033

============================================================
🔄 Round 94 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 94 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0027
   Val:   Loss=0.0758, RMSE=0.2754, R²=-0.0303
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2513, R²: -0.0033

============================================================
🔄 Round 96 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 96 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0016
   Val:   Loss=0.0747, RMSE=0.2732, R²=-0.0594
============================================================


============================================================
🔄 Round 97 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 97 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0056
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0106
============================================================


============================================================
🔄 Round 100 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 100 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0047
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0151
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2513, R²: -0.0033

============================================================
🔄 Round 103 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 103 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=-0.0037
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0227
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2513, R²: -0.0033

📊 Round 103 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2513, R²: -0.0033

📊 Round 103 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2513, R²: -0.0033

============================================================
🔄 Round 111 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 111 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0079
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0011
============================================================


============================================================
🔄 Round 112 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 112 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=-0.0054
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0129
============================================================


============================================================
🔄 Round 114 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 114 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0064
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0078
============================================================


============================================================
🔄 Round 115 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 115 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=-0.0088
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0026
============================================================


============================================================
🔄 Round 116 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 116 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0104
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0049
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2513, R²: -0.0033

============================================================
🔄 Round 117 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0695 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0695, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0694, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0694, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0694, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0692, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0695)

============================================================
📊 Round 117 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0049
   Val:   Loss=0.0695, RMSE=0.2636, R²=-0.0206
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2513, R²: -0.0033

📊 Round 117 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2513, R²: -0.0033

============================================================
🔄 Round 119 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 119 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0115
   Val:   Loss=0.0743, RMSE=0.2726, R²=0.0035
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2513, R²: -0.0033

============================================================
🔄 Round 120 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 120 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0035
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0321
============================================================


============================================================
🔄 Round 121 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 121 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=-0.0047
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0191
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2513, R²: -0.0033

📊 Round 121 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2513, R²: -0.0033

📊 Round 121 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2513, R²: -0.0033

============================================================
🔄 Round 127 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 127 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0074
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0030
============================================================


============================================================
🔄 Round 128 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 128 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0092
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0043
============================================================


============================================================
🔄 Round 130 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 130 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=-0.0028
   Val:   Loss=0.0792, RMSE=0.2813, R²=-0.0247
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2513, R²: -0.0033

============================================================
🔄 Round 132 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 132 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0040
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0179
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2513, R²: -0.0033

📊 Round 132 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2513, R²: -0.0033

============================================================
🔄 Round 135 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 135 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0059
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0092
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2513, R²: -0.0033

============================================================
🔄 Round 136 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 136 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0098
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0031
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2513, R²: -0.0033

============================================================
🔄 Round 138 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 138 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0119
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0007
============================================================


============================================================
🔄 Round 139 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 139 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0044
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0190
============================================================


============================================================
🔄 Round 141 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 141 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0075
   Val:   Loss=0.0717, RMSE=0.2677, R²=-0.0043
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2513, R²: -0.0033

📊 Round 141 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2513, R²: -0.0033

📊 Round 141 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2513, R²: -0.0033

📊 Round 141 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2513, R²: -0.0033

============================================================
🔄 Round 146 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 146 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0022
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0362
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2513, R²: -0.0033

============================================================
🔄 Round 148 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 148 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0062
   Val:   Loss=0.0721, RMSE=0.2685, R²=-0.0090
============================================================


============================================================
🔄 Round 149 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 149 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=-0.0099
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0062
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2513, R²: -0.0033

============================================================
🔄 Round 151 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 151 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0082
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0040
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2513, R²: -0.0033

============================================================
🔄 Round 153 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 153 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0023
   Val:   Loss=0.0750, RMSE=0.2739, R²=-0.0503
============================================================


============================================================
🔄 Round 155 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 155 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0056
   Val:   Loss=0.0759, RMSE=0.2754, R²=-0.0114
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2513, R²: -0.0033

📊 Round 155 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2513, R²: -0.0033

============================================================
🔄 Round 157 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 157 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=-0.0155
   Val:   Loss=0.0873, RMSE=0.2954, R²=0.0021
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2513, R²: -0.0033

============================================================
🔄 Round 160 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 160 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0077
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0037
============================================================


============================================================
🔄 Round 161 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 161 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0029
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0339
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2513, R²: -0.0033

============================================================
🔄 Round 162 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 162 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0126
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0023
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2513, R²: -0.0033

============================================================
🔄 Round 164 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 164 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0080
   Val:   Loss=0.0768, RMSE=0.2772, R²=-0.0002
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2513, R²: -0.0033

📊 Round 164 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2513, R²: -0.0033

📊 Round 164 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2513, R²: -0.0033

📊 Round 164 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2513, R²: -0.0033

============================================================
🔄 Round 168 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 168 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0056
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0110
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2513, R²: -0.0033

============================================================
🔄 Round 170 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 170 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0039
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0185
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0842, RMSE: 0.2903, MAE: 0.2513, R²: -0.0032

============================================================
🔄 Round 172 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 172 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0088
   Val:   Loss=0.0730, RMSE=0.2702, R²=0.0018
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2513, R²: -0.0033

============================================================
🔄 Round 173 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 173 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=-0.0003
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0573
============================================================


============================================================
🔄 Round 174 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 174 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0044
   Val:   Loss=0.0748, RMSE=0.2735, R²=-0.0168
============================================================


============================================================
🔄 Round 175 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 175 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=-0.0082
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0026
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2513, R²: -0.0033

📊 Round 175 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2513, R²: -0.0033

============================================================
🔄 Round 177 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 177 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0132
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0049
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2513, R²: -0.0033

📊 Round 177 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2513, R²: -0.0033

📊 Round 177 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2513, R²: -0.0033

============================================================
🔄 Round 180 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 180 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0039
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0202
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2513, R²: -0.0033

============================================================
🔄 Round 184 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 184 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=-0.0065
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0072
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2513, R²: -0.0033

============================================================
🔄 Round 186 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 186 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0114
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0042
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2513, R²: -0.0033

📊 Round 186 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2513, R²: -0.0033

============================================================
🔄 Round 191 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 191 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0097
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0038
============================================================


============================================================
🔄 Round 192 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 192 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=-0.0131
   Val:   Loss=0.0853, RMSE=0.2920, R²=0.0065
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2513, R²: -0.0033

============================================================
🔄 Round 196 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 196 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0095
   Val:   Loss=0.0753, RMSE=0.2744, R²=-0.0008
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2513, R²: -0.0033

============================================================
🔄 Round 197 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 197 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=-0.0096
   Val:   Loss=0.0923, RMSE=0.3039, R²=0.0027
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2513, R²: -0.0033

============================================================
🔄 Round 198 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 198 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0021
   Val:   Loss=0.0711, RMSE=0.2667, R²=-0.0551
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0842, RMSE: 0.2903, MAE: 0.2513, R²: -0.0032

============================================================
🔄 Round 200 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 200 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0041
   Val:   Loss=0.0798, RMSE=0.2824, R²=-0.0173
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2513, R²: -0.0033

============================================================
🔄 Round 202 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 202 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0087
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0124
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2513, R²: -0.0033

📊 Round 202 Test Metrics:
   Loss: 0.0842, RMSE: 0.2903, MAE: 0.2513, R²: -0.0032

============================================================
🔄 Round 205 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 205 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0070
   Val:   Loss=0.0720, RMSE=0.2683, R²=-0.0068
============================================================


============================================================
🔄 Round 208 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 208 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=-0.0067
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0079
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0032

============================================================
🔄 Round 210 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 210 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0085
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0015
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0032

📊 Round 210 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0032

📊 Round 210 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0032

📊 Round 210 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 218 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 218 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0084
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0017
============================================================


📊 Round 218 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

📊 Round 218 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

📊 Round 218 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 224 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 224 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0061
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0098
============================================================


============================================================
🔄 Round 225 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 225 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0085
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0007
============================================================


📊 Round 225 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

📊 Round 225 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

📊 Round 225 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 233 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 233 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0056
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0144
============================================================


📊 Round 233 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 235 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 235 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0063
   Val:   Loss=0.0763, RMSE=0.2763, R²=-0.0143
============================================================


📊 Round 235 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

📊 Round 235 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 241 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 241 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0070
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0074
============================================================


============================================================
🔄 Round 242 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 242 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0155
   Val:   Loss=0.0718, RMSE=0.2680, R²=0.0037
============================================================


📊 Round 242 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 243 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 243 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0056
   Val:   Loss=0.0748, RMSE=0.2735, R²=-0.0184
============================================================


============================================================
🔄 Round 245 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 245 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0031
   Val:   Loss=0.0845, RMSE=0.2908, R²=-0.0278
============================================================


============================================================
🔄 Round 248 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 248 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=-0.0017
   Val:   Loss=0.0907, RMSE=0.3011, R²=-0.0298
============================================================


📊 Round 248 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

📊 Round 248 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 252 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 252 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=-0.0121
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0014
============================================================


📊 Round 252 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 254 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 254 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=-0.0135
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0046
============================================================


============================================================
🔄 Round 255 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 255 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0114
   Val:   Loss=0.0732, RMSE=0.2706, R²=0.0077
============================================================


📊 Round 255 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 257 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 257 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=-0.0056
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0116
============================================================


📊 Round 257 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 259 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 259 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0010
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0609
============================================================


============================================================
🔄 Round 260 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 260 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0064
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0092
============================================================


============================================================
🔄 Round 261 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 261 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=-0.0103
   Val:   Loss=0.0862, RMSE=0.2935, R²=0.0001
============================================================


📊 Round 261 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

📊 Round 261 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 265 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 265 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0013
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0396
============================================================


============================================================
🔄 Round 266 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 266 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0112
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0093
============================================================


============================================================
🔄 Round 267 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 267 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0075
   Val:   Loss=0.0711, RMSE=0.2667, R²=-0.0048
============================================================


📊 Round 267 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0032

📊 Round 267 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0032

📊 Round 267 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0032

📊 Round 267 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0032

============================================================
🔄 Round 272 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 272 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0052
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0132
============================================================


📊 Round 272 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0032

============================================================
🔄 Round 273 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 273 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0149
   Val:   Loss=0.0746, RMSE=0.2730, R²=0.0056
============================================================


📊 Round 273 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0032

============================================================
🔄 Round 275 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 275 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=-0.0026
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0311
============================================================


============================================================
🔄 Round 276 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 276 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2829, R²=-0.0048
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0160
============================================================


============================================================
🔄 Round 277 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 277 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0046
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0170
============================================================


📊 Round 277 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0032

📊 Round 277 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

📊 Round 277 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

📊 Round 277 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 285 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 285 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=-0.0061
   Val:   Loss=0.0904, RMSE=0.3006, R²=-0.0115
============================================================


============================================================
🔄 Round 286 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 286 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=-0.0076
   Val:   Loss=0.0830, RMSE=0.2882, R²=-0.0048
============================================================


============================================================
🔄 Round 290 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 290 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0063
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0115
============================================================


============================================================
🔄 Round 295 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0689 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0689, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0689, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0688, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0688, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0687, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0689)

============================================================
📊 Round 295 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0058
   Val:   Loss=0.0689, RMSE=0.2625, R²=-0.0131
============================================================


============================================================
🔄 Round 297 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 297 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=-0.0049
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0178
============================================================


============================================================
🔄 Round 298 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 298 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0014
   Val:   Loss=0.0746, RMSE=0.2731, R²=-0.0469
============================================================


📊 Round 298 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 299 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 299 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0106
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0060
============================================================


📊 Round 299 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 302 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 302 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0050
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0209
============================================================


📊 Round 302 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

📊 Round 302 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 304 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 304 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0056
   Val:   Loss=0.0814, RMSE=0.2854, R²=-0.0152
============================================================


📊 Round 304 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

📊 Round 304 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 307 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0881, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0784, val=0.0878, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0783, val=0.0876, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 307 Summary - Client client_2
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=-0.0002
   Val:   Loss=0.0879, RMSE=0.2966, R²=-0.0330
============================================================


============================================================
🔄 Round 309 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 309 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=-0.0104
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0024
============================================================


📊 Round 309 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0032

============================================================
🔄 Round 310 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 310 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0114
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0022
============================================================


============================================================
🔄 Round 311 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 311 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0099
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0022
============================================================


============================================================
🔄 Round 314 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 314 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0061
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0113
============================================================


============================================================
🔄 Round 316 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 316 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=-0.0098
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0054
============================================================


📊 Round 316 Test Metrics:
   Loss: 0.0842, RMSE: 0.2903, MAE: 0.2513, R²: -0.0032

============================================================
🔄 Round 317 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 317 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0059
   Val:   Loss=0.0798, RMSE=0.2826, R²=-0.0101
============================================================


📊 Round 317 Test Metrics:
   Loss: 0.0842, RMSE: 0.2903, MAE: 0.2513, R²: -0.0032

📊 Round 317 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0032

============================================================
🔄 Round 321 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 321 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=-0.0042
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0176
============================================================


📊 Round 321 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0032

📊 Round 321 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0032

============================================================
🔄 Round 324 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 324 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0116
   Val:   Loss=0.0818, RMSE=0.2861, R²=0.0006
============================================================


📊 Round 324 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0032

📊 Round 324 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 328 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 328 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=-0.0128
   Val:   Loss=0.0898, RMSE=0.2997, R²=-0.0011
============================================================


📊 Round 328 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

📊 Round 328 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

📊 Round 328 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

📊 Round 328 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

📊 Round 328 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 335 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 335 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2810, R²=-0.0060
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0113
============================================================


============================================================
🔄 Round 338 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 338 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0051
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0156
============================================================


📊 Round 338 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 341 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 341 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0083
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0028
============================================================


📊 Round 341 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0030

============================================================
🔄 Round 344 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0941, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0941, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0941, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0941, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 344 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=-0.0063
   Val:   Loss=0.0942, RMSE=0.3069, R²=-0.0134
============================================================


📊 Round 344 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0030

============================================================
🔄 Round 348 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 348 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=-0.0083
   Val:   Loss=0.0879, RMSE=0.2964, R²=-0.0039
============================================================


============================================================
🔄 Round 349 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 349 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0112
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0053
============================================================


============================================================
🔄 Round 350 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0982 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0982, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0982, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0981, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0981, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0980, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0982)

============================================================
📊 Round 350 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=-0.0087
   Val:   Loss=0.0982, RMSE=0.3134, R²=-0.0023
============================================================


============================================================
🔄 Round 352 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 352 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0037
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0247
============================================================


📊 Round 352 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 355 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 355 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0079
   Val:   Loss=0.0727, RMSE=0.2696, R²=-0.0063
============================================================


📊 Round 355 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 356 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 356 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0025
   Val:   Loss=0.0851, RMSE=0.2918, R²=-0.0281
============================================================


📊 Round 356 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

📊 Round 356 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 362 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 362 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0121
   Val:   Loss=0.0735, RMSE=0.2712, R²=0.0025
============================================================


📊 Round 362 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 364 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 364 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0070
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0075
============================================================


📊 Round 364 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 365 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 365 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0027
   Val:   Loss=0.0750, RMSE=0.2738, R²=-0.0349
============================================================


📊 Round 365 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

📊 Round 365 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 367 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 367 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0088
   Val:   Loss=0.0747, RMSE=0.2734, R²=-0.0008
============================================================


📊 Round 367 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

📊 Round 367 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 373 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 373 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0073
   Val:   Loss=0.0715, RMSE=0.2675, R²=-0.0064
============================================================


============================================================
🔄 Round 374 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 374 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0078
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0038
============================================================


📊 Round 374 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 375 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 375 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0227
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0025
============================================================


============================================================
🔄 Round 376 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 376 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0066
   Val:   Loss=0.0753, RMSE=0.2744, R²=-0.0083
============================================================


📊 Round 376 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

📊 Round 376 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 380 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 380 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0060
   Val:   Loss=0.0747, RMSE=0.2732, R²=-0.0113
============================================================


📊 Round 380 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 385 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 385 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=-0.0062
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0108
============================================================


============================================================
🔄 Round 386 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 386 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0103
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0028
============================================================


📊 Round 386 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 387 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 387 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0055
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0130
============================================================


============================================================
🔄 Round 389 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 389 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=-0.0082
   Val:   Loss=0.0838, RMSE=0.2896, R²=-0.0045
============================================================


============================================================
🔄 Round 392 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0657 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0657, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0657, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0657, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0656, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0656, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0657)

============================================================
📊 Round 392 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0059
   Val:   Loss=0.0657, RMSE=0.2564, R²=-0.0134
============================================================


============================================================
🔄 Round 393 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 393 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=-0.0099
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0038
============================================================


============================================================
🔄 Round 394 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 394 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0080
   Val:   Loss=0.0734, RMSE=0.2708, R²=-0.0035
============================================================


📊 Round 394 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 396 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 396 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0074
   Val:   Loss=0.0793, RMSE=0.2815, R²=-0.0055
============================================================


📊 Round 396 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 401 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 401 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0046
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0329
============================================================


============================================================
🔄 Round 402 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 402 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=-0.0090
   Val:   Loss=0.0879, RMSE=0.2966, R²=-0.0002
============================================================


📊 Round 402 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 405 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 405 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0049
   Val:   Loss=0.0792, RMSE=0.2815, R²=-0.0167
============================================================


============================================================
🔄 Round 407 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 407 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=-0.0041
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0301
============================================================


📊 Round 407 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0030

📊 Round 407 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0030

============================================================
🔄 Round 409 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 409 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0044
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0209
============================================================


============================================================
🔄 Round 410 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0737, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0819, val=0.0734, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0819, val=0.0732, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 410 Summary - Client client_2
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=0.0005
   Val:   Loss=0.0735, RMSE=0.2712, R²=-0.0432
============================================================


📊 Round 410 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0032

📊 Round 410 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0032

============================================================
🔄 Round 414 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 414 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0092
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0008
============================================================


============================================================
🔄 Round 416 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 416 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0123
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0041
============================================================


📊 Round 416 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0032

============================================================
🔄 Round 419 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 419 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2835, R²=-0.0084
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0047
============================================================


📊 Round 419 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

📊 Round 419 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

📊 Round 419 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0032

============================================================
🔄 Round 426 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 426 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0058
   Val:   Loss=0.0755, RMSE=0.2748, R²=-0.0217
============================================================


============================================================
🔄 Round 427 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 427 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0120
   Val:   Loss=0.0856, RMSE=0.2925, R²=0.0007
============================================================


📊 Round 427 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 429 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 429 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0063
   Val:   Loss=0.0741, RMSE=0.2722, R²=-0.0097
============================================================


📊 Round 429 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

📊 Round 429 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 432 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 432 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0050
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0184
============================================================


============================================================
🔄 Round 434 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 434 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0036
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0262
============================================================


============================================================
🔄 Round 436 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 436 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0055
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0200
============================================================


============================================================
🔄 Round 437 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 437 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0092
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0006
============================================================


📊 Round 437 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 440 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 440 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=-0.0027
   Val:   Loss=0.0929, RMSE=0.3048, R²=-0.0457
============================================================


📊 Round 440 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 442 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 442 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0081
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.0046
============================================================


📊 Round 442 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0032

📊 Round 442 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0032

============================================================
🔄 Round 445 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 445 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0022
   Val:   Loss=0.0775, RMSE=0.2783, R²=-0.0371
============================================================


📊 Round 445 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0032

============================================================
🔄 Round 447 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 447 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0043
   Val:   Loss=0.0740, RMSE=0.2721, R²=-0.0293
============================================================


📊 Round 447 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0032

📊 Round 447 Test Metrics:
   Loss: 0.0842, RMSE: 0.2903, MAE: 0.2513, R²: -0.0032

📊 Round 447 Test Metrics:
   Loss: 0.0842, RMSE: 0.2903, MAE: 0.2513, R²: -0.0032

============================================================
🔄 Round 450 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 450 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0017
   Val:   Loss=0.0760, RMSE=0.2757, R²=-0.0477
============================================================


============================================================
🔄 Round 451 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 451 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=-0.0154
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0027
============================================================


============================================================
🔄 Round 452 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 452 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0106
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0031
============================================================


============================================================
🔄 Round 453 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 453 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0045
   Val:   Loss=0.0714, RMSE=0.2673, R²=-0.0197
============================================================


============================================================
🔄 Round 454 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 454 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0055
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0113
============================================================


📊 Round 454 Test Metrics:
   Loss: 0.0842, RMSE: 0.2903, MAE: 0.2513, R²: -0.0032

📊 Round 454 Test Metrics:
   Loss: 0.0842, RMSE: 0.2903, MAE: 0.2513, R²: -0.0032

============================================================
🔄 Round 457 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 457 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=-0.0061
   Val:   Loss=0.0752, RMSE=0.2743, R²=-0.0108
============================================================


============================================================
🔄 Round 458 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 458 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0051
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0129
============================================================


📊 Round 458 Test Metrics:
   Loss: 0.0842, RMSE: 0.2903, MAE: 0.2513, R²: -0.0032

============================================================
🔄 Round 461 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 461 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0130
   Val:   Loss=0.0787, RMSE=0.2806, R²=0.0046
============================================================


📊 Round 461 Test Metrics:
   Loss: 0.0842, RMSE: 0.2903, MAE: 0.2513, R²: -0.0032

============================================================
🔄 Round 462 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 462 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0048
   Val:   Loss=0.0733, RMSE=0.2707, R²=-0.0247
============================================================


============================================================
🔄 Round 463 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0707, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 463 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0045
   Val:   Loss=0.0710, RMSE=0.2664, R²=-0.0339
============================================================


============================================================
🔄 Round 465 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 465 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0071
   Val:   Loss=0.0815, RMSE=0.2856, R²=-0.0054
============================================================


📊 Round 465 Test Metrics:
   Loss: 0.0842, RMSE: 0.2903, MAE: 0.2513, R²: -0.0032

============================================================
🔄 Round 466 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 466 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0070
   Val:   Loss=0.0830, RMSE=0.2880, R²=-0.0063
============================================================


============================================================
🔄 Round 470 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 470 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=-0.0082
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0041
============================================================


============================================================
🔄 Round 474 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 474 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0166
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0009
============================================================


📊 Round 474 Test Metrics:
   Loss: 0.0842, RMSE: 0.2903, MAE: 0.2513, R²: -0.0032

============================================================
🔄 Round 475 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 475 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0100
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0045
============================================================


📊 Round 475 Test Metrics:
   Loss: 0.0842, RMSE: 0.2903, MAE: 0.2513, R²: -0.0032

============================================================
🔄 Round 476 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 476 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0080
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0040
============================================================


📊 Round 476 Test Metrics:
   Loss: 0.0842, RMSE: 0.2903, MAE: 0.2513, R²: -0.0032

📊 Round 476 Test Metrics:
   Loss: 0.0842, RMSE: 0.2903, MAE: 0.2513, R²: -0.0032

============================================================
🔄 Round 481 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 481 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=-0.0166
   Val:   Loss=0.0862, RMSE=0.2937, R²=0.0012
============================================================


============================================================
🔄 Round 482 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 482 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0028
   Val:   Loss=0.0711, RMSE=0.2666, R²=-0.0299
============================================================


📊 Round 482 Test Metrics:
   Loss: 0.0842, RMSE: 0.2903, MAE: 0.2513, R²: -0.0032

📊 Round 482 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0032

📊 Round 482 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0032

📊 Round 482 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0032

============================================================
🔄 Round 488 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 488 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0082
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0045
============================================================


============================================================
🔄 Round 491 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 491 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0111
   Val:   Loss=0.0732, RMSE=0.2706, R²=-0.0010
============================================================


📊 Round 491 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 495 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 495 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0060
   Val:   Loss=0.0827, RMSE=0.2877, R²=-0.0109
============================================================


============================================================
🔄 Round 497 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 497 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0094
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0034
============================================================


============================================================
🔄 Round 498 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 498 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0043
   Val:   Loss=0.0737, RMSE=0.2715, R²=-0.0310
============================================================


============================================================
🔄 Round 500 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 500 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0056
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0142
============================================================


📊 Round 500 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 501 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 501 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0046
   Val:   Loss=0.0717, RMSE=0.2678, R²=-0.0205
============================================================


============================================================
🔄 Round 503 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 503 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0005
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0507
============================================================


============================================================
🔄 Round 504 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 504 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0082
   Val:   Loss=0.0768, RMSE=0.2772, R²=-0.0018
============================================================


📊 Round 504 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 507 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 507 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0054
   Val:   Loss=0.0713, RMSE=0.2671, R²=-0.0146
============================================================


============================================================
🔄 Round 509 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 509 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0052
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0155
============================================================


📊 Round 509 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

📊 Round 509 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 512 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 512 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=-0.0079
   Val:   Loss=0.0897, RMSE=0.2994, R²=-0.0041
============================================================


============================================================
🔄 Round 513 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0708 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0708, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0708, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0707, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0707, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0705, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 513 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0009
   Val:   Loss=0.0708, RMSE=0.2662, R²=-0.0585
============================================================


📊 Round 513 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 515 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 515 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=-0.0054
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0150
============================================================


============================================================
🔄 Round 516 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 516 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0067
   Val:   Loss=0.0737, RMSE=0.2715, R²=-0.0090
============================================================


============================================================
🔄 Round 517 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 517 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0099
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0028
============================================================


📊 Round 517 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

📊 Round 517 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 522 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 522 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0093
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0018
============================================================


============================================================
🔄 Round 527 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 527 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0106
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0032
============================================================


📊 Round 527 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

📊 Round 527 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

📊 Round 527 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0030

============================================================
🔄 Round 532 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 532 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0074
   Val:   Loss=0.0764, RMSE=0.2763, R²=-0.0065
============================================================


📊 Round 532 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

📊 Round 532 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 536 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 536 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0043
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0278
============================================================


============================================================
🔄 Round 537 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 537 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=-0.0078
   Val:   Loss=0.0838, RMSE=0.2896, R²=-0.0048
============================================================


📊 Round 537 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0030

============================================================
🔄 Round 539 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 539 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0067
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0118
============================================================


============================================================
🔄 Round 540 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 540 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=-0.0044
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0179
============================================================


📊 Round 540 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0030

============================================================
🔄 Round 543 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 543 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0021
   Val:   Loss=0.0734, RMSE=0.2709, R²=-0.0439
============================================================


📊 Round 543 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0030

============================================================
🔄 Round 546 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 546 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0059
   Val:   Loss=0.0798, RMSE=0.2826, R²=-0.0135
============================================================


📊 Round 546 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0030

📊 Round 546 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0030

============================================================
🔄 Round 550 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 550 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0134
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0066
============================================================


📊 Round 550 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0030

============================================================
🔄 Round 553 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 553 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0123
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0005
============================================================


============================================================
🔄 Round 556 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 556 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0072
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0079
============================================================


📊 Round 556 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0030

============================================================
🔄 Round 557 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 557 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=-0.0013
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0623
============================================================


============================================================
🔄 Round 558 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 558 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0130
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0000
============================================================


📊 Round 558 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0030

============================================================
🔄 Round 560 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 560 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=-0.0129
   Val:   Loss=0.0872, RMSE=0.2953, R²=0.0014
============================================================


📊 Round 560 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0030

📊 Round 560 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0030

📊 Round 560 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0030

📊 Round 560 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0030

============================================================
🔄 Round 565 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 565 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0053
   Val:   Loss=0.0753, RMSE=0.2744, R²=-0.0221
============================================================


📊 Round 565 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0030

============================================================
🔄 Round 568 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 568 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=-0.0094
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0001
============================================================


============================================================
🔄 Round 569 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 569 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0073
   Val:   Loss=0.0726, RMSE=0.2694, R²=-0.0086
============================================================


📊 Round 569 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0030

============================================================
🔄 Round 574 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 574 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0037
   Val:   Loss=0.0744, RMSE=0.2728, R²=-0.0353
============================================================


============================================================
🔄 Round 576 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 576 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=-0.0083
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0061
============================================================


📊 Round 576 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0030

============================================================
🔄 Round 577 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 577 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=-0.0113
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0056
============================================================


📊 Round 577 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0030

📊 Round 577 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0030

============================================================
🔄 Round 580 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 580 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0077
   Val:   Loss=0.0737, RMSE=0.2714, R²=-0.0066
============================================================


📊 Round 580 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0030

📊 Round 580 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0030

============================================================
🔄 Round 587 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 587 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0093
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0029
============================================================


============================================================
🔄 Round 588 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 588 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0048
   Val:   Loss=0.0785, RMSE=0.2801, R²=-0.0253
============================================================


📊 Round 588 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0030

📊 Round 588 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0029

============================================================
🔄 Round 591 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 591 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0058
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0160
============================================================


📊 Round 591 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0029

============================================================
🔄 Round 593 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 593 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0173
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0140
============================================================


============================================================
🔄 Round 597 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 597 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0068
   Val:   Loss=0.0766, RMSE=0.2767, R²=-0.0130
============================================================


============================================================
🔄 Round 598 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 598 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0056
   Val:   Loss=0.0767, RMSE=0.2769, R²=-0.0167
============================================================


📊 Round 598 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0029

📊 Round 598 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0029

============================================================
🔄 Round 602 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 602 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0068
   Val:   Loss=0.0784, RMSE=0.2799, R²=-0.0114
============================================================


📊 Round 602 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0029

============================================================
🔄 Round 604 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 604 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0086
   Val:   Loss=0.0744, RMSE=0.2729, R²=-0.0041
============================================================


📊 Round 604 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0029

📊 Round 604 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0029

📊 Round 604 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0029

📊 Round 604 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0029

============================================================
🔄 Round 611 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 611 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0116
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0006
============================================================


📊 Round 611 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0029

============================================================
🔄 Round 614 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 614 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0077
   Val:   Loss=0.0794, RMSE=0.2819, R²=-0.0140
============================================================


============================================================
🔄 Round 615 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 615 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0135
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0029
============================================================


============================================================
🔄 Round 617 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 617 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0075
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0081
============================================================


📊 Round 617 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0030

============================================================
🔄 Round 621 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 621 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0071
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0100
============================================================


============================================================
🔄 Round 622 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 622 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0039
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0238
============================================================


📊 Round 622 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0030

============================================================
🔄 Round 624 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 624 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0034
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0274
============================================================


📊 Round 624 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0030

📊 Round 624 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0029

============================================================
🔄 Round 629 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 629 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0108
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0032
============================================================


============================================================
🔄 Round 632 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 632 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=-0.0062
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0126
============================================================


============================================================
🔄 Round 633 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 633 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0061
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0169
============================================================


📊 Round 633 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0029

📊 Round 633 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0029

📊 Round 633 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0030

============================================================
🔄 Round 638 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 638 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=-0.0094
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0018
============================================================


📊 Round 638 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0030

============================================================
🔄 Round 640 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0852, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0792, val=0.0849, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0792, val=0.0846, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 640 Summary - Client client_2
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=-0.0004
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0481
============================================================


📊 Round 640 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 648 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 648 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0081
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0061
============================================================


📊 Round 648 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 652 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 652 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=-0.0093
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0040
============================================================


============================================================
🔄 Round 653 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 653 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=-0.0061
   Val:   Loss=0.0862, RMSE=0.2937, R²=-0.0138
============================================================


============================================================
🔄 Round 655 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 655 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0065
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0095
============================================================


📊 Round 655 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 658 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 658 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0126
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0057
============================================================


============================================================
🔄 Round 659 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 659 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=-0.0120
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0077
============================================================


============================================================
🔄 Round 662 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 662 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0107
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0015
============================================================


📊 Round 662 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 665 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 665 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0070
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0081
============================================================


📊 Round 665 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 666 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 666 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0121
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0144
============================================================


📊 Round 666 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 667 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 667 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0075
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0073
============================================================


============================================================
🔄 Round 668 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 668 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=-0.0068
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0090
============================================================


📊 Round 668 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

📊 Round 668 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0030

📊 Round 668 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0030

📊 Round 668 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0030

📊 Round 668 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0030

📊 Round 668 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0030

📊 Round 668 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0030

============================================================
🔄 Round 679 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 679 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0063
   Val:   Loss=0.0743, RMSE=0.2726, R²=-0.0116
============================================================


📊 Round 679 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0030

============================================================
🔄 Round 681 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 681 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0051
   Val:   Loss=0.0783, RMSE=0.2799, R²=-0.0284
============================================================


============================================================
🔄 Round 682 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 682 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=-0.0094
   Val:   Loss=0.0731, RMSE=0.2704, R²=-0.0000
============================================================


============================================================
🔄 Round 683 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 683 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0112
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0063
============================================================


📊 Round 683 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0030

📊 Round 683 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0030

============================================================
🔄 Round 686 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0705, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 686 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0096
   Val:   Loss=0.0705, RMSE=0.2656, R²=-0.0028
============================================================


============================================================
🔄 Round 687 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 687 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0092
   Val:   Loss=0.0805, RMSE=0.2838, R²=0.0007
============================================================


============================================================
🔄 Round 691 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 691 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0143
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0169
============================================================


📊 Round 691 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0030

============================================================
🔄 Round 693 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 693 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0155
   Val:   Loss=0.0789, RMSE=0.2808, R²=0.0021
============================================================


============================================================
🔄 Round 694 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 694 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=-0.0084
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0071
============================================================


📊 Round 694 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 697 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 697 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0095
   Val:   Loss=0.0822, RMSE=0.2868, R²=0.0003
============================================================


📊 Round 697 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 699 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 699 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2810, R²=-0.0048
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0232
============================================================


============================================================
🔄 Round 700 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 700 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=-0.0080
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0043
============================================================


============================================================
🔄 Round 701 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 701 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0158
   Val:   Loss=0.0744, RMSE=0.2728, R²=-0.0130
============================================================


============================================================
🔄 Round 703 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 703 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0078
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0093
============================================================


📊 Round 703 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 705 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 705 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0018
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0735
============================================================


📊 Round 705 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 708 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0687 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0687, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0688, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0688, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0688, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0689, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0687)

============================================================
📊 Round 708 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0113
   Val:   Loss=0.0687, RMSE=0.2622, R²=-0.0158
============================================================


📊 Round 708 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

📊 Round 708 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

📊 Round 708 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

📊 Round 708 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

📊 Round 708 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0030

📊 Round 708 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0030

============================================================
🔄 Round 721 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 721 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0070
   Val:   Loss=0.0760, RMSE=0.2757, R²=-0.0091
============================================================


📊 Round 721 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0030

============================================================
🔄 Round 723 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 723 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0101
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0066
============================================================


============================================================
🔄 Round 724 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 724 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=-0.0063
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0124
============================================================


📊 Round 724 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0030

============================================================
🔄 Round 727 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 727 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=-0.0088
   Val:   Loss=0.0862, RMSE=0.2935, R²=-0.0025
============================================================


============================================================
🔄 Round 728 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 728 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0069
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0101
============================================================


📊 Round 728 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0030

📊 Round 728 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0030

============================================================
🔄 Round 730 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 730 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0069
   Val:   Loss=0.0792, RMSE=0.2815, R²=-0.0105
============================================================


📊 Round 730 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0030

📊 Round 730 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0030

📊 Round 730 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0030

============================================================
🔄 Round 734 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 734 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=-0.0080
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0061
============================================================


📊 Round 734 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0030

============================================================
🔄 Round 736 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 736 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0093
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0004
============================================================


============================================================
🔄 Round 738 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 738 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=-0.0065
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0145
============================================================


📊 Round 738 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0030

============================================================
🔄 Round 739 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 739 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=-0.0115
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0034
============================================================


📊 Round 739 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0030

============================================================
🔄 Round 742 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 742 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0099
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0032
============================================================


============================================================
🔄 Round 743 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 743 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=-0.0044
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0262
============================================================


📊 Round 743 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0030

============================================================
🔄 Round 744 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 744 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0099
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0012
============================================================


📊 Round 744 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0030

============================================================
🔄 Round 748 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 748 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=-0.0099
   Val:   Loss=0.0895, RMSE=0.2992, R²=0.0001
============================================================


📊 Round 748 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0030

============================================================
🔄 Round 749 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 749 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0079
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0046
============================================================


📊 Round 749 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

📊 Round 749 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0030

============================================================
🔄 Round 751 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 751 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0072
   Val:   Loss=0.0733, RMSE=0.2706, R²=-0.0069
============================================================


📊 Round 751 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0030

============================================================
🔄 Round 752 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 752 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0049
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0231
============================================================


📊 Round 752 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 754 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 754 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=-0.0044
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0299
============================================================


📊 Round 754 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0030

============================================================
🔄 Round 758 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 758 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0139
   Val:   Loss=0.0740, RMSE=0.2720, R²=0.0057
============================================================


============================================================
🔄 Round 759 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 759 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0073
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0067
============================================================


============================================================
🔄 Round 761 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 761 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0099
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0014
============================================================


📊 Round 761 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 762 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 762 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0120
   Val:   Loss=0.0746, RMSE=0.2732, R²=0.0071
============================================================


📊 Round 762 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 764 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 764 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0168
   Val:   Loss=0.0740, RMSE=0.2720, R²=0.0040
============================================================


============================================================
🔄 Round 765 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 765 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=-0.0052
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0175
============================================================


📊 Round 765 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 767 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 767 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0077
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0047
============================================================


============================================================
🔄 Round 768 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 768 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0075
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0065
============================================================


============================================================
🔄 Round 772 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 772 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0089
   Val:   Loss=0.0774, RMSE=0.2781, R²=0.0003
============================================================


============================================================
🔄 Round 773 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 773 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0089
   Val:   Loss=0.0722, RMSE=0.2686, R²=-0.0061
============================================================


📊 Round 773 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 776 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 776 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2819, R²=-0.0059
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0136
============================================================


📊 Round 776 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

📊 Round 776 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 779 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 779 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=-0.0094
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0009
============================================================


📊 Round 779 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0031

============================================================
🔄 Round 781 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 781 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0104
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0008
============================================================


============================================================
🔄 Round 782 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 782 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0228
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0218
============================================================


============================================================
🔄 Round 783 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 783 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0104
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0036
============================================================


📊 Round 783 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0032

============================================================
🔄 Round 784 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 784 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0181
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0185
============================================================


📊 Round 784 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0032

============================================================
🔄 Round 790 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 790 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0066
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0095
============================================================


📊 Round 790 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0032

============================================================
🔄 Round 792 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 792 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0073
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0058
============================================================


📊 Round 792 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0032

============================================================
🔄 Round 794 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 794 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0056
   Val:   Loss=0.0848, RMSE=0.2911, R²=-0.0173
============================================================


============================================================
🔄 Round 796 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 796 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0106
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0039
============================================================


📊 Round 796 Test Metrics:
   Loss: 0.0842, RMSE: 0.2903, MAE: 0.2513, R²: -0.0032

============================================================
🔄 Round 798 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 798 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=-0.0074
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0048
============================================================


📊 Round 798 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0032

============================================================
🔄 Round 800 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 800 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0039
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0189
============================================================


📊 Round 800 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0032

📊 Round 800 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0032

📊 Round 800 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2513, R²: -0.0032

============================================================
🔄 Round 807 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 807 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0073
   Val:   Loss=0.0754, RMSE=0.2746, R²=-0.0059
============================================================


============================================================
🔄 Round 808 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 808 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0084
   Val:   Loss=0.0774, RMSE=0.2781, R²=-0.0014
============================================================


❌ Client client_2 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_status:14, grpc_message:"Socket closed"}"
>
