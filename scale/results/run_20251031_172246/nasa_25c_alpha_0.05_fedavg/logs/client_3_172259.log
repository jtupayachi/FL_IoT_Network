[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3a40784-9e24-4c2c-855f-a6fdc69b2df6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 068129f5-a5b9-4f22-8c8d-972022342c56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96b33364-25b7-4625-8296-3afd4c2567df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2412473b-ae79-44aa-b7dd-6cf9075920de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4d22836-0939-4c58-804f-4d6c7450c7b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b853fe0-91a3-4f20-8aca-70f62022cac5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d40ba7f-2218-4f9e-89ed-f5e287cde362
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df7f7507-e990-4b42-a0a4-39a5ba34bb8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7e87ae5-0b6e-47d0-aee7-fc5cabfbdab6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5610f427-8042-4187-858f-3e40cb75b346
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a1fcd71-fa2a-4b22-a6e8-db0c40ef270e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94d389ff-c25d-41b1-988f-e083776dcb89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message daa4ef4c-3df6-4cb4-b76f-4d70fc198da5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81fb3314-9d46-4a19-9dff-7ef21f089b63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5913d13b-3f7e-4ee3-8459-0e22cbb6cb8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94ad0288-cd27-4e9b-8e77-58a9ba08e17a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message adc4809b-d847-4763-9568-7a29c8364a44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab0b5b08-8cbf-419c-a17f-fa22ec8e89f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83bb21b9-cd58-4ba2-84fe-48fda1b33503
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c306a1b-2a0e-4a93-977a-34bee6fd9102
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa6335df-8b9d-4479-998f-d5437517f01c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a172308-f138-4e04-a0d1-01538ed21c28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc08a97b-cb22-4f5b-8740-2403ac584e34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5d9a3ae-be06-456e-916b-e10bb843d491
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b8555c9-fa0e-4a0b-aa89-3ecece42fd04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 925c0345-9fb7-4203-a1df-df815bedc599
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b074a5b5-d96f-4fa4-b8d0-e7124182423f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7dbce0bf-64dc-4af2-a523-9cb5363b606e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b4ab813-6061-4f52-bed2-3d5b01fecf3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 800852f2-4640-4096-ba7b-111c3cecb5b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e66fc072-3121-486e-88cb-c1133ab8e999
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b5da343-c02d-44da-8390-92727a2cb9d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da1b73f7-e286-491c-a243-a4f51069053c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d037a006-8959-4696-b3c9-3d30a7c7c7de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e203ed68-c314-4f99-bd26-5020cc953f19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fae615c2-1215-4044-9d32-3ff92e7276d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01ad61ab-40e4-45d0-ba1e-9584eeae45dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 599ad916-4ace-47dc-b012-c765ff11af9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33233076-ae91-4cdb-9e1a-dc85ddcd7827
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3741f1fe-0454-43ab-ad22-3c06e65ff687
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad97b550-d265-4ac9-a90f-2724ee0a97a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5303fccb-a2f1-40c5-afd4-d308d10eb5e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b65d0893-d7df-410e-8b45-39ff29ded3c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5133b35e-6976-41ff-b8ad-17a887ddf958
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f9be5b5-7e2b-476b-87b0-adde8b17f4ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfdd6c13-ad51-4ca4-a1f9-ff9d0e4b1758
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1bf0c78-0445-4e92-9596-b4ad32c44caa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cda21ae1-2618-4997-8d7c-c29db5529466
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac5a572d-4442-432f-a667-cc4a21cf4e29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32fd1e1f-d182-44e3-b73b-3ac32ce8b9f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90282721-e431-43b5-8a96-1f4ceee005f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f5c69cf-1366-47da-99aa-b52270ea2308
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b80b7223-2538-4b6c-b1ad-fcfe3977bc85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cdfd202b-5725-46ab-8a54-96464d535547
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8035940-cfb9-4e88-ba10-f6eb4ea64082
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e61537da-5455-4b5e-8211-106a7749b6c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 487671a9-6ad3-4ea4-9428-f4f5c108516d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2335f97f-c053-4a36-912b-20cbf9ae2edc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6976b6b9-6635-4d60-aa7b-7b164e0b5e0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f393000e-ad2e-4bf9-b3e1-3c453bef6981
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40f86880-76c6-4c4e-a019-e1e3d9ccaafb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b895f308-7aa6-43bf-9ff5-ee86b93a1432
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93901ed4-f72c-44f0-bcdf-ef630f61ebf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0345b98f-b9b7-405f-89c0-a0fb6e79cdbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65ab59eb-8997-445d-bfa7-5e522c8db95f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b7724a1-d7d2-42d8-8d2d-09d5f395efd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d655c8dc-edbb-4f1a-9d81-d37746c0950a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9ee3f26-9367-4eea-9828-57bdbb554fa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f1eea4b-f9be-401e-9de1-db2d545ab859
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afe717ab-01a2-496c-a6c5-7f3aef0b0d04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9fa1c67-14d3-4309-8a1a-db173ff438cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1589fb6b-78ae-4276-8c9e-0bd78fda2f59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fade2f3-2c30-431a-bcbd-b16960fcb45b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f505732f-2db8-4012-a2e6-0dd1f859693c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4057eee-a82a-490b-9db4-af126faf8cf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0342ba0f-f697-4534-ab19-72e079291c7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abf7cb1e-1300-4755-bc7a-86949d61772d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7df718e1-e984-46fc-9a9a-8ca6f7e3ca8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5739c48-5ba7-4721-83a4-fe245cdb62b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1dd4be1-3658-4b48-9ba9-66ffd041c89e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c462191-2496-4bef-b8e3-7044cc2e9611
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72b7fa62-4320-4e3d-b7b2-e5ed28e1c9a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e25dced9-055c-465f-9f5f-d18ca9c4254f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b915b0f-ecef-46a3-9472-77c43da5e29a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebffd40d-aa44-439d-9627-22be4d13f671
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3eb62fb-3b91-4630-9c89-8cc5a13277a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4ef57cb-be82-41af-a923-98f9cc7e45aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 824ed087-38f9-4553-96e0-02605baf2b41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 829efdde-f712-4c10-b69a-afce0c04a3ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b72b9a0c-0a44-45e3-915c-03bc931ea459
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8cf1c97-19be-4ee4-8f95-4522754e34a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c1b417d-9b66-4a9b-abed-616c78ffebb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11230ca0-d345-4e29-836e-69d6f9628909
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd732ed2-8e2e-4909-ba5f-d9f99307ca8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b238240e-e4b4-4e25-b611-f7ac0d7a7059
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b305fdf-9614-41c4-b8d0-4bb0fe193ca1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d06ef44f-f04d-4e15-9c32-8f081384c4d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7cd4be0-5920-42a5-8a8e-8612e1c04f1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75da070c-2d0a-48e0-ab49-0eac9585ebe8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 108197a1-8337-4eb8-80cd-48a4decf2225
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e496f7c-8896-49f6-a940-a5e90c39fb69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9eb023fa-8812-44f7-bb40-bed64138065c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af80bd2d-5b9f-4d3e-bb61-681fe0d2670c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1d24d16-a3f9-46eb-998a-7cba5a0f1f94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d1aa803-7084-4a4b-8ed0-f781398ffd0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a7d4a0f-0c06-4f90-ba0b-173792a40f8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09066180-ced2-49d3-89c7-47fa150c35d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16434a0a-b42f-4b31-846e-6cdb334bb3f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1f3ff6f-9620-469c-87de-9cd87310db84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd0a0d25-ce28-432f-9ed1-1abe6bb08734
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d78081a-bae6-4a62-add1-91363fbdab02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fae7298-b595-4ea2-b6b0-3dff540ef707
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c425853-8a65-4eed-99a3-cc2c7a70b481
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c26853a3-179e-484c-8fb7-b2c1a5a4af77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 096abe22-9e5d-4760-8dff-c8cb9e7e34bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8a5d70c-e3f9-4a89-8ee5-0595abe4361a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93537799-e0e4-42a6-8826-ea309fa28a90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2935dc73-0e35-4f5c-96b6-699ab3360d35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36911d9f-e9e1-407f-94bf-e2c5bcaab98a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6107cd7-09fe-4986-9d4e-da069bb96a86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a18d4cb0-261c-400e-aa0a-8c82c8b1ecba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 714be9a9-c23b-4114-a9d9-955322feb46f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c2fabfb-d4d0-4c5f-80fb-fddbd983c4cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 926ea232-4c9b-41ee-8090-0019d1ecf264
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 095b0595-4402-4f3c-a90c-c6341217f1eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d023982-7212-4560-9317-768d239b912c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fffd3a3-d1c6-4bea-8287-d58de95a430a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ecda9cf-8d6a-4f9a-8da6-2555fb5f4923
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e63d6f3-8cc7-4d5b-aa29-f0b1d479e063
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8b1e61d-dde0-4838-a905-826f75fff03a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8edc7ca-9b7f-4c4d-b589-7ff90c5f1a18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d842abb-5991-4054-821d-47911dee5c54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 538fc2f2-066a-4084-b1e2-ddf230313e81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f29d1a05-4238-4839-b973-c4fc05132069
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c61fb64-a868-4f9e-81d7-c1f76fecc15a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15f86941-ca3b-42c2-ad2f-aaa6ccab5ae2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fba55bf3-8506-4205-8905-153d21f8079c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53bdc9b7-2dee-4d48-b270-2851359bf0a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c91813a0-6d38-4873-b3ed-0df59d156eb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b9536e4-2776-49be-ae49-d824ba24bbb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93b06f10-4945-4750-a824-1582019b31f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f6b7562-6686-4fdd-b284-3755ef966dba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41165ed1-b84d-4650-b585-b1db26364358
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a724d22-2303-41e9-987e-abd8a8355941
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58a74f49-d26e-4f65-b87f-efd4145a54f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 570666a7-b952-4806-97ff-848359dcf28b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 029f062d-87a4-47cf-a9fc-4bce4b63c772
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d6764d2-a6c1-43e2-a29b-70fce1fa6dba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b4973e9-3a89-4594-a4c2-458ce809540d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54923cea-9dcc-4bdb-af52-52a42cb0735a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d713ee30-fd97-48de-91df-22aa2f17f698
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6ec2a2c-b20d-435a-98ac-0307f68b66f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7dbe0522-a879-424c-9416-2e0f538ff00f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b06153cc-dd45-4bda-ab09-7e18384706f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d626fc6-aefb-4d5d-bb2b-54b61d1fc033
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 029fb16f-9af8-43b5-a24c-978b1666c354
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7eaa6fd-b748-469f-8250-a314b8fa09d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe490284-d0f1-48e4-a62c-55dfb1e2566c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09b3e660-f501-4463-bc39-05b68c708a78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a86ace7-adbb-437e-868d-41760c4ae84d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25a1e92c-20b4-4d8a-b2d1-1e69916a19a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69b6d70c-a0f6-4ea3-afca-e0d6dc2324bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 387944f1-637c-428f-bded-bc1fe303a636
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5d57482-636c-4438-b715-5a4d37d28fa0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 275a98d7-8497-4110-abe1-d0ffea41f016
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6483a22-8ad0-4fb0-83ee-3c8112980b2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1a3cedf-0e5c-4f89-abb5-48148ec75c12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ba89a95-51ee-4a78-ae4d-4f95998bb7d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb2250b6-8d2f-4f33-9a89-12ee64128870
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9da71454-ce16-43a3-b753-e719582b49d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96b63708-3d76-491e-8e15-8d88b611a443
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 742ca631-0d8d-4068-a818-0ab887b1265b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3581bf2c-e10d-494c-a576-5a1408a5b976
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bea2e54-9a90-4b1e-9e3f-fa29b8e0c2cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a357fee-c3bf-4cf7-a669-450d7200c617
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55e65124-e798-414e-9cdb-d970cc3eae34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4e50d00-4422-494b-acc3-7c565ba6e437
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9c22127-0638-49c0-91a5-484ff4e49c68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 330c7f2f-8d7c-4f89-8086-0c6b040aec3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbf81f30-ec02-43ef-b8a7-de17f1562edf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38082cc8-9835-4a9d-b770-3f5336863a67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 787b868a-8a73-4762-85f3-e72a58189957
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f00ea685-f66f-4a2e-b537-73c187151c4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a71bf62-b76c-4fe9-8735-ac653199f3f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46b76423-121e-46da-9464-837192a8ad76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca48d766-eece-4c55-8160-0a4deba4e8bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7d0d035-af75-4f9d-b342-1474ede5e329
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6169b2c9-ce6c-4cb1-9687-ad9b9cbb6c5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e67beffe-e25a-4190-bc74-be2ae5f66a32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3825d0f7-5d3e-41d8-99bd-9d03dac61cae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e36c05ff-d672-415d-8172-1b6ba7bd1b5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 614e214a-e16d-493b-8136-6fe8c75f7c54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a5c2a8b-6b17-4c47-90cd-8ddf26790dd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f1013ce-a6c0-4890-8751-193d574057f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60a9d770-12c2-4949-bd64-117f8781cc50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcab982e-74e4-45ae-890b-c49da9c46339
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2b68d82-75c5-4c86-9b76-83099ec16bb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c125f846-a0a2-41be-adc9-11113c8ca79c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a9f851a-00e8-44b8-8e68-6c7177f44818
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a972f88a-0feb-4673-879c-e97202e2f592
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4edf434c-a70f-424d-a635-65af5e8c559e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8cdb4b3c-34f5-4a25-8b2b-1e124878a0fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 750e5845-687e-485d-847c-c78cc1198701
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2f03623-5031-408f-a093-b9dad2c4f1e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d41bb0e-3401-462d-9e97-340db53faa20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35bf63b1-a108-428c-9b6a-eb818f68885b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c61c39e-f613-4f65-af28-252977462abf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbcc0c49-1652-4ade-91fb-c40a51475d6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3de7262-387f-408c-a9b2-36120bc9a7b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 982ed6fc-48c9-4be2-9cd7-9ff7565bf99b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93e4788f-cbcb-48e6-a573-3186564e45cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01bc84e5-b5d6-4a1c-b786-2fc42efc0f97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 584d8aef-2762-4fde-94b3-0cb5acd42810
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38f28170-6b13-462d-93b2-8ad4f52892a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9952d7cd-0e60-4b98-aebe-72ae5bb27ea1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c553742-786e-4935-8525-b2d5628902d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ad97c79-509e-4922-8cc8-6e1299541993
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb4979c9-52a7-429b-948e-955e41237fcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42ac68d3-6dfa-49ca-8be7-335bae0abbf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ac037af-fc3e-42db-967f-a5433c3323d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a28a1ca3-2176-4b94-8057-1c19c205110c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13c4132d-f64f-4a6c-926c-4904923fd4cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d96e08e9-8543-462d-8501-d51997062247
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8e88565-a1f5-4be3-b59b-5950f59014f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 562a10a8-477c-4c4b-839b-6e138aaa4110
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 144f3c2d-112c-4f51-812f-cb70e0092c73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 549da415-ea44-468f-8fa8-b22aef21e94b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a03952a-cbef-4f20-9d19-28a65e02716f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33186990-671d-4729-b17d-a48ebe1b44c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f23530c1-61c9-44bf-81c5-6e948ffd2063
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7d873d6-19cb-405f-8de9-b514cf5b9f4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a0b7b60-ab14-4f53-be53-715331cd32fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6064e620-5dc6-4200-b93c-0fe4cd17a6a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfea268c-c3b3-425c-9877-2ad8310e4155
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f125cdaa-5da7-495a-a630-8e8381a4cbad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b35a35c-92b0-4568-a477-a15f6fb17ff2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb451bc8-2ff8-4202-8021-23336033c513
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45d93abe-c5f5-4f0c-a521-f328357ec254
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94d81955-2652-4b9a-aba3-d32927496b24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bbfeac9-6089-4c59-9313-f716dfdccc04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 942932e4-5a36-45fc-b103-dde7340b9961
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7ea9f41-d992-41bd-9fd2-9fa911c2ce22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62b4e888-f1c0-4294-aadb-71c6d3dbaebc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64397e23-521a-4f10-bc77-ca4a9b6f64b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1edb49cb-5cce-4b6b-ae0e-7dd8c5bc2c62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b3fb462-2803-4021-a3af-870d9c6fc574
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82f44c27-fdec-4f2f-be68-32e1e556c49e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59125b99-5813-43eb-9207-e8ab655c8306
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9162ce5f-28fb-47eb-9218-fff189aa9dd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a23452e1-abb0-4c0d-b00b-c4bab11a4397
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5e70688-6965-4fce-8dc2-87f37df2da83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcb8a757-f249-443c-ac50-d77021b4677c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 733d4d45-3e97-4926-b334-d78af089fb24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f1a323c-4725-44ca-b4ab-b2557e6bb10a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f71529fd-e8e0-4984-93a3-71dfa8b0b0bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39451782-35ed-400e-863c-a09cac198ca0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5117dd0-1498-4ada-953e-55e227ad53b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 399fa361-64d0-4732-9be6-404b68443c72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edddf763-ee4c-404e-9673-85ac417944d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b57365ec-8f6f-4eb6-a689-1754888b7561
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fba6fc65-59df-43be-a58a-8de946a624fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1893435-db66-4908-a6c3-c1a3b61a1d6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95aaa717-a2a8-4331-8a90-7dbfcca4b368
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee6330cc-4363-4110-adef-0a4dcc7a6c5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef18b694-6fc3-44b5-8256-a1ba86e30c79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52ec4620-55a8-406d-9ac4-30dca70555ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58b724f3-faa3-417f-8365-3ed390541544
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3d23e7f-2a1f-4222-b393-8b3b74c55ba0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce79346a-56ac-4177-afbe-6d3909c7115e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b6244db-d05f-4d62-9d58-d7443e77190b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8375833-36f2-4fac-bd97-3a183bc716f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f42d13f5-8d9b-445d-b084-9f6b84c29615
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53fd4be7-296b-43f2-94c6-00bbddd6e363
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4ef1f59-7444-4c46-8944-12582ea80b09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3fd09fb-f271-45e9-b618-d6b04a1f5672
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 909cf19f-320b-4128-9a3a-2d6cb26ec530
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d23c821a-13ff-474f-8c27-d7cbbcbd3472
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f2187f7-2ba7-45bc-b93b-4bf92ef72810
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 084552bf-2a7f-4c53-8430-6f4480a09561
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba3252c2-770c-4c24-99f9-81d96a27ad01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a1d2f8e-5e9c-44fe-a632-0bb909493476
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c82ca341-8d35-469b-8591-11794858ca76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9abe6dfa-2578-418d-8156-0de9ba389d2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c39cff0d-a1de-4983-ad71-ef5d410afe00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 212d37fb-487e-404d-b70a-53ba4cc811c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2ad6af1-7a3b-4b4d-87f9-87a10b8e6160
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b44afbc7-bbe1-4d7e-8c0c-8a87b65bc4dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 123584ff-4906-4eae-88bb-3a908c90d473
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f1bbe54-76ce-49b0-bc75-b512d81c6e8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2888b839-21a5-4b17-9474-7cc257c90387
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d92aa743-06e1-4638-bc93-394cabf6630f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f40a7de0-60a5-461b-ae96-bf7ed402e243
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b50819a-69e6-4fb2-acd6-84a75fc21f32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e219b169-3a52-43d9-b4cc-88c83529dd53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 171778b9-fcd5-4a97-a8a5-84f960d733a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30fe0d90-69da-472f-b9bb-099c955e48a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 611d07c5-252e-4062-a98c-860569b14965
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 227c3b46-048f-485a-a571-e3e89c807f27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 236213fc-4483-4c0d-858d-5d7b22124095
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b20dda7c-1b1c-4983-93d8-18918aa373fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06537b9a-fcd3-4772-acf0-d6e43b77fc43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06713a64-2b18-4500-9cee-ec918e966edb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f337c5d-5b5b-46d8-89ba-dda429dd2604
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0af46204-a7f4-4eca-ac65-f60cf4b17821
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6dd9d36-c798-40a1-9f1c-3a190b077420
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d00f14b6-4a74-4ba9-816a-e84f635af86e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e3d5f00-79af-4def-afba-91582528eee5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e787199a-8a7e-4a85-bbd8-94b45a633635
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d509d4df-8d41-473b-9d66-886ad97abef7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 725f1ff9-d6da-49b0-8895-9a1abc4699b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f189c1f4-6f23-417e-b3fc-f20b5f02968d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59e597ac-71aa-46a9-ba8c-61e0678e444c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45015951-a3d7-4d60-bb11-e22d016622e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c1e28ca-9f60-4ac7-8d4a-5a3e25b9a0ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7ac3f63-6d81-4177-8b90-351969e54936
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf8b7ac3-8614-412a-a0ff-ae9be78bdf34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8cd5eec6-7286-43bf-8e8c-f4e0ecfdadea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35a325bb-297f-4c2e-8272-999cc982b33a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6279c254-6d50-45a6-80b1-f66bb72c13f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75e5cfb4-fbd6-4317-a0d5-9d4fee9edde9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fb92074-d36d-4c24-abc8-9114cf2b9371
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04f0054f-58ff-4688-9b1b-e774c46f7cad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 287afe16-ce1c-40c5-a208-f501ebec3d8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 448f69db-c161-4817-8114-921845743edb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49a89603-db3a-405f-88c9-f535c2620325
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13b64ace-81be-4e17-be33-3c1b082bd9ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d4eb872-168b-4976-b04c-b97c4062bc18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 492d4c12-d09a-44ee-b3d5-4d9f467b83c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e56a8ec-9f54-41fd-9091-700e9779903b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed37b926-1ffc-44bf-8572-c9939d8c15c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7461071-0459-4d27-896e-b52f2ea0ae9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51d285f5-1c6e-4936-aeee-253f3f1f78b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09b209e1-f463-4ca4-b14d-5d5131ed7c3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed480f7b-4e71-42aa-9b6f-92f0663ca1f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a64b83d-a235-44fb-86e1-c35963de055e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b64034e-53c9-4637-a9b5-720f8a278049
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94c3e702-fc28-4867-aef8-ce56516d69dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d012c746-ebc0-4e27-92c6-0892688d5c57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d175454c-5a05-4423-8229-e8fb89c93786
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 069bbec8-b1e0-4247-8493-f70d29963907
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d79d0bcb-6712-4eec-85f2-8ec0577a267b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88b7e9f2-e332-427d-984a-e2755be46fae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52a891d7-6367-4967-be24-119a909bc3fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 928b9939-662a-4a4b-884f-408f48a17fef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb1d2b75-b3bf-47e3-aa36-88af74c7f1d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06a23f1b-5f12-483e-b8f0-5896eca3c67e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdcc5524-6c50-4e1c-9c67-185b129e5354
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4eff3a7-4fe9-4106-80a7-9a798d9045ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9f5abff-8b61-43ed-b6a9-f4abca3b177f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f769c628-4bee-4eca-81c5-ffd2158aaa80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f31b0c8-3d26-492e-af0b-a140f7acd0d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f2a5005-52cf-4dd4-9629-c285ff02815d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 857e6cd7-4b8a-4bea-9e50-bc78a1a87308
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3885d30d-b19b-4f4d-bea0-fefcf2b6790a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da80c19d-df7a-4707-b3e0-0ce7c6fa8d14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abff1f39-0d6d-4049-9329-1274783a89ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ffba07b-a48b-4d5c-82fc-800d5c30e47c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7428e908-d4d2-4edd-8b5c-23f3453cc151
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b7e29e1-4688-490e-933a-00f49b58f2cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5971b7f-b9f1-4330-8aad-6a39dc0ba41f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd534286-1b58-48bc-b776-3ca28ed4deaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67c0f481-867d-4d5e-86e6-7e0ebc5a1181
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3ff5de3-79e5-4025-960e-17bc1edc0472
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0388a7eb-4cd8-4ff2-978b-43a398f5b043
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eab14b04-8e87-404b-8d33-7d9d9fbdb3f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87a0ca35-082f-4aec-b05e-8c230a59462a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78992215-4f3b-4d61-bb80-352afdd42b96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77962af1-d29f-4704-9471-f1bd715ae8fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bcf27493-bae7-47be-948f-5140f7ea9f9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56bf33cd-8c05-4345-b2dd-92639487eae7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba0a7e72-7b54-44e9-b1ea-678a1becda18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46d4d2a6-3c3c-4966-b11c-c379882b0f6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4f79865-e26b-4bb4-8419-d5d41b17c632
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9063461-3429-4fb0-88b0-8681ba55f3e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1feae152-ee6d-457a-9200-9ba9018f3d23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8770159a-3943-445f-82b2-b1f96d392d12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fa9bf23-2752-4bd2-8141-63bab7699fec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1316c5dc-1db2-4e76-8cbb-9e2fc64f2971
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1817a6a0-8ce0-4096-88d4-e62363de786f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9687c190-1824-4b01-9d9e-ba19a3dc87e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d726390-40c6-46dd-bb42-8fa8fffe9a65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b7b683c-79a4-428d-9d5c-d2d8f4e35f81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b14e835f-ba48-48ee-af38-d5e94118a3b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 121e62da-29f0-4e3e-b5af-794825658bd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46fad775-19a2-4158-8dc2-a914587c0a7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b725d55-6034-4262-945f-9229de5870e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b392b70a-bb4b-4ec3-a2d8-b5ccb3696038
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e24a24f-3269-4b44-8c0b-f61aca135b4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1516436-7ab5-42dc-b558-af3b3c331fbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 075e2595-5d22-4290-9cf5-ba51823d1547
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96e8799b-a687-48c5-896a-66a25bc2c3f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 375b7557-5a72-4a1a-90c4-15e41fbf110f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 452ceec0-5cb9-47e3-a317-5f4f484580a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3775aba8-2985-4040-8d64-7a265a7db8a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6de9aeec-ff4e-4bf1-8804-7d63a7a9646f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77550360-640c-4f13-a03b-ec9297c4b500
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 247931bd-b7a8-4881-ba53-e97d077295ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1efc8757-e4f5-4b28-9797-13ece67de92e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8c855b3-b52a-4772-8590-ff7e6b3b834a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 618c1ba7-5c88-4231-9543-b0ac0289a8bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5bb5ad5-3167-4878-a36c-9b09bf4225c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcf093d9-27e3-4925-bbc3-e88a95f1c5b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e59c76f5-9532-40bc-bb9f-05be8e55b5f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3c53b14-003d-476d-9d77-d1066609f66f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73996f59-9ccc-43cd-a738-c0af7e3206b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ae04277-c83f-449e-ac04-e06ea46cb0d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08fcc24b-1738-4be4-9b75-de736b131c35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e297cd1f-2de1-472f-b5f7-3fb1fcfbc58e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 453017c9-47d7-43ee-a9df-f8f443b614f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b3fd8c6-b752-4c38-9a8a-4824a0ff7e9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cfbd865-a9aa-4df3-bc55-260ac2102b5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbef3373-8ccf-4202-9632-49571b8507eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbdb781c-723e-45c0-b62f-49016d240f3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d36e42ca-b436-41d9-817f-73f1600ba3fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7ea86e7-a8b7-41d6-b9cc-adf22191da45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 293d3c35-2cab-42b2-908b-35ee7442049d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52a3aa26-0054-42f3-b42d-2dfa7d75a718
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e383a17-6ee5-4d4d-aba5-6a747a1be9d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24812196-1ed0-44f2-b1a7-e11d24fcefa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed167ee1-1e3b-489e-a236-3ec622405e02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b9ed47a-4609-4cea-8924-29f3994d3755
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98b42562-609f-4cd5-ac52-1250f42f7796
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11b21e71-849e-4563-a141-9676574a967c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b96f199a-d251-4541-a54e-ee511ef57341
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7ae0f89-5648-4703-83c7-7393c82eeb47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea31c3b5-da39-41bc-8d4e-7839407226e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d1b77bf-69fc-45c1-a5e6-9a17027164f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6573a92c-7cfc-4121-ae0a-49c436e13712
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8fe7f6e-a13d-4160-9620-2655b9d94b90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97b13ad6-668b-4354-b945-1141fb2f55ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a86d8613-0576-4faf-9037-3af8cbb7dfd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0d87dfa-05fa-48a1-8202-08a2e7e68a02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 286c8e29-e660-43c4-b91a-5de5e268ce39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bdc6207-ede4-4177-bdec-99a1da0369a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cdf1387-dd12-4053-a429-9f065a0c7144
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 126b15d2-6e93-4dcc-a769-6bcc0d095dd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d44cac4-af4e-48d7-8fdc-63c7ec6d27cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ae4cac5-79ae-4e28-8572-fda80f959576
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 121817a9-bf49-4096-af07-0946072f0e91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79d55e1d-d0dd-4574-83dd-deb173ad35d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74d6093b-9c85-4d9c-b22b-99ef229f4453
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e69363f4-6b71-46b5-9e0a-90862829e21b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6cc74e67-fa5c-4457-9afb-a9308527e6c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c7543c7-f4da-4e4d-99ac-21ee502d23cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f37f2e65-4bd3-4eab-9e5d-103c8f6bb293
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16a5072c-0b98-4f3e-9a9a-cbeef1766b36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 506d768b-3019-478c-a506-30b6b889cf2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f81eaff-a05b-45f0-96fa-4e5bddf448fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9c872a3-7ec1-46d4-a306-9f114966cea4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56c7af8d-e5d8-4aa2-8044-60de41240f5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9bcd046-8c1f-4a10-8caf-a76163507d9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10d678ac-08e9-4de3-bfb1-dc066aed4f8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca6e8597-1f5c-4950-a168-96da344e8439
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9247e27d-aa0f-412f-b887-1ddf612cb64b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82b7bf9e-377d-464d-a88d-e2e565801f63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb630e07-e6a2-4312-812e-322b74519934
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce55c36e-df08-4429-90d6-2ba2c1c50ebf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ff982d8-cac6-424d-8684-e985e6bbfff2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0146bd5-5f0f-49c0-a30a-60a511094b5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 312d380e-2333-46ce-b44e-27db694d4772
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 898fc243-3e16-46e7-8a7a-1fdbdf6dbaee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be6d6950-20f4-489d-aae2-e7474a668960
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b219e6b-59fe-4962-90ac-32881c5c9987
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6a1af1d-7918-4a6f-a199-1b9c282d68a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e475942-a30f-4001-9fda-a545e2c388ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46e21b86-fcdc-4828-a7f3-953d16b1d962
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 889fe9c3-cebf-45bf-aecc-36984caf54e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3351e5a3-87b4-4775-b9c5-b96cd69de0ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c68c947-5c59-47a8-a1ac-0b48030067d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a687d71-be1e-4ecb-b158-d90d541b1e58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e0d49a0-22fd-40b4-8726-0b99e3a09246
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00d4af8a-4bd3-4421-8adf-5b81d43a6954
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7182536b-9f7e-4a8b-b284-072d51e5b3ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5eab4174-bf57-4ad0-94d3-c6d8fa6146c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c470906-4e3f-4690-a08f-f4154381b178
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 238e1ea2-a3fe-4002-8c68-0753b9af2e63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 786fb216-ebd0-402c-85cd-c2521f319b42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a500bf5-a072-45df-a215-e79c9bfe3c1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1da4d6a9-bba7-4d67-8e45-f0775430700b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8db497b-e119-4046-a99c-2f91bf20245b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e6bde26-661c-4fb3-b93c-a1a3c31c1d6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cd5d898-6660-46dc-ab71-f40be08dc402
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18ef8d15-f590-42be-a2b7-5d2ce5f96bd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56806912-dc80-4a58-bbb4-9815acfd7674
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76c6ae48-f303-40a0-bff2-c28e9f7284ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 707de06d-da76-43d2-bf15-7e87666bf5b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32b08186-9279-4e52-a104-7f576f1ce86b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44f48919-d91d-459e-93b1-ad6799cdee7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 739d12f2-b37b-4c44-bf74-a8275962a036
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff82862d-9319-4c02-9d09-7e855fe497e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b719db9f-278f-40fd-8c15-03060d33c4a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2905722f-93c0-464f-8955-1c2195d768d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c6bfaad-3a81-4788-b0f8-289f00e75f2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77c096f0-751c-44d2-9060-e1c625c033dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44c4b42f-194f-4630-97a9-21f44d12c209
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfcbab94-092b-4a12-994e-46fdd1d34bc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cefac07-2776-4e07-9b14-23f2b31d373f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d3b33ac-1473-42b5-89c0-3fff3cf7e700
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e340059f-4d6a-4373-9a00-d650fafb415d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 255aeaa6-3766-4ebd-b3e0-b8dd91103bb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 266f9f2d-3ae0-4a2f-b370-e9d02f61c88a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bd432bb-9900-46b1-9bfd-c395ecdd3c7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e4bb4f1-432b-4ff4-8ffc-be050c3d571e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3dac299-fb5c-43c3-aead-f4874332a0d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbe3e169-1bef-41a9-b116-b3602c9fa911
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ab2277d-e7f1-4833-9486-aa9477399999
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ca93ef8-b31f-47da-8e1e-a4776cd5edc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3e3de78-ed2c-415c-83c7-9d77c2fa160d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a4be4b5-d038-4d3f-be62-47dbd93eb544
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55f98a99-a83d-42fb-89da-2ab19843a106
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f32c6d0a-5146-4b18-b03d-b870a1523ed0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0de2c4fd-f9c8-4d29-9bc6-f3c41cc51cee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cd83688-90a2-4034-b56a-c69cc45b71ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bc5766d-ce16-40d0-964a-ac1267c4379d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b28a9df1-3668-46ca-8347-57636ce7c5dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05ad98c8-64ce-440d-84c7-0625cdbec5cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bc9916a-ed79-4dbb-87df-53c62b076620
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10361a9b-9a94-45b7-b676-ee8748d3ad05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6a3df80-1474-4834-84f5-c369bdc3bf6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e95f2c2-d025-4784-860b-51152ba034fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22921cfc-e955-4c85-9543-21f10e0a3c26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20ec82ca-4ba3-4036-884a-9c83bee0dc8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c7d9f38-4386-4e11-a425-33f8ec93873c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00cc705e-fbb6-4772-8e44-943e4a15f085
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b81c98b-f33a-4039-8e33-c2635a908042
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87d843b8-6287-42f0-a1dc-57656adc95d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 741da069-4639-43c3-9a96-f1361055f763
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c993ad33-67d8-48ef-9f99-547263e381b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98400502-241d-4acb-9f0c-35f9868bd940
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ceb19843-ffe8-40cb-8715-002a585c029b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7568e36-fb4e-4936-9800-7730853dd897
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95559130-9b02-44cf-bc7a-db269b9354cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message deb76ae4-4f21-45f8-b04a-5c8d3ddbb1d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e39a624-15bd-4564-8239-a43248eab8de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae6fba23-7834-48fc-9758-6533304b4cb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2642aa9-9c8b-4811-a7f0-dba5d1a97e83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ce5f769-d19f-4875-bb36-48cdce163ae7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad661e79-bb28-4cbc-b39b-e265ae10accc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a015910-dde8-4b04-aec6-e2d5138bdb16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47b1e8ae-dcc2-444f-b8e6-0307fe12153a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8809d3a-1465-4110-aa9f-e1afb9940118
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5ad0dd2-0414-4321-a1ab-34757531068a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93c48608-e807-436e-861e-b84eb23cbefe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b94dfb95-a996-4272-95c8-2d911d0ad9c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 968c6f42-d2c4-4871-b35a-e0fda7b68bcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7760127c-65ad-45a8-892c-cee5e913960a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53b983dc-7b57-46ad-bbe6-b094569c5391
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 920c4690-34ab-4037-aa58-ca26d0998276
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e19982aa-ed5a-4601-b9fe-b90e849c3531
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31993a5e-2380-4ab5-b2e1-5617599cf8fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4be5e49b-5adb-4802-9239-2e948f76ec9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c57fb806-f0ac-4ba7-8bdb-9fe9e0b1874a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5fd3f76-4d89-491b-8863-ec20d4ceeeed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84d0152d-392a-40b5-a7f4-138f57b542d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c235746-aa3b-4256-a7ce-370bce3f20af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd76b14f-349f-4470-93ba-c37962517657
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc8cfaab-dbc6-4ab4-8715-c4ffc7997b8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0640d78d-b8ba-4b72-bb44-a10a32fd9cb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fca64248-33fa-46e9-b421-76bac5662923
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d491df4d-3c0a-4f4a-a23d-f447f2e3c0f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f02ea4d-12b4-4e30-a9e1-a7b5bd0f3308
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f6423db-4d61-42c2-8818-be53c1b163c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39a06be5-147c-426e-8944-c0f161957041
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77d3df4f-2c4a-433b-aa5a-4366c991b5ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b714a975-d7e2-4886-8b85-068bb703df6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ae323d8-b80a-4285-b255-112afab9db0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de9392af-e953-4406-a9cf-022ca31ec88a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ce6801b-a492-4ca4-81f3-002135159424
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be55d4e1-fa85-470c-a657-edeb07bbf3cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45197e7d-7624-44c5-be31-fec759bfefea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96a5a10a-2963-4072-826c-f44778dba9a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b38215f-d3c1-432f-8580-54d8146f5836
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c68ce6d5-7034-4231-82e7-58e36f182114
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38df2d3c-a075-4f67-81e5-a7ec4dd5cd01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06b66836-52f8-4ca2-a822-d7075a8226bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be88fe67-169e-46f7-901a-8db35d9aab81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f23accd-495f-460b-9ebd-07bf53424ecd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ce10975-d818-49a4-847c-6e52556db4b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6d6d392-13c3-4bc1-900b-e83c20e458c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce407044-dec0-4f07-8372-0702c5b5467d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a274342-5745-412a-b2c7-f1fc4da0400e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59384bb5-0e29-45df-b1d4-237f9b8c5333
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2705b7d3-5a25-4e57-bf0b-e4255c2c587d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f474dbc-39dc-4861-bb7f-4277d0e7d672
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6ef8dfb-146a-4e0d-b828-9854ad311486
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f1b8f27-dbc8-45ad-87e0-e5186eb6097c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16b8c868-3176-4d74-af9e-08178be7b16d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac9aee42-63a2-4491-b3f7-f916268e26ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65806704-f28c-4c60-828d-d149f65cfdd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97b71309-045d-4a96-8a9e-f26c653e3ad4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc89b459-f2bc-4b52-8cba-5651cbfeac46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76a5b309-4d26-4b1e-bdc0-16c722ab4f6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d7fe183-b48c-48ff-922a-7ed87ece8c69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d433723b-073e-43b4-9475-ad0fbfb59025
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d2155af-32df-4255-a0b3-229d25c795ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 526af37f-6c33-4cfd-a4cd-02eab300eeaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f9ebd89-99f4-40ff-ad3f-c4f050c284fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbd3c633-b6c2-4109-9c5a-aeb28e775dd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b97ad570-5031-4595-91bf-6c38574d2bdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d360c70e-0a36-4416-8977-3143107ededb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message becc082d-a971-400c-9903-fc88aac51350
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e807f08e-2f0b-41a0-9b46-73b298d46b84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a590e05-ee44-4c36-94ad-be00a3db7edf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b338fbe8-2616-450e-b639-34f9c86065dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 178b75fc-4dd6-4b1c-b229-9df30b9ad16e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c692a5f-9eef-4185-916c-7fea47182b44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55bedd24-27a5-4ffc-afb8-7dcb0a19f0b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a015f51f-dd28-4d48-94bd-03f9d6b1265b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35ebda9a-82da-4fd4-a3eb-6ab71fac1bb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8efc3d5c-93fb-40cc-9e57-c8ebaf065bee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e9fa42e-d1c0-476e-8056-71f2a0dabba9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8449f83-2ae1-42e4-a32d-af21a424cea0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e7af544-8b47-4b11-afb1-0043c1f40b8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c70edc24-13b9-4c81-9f96-40d0da602728
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message adf9a675-7a58-4522-95bb-9bfa35789e16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5da6e51f-4cb4-425d-8194-3844702ccd94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6dfa4c3-767e-4dca-a401-5bff2b436467
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8307705-95ff-43d0-8880-e422b2d6198c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fb67126-d780-4624-afb1-2016bc3e6acf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f651a7ab-b75b-44c2-83cb-1da0531190b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f0f3791-938d-48c0-8df0-3c18bcf3f1c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f63a611e-5b7b-4192-ab2a-958f0ba58ddf
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_3
Server: localhost:8686
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_3
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_3/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_3/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_3/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_3/test_labels.txt

📊 Raw data loaded:
   Train: X=(4483, 24), y=(4483,)
   Test:  X=(1121, 24), y=(1121,)

⚠️  Limiting training data: 4483 → 800 samples
⚠️  Limiting test data: 1121 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_3 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 2 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0743 (↓), lr=0.001000
   • Epoch   2/100: train=0.0843, val=0.0745, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0833, val=0.0754, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0827, val=0.0758, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0825, val=0.0757, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0807, val=0.0774, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 2 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0195
   Val:   Loss=0.0743, RMSE=0.2727, R²=0.0009
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2486, R²: 0.0004

============================================================
🔄 Round 4 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0756 (↓), lr=0.000250
   • Epoch   2/100: train=0.0830, val=0.0757, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0829, val=0.0756, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0828, val=0.0757, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0827, val=0.0757, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0819, val=0.0757, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 4 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0029
   Val:   Loss=0.0756, RMSE=0.2750, R²=-0.0027
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2480, R²: 0.0040

📊 Round 4 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2484, R²: 0.0022

============================================================
🔄 Round 8 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0798 (↓), lr=0.000063
   • Epoch   2/100: train=0.0813, val=0.0799, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0812, val=0.0799, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0812, val=0.0800, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0811, val=0.0800, patience=4/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0810, val=0.0800, patience=10/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 8 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0022
   Val:   Loss=0.0798, RMSE=0.2826, R²=-0.0026
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0026

============================================================
🔄 Round 12 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0856 (↓), lr=0.000016
   • Epoch   2/100: train=0.0798, val=0.0856, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0798, val=0.0856, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0798, val=0.0856, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0798, val=0.0856, patience=4/15, lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0797, val=0.0856, patience=10/15, lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 12 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0030
   Val:   Loss=0.0856, RMSE=0.2925, R²=0.0041
============================================================


============================================================
🔄 Round 14 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0800 (↓), lr=0.000004
   • Epoch   2/100: train=0.0810, val=0.0800, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0810, val=0.0800, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0810, val=0.0801, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0810, val=0.0801, patience=4/15, lr=0.000004
   📉 Epoch 7: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0810, val=0.0802, patience=10/15, lr=0.000002
   📉 Epoch 15: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 14 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=0.0036
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0153
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0029

============================================================
🔄 Round 15 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 15 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0005
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0069
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 18 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 18 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0030
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0004
============================================================


============================================================
🔄 Round 19 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0641 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0641, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0641, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0642, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0642, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0643, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0641)

============================================================
📊 Round 19 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0038
   Val:   Loss=0.0641, RMSE=0.2532, R²=-0.0348
============================================================


============================================================
🔄 Round 21 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 21 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0031
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0015
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 25 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 25 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0034
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0027
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 30 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 30 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=0.0041
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0034
============================================================


============================================================
🔄 Round 31 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 31 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2810, R²=0.0024
   Val:   Loss=0.0888, RMSE=0.2979, R²=0.0062
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

📊 Round 31 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

📊 Round 31 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

📊 Round 31 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

📊 Round 31 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 38 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 38 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=0.0033
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0001
============================================================


============================================================
🔄 Round 40 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 40 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0048
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0044
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 42 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 42 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0039
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0035
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

📊 Round 42 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 47 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 47 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0050
   Val:   Loss=0.0733, RMSE=0.2707, R²=-0.0078
============================================================


============================================================
🔄 Round 49 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 49 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0022
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0064
============================================================


============================================================
🔄 Round 53 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 53 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0023
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0047
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 54 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 54 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0036
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0011
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 58 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 58 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0021
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0054
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 58 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 61 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 61 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0026
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0006
============================================================


============================================================
🔄 Round 62 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 62 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0019
   Val:   Loss=0.0841, RMSE=0.2899, R²=0.0007
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 62 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 62 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 67 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 67 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0040
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0026
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 69 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 69 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0043
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0124
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 69 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 73 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 73 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0041
   Val:   Loss=0.0908, RMSE=0.3013, R²=0.0004
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 73 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 73 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 73 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 79 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 79 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0022
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0001
============================================================


============================================================
🔄 Round 80 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 80 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0036
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0018
============================================================


============================================================
🔄 Round 83 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 83 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0040
   Val:   Loss=0.0744, RMSE=0.2728, R²=-0.0034
============================================================


============================================================
🔄 Round 84 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 84 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=0.0037
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0028
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 84 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 87 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 87 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0017
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0073
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 87 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 91 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 91 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0034
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0011
============================================================


============================================================
🔄 Round 92 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 92 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0011
   Val:   Loss=0.0715, RMSE=0.2675, R²=-0.0469
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 93 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 93 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0036
   Val:   Loss=0.0738, RMSE=0.2717, R²=-0.0100
============================================================


============================================================
🔄 Round 95 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 95 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0040
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0003
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 96 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 96 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0038
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0022
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 98 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 98 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0042
   Val:   Loss=0.0892, RMSE=0.2986, R²=-0.0045
============================================================


============================================================
🔄 Round 99 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 99 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0014
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0091
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0028

============================================================
🔄 Round 100 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 100 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0033
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0021
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0028

📊 Round 100 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 106 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 106 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0031
   Val:   Loss=0.0906, RMSE=0.3010, R²=-0.0055
============================================================


============================================================
🔄 Round 107 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 107 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0017
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0012
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 107 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 109 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 109 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0056
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0063
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 112 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 112 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0010
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0084
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 112 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0028

============================================================
🔄 Round 116 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 116 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0021
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0003
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0028

============================================================
🔄 Round 121 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 121 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0021
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0057
============================================================


============================================================
🔄 Round 123 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 123 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0031
   Val:   Loss=0.0870, RMSE=0.2949, R²=0.0041
============================================================


============================================================
🔄 Round 125 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 125 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0023
   Val:   Loss=0.0719, RMSE=0.2681, R²=-0.0026
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0028

📊 Round 125 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0028

📊 Round 125 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0028

📊 Round 125 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0028

📊 Round 125 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0028

📊 Round 125 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0028

============================================================
🔄 Round 135 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 135 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0034
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0076
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0028

============================================================
🔄 Round 137 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 137 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0024
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0008
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0028

============================================================
🔄 Round 139 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 139 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0030
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0042
============================================================


============================================================
🔄 Round 141 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 141 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0019
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0088
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0028

============================================================
🔄 Round 142 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 142 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0027
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0057
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0028

============================================================
🔄 Round 144 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 144 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0036
   Val:   Loss=0.0760, RMSE=0.2756, R²=-0.0075
============================================================


============================================================
🔄 Round 145 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 145 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0026
   Val:   Loss=0.0716, RMSE=0.2675, R²=0.0071
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0028

📊 Round 145 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0028

============================================================
🔄 Round 148 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 148 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0055
   Val:   Loss=0.0761, RMSE=0.2758, R²=-0.0062
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0028

============================================================
🔄 Round 149 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 149 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0026
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0058
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0028

📊 Round 149 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0028

============================================================
🔄 Round 151 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 151 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0035
   Val:   Loss=0.0797, RMSE=0.2822, R²=0.0023
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 151 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 155 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 155 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0040
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0016
============================================================


============================================================
🔄 Round 157 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 157 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0019
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0093
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 159 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 159 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0040
   Val:   Loss=0.0871, RMSE=0.2952, R²=0.0015
============================================================


============================================================
🔄 Round 160 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0933, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 160 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0045
   Val:   Loss=0.0933, RMSE=0.3055, R²=-0.0000
============================================================


============================================================
🔄 Round 161 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 161 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0030
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0024
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0028

============================================================
🔄 Round 165 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 165 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0031
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0011
============================================================


============================================================
🔄 Round 167 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 167 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0042
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0057
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 168 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0696 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0697, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0697, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0697, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0697, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0696)

============================================================
📊 Round 168 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0039
   Val:   Loss=0.0696, RMSE=0.2639, R²=-0.0012
============================================================


============================================================
🔄 Round 169 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 169 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2828, R²=0.0033
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0037
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 171 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 171 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0047
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0020
============================================================


============================================================
🔄 Round 173 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 173 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0022
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0074
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0028

============================================================
🔄 Round 176 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 176 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0030
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0045
============================================================


============================================================
🔄 Round 177 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 177 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0038
   Val:   Loss=0.0890, RMSE=0.2984, R²=0.0018
============================================================


============================================================
🔄 Round 180 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 180 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0037
   Val:   Loss=0.0833, RMSE=0.2885, R²=0.0023
============================================================


============================================================
🔄 Round 183 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 183 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0045
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0003
============================================================


============================================================
🔄 Round 184 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 184 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0008
   Val:   Loss=0.0740, RMSE=0.2721, R²=-0.0626
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 184 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 184 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 187 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 187 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0044
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0022
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 188 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 188 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0038
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0015
============================================================


============================================================
🔄 Round 189 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 189 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0028
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0032
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 190 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 190 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0045
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0059
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0028

📊 Round 190 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0028

============================================================
🔄 Round 193 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 193 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0044
   Val:   Loss=0.0829, RMSE=0.2878, R²=-0.0254
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 193 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 193 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 193 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 197 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 197 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0032
   Val:   Loss=0.0802, RMSE=0.2833, R²=-0.0197
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 197 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 199 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 199 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=0.0039
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0181
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 202 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 202 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0006
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0047
============================================================


============================================================
🔄 Round 204 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 204 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0025
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.0050
============================================================


============================================================
🔄 Round 207 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 207 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0028
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0060
============================================================


============================================================
🔄 Round 209 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 209 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0054
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0041
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 209 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 209 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 214 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 214 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0019
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0096
============================================================


============================================================
🔄 Round 215 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 215 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0030
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0024
============================================================


📊 Round 215 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 215 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

📊 Round 215 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

📊 Round 215 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

📊 Round 215 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 223 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 223 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0046
   Val:   Loss=0.0912, RMSE=0.3019, R²=-0.0002
============================================================


============================================================
🔄 Round 225 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 225 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0020
   Val:   Loss=0.0773, RMSE=0.2779, R²=-0.0042
============================================================


============================================================
🔄 Round 226 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 226 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0046
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0087
============================================================


📊 Round 226 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 228 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 228 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0039
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0017
============================================================


📊 Round 228 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 230 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 230 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0044
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0017
============================================================


📊 Round 230 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 234 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 234 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0040
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0043
============================================================


============================================================
🔄 Round 235 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 235 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0033
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0043
============================================================


📊 Round 235 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 236 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0938, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 236 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0042
   Val:   Loss=0.0938, RMSE=0.3063, R²=-0.0040
============================================================


============================================================
🔄 Round 237 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 237 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0053
   Val:   Loss=0.0730, RMSE=0.2702, R²=-0.0051
============================================================


📊 Round 237 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

📊 Round 237 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

📊 Round 237 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 246 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 246 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0035
   Val:   Loss=0.0745, RMSE=0.2730, R²=0.0035
============================================================


📊 Round 246 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 250 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 250 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0044
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0003
============================================================


📊 Round 250 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 255 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 255 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=0.0042
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0005
============================================================


📊 Round 255 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 255 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 255 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 259 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 259 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0022
   Val:   Loss=0.0728, RMSE=0.2698, R²=0.0044
============================================================


📊 Round 259 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 259 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 259 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 262 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 262 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0041
   Val:   Loss=0.0909, RMSE=0.3015, R²=0.0015
============================================================


============================================================
🔄 Round 264 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 264 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0037
   Val:   Loss=0.0728, RMSE=0.2698, R²=-0.0021
============================================================


📊 Round 264 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 266 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 266 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0020
   Val:   Loss=0.0911, RMSE=0.3018, R²=0.0018
============================================================


📊 Round 266 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 266 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 269 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 269 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0061
   Val:   Loss=0.0775, RMSE=0.2783, R²=-0.0111
============================================================


============================================================
🔄 Round 270 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 270 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=0.0059
   Val:   Loss=0.0750, RMSE=0.2738, R²=-0.0069
============================================================


============================================================
🔄 Round 274 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 274 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0021
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0092
============================================================


📊 Round 274 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 275 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 275 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0037
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0040
============================================================


📊 Round 275 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 275 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 282 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 282 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0043
   Val:   Loss=0.0745, RMSE=0.2730, R²=0.0002
============================================================


============================================================
🔄 Round 283 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 283 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0033
   Val:   Loss=0.0818, RMSE=0.2861, R²=-0.0030
============================================================


📊 Round 283 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 283 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 287 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 287 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0015
   Val:   Loss=0.0748, RMSE=0.2736, R²=0.0072
============================================================


📊 Round 287 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 287 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

📊 Round 287 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 291 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 291 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0032
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0081
============================================================


============================================================
🔄 Round 292 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 292 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0008
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0147
============================================================


📊 Round 292 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 294 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 294 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0029
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0040
============================================================


📊 Round 294 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 296 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 296 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0035
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0054
============================================================


📊 Round 296 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 296 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 299 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 299 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0053
   Val:   Loss=0.0815, RMSE=0.2856, R²=-0.0036
============================================================


📊 Round 299 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 303 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 303 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0001
   Val:   Loss=0.0877, RMSE=0.2962, R²=0.0143
============================================================


📊 Round 303 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

📊 Round 303 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

📊 Round 303 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 303 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 303 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 315 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 315 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0038
   Val:   Loss=0.0763, RMSE=0.2763, R²=0.0024
============================================================


📊 Round 315 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 315 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0028

📊 Round 315 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 322 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 322 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0043
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0030
============================================================


📊 Round 322 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 324 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 324 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0039
   Val:   Loss=0.0806, RMSE=0.2840, R²=-0.0048
============================================================


============================================================
🔄 Round 326 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 326 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0036
   Val:   Loss=0.0859, RMSE=0.2930, R²=0.0034
============================================================


📊 Round 326 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 326 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

📊 Round 326 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

📊 Round 326 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

📊 Round 326 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 337 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 337 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0051
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0054
============================================================


📊 Round 337 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

📊 Round 337 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 340 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 340 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0051
   Val:   Loss=0.0793, RMSE=0.2817, R²=-0.0026
============================================================


============================================================
🔄 Round 341 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 341 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0035
   Val:   Loss=0.0840, RMSE=0.2899, R²=0.0034
============================================================


📊 Round 341 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 342 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 342 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0034
   Val:   Loss=0.0896, RMSE=0.2993, R²=0.0020
============================================================


📊 Round 342 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

📊 Round 342 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 347 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 347 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0032
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0041
============================================================


📊 Round 347 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 348 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 348 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0036
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0038
============================================================


============================================================
🔄 Round 349 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 349 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0019
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0082
============================================================


============================================================
🔄 Round 350 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 350 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0042
   Val:   Loss=0.0833, RMSE=0.2887, R²=0.0007
============================================================


============================================================
🔄 Round 351 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 351 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0023
   Val:   Loss=0.0744, RMSE=0.2727, R²=0.0097
============================================================


📊 Round 351 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

📊 Round 351 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

📊 Round 351 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

📊 Round 351 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 356 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 356 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0045
   Val:   Loss=0.0915, RMSE=0.3025, R²=0.0008
============================================================


📊 Round 356 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 358 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 358 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0050
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0026
============================================================


📊 Round 358 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 358 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 364 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 364 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0021
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0016
============================================================


📊 Round 364 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 366 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 366 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0028
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0064
============================================================


============================================================
🔄 Round 367 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 367 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0024
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0079
============================================================


📊 Round 367 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 368 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 368 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0043
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0169
============================================================


📊 Round 368 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 369 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 369 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0043
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0006
============================================================


📊 Round 369 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 371 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 371 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0039
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.0031
============================================================


📊 Round 371 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 372 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 372 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0038
   Val:   Loss=0.0719, RMSE=0.2681, R²=0.0031
============================================================


============================================================
🔄 Round 373 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 373 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0020
   Val:   Loss=0.0711, RMSE=0.2666, R²=0.0101
============================================================


📊 Round 373 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 373 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 373 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 373 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 381 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 381 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0048
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0034
============================================================


📊 Round 381 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 382 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 382 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0043
   Val:   Loss=0.0767, RMSE=0.2769, R²=-0.0365
============================================================


============================================================
🔄 Round 383 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 383 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0035
   Val:   Loss=0.0898, RMSE=0.2997, R²=-0.0025
============================================================


📊 Round 383 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 385 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 385 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0022
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0022
============================================================


📊 Round 385 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

📊 Round 385 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 390 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 390 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0028
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0025
============================================================


📊 Round 390 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

📊 Round 390 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

📊 Round 390 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 393 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 393 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0037
   Val:   Loss=0.0889, RMSE=0.2981, R²=0.0025
============================================================


============================================================
🔄 Round 396 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 396 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0012
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0092
============================================================


============================================================
🔄 Round 397 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 397 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0008
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0063
============================================================


📊 Round 397 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 398 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 398 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0025
   Val:   Loss=0.0872, RMSE=0.2953, R²=0.0073
============================================================


📊 Round 398 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 400 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 400 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0020
   Val:   Loss=0.0788, RMSE=0.2806, R²=-0.0119
============================================================


📊 Round 400 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 401 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 401 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0057
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0077
============================================================


📊 Round 401 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 404 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 404 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0030
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0063
============================================================


📊 Round 404 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 408 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 408 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0047
   Val:   Loss=0.0732, RMSE=0.2705, R²=-0.0018
============================================================


📊 Round 408 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

📊 Round 408 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 410 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 410 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0035
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0076
============================================================


============================================================
🔄 Round 411 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 411 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0040
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0061
============================================================


============================================================
🔄 Round 412 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0700 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0700, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0700, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0700, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0700)

============================================================
📊 Round 412 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0033
   Val:   Loss=0.0700, RMSE=0.2645, R²=0.0006
============================================================


📊 Round 412 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 416 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 416 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0041
   Val:   Loss=0.0738, RMSE=0.2717, R²=-0.0031
============================================================


📊 Round 416 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 416 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 418 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 418 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0024
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0048
============================================================


📊 Round 418 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 421 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 421 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0024
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0052
============================================================


📊 Round 421 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 421 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 424 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 424 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2806, R²=0.0050
   Val:   Loss=0.0893, RMSE=0.2989, R²=-0.0060
============================================================


📊 Round 424 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 424 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 424 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 424 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 433 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 433 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0033
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0015
============================================================


============================================================
🔄 Round 434 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 434 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0071
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0154
============================================================


📊 Round 434 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 435 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 435 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0036
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0021
============================================================


============================================================
🔄 Round 437 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 437 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0030
   Val:   Loss=0.0778, RMSE=0.2788, R²=0.0032
============================================================


📊 Round 437 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 440 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 440 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0040
   Val:   Loss=0.0792, RMSE=0.2815, R²=0.0025
============================================================


📊 Round 440 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 442 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 442 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0016
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0419
============================================================


============================================================
🔄 Round 443 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 443 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2792, R²=0.0014
   Val:   Loss=0.0926, RMSE=0.3043, R²=0.0019
============================================================


📊 Round 443 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 446 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 446 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0014
   Val:   Loss=0.0738, RMSE=0.2717, R²=0.0120
============================================================


📊 Round 446 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 446 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 452 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 452 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0039
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0022
============================================================


📊 Round 452 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0028

📊 Round 452 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0028

📊 Round 452 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0028

📊 Round 452 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0028

============================================================
🔄 Round 457 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 457 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0041
   Val:   Loss=0.0884, RMSE=0.2973, R²=0.0009
============================================================


============================================================
🔄 Round 459 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 459 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0019
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0037
============================================================


📊 Round 459 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0028

📊 Round 459 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0028

============================================================
🔄 Round 464 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 464 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0039
   Val:   Loss=0.0746, RMSE=0.2731, R²=-0.0144
============================================================


📊 Round 464 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0028

📊 Round 464 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0028

📊 Round 464 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0028

============================================================
🔄 Round 467 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 467 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0013
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0009
============================================================


📊 Round 467 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0028

============================================================
🔄 Round 470 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 470 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0029
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0067
============================================================


============================================================
🔄 Round 471 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 471 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0014
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0055
============================================================


📊 Round 471 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0028

📊 Round 471 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0028

📊 Round 471 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0028

============================================================
🔄 Round 478 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 478 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0042
   Val:   Loss=0.0809, RMSE=0.2843, R²=-0.0035
============================================================


📊 Round 478 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0028

📊 Round 478 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0028

============================================================
🔄 Round 480 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 480 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0046
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0028
============================================================


📊 Round 480 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 485 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 485 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0034
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0013
============================================================


📊 Round 485 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 486 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 486 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0040
   Val:   Loss=0.0760, RMSE=0.2756, R²=0.0020
============================================================


📊 Round 486 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 488 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 488 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2810, R²=0.0035
   Val:   Loss=0.0886, RMSE=0.2976, R²=0.0034
============================================================


📊 Round 488 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 488 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 490 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 490 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0028
   Val:   Loss=0.0748, RMSE=0.2734, R²=-0.0080
============================================================


📊 Round 490 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 491 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 491 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0034
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0001
============================================================


📊 Round 491 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 493 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 493 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0022
   Val:   Loss=0.0739, RMSE=0.2719, R²=-0.0166
============================================================


📊 Round 493 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 493 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 493 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 496 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 496 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0057
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0038
============================================================


📊 Round 496 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 503 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 503 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0034
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0014
============================================================


📊 Round 503 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 503 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 503 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 503 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 503 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 503 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 514 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 514 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0043
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0004
============================================================


📊 Round 514 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 515 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 515 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0023
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0036
============================================================


📊 Round 515 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 516 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 516 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0037
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0010
============================================================


============================================================
🔄 Round 517 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 517 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0048
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0093
============================================================


📊 Round 517 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 518 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 518 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0031
   Val:   Loss=0.0895, RMSE=0.2992, R²=0.0060
============================================================


📊 Round 518 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 525 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 525 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0014
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0144
============================================================


📊 Round 525 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 527 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 527 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0021
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0019
============================================================


📊 Round 527 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 530 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 530 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0034
   Val:   Loss=0.0715, RMSE=0.2673, R²=-0.0048
============================================================


📊 Round 530 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 531 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 531 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0047
   Val:   Loss=0.0807, RMSE=0.2842, R²=-0.0012
============================================================


============================================================
🔄 Round 533 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 533 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0034
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0066
============================================================


============================================================
🔄 Round 534 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 534 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2797, R²=0.0035
   Val:   Loss=0.0913, RMSE=0.3022, R²=0.0041
============================================================


============================================================
🔄 Round 535 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 535 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0026
   Val:   Loss=0.0734, RMSE=0.2708, R²=0.0011
============================================================


📊 Round 535 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 538 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 538 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0017
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0054
============================================================


============================================================
🔄 Round 539 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 539 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0039
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0032
============================================================


📊 Round 539 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 541 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 541 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0051
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0021
============================================================


============================================================
🔄 Round 542 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 542 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0026
   Val:   Loss=0.0736, RMSE=0.2713, R²=0.0087
============================================================


📊 Round 542 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 544 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0702, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 544 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0012
   Val:   Loss=0.0702, RMSE=0.2649, R²=-0.0001
============================================================


📊 Round 544 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 547 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 547 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0049
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0019
============================================================


📊 Round 547 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

📊 Round 547 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 551 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 551 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0043
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0010
============================================================


📊 Round 551 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 553 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 553 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0027
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0043
============================================================


📊 Round 553 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 562 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 562 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0032
   Val:   Loss=0.0859, RMSE=0.2930, R²=0.0058
============================================================


📊 Round 562 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

📊 Round 562 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 564 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 564 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=0.0024
   Val:   Loss=0.0749, RMSE=0.2737, R²=0.0086
============================================================


============================================================
🔄 Round 565 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 565 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0026
   Val:   Loss=0.0844, RMSE=0.2906, R²=0.0052
============================================================


📊 Round 565 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

📊 Round 565 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

📊 Round 565 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 570 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 570 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0044
   Val:   Loss=0.0775, RMSE=0.2785, R²=-0.0223
============================================================


📊 Round 570 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 571 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0700 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0700, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0700, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0700, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0701, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0700)

============================================================
📊 Round 571 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0021
   Val:   Loss=0.0700, RMSE=0.2646, R²=-0.0140
============================================================


============================================================
🔄 Round 573 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 573 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0042
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0009
============================================================


============================================================
🔄 Round 575 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 575 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0058
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0040
============================================================


📊 Round 575 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

📊 Round 575 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

📊 Round 575 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 582 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 582 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0036
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0079
============================================================


📊 Round 582 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 584 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 584 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0019
   Val:   Loss=0.0802, RMSE=0.2831, R²=-0.0063
============================================================


============================================================
🔄 Round 586 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 586 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0035
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0084
============================================================


📊 Round 586 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

📊 Round 586 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0031

============================================================
🔄 Round 589 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 589 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0034
   Val:   Loss=0.0793, RMSE=0.2817, R²=0.0053
============================================================


📊 Round 589 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0031

============================================================
🔄 Round 591 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 591 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0042
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0019
============================================================


📊 Round 591 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0031

============================================================
🔄 Round 593 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 593 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0030
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0034
============================================================


============================================================
🔄 Round 595 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 595 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0040
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0021
============================================================


============================================================
🔄 Round 596 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 596 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0042
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0032
============================================================


============================================================
🔄 Round 597 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 597 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0038
   Val:   Loss=0.0810, RMSE=0.2847, R²=0.0029
============================================================


📊 Round 597 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0031

============================================================
🔄 Round 598 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 598 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0049
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0004
============================================================


📊 Round 598 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0031

============================================================
🔄 Round 601 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 601 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0033
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0006
============================================================


📊 Round 601 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0031

============================================================
🔄 Round 603 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 603 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0028
   Val:   Loss=0.0806, RMSE=0.2840, R²=-0.0027
============================================================


============================================================
🔄 Round 606 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 606 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0015
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0050
============================================================


============================================================
🔄 Round 607 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 607 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0053
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0016
============================================================


📊 Round 607 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0031

📊 Round 607 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0031

============================================================
🔄 Round 609 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 609 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0036
   Val:   Loss=0.0860, RMSE=0.2932, R²=0.0047
============================================================


📊 Round 609 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0031

📊 Round 609 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0031

📊 Round 609 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

📊 Round 609 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 615 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 615 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0047
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0094
============================================================


📊 Round 615 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 616 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 616 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0037
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0044
============================================================


📊 Round 616 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 617 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 617 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0002
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0169
============================================================


============================================================
🔄 Round 618 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 618 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0009
   Val:   Loss=0.0833, RMSE=0.2887, R²=0.0118
============================================================


📊 Round 618 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 619 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 619 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0041
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0018
============================================================


📊 Round 619 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 620 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 620 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0021
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0089
============================================================


📊 Round 620 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

📊 Round 620 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 622 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 622 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0043
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0008
============================================================


============================================================
🔄 Round 624 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 624 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0050
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0007
============================================================


============================================================
🔄 Round 625 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 625 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0027
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0063
============================================================


📊 Round 625 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

📊 Round 625 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

📊 Round 625 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

📊 Round 625 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 629 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 629 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0060
   Val:   Loss=0.0756, RMSE=0.2750, R²=-0.0091
============================================================


============================================================
🔄 Round 630 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 630 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0061
   Val:   Loss=0.0758, RMSE=0.2753, R²=-0.0077
============================================================


📊 Round 630 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0031

============================================================
🔄 Round 631 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 631 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0028
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0220
============================================================


📊 Round 631 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0031

📊 Round 631 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0031

📊 Round 631 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 637 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 637 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0016
   Val:   Loss=0.0702, RMSE=0.2650, R²=0.0039
============================================================


============================================================
🔄 Round 639 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 639 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0020
   Val:   Loss=0.0871, RMSE=0.2952, R²=0.0080
============================================================


📊 Round 639 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 641 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 641 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0048
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0000
============================================================


📊 Round 641 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 641 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 643 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 643 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0049
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0001
============================================================


📊 Round 643 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 645 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 645 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0043
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0114
============================================================


📊 Round 645 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 647 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 647 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0011
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0045
============================================================


============================================================
🔄 Round 649 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 649 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0020
   Val:   Loss=0.0720, RMSE=0.2683, R²=0.0066
============================================================


============================================================
🔄 Round 651 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 651 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0032
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0038
============================================================


📊 Round 651 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 653 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 653 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0025
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0005
============================================================


============================================================
🔄 Round 654 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 654 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0047
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0013
============================================================


📊 Round 654 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 657 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 657 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0026
   Val:   Loss=0.0873, RMSE=0.2955, R²=0.0065
============================================================


📊 Round 657 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 657 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 665 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 665 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0034
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0121
============================================================


📊 Round 665 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 665 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 665 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 665 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 674 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 674 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0038
   Val:   Loss=0.0814, RMSE=0.2854, R²=-0.0093
============================================================


============================================================
🔄 Round 675 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 675 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0053
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0028
============================================================


============================================================
🔄 Round 678 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 678 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=0.0044
   Val:   Loss=0.0780, RMSE=0.2794, R²=0.0014
============================================================


📊 Round 678 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 679 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 679 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0035
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0054
============================================================


📊 Round 679 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

📊 Round 679 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

📊 Round 679 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 687 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 687 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0053
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0053
============================================================


📊 Round 687 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 689 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 689 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0031
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0074
============================================================


📊 Round 689 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

📊 Round 689 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

📊 Round 689 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

📊 Round 689 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

📊 Round 689 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

📊 Round 689 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

📊 Round 689 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 702 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 702 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0036
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0053
============================================================


============================================================
🔄 Round 703 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 703 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0030
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0066
============================================================


📊 Round 703 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 705 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0938, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 705 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0062
   Val:   Loss=0.0938, RMSE=0.3063, R²=-0.0120
============================================================


📊 Round 705 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

📊 Round 705 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 710 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 710 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0042
   Val:   Loss=0.0725, RMSE=0.2693, R²=0.0022
============================================================


📊 Round 710 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 714 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 714 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=0.0022
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0068
============================================================


============================================================
🔄 Round 715 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 715 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0052
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0049
============================================================


📊 Round 715 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 719 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 719 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0031
   Val:   Loss=0.0858, RMSE=0.2930, R²=0.0070
============================================================


============================================================
🔄 Round 720 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 720 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0012
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0132
============================================================


============================================================
🔄 Round 722 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 722 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=0.0030
   Val:   Loss=0.0765, RMSE=0.2765, R²=0.0059
============================================================


📊 Round 722 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

📊 Round 722 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 725 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 725 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0025
   Val:   Loss=0.0749, RMSE=0.2737, R²=0.0102
============================================================


📊 Round 725 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 726 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0665 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0665, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0665, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0665, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0665, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0665, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0665)

============================================================
📊 Round 726 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0047
   Val:   Loss=0.0665, RMSE=0.2579, R²=-0.0002
============================================================


============================================================
🔄 Round 730 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 730 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0032
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0035
============================================================


📊 Round 730 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 733 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 733 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=0.0041
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0017
============================================================


============================================================
🔄 Round 735 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 735 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0052
   Val:   Loss=0.0760, RMSE=0.2758, R²=-0.0018
============================================================


📊 Round 735 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

📊 Round 735 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

📊 Round 735 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

📊 Round 735 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 743 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 743 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0055
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0043
============================================================


📊 Round 743 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

📊 Round 743 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 747 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 747 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0031
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0201
============================================================


============================================================
🔄 Round 748 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 748 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0043
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0015
============================================================


============================================================
🔄 Round 751 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 751 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0030
   Val:   Loss=0.0718, RMSE=0.2679, R²=-0.0216
============================================================


📊 Round 751 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

📊 Round 751 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 757 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 757 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0047
   Val:   Loss=0.0852, RMSE=0.2920, R²=0.0008
============================================================


📊 Round 757 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

📊 Round 757 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 760 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 760 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0024
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0019
============================================================


============================================================
🔄 Round 762 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 762 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0053
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0010
============================================================


============================================================
🔄 Round 763 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 763 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0040
   Val:   Loss=0.0823, RMSE=0.2870, R²=-0.0071
============================================================


📊 Round 763 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 764 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 764 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0020
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0103
============================================================


📊 Round 764 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 765 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 765 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0048
   Val:   Loss=0.0937, RMSE=0.3061, R²=-0.0097
============================================================


📊 Round 765 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 766 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 766 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0031
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0077
============================================================


============================================================
🔄 Round 773 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 773 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0036
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0111
============================================================


============================================================
🔄 Round 775 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 775 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0039
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0042
============================================================


============================================================
🔄 Round 776 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 776 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0032
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0068
============================================================


📊 Round 776 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 776 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 776 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 783 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 783 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0034
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0062
============================================================


📊 Round 783 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 783 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 789 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 789 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0048
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0029
============================================================


📊 Round 789 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 789 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 789 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 789 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 796 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 796 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0042
   Val:   Loss=0.0910, RMSE=0.3016, R²=0.0027
============================================================


============================================================
🔄 Round 797 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 797 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0048
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0053
============================================================


📊 Round 797 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 798 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 798 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0024
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0097
============================================================


📊 Round 798 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0028

📊 Round 798 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

📊 Round 798 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0028

📊 Round 798 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0028

============================================================
🔄 Round 805 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 805 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0062
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0049
============================================================


📊 Round 805 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 808 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0704, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0704, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0704, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0705, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 808 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=0.0030
   Val:   Loss=0.0704, RMSE=0.2653, R²=-0.0197
============================================================


❌ Client client_3 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_message:"Socket closed", grpc_status:14}"
>
