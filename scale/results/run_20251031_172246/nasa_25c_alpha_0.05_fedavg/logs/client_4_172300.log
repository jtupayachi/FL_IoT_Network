[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9c684c3-7082-4e41-92dc-cb5a4fd46aca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3243e044-4d92-4c88-9086-393f1fa298a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abd1be41-0d2a-4b43-8851-be4372ae05c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76135548-bd18-4fb5-a4ee-e8f796c7ac31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe3547c1-72c7-4f7f-a8f8-8a97de1ccdad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76af7749-682e-46cd-a70a-fd685fa4f94c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3974564-fdea-49f4-8fe7-21b6bd3b0ccb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b45e6af-c75a-478e-9052-7143538e8d5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a5b5062-96a3-4e68-b30e-6051eee14719
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fc8ec31-b9c8-4c51-8e9a-8b36ca5d5cdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f0574ae-7644-4bf7-9e12-41985d86ccd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 119fa2f2-f1d9-47d2-bb40-a131e6a9c416
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8109ef62-1830-400b-b279-47e9bfbc766c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 305b113f-ffd8-4873-b74c-190f3cf4db53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17f27cb2-39b7-4cc6-8e5f-0c1d6fa5511a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9dc1d698-92d3-4cfa-b8b2-70e5a8ab15c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 235e2e2d-316c-455a-b066-ad4a2041b8a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8842f836-df7d-4a56-9dc4-30e8d38be6ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c6fe5c5-3408-462e-9335-dc1a3a03d3b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 854dbfdb-c491-4946-ace9-90190b570947
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cb0a0d1-1871-4c81-8729-e71829c9c775
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ac4fa44-ce3e-4cd0-91bc-14c42ae82daf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0afdcc87-3ecc-4aef-8f43-96255af16bba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7999231-ca5d-4961-8492-ad4aeb421acd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d25dd8b-5137-4ffe-b554-af3d780a4337
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35287684-1730-433e-a718-c4d1cc55aa3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf47c070-ec1f-4044-ac2f-f078ff02d091
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4fa0c1ce-aae3-4bf6-927b-d8e5f1f1fe10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e703830-cafa-4f83-a4b9-cfdafd4b2f2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a7b6499-acfa-452f-9ce1-ec7cfae68ac5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7bd9fe4-1971-462f-82bf-b702dd95f5b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8516e29e-a63e-491a-b6c5-f4de5ff921c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93390770-3aad-4ecf-bcde-21283fb9d0c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 119a8919-8763-45dc-a1b9-75f168fe6ac8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 739126b8-3db4-4df1-9023-c82a5b0acc90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d80b3ce-e57b-4f22-a000-da1c733407ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 320a9895-1e87-4e50-9381-3f9bfccab247
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e5f60a7-2446-4ffd-8571-a259a1027c40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd0fc66b-b614-4673-97af-9769c429ee7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e92cae86-9ad7-44f3-a09d-cafa13084dbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 543cd535-5a1c-4ab5-aebf-292a88d2821b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 779b3827-f0cb-4a7e-b54b-b08da55b5854
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 270ec9ef-eebe-4378-8b08-a77def64b163
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8e9de9d-7cc0-4425-b779-43a1bd522641
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7c503f7-6479-4f7c-a126-ebea4adea74c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4682861b-0488-42a5-bc35-40dddd19399b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53e2023a-63a7-4553-88bc-6a54a3994c36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4bbe32e-d33e-49ef-b92f-2439dc1dcc45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24aad5fc-df07-4930-a8d4-fe97f9bbf864
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66e90be0-84a9-4dca-a93e-07d06b5a8823
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message beca89f1-b68b-4dd1-81da-a9a254f01a47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07fd96dc-8ec1-47c5-9f32-aba71b9c16eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e7f323c-627b-4c96-8351-85b284819fb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e1a3575-f5fa-4ec3-bdb2-5827e4db872f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac372db0-29ce-4c99-8c82-999f49ef4ce3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1df1a07c-90b8-42e4-8010-c20f4883b532
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fc43a8e-51d4-45e2-89df-2235e2ad6b09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a89819f-ed1c-4479-9625-85b699aae87e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 103b2bd6-11ef-439b-8af8-35da695cd7e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7710b13d-fd59-4ca2-8d73-590a70e307bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa5ecc3a-55a0-483f-b231-49c9cd2b1bfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9bae7549-b320-40d0-aa3d-7b46c3542c14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa33e2ef-1823-4567-9754-3cbc565541bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fbf5451-65e9-434a-a054-184b1b697799
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c51e9be2-eee0-4c54-bcf9-4e2e5789598e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aef76df5-5022-4df4-af5d-2c9171ec2b7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d979199-3ba3-4d6a-ba22-ea9418419693
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c97495c-306b-4f18-a454-1bbe97004813
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d077b354-589c-4857-b066-189c32899c50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ecbe0159-acfb-476d-ac7a-22006c2c85e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b78dc99c-17d6-49d7-bbba-bc151f5077a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7dcb53af-5def-4360-9758-03d11f58eab3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d806579-3d17-4af8-a346-21a8c2265254
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 371a6bfe-8bfd-4ea7-9b84-c18c000092ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24e49dba-89b3-47c2-bcf9-7bed373bffc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b7a021c-ba83-42e9-8cfd-15419ae6539a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7dd0b636-aad0-45ec-840b-43f34615f7cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78b43ffe-ab81-4d61-81b6-e2c69f97f6db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4aaca545-e681-40f6-8a7c-01385fbdc514
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9cc6f70f-4d98-464b-adde-b2a984f9f60a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9090e19-4b5d-42fd-80cd-2fcd4203fe5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message babb4871-5c7d-4af9-b474-3065dd7f9c3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a11626e8-8615-4b16-b868-81cc09db688b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 758d2449-fcee-4c5b-bdf3-97fb2a47fe9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bec3f004-f50f-45ec-a2da-2b836358c891
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c6b7f53-e705-4933-8559-65ca624466c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8894cce9-27a3-4a19-98d3-0a55d849dc62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ba7ddcf-94d6-44d9-9ad3-af8cb1aabea4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5cb03b6-0a18-412a-b423-f57d68d486f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1151b90-48c6-49f6-8c9c-f3500bc88d92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 413ea5b6-9f60-43a7-9384-0b96dda60367
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0b8bb01-58e9-47bc-82b0-7cb64a0f6c5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80d1d28a-b8af-453d-ada7-bc2edd7af600
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4aeb69eb-7578-4565-ab27-cf306d3128b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1be45003-bbdc-4691-81cf-7b7133a0fcdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e641229-5991-4dbc-8f03-cac83c4117ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90056e2c-41e9-4ed7-b899-8e95e4d502c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edb1c9b5-817c-4ee9-958f-072790d4f6b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2094a0d-d67f-40fc-aea1-e281ea52250a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4327fdd3-2eb5-48e8-b6cf-1f65115a890b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2a4832f-a23e-466c-ba59-840a001b35da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efeaf567-fc06-49b1-bedb-89340962e95f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb05a69b-9ca3-4211-8d55-cf2c686baeda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 329a9cd3-fc05-418b-ac70-bfdd350faec6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3d7302c-3176-457b-b0fa-8ed6637d50b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d102f6e4-682a-4fb1-bc71-dca9a9117968
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 498d201e-1f8f-46a7-96b7-baeb2e367123
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3b2ff20-dfd3-4631-9182-339c19e2d245
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50c0ca68-c1d7-4ea4-8f70-038a3785a35e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f098130-5c28-4f06-92c5-7c959245b82a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1bebec3-91b2-45ac-9c3a-288039d5d83b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77382422-d06c-4822-a038-308f75353830
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4119aba-e5c3-4f2a-922b-67462606f0c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86919d30-89a2-4ba9-8bf1-1479a9053d8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40e7951a-83e0-4dc3-aa21-c4fcd57d9749
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ad24b83-fca6-4fa7-82e5-b52722b9fc27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 105be9c9-5907-406c-af05-f7283871abee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a754dd68-1158-4e18-94fd-249a1ef1bc78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da9ad39b-ab9c-4a34-b2b0-8708ebedf288
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7da17864-79c7-49be-829b-22fe5352c4fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59b2ca15-3f8f-4c4e-9ff1-80ee0e4ecd6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c49b46ea-3cec-4c45-a882-d589ff51c7be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c299a2a1-3fb9-423c-93d1-74221103c12b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d2ccc54-b388-40c6-9c17-0d9ce4848815
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6295d8a-c366-4176-8299-9c67b6c3dbb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad67a177-b6d0-40eb-8d91-29fe7d7872ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57b57cb6-2655-44e8-8ecb-61894e4590b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ecb613a5-24c5-417a-bbf6-6502ea63f527
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d05c9408-4def-4b9c-a6ab-70a70e0f92bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96992346-6d87-40c8-962f-03229cfcece9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d7dd457-4b75-4613-b3b1-2c2fa5fafb77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01508ec9-d064-4891-a0a4-79de2db384fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c8c0530-78d2-41fa-88db-cb0702652e2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 516b634a-6e73-4171-b07a-47ae96ad1802
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 010311f2-d3e4-4b9d-9f29-5de0e40dfbb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c91fd59-8520-456f-bc8e-2e1d9e9f2e20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47acb135-ebde-4463-afd9-6d3da7dcb262
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 009020e3-9f04-42a8-94fb-7ad2e5e8df5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cdee1d6-18ba-47f5-8adf-db65616b36b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed4c0334-3ece-43fb-b118-f6f2199ce585
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6abf5dad-2d51-4055-8c1d-bc9f790650d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc566519-2105-46b9-b414-946609bce524
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f49b7f0-42b8-4ceb-aa01-f21926da7a48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b503f16-4043-4beb-a42e-670df6d27315
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e7a5af6-2d87-44d4-b87b-2e003c5587a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a54ba9fe-5159-494a-89f7-8126df21f528
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 279ade92-19e0-465f-8a19-1ecdbfa3291c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffe820ed-4c34-46d4-83a5-68c60c6a4726
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d41342e-18ce-48f2-8c29-02b7863cf6f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c07843e-f8b5-4079-9b01-6af76f3411f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c0c7fa0-8e3f-4c5a-95df-c217976b7c8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b559533-c2b8-4bb6-91b0-df47ce17f4bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75edaad0-78be-489c-b583-07710b67f574
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1b70773-562d-4105-b4b3-deeb3bab7ced
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de35f7c4-eca6-4f1b-8ecc-666f758d7b83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd642dfa-4ae4-4532-8728-6f1d81136392
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d766a9d-e421-4289-8368-1d287c331117
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 723ad534-3193-4e68-81fb-51361f5667c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cfff580-5e25-4882-a649-76fd35849f2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c766787-9195-42de-9c83-56b2f458220e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3849e5d8-2d37-4de8-8a2b-157f29a16ae3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e658ea4a-6cda-4b78-bd60-c6b066bff4a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8891b81-2685-4346-9b2a-e56f95bf8fe4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f503c1d-2c65-4b61-9f13-4d7298b41f8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd40effd-ee07-4138-a7c1-6cabba7a8a12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d32a4ca6-e53a-4c8d-930b-e6485dfa086d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f836d8d-6e04-4b4c-8aa3-9d9b3b08b2ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bf3d2f6-4506-4586-a315-2d3d25eb294a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7c9490e-4eaa-4959-96d5-20a99e210f12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9ac1193-6486-494b-a781-8b290d3cf966
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75ffcd97-20cc-4b1f-9ea8-27689de15970
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9887bce7-be62-4738-943d-0f6353c34093
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66bdf06f-d431-472b-9a02-be76395ee997
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 491d25d6-7538-4cb7-a6c2-9746743b7239
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfa5d3e6-aa33-4871-97ca-d7ce9b6e2efb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b95d0be2-8efa-43ca-9244-d0a57de3fb06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 782f5b88-9555-4ff9-bd36-64acae67705e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 449b2056-b0ff-4a5f-87ce-73cac48d1f80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e08ed62f-e832-4421-b6c8-a829bb1e2c48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d19a1e2-ca25-46e1-ad9b-e11f8d1c39ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d4f0fa5-d5b8-4da0-8b3e-e5f1d0b79201
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a79a6809-047b-4db8-8913-103b5d1d699f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed3a570d-d8e7-4c51-ad5a-a42778f67a57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f6e17d0-40de-4a62-a6b1-ed319259cfb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fa7f1d1-060a-4514-90d9-c9a85decb8bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d1ed7e6-95ac-4c79-af87-0055c1d4d73a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a145197b-0e97-44ee-8f9f-b6338d20abfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 896bc02b-ce49-41cc-b354-a73928590b94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bcad296-f221-4725-bd8d-06eebbd3196d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5ab02df-fbaf-40fd-8404-ceef140114c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28b5a42a-1017-4a24-beac-255a1c8af7e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6049a18d-fe13-4356-8b39-6274cfc57a48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b349984f-5bd6-43b2-8774-9deda439b841
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e27de48-6ea8-4569-b74a-74007d308f24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d02e2fd-1658-464e-9fb9-04aff1ec9711
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d45fb9e0-dc75-45b1-ba7a-1681602398c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c17be5bf-a759-44bc-8e65-8001b169bcc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e2effe6-3025-43d4-a304-6601dc186b39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bad903f6-ddf9-4b56-b58d-8d179c0bee03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f848736-559f-4b5a-b1c2-aefc44eecd2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e95f6dea-54ec-410d-bf5b-e965edd21f42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cd9044d-265b-4fa3-b216-3716cb0ba090
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60ef377a-88d7-4193-9548-cee39d61e477
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ea57b72-2e17-4e38-8721-c8a28931a2bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d518e04c-78a1-4eeb-9b15-85920333d83d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a79fdfed-d635-4cb5-a14d-5a41e2c52101
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9c44c16-b6f7-4602-84c8-dc68a1c50618
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 693333af-aa0a-4ce3-bc89-ec3ffaa5f109
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e1dbacc-3b17-45e7-a722-d44495fb3a9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54706432-5d0c-481b-a31d-71a766e5b186
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76977329-94bd-40bd-9b48-51e5b616f29b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d646f992-c706-4f35-be3b-ad80ae231247
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 235fe235-a753-4bb8-a1f8-d5d14fe0b71d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe06de0b-1f3a-4a05-8ea4-10cc9fd76114
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72bcf35c-ee79-40bb-b3cb-eadc1c1c6162
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 223d4437-d11c-410b-80cf-8a1168f88918
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85ca607c-a658-4251-b78b-4c02840c09dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3456aad9-f27a-423d-a993-46881d86fc54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fa0fbca-d2a4-4ae5-a7c0-7a008380304e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e91698e-0669-4ef4-b710-76468e40c92d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17e5ef47-6a4e-40ea-9f6e-a5f17b8efea2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 991f9789-7ee6-47a6-a58c-72b1c277cddd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f4c260b-4181-425c-84c0-a6c06931d4ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52015f83-b058-463e-a71c-b2710c0bffb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ebb0900-1b14-4125-9422-988f708019a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7eba312b-ccaa-419f-9305-0e0b0ab12882
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed570722-b5e3-45e3-80f5-be525a30b7bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3d0d44b-4020-4409-a3ca-5c333816331b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 425a4c55-ce2f-4ac9-90b6-54f500ad9f21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4757c243-acb2-4ebd-bb12-3df1030bab93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bd28fa0-e9f5-4b51-bbab-4e1b9c98a587
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37159b57-2a96-450b-b974-1c72d83dddaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 407344bd-5ac4-43ad-a048-65a693f618c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edd4ec59-4f2a-47a0-a128-836dd73a7ea4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06bd850e-2425-4ef4-acae-e5b87b1ba7bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d424aefe-3869-49b5-a4ed-3ab3ee0902d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e87b63ff-ceb9-4dc4-a128-f743908f8c44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4037fac4-967f-4998-8703-3715b6c02296
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa55bea0-4b17-4245-9cdf-39f3f8f0c9a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dda29657-c96e-435c-b942-0b318bd33043
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c60c7bdf-7d70-4bc7-b84f-541008fb401a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea849df5-4c08-4269-9284-6490c0227531
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83626913-b774-4a95-9f67-24d4a5d53175
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 240ff187-5d1c-45b4-b7b9-683e876f07c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8dbd7a83-24a6-4211-8bc2-ee98bb9b41c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b80e01a5-fbce-4d07-aab2-8c2434f4b6c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b28a37e-b16e-405f-9db3-b7df85624f98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3df37362-6f2e-4526-8ab2-901e8616f676
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7387f58-7d45-445d-94e5-b0c4a16fd002
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f24a7eb-b79a-4efd-af80-837a99d61a18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3eb87dee-f588-478b-92bb-bb4890677e22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94bc6ed9-1490-4390-ac36-23e7bb54e9bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3059feb3-0188-44c5-bf55-1b20b8bd5027
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe4db644-cbf1-4348-93aa-cf93cccd2805
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8095ce5f-1c4b-4df6-97a4-c91d9b564803
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a68c3d53-16a2-4564-b465-ff4594cff077
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd4bc248-cbe9-407e-88fd-2160f4ac9bab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e71a121-5ce9-474d-9bed-b29dfb7a381e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd1fe93b-7c81-4cd4-8331-3c383ac50352
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d91ce668-5ee2-4023-b7b5-d0e06eeec658
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d053071-b1db-435b-b21c-177fd6e368a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afbcb0d7-3b95-48c5-ac41-71f5fa095ea6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4e3ebf5-4286-4273-9b0a-dd1c0eaf0285
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1aee269a-c6e7-42e8-8746-3872cf8c1f6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0896a51c-3751-4b47-b2c9-3ebbf786c659
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff634452-55ca-4925-aa4b-c45036ae61d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b4c25fa-3160-41cc-b49f-d9f67ba6fdfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffa2c3af-a613-41c3-a95b-db408ad159dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 285bbb6a-5016-4cc6-a551-342208fb1791
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfa44124-dd59-4ccd-ba62-2bbe73cdb3ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d59bfaef-2990-4017-877a-bb48cd527483
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43e9f127-6eee-4ca2-98d1-9e71b981ecf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2125483-8ab1-4141-aefe-43abc02bbcb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message baa62591-0018-4a77-a373-921714a896d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c75a9e5b-d6fd-4fa9-851d-d19b8f815c92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50dbeb02-f2eb-4c53-8b52-f7b39178a8e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45561fda-ab99-40dd-9e57-752050432482
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdb40868-cbd6-4737-9d31-1006eb756774
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8aa5bf21-07f2-4f05-8b67-5cdd27b12f81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6724b2f-baab-4ea5-a7a7-84078c4ab929
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b29c002-7638-44bc-92a0-3587f2158f63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37449c8b-a5a9-44ed-9fbd-f8fc36278619
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19f65f67-2328-4e59-837f-25bdaf8d50ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 162c5e27-88a0-4d37-b0f3-0dd691eb3e75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04243859-f638-41f7-95fd-07a8c7159c73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0819e2a-17d4-4122-a33e-efce18235e02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ceea6774-b819-4738-a429-828c81c67d24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 774736c3-b284-4bf8-98cd-692d70cb01a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29f2f5e7-7db5-46a3-a582-f9cff28e04e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49e44d10-a852-4f8c-9350-0aec05a54076
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43de5ef7-02e8-45e5-b67c-acbf59b1ff4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bf75712-c7fa-4c40-b3a8-7098f2b5e79e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fab72ce2-3f61-42b3-ba1f-798ad39b6d1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fec1342b-0ba1-44d3-90ec-4f61c5f23d0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f44c4c2-0872-42f0-bc2b-2d77bdbdf7ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef450f04-6355-4d0d-9d6b-fbdc5b4f443e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 753c3ce7-5c0b-4e9d-b00a-ba272c7b5cd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01fcb24a-157e-4043-a7c7-291dff0f2fb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0dbe0a2e-27dd-4f08-b160-cd7cc8aa8896
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d93c372-fe03-486d-9cce-68001ce7b5bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebfba4e6-c7d8-4aa2-8164-1ce0a8d2ceaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2695eea5-92df-472c-afed-5a803183077d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65ade193-9323-484e-b1e5-8972b8630316
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c99fef34-9367-4505-a9c6-804355ece6e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fd7f665-5f7a-4d08-aa7b-2ceb11a0e557
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc38d583-184f-44f1-9b78-2886465e0f91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9940c98-503a-4702-9a0d-47498e4a5a26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3454348d-0121-48b2-8669-f25f3bbd45cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1e46d05-9bb5-4baf-82fe-37398a917c4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7302f6da-ab3e-4528-96f0-0d939ea8125a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43c5769e-41ed-490c-81e5-b0af35864e20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bed6e4e7-6d5e-4b3c-bd92-d8a0816931cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e88a5a64-dc41-4ec9-9c1d-082a6ed46c13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7eec75a5-023e-4a5d-88b2-1b4b33da4aa5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f9b7bcf-8af3-474b-bb54-033a4b903062
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0f2aaff-981a-4a26-af46-4abba5402370
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02f482db-18da-4837-a54b-16605f911a6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e495a690-5eb9-4483-a959-a5ecac5ec335
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9c8d237-abef-46cb-9b1d-9e295dcf6a10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc2daf74-cac3-43a7-b94c-7c4398ddf720
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b998dea0-8212-4d79-9350-06a4b2042b3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b39e6384-cd44-44a4-a91c-65eb5224ba78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf5b3806-6430-4f78-a1dc-49a1b946f3ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6ff6373-1176-401a-9d8a-237e388515f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76e37b6f-69ec-4370-a697-713905902de7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a822ea9f-c057-49bd-9cf3-da64a49d66c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4c02263-190a-4690-9d00-32d5199659d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0a7d3db-85be-447e-a8dc-6562211179b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53b4b730-5227-46e7-a85e-9f37d1d8e021
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51fd1a5d-123b-4579-9961-0d38b17f3096
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21c293f6-c4c1-491a-94e6-d81e88aa87f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10bf79ed-0ee8-4588-9c0f-feea34914812
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87f22168-99ad-4aed-828c-721ef14bc480
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52a5d899-4aa0-49d5-8650-ae489882ea2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 423a77f3-0ccb-40d5-83d3-a14cbe073893
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10bfc109-a905-454e-a049-0f54291435c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e03073c6-b090-4631-b965-3b8ba7139d84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd2004b0-f3c6-482d-8b9f-43ee7ec1c7a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 580fa984-324d-47db-a546-67a0c93ca8aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca8a5f3a-93fc-4ea5-b8cf-256b9d752a7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd84df39-5d7a-436a-94a6-cbabd3721b58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd24d6af-3944-4127-933b-2f916e0f3208
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e3956b0-bc54-481a-9797-29da70896df9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f744f3c-00b4-497a-a286-b31463799268
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 217d8822-0eac-4457-b9dd-f87a1ed235a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 769e28d1-56c9-4586-86e1-1d5cd49f7b67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08b097d1-660f-4fe1-a4de-d6f3846aa934
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9b11974-af21-423b-911c-2eec39f7ca94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3ade110-0f40-4377-8ef1-3862d9d1cc9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 222ed586-55de-43ed-be02-49f6a6ad523e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8506d0e7-e196-4ce6-8dc4-3f3943b1b025
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f96e59b-8604-45f6-b12f-efa254e0b334
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56bb50f5-83dc-47b3-8457-bd0676e92828
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e57fa5b8-42de-4dad-a8f0-0c3bbe8d74f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55c978ec-b85f-4b93-aaa4-613b85d3a2df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0068409b-15f0-47d6-ac88-5e0b3f321b82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c7464f5-fd41-49ff-bdf9-ef44f4dc1372
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0eabf45c-bb9c-4fdf-be82-46cf2f45cd4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f10d128-9b98-4b95-8577-397adf8d9a78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5808ab60-f50d-4599-a7bd-2f5c2d3b3e27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f8fe028-0bf1-4c85-b2e5-eddd8ad9c96a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab9ae91e-2b90-4edb-87c1-2fee961c8233
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbf41d1d-cc23-408c-9a39-a233172e3110
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0aff6a7-f594-4d53-845b-9e9a64f074de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f9c538e-74b9-4723-873e-020375015c20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f28563f6-8047-4d95-99bc-63f2c4cf3c69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81b70280-9820-448d-a146-49ddf0d2d0a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bcf673f-f6ef-402e-aca6-a0c70654190a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01595404-6285-4cf3-82be-621a4d1c77f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ab8ee54-2d99-42e1-92e9-6a999f6b7557
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4fe72b9b-a04c-45ab-a8a8-641f4e8a9901
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b4d40c4-56db-4548-8458-caa45b517e71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff3d1751-8efe-49fc-b1b0-f44ede12b320
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c221ab7-9955-450f-982b-50e41493e2ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e318806-f9fb-40e3-9225-042d248a0bcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 737952c0-6d68-4d04-a30e-9a659dd43271
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dea4873b-83e0-4375-a380-d8ffd422791f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 166fd473-6a45-4d55-b303-2fd8b46368b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0d88860-ca8b-4b41-b307-3a5074f15ffb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c2c1cfa-139a-4cb5-a332-5dc3c7fd1382
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0526ce88-b6aa-4ab1-b1bd-bf36c21aa938
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4e16150-e047-4203-8daa-82a354889aa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3df64043-fb13-422a-93aa-3bc4ae6ac343
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15eeed92-89d9-4b39-9a60-91af5018e656
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 989d2c3e-c6d6-43e2-80cf-c1ce5b1a7648
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c521e5b0-e685-48fa-a42d-3cada3788596
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04e07285-30c2-430c-bb48-c551e8437ea6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59f2c828-2bcf-4277-87e4-294cda43ee21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fbbc016-88c1-421a-ab70-59f072691682
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ce39ece-938a-439b-b574-f920f17d08ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fbcc194-45e3-4394-9d6f-28c5167551a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98ab9acd-2cd1-49da-ae8b-7c082ee3779a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87c1cab0-f2d9-4c29-ac71-35136c7c3729
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ecba19e-e88c-49b7-914c-6433ddc13f4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35b3cb27-2b86-4881-bfde-0dc46e1c9b15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc904770-cef5-43d3-b382-2543cb2ce862
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19da9fe1-de68-4712-b6bc-6c8966e13a3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0b89c91-7676-41f6-8ba8-62703d5939ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4152fc6b-64fe-4365-87a7-e9e80b696649
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9639deae-62b0-4afb-ae28-475cc66d460f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2715149c-0a62-48ca-a46a-045949bef251
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24f5ea2b-6134-4a48-b102-3e9c719beb28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31a5097b-2360-416b-b842-ec2a1a01f174
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c94cdae6-ecf3-43c1-907b-39a687f46b27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5134934b-0e77-43d9-a8d6-110484fd308d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49e4e295-3928-4f5e-b4f1-c478c1f3127d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51252f14-58ff-4787-bd1c-ae11af4fd502
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04f81199-968f-4d0c-8e8b-68d6056aae39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52786531-5ab6-49d3-9866-31be3866950b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31e50d07-123b-4b52-9209-74c562b05669
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28cd16c9-6591-4cf0-9e6a-247469710964
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 738f6bcd-24a9-4739-9422-441c17c72834
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db4f8a90-da3e-4323-a4a8-b4addc20ba6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ef169a2-09f3-44b8-bc6c-45679cfac9a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e2a33af-10e8-49fc-8fdf-19a1c30af857
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46b33d04-2a5e-459d-ab9f-3f7be962951e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7103428f-715b-437e-9dcd-538435366041
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 496bf83f-9fd8-48b8-8488-7ad66d6b4fa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 371bd263-4a1d-4ce8-abb6-962628de35f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9583f16-e34d-49b9-9eaa-f1b62d11e40d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d499eea4-9bf2-4c5b-8282-7795fd44a463
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e24a86e-997f-4a13-ab4e-4d6d2f1f9859
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a952080-0406-4b8c-b3b8-89c1790024f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64a34202-8a6d-4ed3-912a-7d304d766a48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05e73ce8-a2e0-4be3-8367-d84770e231a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 362fad1b-5f9a-49f1-b46c-1cd507ff58c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf72df62-61e9-48f9-ace1-279a476a767d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4579170f-6320-42b4-b86c-f7e1e22388ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb66b5b6-2721-4d96-ba1b-d7fca0e7aea8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffc242d5-ccc5-4786-8f09-65beb01bc4f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73e3605b-c108-4f10-8dc2-21c100b478a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23107ce7-8c5d-4bbe-9cdb-92711817ded5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c756777-c3bf-401a-bc06-85d548fc5566
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40542ece-1a1c-40ff-b700-321350b67c0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0dac8576-9770-42fe-898f-20eb6e1925fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 171b6776-24a6-4338-af37-b99053764be9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95b0551b-88a4-4c41-86c2-f2c3eea4ad3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af8835bd-7919-419b-a5e7-641797e1e482
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7dc40be2-3f17-4fbb-851e-0efcfa3a984d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b577727a-0292-4f71-afb3-f1ae8a31039d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 338a21a0-a60b-4790-b323-f3ebde174497
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fe0e53f-0964-4082-a09b-bfea8b6fc98f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfda88d9-5d72-44e9-9f37-679a747cf16b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e64bef4-8005-4612-8155-205ff39541e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41add857-8e78-4098-a74c-d6dba3c45619
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b9aa174-721b-4a07-8aa0-b965d902ee7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3895d290-627a-4751-9f41-b7deff2c4483
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 971b5682-730f-4c9f-b706-fb58d833a399
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4adf259b-8f03-44de-ab4d-6ef8bd2a8a3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b871ffbd-602b-4935-b1c3-a14ba911a3cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f12de766-5094-40f3-b6b6-0abe404963ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 571d6589-bbf3-4ff8-9174-901ab6d8cd5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2400049-d144-4448-b1cf-8769f2576657
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abdd8913-77bb-4eb5-bb9c-b6112fd1a325
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7dcae5a0-3f19-442d-b243-6e640100cb0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7b55317-4e5e-4137-aae3-e276e61182b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fac9382-f68f-4902-a6d8-2826365dc478
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5526f9a-de88-494c-ae46-8fd798fd09b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9394c3b-eab0-4a1f-a3c3-d4920f4f7d1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 661fbec6-e0b6-499c-b34c-65fc6b119b00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f706bacd-66b2-4eba-8b8f-854b6ca0ebc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e72f77f0-c8ce-4e32-a673-5ceed6b5c9e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46582279-579f-400b-80ef-57a5f66b2e27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42cb6435-9d25-4526-b688-455ecbee6e01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28b6d5dd-f13e-4081-af73-cd0a66fa22f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 862e409e-eb66-4326-a07e-5a7daa08d08a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58aed354-b14c-4f8b-b176-b6c4fdd5b8e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b0d158b-bf2c-4f9c-a7b8-7e757a6c20a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41116a6b-9a58-42f3-bbb0-39918332fe7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a1a5f42-224f-4e0e-bd30-5bb83c9db32e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b149272-a722-4959-a74e-7e0a48b74d49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0067bef-a8af-4b54-afab-885508f2c012
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7869c92b-2bef-477c-84c3-4d75f857182b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a780a250-af75-4e97-a6b3-89bc82f96802
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8467ee4-8ebe-41e6-9415-3fb7dcf54c20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fad9f1f-6380-4866-9cdc-a8e70aa3ba7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a31c8d7e-2ead-4e64-ac00-977fc8c92801
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c698a6f4-ce1b-4bb6-91c9-e7e9826a2b54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b21c210-c443-4ff2-987c-4b5dc7a65cef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f722199-4e85-4e52-baf1-725eddcb1418
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e22d621c-de4e-4875-9d65-c0c165746f3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f91b4d1-f1e4-4e9c-9946-848030901b75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99b2b728-7ecb-46c3-b9ee-41adb19bb958
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 996da61e-3eb7-4123-b7fa-820f5d237899
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3aff58e-9731-4adb-9a50-05a2f0521626
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e8ac2c5-4b71-46db-9fb1-274e42d89525
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41b548b9-1417-4b80-b49e-57c3b22b96a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 137b2970-c823-48c0-93b4-98e87deb2362
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42bfe216-aa55-4cf4-a8cb-ae7740ed1f56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1175105-1a97-4081-bb90-a89e009658dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43c6291b-9d35-46ec-96ac-88875bb7ef81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91d2c736-486b-4b4c-b783-a6409aa1a48d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27f19f10-109d-446b-9914-ae0ebd40a871
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e41ce4e7-af69-4a44-bf69-4d66e00533b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7cfd132e-423f-47df-ad71-1852e63d3deb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3bba5a5-6963-458f-aac1-791039fd2de5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1bbb7c6-2402-43fc-b4b2-4bfe28a99116
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3310dd06-45a8-4026-b40e-80922832d2b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97ec57e8-1fea-4ccb-84cc-4b1476fdefe4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f398542-13d6-4e2f-aed9-5c2a91fcdd8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 367b862e-64f9-4e59-9c8d-f1da73a703cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5043100-ee56-4f2d-a087-0b986a19944d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 357ff567-067b-4221-a72c-0f308b5c08f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e5dc283-9cbf-46ec-8bb2-70e648296604
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 148fb907-1498-4a36-8755-ece846c73bff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c5bf5f7-4f95-4aae-b7d7-fe8682b464e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57f7da13-574b-47a7-af9d-af9a907a23a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17d09835-aa75-4894-9300-249a6fd99443
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a169852-59cc-4a6d-aea3-b6264b358bf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3df048eb-c373-4acb-856d-efc4200d9839
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b8e6660-b037-4060-b805-4c093de6875d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a144440-a1d9-4844-ae45-a6b21274e307
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4eaf152-4d10-4756-b250-2e17f663ef62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5870a9e4-6c12-43a8-b950-f0ecc930916a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88ab7a0b-902e-49c0-86fb-e7cfa9b45fde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80397695-fccd-47c0-a5c4-0990ad199df9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15a6973a-6b14-4c5b-a780-16ddfebf49eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f696cf6-4245-4bc5-a4c7-79815e29fa79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f764645a-f405-4ea4-b7b1-7a0f0a682f77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab06f62e-2b95-45fd-af2e-2367a70c393a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0899110-1ee6-4cd9-a8f6-e9fabed55d7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6032e59-e77b-48fe-b3ce-2e9be79f2d08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38125b32-4d9d-4584-8417-cc2cd53ac619
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff2ed5ad-6462-4350-8b53-c87fb61e6fc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09b41a08-f5c8-4b62-8fb4-d79216c808c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 896e2965-4829-4b9b-9c74-4369a7ce7472
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f5a26bc-511c-4bfc-b689-323af1682275
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e04b2122-6c08-431f-a981-70c2740c51e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91f10de7-4d08-4d10-95b9-b04d78407d9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0e8d669-9838-4d55-b338-5db22c693974
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb9cd8f9-ef23-44ec-b548-c937acd01784
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6c1ff62-a58f-47c3-8387-1d8eb13fa306
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1957af73-f5e3-43c1-9b5a-c29ec33a9067
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6d0973a-b4d9-48de-9906-03a91124d56a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcbd72e6-7826-4448-b707-9c59ec96c933
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0acc33c8-153e-4385-b0fb-2d7956ad7aec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d13198a1-e20b-46f7-af78-c07e3c8a54df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23f8c68b-373c-41fa-acf2-99822bdda59c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 533460f2-57ef-417d-b384-ac0412c51a58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75a4ac32-c6fb-4eb1-b077-d83b749797ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0f9b499-d58a-4dd3-bb2a-0afb37c16848
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 087c261a-0b05-480a-ae6e-d57307b6e6bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bd1d97a-a9b0-483f-bff6-e4736f43a9c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fd0ef38-5ee2-45b2-9753-34f1ad4691bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a807036-91c5-4817-9a33-cf8531c60a2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e5e6f35-a15b-4967-9663-57c943f32235
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d915f56e-f4ae-41bb-9238-93cccf5eb1dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c13a8a56-de81-4b75-824a-7f325bfc6559
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2aa9ca05-2eb2-4b59-a909-3fcd6e934479
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be826976-1475-4079-90a0-c3cd337b017d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1b3ae4a-a508-4eba-bcea-cca99c8d5585
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 208008a2-b527-48ea-8eb0-1e6a6dda198d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06a904e6-3284-4e27-8724-d12fefa041cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bffa1a18-f184-4405-b892-541f93ce64d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43ef76ae-a939-47c0-81df-5710b9a2c3f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2e3e7e3-0f6d-4fce-b2cf-df930eb55b30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8533e8e-e2dc-43f0-82e5-b2b5bac06cca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6579a029-90c6-4b82-97dc-b9904174aa53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae9211fc-47d3-4bad-a666-eb79e745c647
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d2d4e80-bc85-4980-91cc-3ed6636bd3f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7aa9fd37-19f5-4ebf-a87b-8f8a81a8645a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 585c9096-0f9d-44c1-b3ab-001bd5ffdcb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0febaf41-42b9-4d2f-96cd-ee1f23b12577
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a38d7fa6-a251-40d3-b001-727d2fe53450
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 622696be-1504-4e43-97c2-13ca436c8fbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91575e3f-14f5-4589-a66d-8d2d36e3ddcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2094a1f1-6c4e-48d1-9573-1d11543ab7e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba8d40ce-181a-4b7d-93e8-28feb407d5f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 575c159f-5291-4330-b65d-3277958efc5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0c3dd65-0fcd-4e80-a23c-e55fbb4e367f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7271a0c0-2525-4947-852b-1231df0be755
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc59d358-68a6-458d-81c6-75acfd5c3566
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7edfac4-f996-4202-b751-fc0256612b26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8faafb51-7c0f-497e-ad51-03157604c00c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88630219-5209-4617-a793-d7abf4ae4f16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8c74a29-c374-4029-a3fa-f49d8632c9c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08638659-f022-4f4b-bbe3-050853caef0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0b8d6a9-d5a9-4a9f-84f9-abf8fee7284b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45c67448-96d3-419b-bd7d-d12f2f19eb16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 389c62da-b230-4d08-aa60-9a77bce07fce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f723b93e-5b52-474c-a43a-af43235df669
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 717a4985-d8b1-4b8a-a741-f9d6e4bfe211
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27946ebe-8a70-49bb-ab16-6cf4ba842e09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0151d92b-b499-4ef4-bbf4-c780bc96d9a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 807eb5dc-bc2a-4122-a223-f5e7099af786
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc49ceb6-9181-4bc2-a926-eefb0df62d17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 305ef36e-30f7-4493-a0f5-ad5ae55ff7e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 927ad89e-4773-4f2b-acec-061aaada9f29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76d9930d-cc05-4626-8a68-e27d55b5aca8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4333cd11-6d55-4c9d-9177-c1c151335c75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ff17fd4-ea62-48a6-9099-1c23421c15ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28f69655-45e6-4da4-8f43-f0eb8ff7e5a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e1c7e84-2c57-4d0c-b1b9-39361773665c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86d5ab24-502c-4144-bbfd-8e0bf65bddd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c5bcfef-88ad-497d-8589-7b8871baa18a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfb6925e-0805-438b-8d13-feb13fd3d0fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c640dd9c-b260-4226-9c11-3b24ff92ffe8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e43461b-3460-468a-b025-663624201e95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 598712b3-73f5-44f2-a416-af4519ed6b4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 083d9877-bd8d-4407-8dbf-101eb5755362
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2db743f9-092d-45b2-ba30-6be1c6549e3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32be8506-6a24-4847-9809-9278343db713
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae690211-85e6-4b02-ba93-15da4e933800
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0855cda4-0e7b-4b86-975b-ff84ea52ce1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0645de1-4ac0-478c-8536-c41247ec853d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8ac58e2-287b-44f8-9df9-9e879befa8af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff829412-e653-4d82-8d7a-c7a1a9690bd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 133b3d15-86ec-415a-a66a-d42054de3492
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee9af077-951b-4972-9227-d7f3ab39fab2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3048a8a-0164-4b11-898d-0d137944730f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9de2e18-4c03-4bd9-8d9f-babfd099366d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32d94d10-7cc8-4803-bd82-cd9924e94c2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43f282eb-f363-4995-a3d9-c31c8ac34d77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 258928ca-cf9d-4b21-a5c2-49a8e5000778
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 524b782e-ade4-44f4-a067-353bb6256f69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5e126e9-1198-46f5-bfc7-3473365d8d81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a7c3ba2-71b9-40cc-a95c-6e7454a4ce7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 444c2705-4db6-4724-88e2-9791c89585d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9501d7d8-4b15-43a4-9bea-ac2a017bf906
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc693889-9a60-4c43-af46-82964f00d0ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4d54d45-fe79-465d-8dc5-8ee5b6e3b258
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6eada8e9-a839-4f9d-8dfe-2f67db3e0289
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eec2c2ff-1310-4054-9b48-5dbadffebaad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4420f8a6-95be-494c-983f-dd5fff4dbf4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9813d46-241b-46d5-97b6-4d812d1b8735
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e5f4512-2de4-487f-8fe6-1ba5f71aa7ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c61876af-8d2e-4a73-b9e9-3a903e85218e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa01e8cc-0319-4665-a1ed-7d9fe443411b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e4acdcb-f821-40a5-89ef-19051bc40741
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51f39b16-9c90-407e-82b0-3bf7ca647b67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a0c42e9-501c-4ecd-bf7d-10729a081cfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05541cc0-d1c8-4972-8101-d7d653709728
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f919dcc1-e268-475b-8047-4d02ed429b4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbfb7b91-d6e1-4623-a309-a03760bdc916
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03f8044a-3651-49b7-a0d3-7d3dbc72b2ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 995858f6-c43a-476e-8479-d45e8e528040
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fd958e6-5088-4f69-b754-7c22cc22f163
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9e7fe83-9041-4be3-b3a4-3da7cae3b19f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec4aaff2-772d-4b06-9874-b06e26cba2a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 269db97d-91b2-41bc-b28f-661d2772997f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a84a5c06-0c96-47a5-b9b0-69f7fe36e7eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00de331c-929c-4484-b074-5eda6145046d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8518fe5-cfdd-47ca-b037-adb0df059ca4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0521f11b-2425-4f38-bc53-638e3f849742
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b07cae59-6292-4ea2-8635-22bf4f12a562
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33e51dca-1e0e-49b8-9550-b2de154be376
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd6e2cef-e573-4ee7-a689-48a70ec4b480
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 204b40f3-6f9e-4ec6-ae1b-a8dee0bea3c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07b78a0f-faef-43f2-8d5f-61e24a2ad9ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b3740b2-084f-4efa-8bde-1b63797a2ea1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de504bae-eabf-4f96-9cab-85ee7ac2366b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8d3441c-80ef-4ec1-8ce9-ab87f5922698
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 359a55e0-e395-4ac2-951a-89e92eae33b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e76d902a-869f-4668-897a-e11f9b5c0644
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_4
Server: localhost:8686
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_4
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_4/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_4/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_4/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_4/test_labels.txt

📊 Raw data loaded:
   Train: X=(5467, 24), y=(5467,)
   Test:  X=(1367, 24), y=(1367,)

⚠️  Limiting training data: 5467 → 800 samples
⚠️  Limiting test data: 1367 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_4 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 4 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0919 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0833, val=0.0905 (↓), lr=0.001000
   • Epoch   3/100: train=0.0836, val=0.0903, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0838, val=0.0905, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0836, val=0.0908, patience=3/15, lr=0.001000
   📉 Epoch 9: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0794, val=0.0938, patience=9/15, lr=0.000500
   📉 Epoch 17: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 4 Summary - Client client_4
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0104
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0125
============================================================


============================================================
🔄 Round 5 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0776 (↓), lr=0.000250
   • Epoch   2/100: train=0.0863, val=0.0774, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0860, val=0.0774, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0860, val=0.0774, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0859, val=0.0774, patience=4/15, lr=0.000250
   📉 Epoch 10: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0855, val=0.0774, patience=10/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 5 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000125 (1 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0016
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0007
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2516, R²: 0.0072

============================================================
🔄 Round 7 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0838 (↓), lr=0.000125
   📉 Epoch 2: LR reduced 0.000125 → 0.000063
   • Epoch   2/100: train=0.0848, val=0.0838, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0847, val=0.0838, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0846, val=0.0838, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0846, val=0.0839, patience=4/15, lr=0.000063
   📉 Epoch 10: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0843, val=0.0841, patience=10/15, lr=0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 7 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0032
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0038
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

📊 Round 7 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2519, R²: 0.0069

============================================================
🔄 Round 10 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0858 (↓), lr=0.000031
   📉 Epoch 2: LR reduced 0.000031 → 0.000016
   • Epoch   2/100: train=0.0841, val=0.0858, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0841, val=0.0859, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0841, val=0.0859, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0840, val=0.0859, patience=4/15, lr=0.000016
   📉 Epoch 10: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0839, val=0.0860, patience=10/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 10 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0001
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0030
============================================================


============================================================
🔄 Round 11 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0822 (↓), lr=0.000008
   📉 Epoch 2: LR reduced 0.000008 → 0.000004
   • Epoch   2/100: train=0.0851, val=0.0822, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0851, val=0.0822, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0851, val=0.0823, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0851, val=0.0823, patience=4/15, lr=0.000004
   📉 Epoch 10: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0851, val=0.0823, patience=10/15, lr=0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 11 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0031
   Val:   Loss=0.0822, RMSE=0.2868, R²=-0.0152
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0070

📊 Round 11 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2519, R²: 0.0069

============================================================
🔄 Round 13 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0811 (↓), lr=0.000002
   📉 Epoch 2: LR reduced 0.000002 → 0.000001
   • Epoch   2/100: train=0.0853, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 13 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0032
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0031
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2519, R²: 0.0069

============================================================
🔄 Round 15 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 15 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0005
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0039
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0069

============================================================
🔄 Round 16 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 16 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0026
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0073
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2519, R²: 0.0069

📊 Round 16 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2519, R²: 0.0069

============================================================
🔄 Round 19 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 19 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0005
   Val:   Loss=0.0818, RMSE=0.2859, R²=-0.0045
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2519, R²: 0.0069

============================================================
🔄 Round 20 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 20 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0008
   Val:   Loss=0.0898, RMSE=0.2996, R²=-0.0004
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2519, R²: 0.0069

📊 Round 20 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2519, R²: 0.0069

============================================================
🔄 Round 23 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 23 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0015
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0062
============================================================


============================================================
🔄 Round 24 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0945 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0945, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0946, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0947, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0945)

============================================================
📊 Round 24 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0026
   Val:   Loss=0.0945, RMSE=0.3074, R²=-0.0052
============================================================


============================================================
🔄 Round 26 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 26 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0009
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0141
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2519, R²: 0.0069

📊 Round 26 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2519, R²: 0.0069

📊 Round 26 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2519, R²: 0.0069

📊 Round 26 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2519, R²: 0.0069

📊 Round 26 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2519, R²: 0.0069

📊 Round 26 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2519, R²: 0.0069

📊 Round 26 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2519, R²: 0.0069

============================================================
🔄 Round 35 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 35 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0005
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0188
============================================================


============================================================
🔄 Round 36 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 36 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2877, R²=0.0012
   Val:   Loss=0.0912, RMSE=0.3019, R²=-0.0018
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2519, R²: 0.0069

============================================================
🔄 Round 39 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 39 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0011
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0000
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2519, R²: 0.0069

📊 Round 39 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2519, R²: 0.0069

📊 Round 39 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2519, R²: 0.0069

📊 Round 39 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0070

============================================================
🔄 Round 45 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 45 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0008
   Val:   Loss=0.0818, RMSE=0.2859, R²=-0.0071
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0070

============================================================
🔄 Round 48 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 48 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0001
   Val:   Loss=0.0826, RMSE=0.2875, R²=0.0052
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0070

📊 Round 48 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2519, R²: 0.0070

============================================================
🔄 Round 52 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 52 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0013
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0012
============================================================


============================================================
🔄 Round 53 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 53 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0029
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0336
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0070

📊 Round 53 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0070

============================================================
🔄 Round 56 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 56 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0000
   Val:   Loss=0.0793, RMSE=0.2815, R²=0.0035
============================================================


============================================================
🔄 Round 61 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 61 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0007
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0052
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0070

============================================================
🔄 Round 64 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 64 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0021
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0041
============================================================


============================================================
🔄 Round 65 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 65 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0001
   Val:   Loss=0.0876, RMSE=0.2959, R²=0.0040
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0070

============================================================
🔄 Round 68 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 68 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0003
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0032
============================================================


============================================================
🔄 Round 73 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 73 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0014
   Val:   Loss=0.0907, RMSE=0.3011, R²=-0.0017
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0070

============================================================
🔄 Round 75 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 75 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0009
   Val:   Loss=0.0858, RMSE=0.2930, R²=0.0008
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0070

📊 Round 75 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0070

============================================================
🔄 Round 77 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 77 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0004
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0024
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0070

============================================================
🔄 Round 81 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 81 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0005
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0027
============================================================


============================================================
🔄 Round 83 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 83 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0002
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0059
============================================================


============================================================
🔄 Round 84 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 84 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0010
   Val:   Loss=0.0770, RMSE=0.2774, R²=0.0002
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0070

============================================================
🔄 Round 86 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 86 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0003
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0032
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0070

📊 Round 86 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0070

============================================================
🔄 Round 90 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 90 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0007
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0018
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0070

📊 Round 90 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0070

============================================================
🔄 Round 94 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 94 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0009
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0285
============================================================


============================================================
🔄 Round 95 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 95 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0017
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0086
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0070

============================================================
🔄 Round 100 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 100 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0023
   Val:   Loss=0.0779, RMSE=0.2792, R²=-0.0060
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0070

📊 Round 100 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0070

============================================================
🔄 Round 106 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 106 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0022
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0002
============================================================


============================================================
🔄 Round 107 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 107 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=0.0020
   Val:   Loss=0.0811, RMSE=0.2849, R²=-0.0178
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0070

📊 Round 107 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0070

============================================================
🔄 Round 112 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 112 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=0.0014
   Val:   Loss=0.0752, RMSE=0.2742, R²=-0.0015
============================================================


============================================================
🔄 Round 114 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 114 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0020
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0061
============================================================


============================================================
🔄 Round 117 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 117 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0005
   Val:   Loss=0.0899, RMSE=0.2998, R²=0.0007
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0070

============================================================
🔄 Round 119 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 119 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0023
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0363
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

============================================================
🔄 Round 122 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 122 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=0.0028
   Val:   Loss=0.0733, RMSE=0.2707, R²=-0.0080
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

============================================================
🔄 Round 123 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 123 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0020
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0050
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

============================================================
🔄 Round 125 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 125 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0001
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0042
============================================================


============================================================
🔄 Round 126 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 126 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0019
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0034
============================================================


============================================================
🔄 Round 127 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 127 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0012
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0016
============================================================


============================================================
🔄 Round 128 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 128 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0001
   Val:   Loss=0.0766, RMSE=0.2767, R²=-0.0092
============================================================


============================================================
🔄 Round 130 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 130 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0022
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0042
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

============================================================
🔄 Round 136 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 136 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0001
   Val:   Loss=0.0790, RMSE=0.2810, R²=0.0043
============================================================


============================================================
🔄 Round 137 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 137 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0015
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0011
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

============================================================
🔄 Round 139 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 139 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0007
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0002
============================================================


============================================================
🔄 Round 140 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 140 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0004
   Val:   Loss=0.0862, RMSE=0.2935, R²=0.0000
============================================================


============================================================
🔄 Round 142 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 142 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0004
   Val:   Loss=0.0919, RMSE=0.3032, R²=0.0043
============================================================


============================================================
🔄 Round 144 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 144 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0001
   Val:   Loss=0.0905, RMSE=0.3008, R²=0.0011
============================================================


============================================================
🔄 Round 145 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 145 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0032
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0090
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

📊 Round 145 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

============================================================
🔄 Round 150 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0933, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 150 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0026
   Val:   Loss=0.0933, RMSE=0.3055, R²=-0.0072
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

============================================================
🔄 Round 151 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 151 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0013
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0096
============================================================


============================================================
🔄 Round 152 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 152 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0015
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0006
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

📊 Round 152 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

📊 Round 152 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

============================================================
🔄 Round 157 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 157 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0015
   Val:   Loss=0.0890, RMSE=0.2984, R²=-0.0038
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

📊 Round 157 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

📊 Round 157 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

📊 Round 157 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

============================================================
🔄 Round 166 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 166 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0000
   Val:   Loss=0.0867, RMSE=0.2945, R²=0.0043
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

============================================================
🔄 Round 168 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 168 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0023
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0053
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

============================================================
🔄 Round 171 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 171 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0011
   Val:   Loss=0.0792, RMSE=0.2815, R²=-0.0012
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

📊 Round 171 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

📊 Round 171 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

============================================================
🔄 Round 175 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 175 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0016
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0020
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

============================================================
🔄 Round 177 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 177 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0016
   Val:   Loss=0.0862, RMSE=0.2937, R²=-0.0247
============================================================


============================================================
🔄 Round 179 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 179 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=0.0015
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0031
============================================================


============================================================
🔄 Round 181 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 181 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0013
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0079
============================================================


============================================================
🔄 Round 183 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 183 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0024
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0059
============================================================


============================================================
🔄 Round 184 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 184 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=-0.0018
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0064
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

============================================================
🔄 Round 189 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 189 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0002
   Val:   Loss=0.0790, RMSE=0.2812, R²=0.0033
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

============================================================
🔄 Round 191 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 191 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0012
   Val:   Loss=0.0882, RMSE=0.2969, R²=-0.0010
============================================================


============================================================
🔄 Round 193 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 193 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0014
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0049
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

============================================================
🔄 Round 195 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 195 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0001
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0023
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

============================================================
🔄 Round 197 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 197 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0019
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0091
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

============================================================
🔄 Round 199 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 199 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0014
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0027
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

📊 Round 199 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

============================================================
🔄 Round 202 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 202 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0003
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0007
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

============================================================
🔄 Round 204 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 204 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0017
   Val:   Loss=0.0871, RMSE=0.2952, R²=-0.0026
============================================================


============================================================
🔄 Round 205 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 205 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0000
   Val:   Loss=0.0758, RMSE=0.2754, R²=-0.0032
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

📊 Round 205 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

📊 Round 205 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

============================================================
🔄 Round 208 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 208 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0011
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0067
============================================================


============================================================
🔄 Round 209 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 209 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0008
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0013
============================================================


============================================================
🔄 Round 211 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 211 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0025
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0086
============================================================


📊 Round 211 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

📊 Round 211 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

📊 Round 211 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

============================================================
🔄 Round 219 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 219 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0006
   Val:   Loss=0.0905, RMSE=0.3009, R²=-0.0056
============================================================


📊 Round 219 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

📊 Round 219 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

📊 Round 219 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

============================================================
🔄 Round 222 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 222 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0011
   Val:   Loss=0.0859, RMSE=0.2930, R²=-0.0112
============================================================


📊 Round 222 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

============================================================
🔄 Round 225 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0986 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0986, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0986, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0986, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0986, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0986, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0986)

============================================================
📊 Round 225 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0017
   Val:   Loss=0.0986, RMSE=0.3141, R²=-0.0023
============================================================


============================================================
🔄 Round 226 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 226 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0033
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0126
============================================================


📊 Round 226 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

============================================================
🔄 Round 229 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 229 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0021
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0084
============================================================


📊 Round 229 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

============================================================
🔄 Round 232 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 232 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0015
   Val:   Loss=0.0921, RMSE=0.3035, R²=-0.0091
============================================================


📊 Round 232 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

============================================================
🔄 Round 233 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 233 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0023
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0132
============================================================


📊 Round 233 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

📊 Round 233 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

============================================================
🔄 Round 235 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 235 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2921, R²=-0.0017
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0032
============================================================


============================================================
🔄 Round 236 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 236 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0007
   Val:   Loss=0.0785, RMSE=0.2801, R²=0.0001
============================================================


============================================================
🔄 Round 237 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 237 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0004
   Val:   Loss=0.0917, RMSE=0.3029, R²=0.0045
============================================================


📊 Round 237 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

============================================================
🔄 Round 238 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 238 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0027
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0037
============================================================


============================================================
🔄 Round 240 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 240 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0014
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0140
============================================================


📊 Round 240 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

============================================================
🔄 Round 243 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 243 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0008
   Val:   Loss=0.0913, RMSE=0.3022, R²=-0.0010
============================================================


📊 Round 243 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

📊 Round 243 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

============================================================
🔄 Round 245 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 245 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0000
   Val:   Loss=0.0881, RMSE=0.2969, R²=0.0035
============================================================


📊 Round 245 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

📊 Round 245 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

📊 Round 245 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

📊 Round 245 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

============================================================
🔄 Round 249 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 249 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=-0.0011
   Val:   Loss=0.0928, RMSE=0.3047, R²=-0.0057
============================================================


============================================================
🔄 Round 250 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 250 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=0.0003
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0015
============================================================


📊 Round 250 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

============================================================
🔄 Round 252 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 252 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=0.0023
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0095
============================================================


📊 Round 252 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

📊 Round 252 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

============================================================
🔄 Round 254 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 254 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0009
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0032
============================================================


============================================================
🔄 Round 255 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 255 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=0.0012
   Val:   Loss=0.0734, RMSE=0.2709, R²=-0.0027
============================================================


📊 Round 255 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

📊 Round 255 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

📊 Round 255 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

============================================================
🔄 Round 260 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 260 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0007
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0322
============================================================


============================================================
🔄 Round 261 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 261 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0005
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0016
============================================================


============================================================
🔄 Round 264 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 264 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0015
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0055
============================================================


📊 Round 264 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

📊 Round 264 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

============================================================
🔄 Round 267 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 267 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0009
   Val:   Loss=0.0789, RMSE=0.2810, R²=-0.0029
============================================================


============================================================
🔄 Round 268 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 268 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0015
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0042
============================================================


📊 Round 268 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

============================================================
🔄 Round 269 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 269 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0022
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0185
============================================================


📊 Round 269 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

============================================================
🔄 Round 271 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 271 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0002
   Val:   Loss=0.0763, RMSE=0.2761, R²=-0.0059
============================================================


============================================================
🔄 Round 272 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 272 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0027
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0126
============================================================


============================================================
🔄 Round 274 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 274 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0009
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0011
============================================================


📊 Round 274 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

============================================================
🔄 Round 275 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 275 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0023
   Val:   Loss=0.0728, RMSE=0.2697, R²=0.0115
============================================================


📊 Round 275 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

📊 Round 275 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

============================================================
🔄 Round 280 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 280 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=0.0018
   Val:   Loss=0.0721, RMSE=0.2686, R²=-0.0113
============================================================


📊 Round 280 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

============================================================
🔄 Round 282 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 282 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0007
   Val:   Loss=0.0778, RMSE=0.2790, R²=0.0052
============================================================


============================================================
🔄 Round 283 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 283 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0037
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0191
============================================================


📊 Round 283 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

📊 Round 283 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

📊 Round 283 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

📊 Round 283 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

📊 Round 283 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

============================================================
🔄 Round 295 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 295 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0026
   Val:   Loss=0.0766, RMSE=0.2767, R²=0.0031
============================================================


📊 Round 295 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

============================================================
🔄 Round 297 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 297 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=0.0009
   Val:   Loss=0.0741, RMSE=0.2722, R²=-0.0004
============================================================


📊 Round 297 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

============================================================
🔄 Round 298 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 298 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0018
   Val:   Loss=0.0910, RMSE=0.3016, R²=-0.0105
============================================================


============================================================
🔄 Round 299 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 299 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0008
   Val:   Loss=0.0926, RMSE=0.3043, R²=-0.0064
============================================================


📊 Round 299 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

📊 Round 299 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

============================================================
🔄 Round 302 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 302 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0008
   Val:   Loss=0.0897, RMSE=0.2994, R²=-0.0057
============================================================


============================================================
🔄 Round 303 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 303 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0024
   Val:   Loss=0.0915, RMSE=0.3025, R²=-0.0288
============================================================


============================================================
🔄 Round 305 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 305 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0004
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0059
============================================================


📊 Round 305 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

============================================================
🔄 Round 308 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 308 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0009
   Val:   Loss=0.0726, RMSE=0.2694, R²=0.0079
============================================================


📊 Round 308 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 310 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 310 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0005
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0048
============================================================


📊 Round 310 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

📊 Round 310 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

📊 Round 310 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

📊 Round 310 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 317 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 317 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0013
   Val:   Loss=0.0838, RMSE=0.2896, R²=0.0090
============================================================


============================================================
🔄 Round 318 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0687 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0687, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0687, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0687, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0687, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0687, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0687)

============================================================
📊 Round 318 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=-0.0008
   Val:   Loss=0.0687, RMSE=0.2620, R²=-0.0016
============================================================


📊 Round 318 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 320 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 320 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0002
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0002
============================================================


📊 Round 320 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

📊 Round 320 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 326 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 326 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0004
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0010
============================================================


📊 Round 326 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

============================================================
🔄 Round 328 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 328 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0004
   Val:   Loss=0.0768, RMSE=0.2772, R²=0.0027
============================================================


============================================================
🔄 Round 329 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 329 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0004
   Val:   Loss=0.0891, RMSE=0.2986, R²=-0.0161
============================================================


============================================================
🔄 Round 331 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 331 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0013
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0019
============================================================


📊 Round 331 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

📊 Round 331 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

============================================================
🔄 Round 336 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 336 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0011
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0015
============================================================


📊 Round 336 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

📊 Round 336 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

📊 Round 336 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

============================================================
🔄 Round 339 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 339 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0020
   Val:   Loss=0.0894, RMSE=0.2991, R²=-0.0067
============================================================


📊 Round 339 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2519, R²: 0.0071

📊 Round 339 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2519, R²: 0.0071

📊 Round 339 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2519, R²: 0.0071

============================================================
🔄 Round 347 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0980 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0980, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0980, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0980, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0980, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0980, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0980)

============================================================
📊 Round 347 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0024
   Val:   Loss=0.0980, RMSE=0.3131, R²=-0.0071
============================================================


📊 Round 347 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2519, R²: 0.0071

📊 Round 347 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

============================================================
🔄 Round 351 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 351 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0016
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0036
============================================================


📊 Round 351 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

📊 Round 351 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

============================================================
🔄 Round 353 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 353 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0002
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0026
============================================================


============================================================
🔄 Round 354 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 354 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0016
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0032
============================================================


📊 Round 354 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

============================================================
🔄 Round 357 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 357 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0013
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0089
============================================================


📊 Round 357 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

============================================================
🔄 Round 359 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 359 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0016
   Val:   Loss=0.0889, RMSE=0.2981, R²=0.0093
============================================================


📊 Round 359 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

📊 Round 359 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

============================================================
🔄 Round 361 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 361 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0018
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0099
============================================================


📊 Round 361 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

📊 Round 361 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

📊 Round 361 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

📊 Round 361 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

📊 Round 361 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

📊 Round 361 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

============================================================
🔄 Round 368 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 368 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=0.0002
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0062
============================================================


📊 Round 368 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

============================================================
🔄 Round 369 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 369 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0009
   Val:   Loss=0.0774, RMSE=0.2783, R²=-0.0005
============================================================


📊 Round 369 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

============================================================
🔄 Round 371 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 371 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0016
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0055
============================================================


📊 Round 371 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

============================================================
🔄 Round 372 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 372 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0010
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0040
============================================================


============================================================
🔄 Round 373 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 373 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0003
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0017
============================================================


📊 Round 373 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 375 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 375 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0062
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0179
============================================================


📊 Round 375 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 380 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 380 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2959, R²=0.0005
   Val:   Loss=0.0720, RMSE=0.2684, R²=0.0016
============================================================


============================================================
🔄 Round 382 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 382 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0012
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.0033
============================================================


📊 Round 382 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

============================================================
🔄 Round 386 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 386 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0012
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0022
============================================================


📊 Round 386 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

📊 Round 386 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0071

============================================================
🔄 Round 389 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 389 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0016
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0098
============================================================


============================================================
🔄 Round 392 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 392 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0016
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0076
============================================================


============================================================
🔄 Round 393 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 393 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0006
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0008
============================================================


============================================================
🔄 Round 394 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 394 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=-0.0005
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0049
============================================================


📊 Round 394 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

📊 Round 394 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

📊 Round 394 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 398 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 398 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0011
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0012
============================================================


📊 Round 398 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 400 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 400 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0009
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0008
============================================================


============================================================
🔄 Round 402 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 402 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0037
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0210
============================================================


📊 Round 402 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

📊 Round 402 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

📊 Round 402 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

📊 Round 402 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 407 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 407 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2916, R²=-0.0006
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0093
============================================================


📊 Round 407 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

📊 Round 407 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 410 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 410 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0036
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0108
============================================================


📊 Round 410 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 412 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 412 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0019
   Val:   Loss=0.0919, RMSE=0.3031, R²=-0.0037
============================================================


📊 Round 412 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

📊 Round 412 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

📊 Round 412 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 422 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 422 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0007
   Val:   Loss=0.0922, RMSE=0.3037, R²=0.0008
============================================================


📊 Round 422 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 424 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 424 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0020
   Val:   Loss=0.0898, RMSE=0.2996, R²=-0.0012
============================================================


============================================================
🔄 Round 425 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 425 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0015
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0043
============================================================


📊 Round 425 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

📊 Round 425 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 429 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 429 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2932, R²=0.0007
   Val:   Loss=0.0784, RMSE=0.2801, R²=-0.0035
============================================================


============================================================
🔄 Round 430 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 430 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0016
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0070
============================================================


============================================================
🔄 Round 431 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 431 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0007
   Val:   Loss=0.0778, RMSE=0.2790, R²=-0.0088
============================================================


📊 Round 431 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 434 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 434 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0030
   Val:   Loss=0.0837, RMSE=0.2892, R²=-0.0110
============================================================


📊 Round 434 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 436 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 436 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0017
   Val:   Loss=0.0774, RMSE=0.2783, R²=-0.0041
============================================================


📊 Round 436 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

📊 Round 436 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

📊 Round 436 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 440 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 440 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0011
   Val:   Loss=0.0875, RMSE=0.2959, R²=0.0055
============================================================


📊 Round 440 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 441 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 441 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0007
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0024
============================================================


📊 Round 441 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 443 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 443 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0024
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0160
============================================================


📊 Round 443 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 444 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 444 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=0.0018
   Val:   Loss=0.0748, RMSE=0.2735, R²=-0.0251
============================================================


📊 Round 444 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 449 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 449 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0002
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0019
============================================================


============================================================
🔄 Round 450 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 450 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0009
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0044
============================================================


📊 Round 450 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

📊 Round 450 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

📊 Round 450 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 455 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 455 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=0.0009
   Val:   Loss=0.0901, RMSE=0.3001, R²=-0.0003
============================================================


============================================================
🔄 Round 456 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 456 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0003
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0013
============================================================


📊 Round 456 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 457 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 457 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0018
   Val:   Loss=0.0923, RMSE=0.3039, R²=-0.0337
============================================================


📊 Round 457 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 459 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 459 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0014
   Val:   Loss=0.0901, RMSE=0.3001, R²=0.0049
============================================================


📊 Round 459 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

📊 Round 459 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 463 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 463 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0012
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0008
============================================================


📊 Round 463 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 465 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 465 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0001
   Val:   Loss=0.0852, RMSE=0.2918, R²=0.0011
============================================================


📊 Round 465 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 466 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 466 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0008
   Val:   Loss=0.0906, RMSE=0.3010, R²=-0.0000
============================================================


📊 Round 466 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

📊 Round 466 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

📊 Round 466 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

📊 Round 466 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

📊 Round 466 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 480 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 480 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0014
   Val:   Loss=0.0891, RMSE=0.2984, R²=-0.0121
============================================================


============================================================
🔄 Round 481 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 481 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0028
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0097
============================================================


📊 Round 481 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 482 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 482 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0008
   Val:   Loss=0.0882, RMSE=0.2971, R²=-0.0004
============================================================


============================================================
🔄 Round 484 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 484 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0016
   Val:   Loss=0.0931, RMSE=0.3051, R²=-0.0006
============================================================


📊 Round 484 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

📊 Round 484 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 486 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 486 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0000
   Val:   Loss=0.0884, RMSE=0.2973, R²=0.0016
============================================================


📊 Round 486 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 488 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 488 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0002
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0099
============================================================


📊 Round 488 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 489 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 489 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0011
   Val:   Loss=0.0845, RMSE=0.2908, R²=-0.0601
============================================================


============================================================
🔄 Round 491 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 491 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0004
   Val:   Loss=0.0822, RMSE=0.2866, R²=0.0002
============================================================


============================================================
🔄 Round 493 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 493 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=-0.0013
   Val:   Loss=0.0724, RMSE=0.2691, R²=-0.0026
============================================================


============================================================
🔄 Round 494 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 494 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0009
   Val:   Loss=0.0897, RMSE=0.2995, R²=0.0046
============================================================


📊 Round 494 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

📊 Round 494 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

📊 Round 494 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 502 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 502 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0017
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0116
============================================================


📊 Round 502 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

📊 Round 502 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 506 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0962 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0962, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0962, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0962, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0962, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0962, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0962)

============================================================
📊 Round 506 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0005
   Val:   Loss=0.0962, RMSE=0.3101, R²=0.0015
============================================================


📊 Round 506 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 508 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 508 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0005
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0012
============================================================


📊 Round 508 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 509 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 509 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0012
   Val:   Loss=0.0884, RMSE=0.2974, R²=-0.0037
============================================================


📊 Round 509 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 510 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 510 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0016
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0031
============================================================


📊 Round 510 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 511 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 511 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0004
   Val:   Loss=0.0919, RMSE=0.3032, R²=0.0005
============================================================


📊 Round 511 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

📊 Round 511 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 514 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 514 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=0.0020
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0068
============================================================


📊 Round 514 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 519 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 519 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0005
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0007
============================================================


📊 Round 519 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

📊 Round 519 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

📊 Round 519 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

📊 Round 519 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

📊 Round 519 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 526 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 526 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0003
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0005
============================================================


📊 Round 526 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 527 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 527 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0014
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0105
============================================================


📊 Round 527 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 530 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 530 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0002
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0085
============================================================


📊 Round 530 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

📊 Round 530 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 533 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0706 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0706, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0706, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0706, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0706)

============================================================
📊 Round 533 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=0.0002
   Val:   Loss=0.0706, RMSE=0.2657, R²=0.0018
============================================================


📊 Round 533 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 535 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 535 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0009
   Val:   Loss=0.0851, RMSE=0.2916, R²=-0.0004
============================================================


============================================================
🔄 Round 537 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 537 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0011
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0009
============================================================


============================================================
🔄 Round 538 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 538 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0004
   Val:   Loss=0.0756, RMSE=0.2750, R²=-0.0004
============================================================


============================================================
🔄 Round 545 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 545 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0001
   Val:   Loss=0.0909, RMSE=0.3016, R²=-0.0076
============================================================


📊 Round 545 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 549 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 549 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0021
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0132
============================================================


📊 Round 549 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 550 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 550 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0002
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0040
============================================================


============================================================
🔄 Round 551 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 551 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0009
   Val:   Loss=0.0760, RMSE=0.2756, R²=0.0022
============================================================


📊 Round 551 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 552 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 552 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0022
   Val:   Loss=0.0904, RMSE=0.3006, R²=-0.0094
============================================================


📊 Round 552 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 553 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 553 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0021
   Val:   Loss=0.0859, RMSE=0.2930, R²=-0.0287
============================================================


📊 Round 553 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

📊 Round 553 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 557 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 557 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0012
   Val:   Loss=0.0840, RMSE=0.2897, R²=-0.0024
============================================================


📊 Round 557 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 562 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 562 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0001
   Val:   Loss=0.0881, RMSE=0.2969, R²=-0.0061
============================================================


============================================================
🔄 Round 563 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 563 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0021
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0106
============================================================


============================================================
🔄 Round 565 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 565 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0005
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0007
============================================================


📊 Round 565 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 566 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 566 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0002
   Val:   Loss=0.0869, RMSE=0.2949, R²=0.0009
============================================================


============================================================
🔄 Round 567 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 567 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0008
   Val:   Loss=0.0830, RMSE=0.2882, R²=-0.0010
============================================================


============================================================
🔄 Round 568 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 568 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0005
   Val:   Loss=0.0887, RMSE=0.2978, R²=0.0008
============================================================


📊 Round 568 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 570 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 570 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0018
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0282
============================================================


📊 Round 570 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

📊 Round 570 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 578 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 578 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0010
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0014
============================================================


📊 Round 578 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 581 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 581 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0009
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0058
============================================================


============================================================
🔄 Round 582 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 582 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0020
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0095
============================================================


📊 Round 582 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 583 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 583 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0002
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0020
============================================================


📊 Round 583 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 584 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 584 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0003
   Val:   Loss=0.0883, RMSE=0.2971, R²=0.0004
============================================================


============================================================
🔄 Round 585 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 585 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0000
   Val:   Loss=0.0798, RMSE=0.2824, R²=-0.0014
============================================================


📊 Round 585 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 587 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0962 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0962, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0963, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0963, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0963, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0964, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0962)

============================================================
📊 Round 587 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0008
   Val:   Loss=0.0962, RMSE=0.3102, R²=-0.0126
============================================================


📊 Round 587 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

📊 Round 587 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2519, R²: 0.0072

📊 Round 587 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2519, R²: 0.0072

📊 Round 587 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2519, R²: 0.0072

📊 Round 587 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2519, R²: 0.0072

📊 Round 587 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2519, R²: 0.0072

📊 Round 587 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2519, R²: 0.0072

============================================================
🔄 Round 597 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 597 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0015
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0245
============================================================


📊 Round 597 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2519, R²: 0.0072

============================================================
🔄 Round 600 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0935 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0935, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 600 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0008
   Val:   Loss=0.0935, RMSE=0.3058, R²=-0.0262
============================================================


============================================================
🔄 Round 601 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 601 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0000
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0014
============================================================


📊 Round 601 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2519, R²: 0.0072

============================================================
🔄 Round 603 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 603 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0003
   Val:   Loss=0.0910, RMSE=0.3016, R²=0.0036
============================================================


📊 Round 603 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2519, R²: 0.0072

📊 Round 603 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2519, R²: 0.0072

============================================================
🔄 Round 607 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 607 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2903, R²=-0.0014
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0081
============================================================


📊 Round 607 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2519, R²: 0.0072

============================================================
🔄 Round 608 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 608 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0024
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0064
============================================================


📊 Round 608 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 611 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 611 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0008
   Val:   Loss=0.0801, RMSE=0.2829, R²=-0.0008
============================================================


📊 Round 611 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

📊 Round 611 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

📊 Round 611 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

📊 Round 611 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 617 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 617 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0011
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0061
============================================================


📊 Round 617 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

📊 Round 617 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

📊 Round 617 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 627 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 627 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=0.0018
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0200
============================================================


============================================================
🔄 Round 628 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 628 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0005
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0018
============================================================


📊 Round 628 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

📊 Round 628 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 630 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 630 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0008
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0075
============================================================


============================================================
🔄 Round 631 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 631 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0022
   Val:   Loss=0.0906, RMSE=0.3009, R²=-0.0082
============================================================


============================================================
🔄 Round 633 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 633 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0003
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0016
============================================================


============================================================
🔄 Round 634 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 634 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0026
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0015
============================================================


📊 Round 634 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0072

============================================================
🔄 Round 639 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 639 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0001
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0022
============================================================


============================================================
🔄 Round 640 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 640 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=0.0005
   Val:   Loss=0.0726, RMSE=0.2695, R²=0.0008
============================================================


============================================================
🔄 Round 641 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 641 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0028
   Val:   Loss=0.0770, RMSE=0.2774, R²=-0.0158
============================================================


============================================================
🔄 Round 642 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 642 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0003
   Val:   Loss=0.0852, RMSE=0.2918, R²=0.0022
============================================================


============================================================
🔄 Round 643 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 643 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0008
   Val:   Loss=0.0881, RMSE=0.2969, R²=-0.0003
============================================================


============================================================
🔄 Round 644 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 644 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0014
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0106
============================================================


📊 Round 644 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

📊 Round 644 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

============================================================
🔄 Round 646 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0938, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 646 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0001
   Val:   Loss=0.0938, RMSE=0.3063, R²=0.0012
============================================================


📊 Round 646 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

============================================================
🔄 Round 647 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 647 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0011
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0046
============================================================


============================================================
🔄 Round 648 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0958 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0958, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0958, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0958, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0958, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0958, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0958)

============================================================
📊 Round 648 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0033
   Val:   Loss=0.0958, RMSE=0.3095, R²=-0.0084
============================================================


📊 Round 648 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

============================================================
🔄 Round 649 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 649 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=-0.0004
   Val:   Loss=0.0748, RMSE=0.2734, R²=0.0057
============================================================


📊 Round 649 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

📊 Round 649 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

============================================================
🔄 Round 651 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 651 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0018
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0175
============================================================


📊 Round 651 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

============================================================
🔄 Round 654 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 654 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0007
   Val:   Loss=0.0920, RMSE=0.3032, R²=-0.0094
============================================================


============================================================
🔄 Round 655 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 655 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0003
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0011
============================================================


📊 Round 655 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

============================================================
🔄 Round 656 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 656 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0015
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0103
============================================================


📊 Round 656 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

============================================================
🔄 Round 657 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 657 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=0.0001
   Val:   Loss=0.0869, RMSE=0.2947, R²=0.0022
============================================================


📊 Round 657 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

============================================================
🔄 Round 658 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 658 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0005
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0039
============================================================


📊 Round 658 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

📊 Round 658 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

📊 Round 658 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

============================================================
🔄 Round 663 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 663 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0010
   Val:   Loss=0.0875, RMSE=0.2959, R²=-0.0016
============================================================


============================================================
🔄 Round 665 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 665 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0008
   Val:   Loss=0.0910, RMSE=0.3017, R²=0.0060
============================================================


📊 Round 665 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

📊 Round 665 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

📊 Round 665 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

============================================================
🔄 Round 673 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 673 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0009
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0071
============================================================


============================================================
🔄 Round 676 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0955 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0955, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0955, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0955, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0955, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0955, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0955)

============================================================
📊 Round 676 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0001
   Val:   Loss=0.0955, RMSE=0.3091, R²=0.0022
============================================================


============================================================
🔄 Round 678 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 678 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0001
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0012
============================================================


============================================================
🔄 Round 681 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 681 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0009
   Val:   Loss=0.0925, RMSE=0.3041, R²=-0.0021
============================================================


📊 Round 681 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

📊 Round 681 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

============================================================
🔄 Round 684 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 684 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0004
   Val:   Loss=0.0758, RMSE=0.2754, R²=-0.0003
============================================================


📊 Round 684 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

📊 Round 684 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

============================================================
🔄 Round 688 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 688 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0015
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0004
============================================================


============================================================
🔄 Round 689 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 689 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0005
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0038
============================================================


📊 Round 689 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

📊 Round 689 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

📊 Round 689 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

📊 Round 689 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

============================================================
🔄 Round 695 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 695 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0019
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0103
============================================================


============================================================
🔄 Round 696 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 696 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0006
   Val:   Loss=0.0914, RMSE=0.3023, R²=0.0002
============================================================


📊 Round 696 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

📊 Round 696 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

============================================================
🔄 Round 699 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 699 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0007
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0059
============================================================


📊 Round 699 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

📊 Round 699 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

============================================================
🔄 Round 704 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 704 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0024
   Val:   Loss=0.0927, RMSE=0.3045, R²=-0.0103
============================================================


📊 Round 704 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

============================================================
🔄 Round 707 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 707 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0003
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0010
============================================================


📊 Round 707 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

============================================================
🔄 Round 708 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 708 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0012
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0071
============================================================


📊 Round 708 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

============================================================
🔄 Round 709 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 709 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0007
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0115
============================================================


============================================================
🔄 Round 710 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 710 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0013
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0224
============================================================


📊 Round 710 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

============================================================
🔄 Round 711 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 711 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0004
   Val:   Loss=0.0818, RMSE=0.2861, R²=0.0014
============================================================


============================================================
🔄 Round 712 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 712 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0009
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0010
============================================================


============================================================
🔄 Round 713 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 713 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0006
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0056
============================================================


============================================================
🔄 Round 714 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0955 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0955, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0955, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0955, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0955, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0955, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0955)

============================================================
📊 Round 714 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0007
   Val:   Loss=0.0955, RMSE=0.3090, R²=-0.0026
============================================================


============================================================
🔄 Round 715 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 715 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0006
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0117
============================================================


📊 Round 715 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

📊 Round 715 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

============================================================
🔄 Round 719 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 719 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0011
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0017
============================================================


📊 Round 719 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

📊 Round 719 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

📊 Round 719 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

📊 Round 719 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

============================================================
🔄 Round 727 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 727 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0007
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0036
============================================================


============================================================
🔄 Round 728 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 728 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0003
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0138
============================================================


============================================================
🔄 Round 729 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 729 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0004
   Val:   Loss=0.0871, RMSE=0.2951, R²=0.0043
============================================================


📊 Round 729 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

📊 Round 729 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

============================================================
🔄 Round 733 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0941, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 733 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0009
   Val:   Loss=0.0940, RMSE=0.3066, R²=-0.0035
============================================================


📊 Round 733 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

============================================================
🔄 Round 734 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 734 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0023
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0072
============================================================


============================================================
🔄 Round 737 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 737 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0015
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0241
============================================================


📊 Round 737 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

📊 Round 737 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

============================================================
🔄 Round 739 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 739 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0044
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0001
============================================================


============================================================
🔄 Round 740 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 740 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0009
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0015
============================================================


📊 Round 740 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

📊 Round 740 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

📊 Round 740 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

📊 Round 740 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

📊 Round 740 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

📊 Round 740 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

📊 Round 740 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

============================================================
🔄 Round 751 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 751 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0002
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0023
============================================================


📊 Round 751 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

📊 Round 751 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

📊 Round 751 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

============================================================
🔄 Round 756 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 756 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0005
   Val:   Loss=0.0756, RMSE=0.2749, R²=0.0057
============================================================


📊 Round 756 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

📊 Round 756 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

============================================================
🔄 Round 759 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 759 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0012
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0056
============================================================


📊 Round 759 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

📊 Round 759 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

============================================================
🔄 Round 761 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 761 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0032
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0171
============================================================


📊 Round 761 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

============================================================
🔄 Round 762 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 762 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0024
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0081
============================================================


📊 Round 762 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

============================================================
🔄 Round 763 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 763 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0002
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0017
============================================================


📊 Round 763 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

============================================================
🔄 Round 765 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 765 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0008
   Val:   Loss=0.0900, RMSE=0.3001, R²=-0.0065
============================================================


============================================================
🔄 Round 766 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 766 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0005
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0017
============================================================


📊 Round 766 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

📊 Round 766 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

📊 Round 766 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0073

============================================================
🔄 Round 769 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 769 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0007
   Val:   Loss=0.0911, RMSE=0.3018, R²=-0.0018
============================================================


📊 Round 769 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0074

============================================================
🔄 Round 775 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 775 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0016
   Val:   Loss=0.0744, RMSE=0.2727, R²=-0.0090
============================================================


📊 Round 775 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0074

============================================================
🔄 Round 777 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 777 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0005
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0035
============================================================


============================================================
🔄 Round 778 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 778 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0009
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0041
============================================================


📊 Round 778 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0074

============================================================
🔄 Round 781 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 781 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0018
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0035
============================================================


📊 Round 781 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0074

============================================================
🔄 Round 785 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 785 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0017
   Val:   Loss=0.0802, RMSE=0.2831, R²=-0.0040
============================================================


📊 Round 785 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0074

============================================================
🔄 Round 786 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 786 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0002
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0013
============================================================


📊 Round 786 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0074

============================================================
🔄 Round 788 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 788 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0008
   Val:   Loss=0.0869, RMSE=0.2949, R²=-0.0006
============================================================


📊 Round 788 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0074

============================================================
🔄 Round 791 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 791 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0013
   Val:   Loss=0.0754, RMSE=0.2746, R²=-0.0518
============================================================


============================================================
🔄 Round 792 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 792 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0000
   Val:   Loss=0.0853, RMSE=0.2920, R²=0.0032
============================================================


📊 Round 792 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0074

📊 Round 792 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0074

============================================================
🔄 Round 795 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 795 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=0.0013
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0013
============================================================


📊 Round 795 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0074

============================================================
🔄 Round 797 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0944 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0944, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0944, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0944, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0944, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0944, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0944)

============================================================
📊 Round 797 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0014
   Val:   Loss=0.0944, RMSE=0.3072, R²=-0.0025
============================================================


📊 Round 797 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0074

📊 Round 797 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0074

📊 Round 797 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0074

📊 Round 797 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0074

📊 Round 797 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0074

📊 Round 797 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0074

📊 Round 797 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0074

============================================================
🔄 Round 806 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 806 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0005
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0005
============================================================


📊 Round 806 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2518, R²: 0.0074

============================================================
🔄 Round 808 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 808 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0012
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0015
============================================================


❌ Client client_4 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_status:14, grpc_message:"Socket closed"}"
>
