[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0540f3c6-a5e8-4ff7-9575-49b77441a207
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 142db5ab-b492-415d-b1fe-bc9d1c6a9d50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b666b270-9696-4baf-ad7c-a8bb72d786e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a6147e5-0156-42ac-91f5-64bfd8dbf2a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8303821d-2fd7-47b7-88ba-b1b7f2c823ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80d89052-2317-412b-be24-04fbc09c5f94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82340b21-55f2-49ed-ad67-64dc6a8f3414
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4874b53-4aa4-4467-94b8-0d63eeb383ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c67a5e6a-fdc2-4b87-aaff-d7fc83db3ea2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43498ae5-4bce-4fab-b2f1-d859c755ce93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b2861bd-9b1e-4a07-8ac8-258d4ff808b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6b51a4f-eb86-4cca-b020-5f3c96491cc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82491837-b101-4adc-90c7-57a257a0204b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fde7b695-a316-46cb-b07f-36e2e8a819cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c447f55d-8783-4b06-b62b-140c77f122bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c7f6de5-1e2e-435a-b6b4-e875ecd4b618
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa528d43-72b1-444c-95bf-af9a2d61fc17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47f6d20d-eb65-494c-a3af-bd540cb25222
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f5f087c-c3e4-4b9c-b4f8-b153b64345b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c380b315-24b8-4384-be65-3d8cc67a5cda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c572d09-7ed1-4c74-9528-11626cb7d2a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e117f9b4-5d0f-4c78-8966-c9d7a7a8b505
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55dcdb62-f35b-4965-b6d2-43f10248698a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5c32e4f-6578-4b4a-a9fa-fbc67416cd0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6dcc525-06b1-4a41-91ae-8451fc55c094
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f45cbf0-da49-4e53-ab1f-027a5608d174
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b4c07b8-e5cc-4a64-897b-b19ff71ce084
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 222729b7-33aa-4972-a8dd-c2d28f299e7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a149b55-2a49-4236-ac54-d7e5e6a704e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f46bf1d-ba7a-4068-8aa8-2c911dfa0079
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1502a639-f2a1-42d6-9cd4-ac46d6e09d1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b50cdba-7189-4ba1-82ff-4067e1bf3bf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a892e9b2-7ccd-4531-ae91-7af13a5b3e76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c92f181b-851a-483e-a249-03d95dd7b49f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6e6b8ef-9a16-4cb0-be73-913057fba2ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e81197f3-6cb7-4ba2-aa23-4e3316d32c61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5a21026-e3fc-4f51-afcc-a258a27370f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85a828f7-3631-409b-baa1-e2753d314d4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4fcf610b-c530-49d1-836f-da3bbc811f84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2126961e-5f59-4c09-a21f-a0e207dc5165
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c862d3f1-d545-4683-8be8-8f26caa0b711
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4f32c29-3730-4bae-a2a2-80e92290c5d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5a6c5c6-84de-4a34-b96d-357be3c2d006
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9c0ad7a-b122-45e8-ae3f-e447b0d4e2be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8234370-84da-4803-a789-3e3224d611f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0661b7e-670d-4f11-9391-4a84e31dd20c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b255dc2-3b63-4528-8b83-4665ab79705c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40b3e69a-debe-4983-8be1-4545e930ac6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c850350e-4874-49d7-8acb-75258beed4e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8771f695-f9c0-4ab4-a09c-e16955c32f78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5ed9483-1b7b-47ee-bbcf-ca8d0747a679
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b138dc45-cf93-4840-bb9d-af9db347b97e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c52602fe-2ba0-4979-a154-b09decaa6f2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3c1ae7c-76eb-4a41-8e49-7ae18360a1cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7734a1aa-7b36-4235-9a04-d0d82491a386
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64f4bb57-f05e-4304-83b3-ad9c8af8eed6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eced3f10-722d-44e4-a88e-f6cc0311a855
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 276acbdb-4f4e-486b-bbcf-ce3a7dc8d04d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0746a322-4bce-4e67-84ef-d3556aa64c92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6aa9c824-a61a-4cf5-b342-9e32003f8869
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e7748e6-e465-46fa-a067-342422b15493
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 342b8f10-e81c-472d-b42f-0c1afd545f0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04bae0fa-8447-4cc0-84a0-07c226b04429
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a7a6ee5-8311-4e0f-b7b6-fc57cedb3ffc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e04d9c4-de06-4db8-815b-ab6d3478c31f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c87efb4c-e5e4-415c-8693-0799356f5cfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0518a82-0b17-4c5b-835d-d63059e8fa1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b746a11-d1cb-4ac1-afa2-6185fff66be6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f3990ba-3791-4cd7-8127-4b51c90eeafb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1375f9ed-f144-44ff-bc3b-ba9ef5a27cd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03bb39de-6936-4f3c-be4b-48686d72eb4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2cb5837-53ae-4909-baa9-691b96f7ec64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b87fdeed-dcd5-4562-850a-7377767ced69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfcb1684-0e40-4e20-b374-178d765a5831
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60e08d3b-3103-46ae-9465-0742c37d7ad1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e32d6c3-2637-471d-8bd5-d626d0fc6e98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3502eca2-5a86-481b-9210-4c426c195b40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b00e7e9-fbbd-48be-a978-c620f12ea8b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47ffac5b-0812-482d-aecf-df9716f6a22c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cea0f530-1ef3-4ecd-90cf-c1f51a613b6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5647b967-6694-4843-a184-47f8d4524bcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70eb0254-1f37-4b6d-b015-01857d44be6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8bb7c768-a0e0-4c7b-8f9e-1cd9c99dafe7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d537d75d-ad31-4a45-b608-23ac0296ce55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4dcee2ce-714d-4172-a746-8c47cd6134da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64cc6d3f-6705-4fe8-a3d0-e50c48945460
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b1d0722-0f09-4e68-a57b-0b20d03c00a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38d69276-c91d-479a-8c9f-26041bc02cb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26a4c30c-29dc-4ff7-ab00-1e30714191dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35f2d47b-ff68-4086-87c1-cb9dd1eb2bd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57c52117-69cd-4c23-ba3a-9b36831a81bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d02cc3b-e3c3-494b-9b30-42e99b770db5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62fc35ca-e73e-4e82-a397-eaf689d4d24a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8791dab3-f81a-4300-a5d4-df7e5d0a4edd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f6b4e1a-363d-4199-9b40-3bc9cb4175df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6cfe78a3-4244-4349-96c5-0c1573df2930
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2799afc8-f636-41e1-b47e-32130b7538f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4416adff-73df-451a-8d7d-c0b20be8a2e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eeb513c4-a4d8-4303-886f-5dbeb8eea18a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec22b7f9-2e93-4b4f-90a3-8041a2b849a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 841904e9-614c-4684-a80a-1ad719db62c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff2927fc-c02c-422b-943b-190f0215663c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24c57f1e-7bf5-43da-9a08-90f5efd6f811
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6411288-cadf-4cac-ac86-3ebf92dee548
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 382120af-3158-4824-955d-7717d59ea2ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d659f4f2-4ba4-4155-a6d1-6b1d6cf44593
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70c9531c-7d9f-432b-a4c4-81a7f608096f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85438e42-b249-4d15-abf6-516060845db3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0a046aa-64ed-40ca-90a7-ce98c8d4f93b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2d44892-4ada-4482-b290-98d426a9b52b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 209206f8-aedf-4dc1-a9e3-3a383878ac39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67aa2c19-7ae2-4267-acbc-253b96636723
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3edc4e18-9955-4fb4-99d9-4f5e59152e4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c456801c-e678-414b-ada3-430b5f932839
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d46ebe0-d6e3-4faa-9f37-b49e9700e1c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message caad6647-6007-436f-b711-57c10bea384c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25551e23-7321-4302-8bf9-763b8598ac8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b55d0d77-0b31-408e-9693-164183d2a5cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93814f37-5493-42b3-96ac-eaec7f11d197
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a859dde8-d62d-49d1-872b-823d3b544e1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c1986d0-30a7-4936-b176-b24d137171a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dde2c96b-1ff3-40be-8573-3c72d8aa6976
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 347466a9-e5b3-473d-b83d-30f2fcb5ba8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad01c3a4-048d-4038-893b-c2b5466555a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f8365f7-69c3-44ac-9e3c-a18c1b44837e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a39cb5ec-f28e-4b2b-aaf0-1b0001cc277c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41472774-263b-48c2-b660-dbc2878c6bcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccae0aac-2d60-4e8e-8cee-2099a714f1ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca95f83a-bdde-401c-89b9-0ddc01631bda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e3e66cc-839a-41c4-9403-cadee5258509
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28f93e37-1f25-47c6-82a6-6895a9672d10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f95c6bac-fb88-42ea-8628-66fcb430324d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 123bef96-5579-472e-9ba5-12bcf88b95da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a404fb03-99ef-4e3d-b015-010c1ee38bd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1781b2c-d8e3-404b-9fa6-3722690caf2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 813726dc-af7b-4f8e-8e02-53cfe1db97be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 895d183e-9612-48dc-a652-8ef3bb6b5ed5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92a1595d-79c6-4ef7-a9a5-6430cc8ae4a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dce980f2-2608-4c5b-9fb7-90ffc4d0bcbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75437147-80f0-4d65-8198-550df39230df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9eb31b7-91e4-48ce-81ca-7ff44bb9b50e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc27e200-9127-420b-a6f5-27f2a129a388
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa844ed9-da25-45ce-8fe8-f4fbce95ad5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8a03324-b4fe-4db7-8152-8858eb993b88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 529db480-defd-429f-9810-3b12e2e5a2d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07c52aa1-5b44-42e9-a8e5-c37adc7a31a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da8f57ef-fcd2-4de9-930e-fd73c26defb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7318536d-4d4b-4408-989c-e6b2c5ad2c0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2988bd6-41e2-466b-8dbb-0b7e4cbf5307
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27a5271c-527a-4007-b1cb-7e15baa6b49b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f37a6aac-7838-499c-a64e-b7978e616a21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a748d697-68a6-4740-8937-a35680c52b6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce1324f7-c180-46a0-9053-64b52207bec9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a13aa964-41ba-4afc-9bda-dcb77a11ffb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25f99561-fbeb-49c5-8e05-9afb40a1a337
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 708ffcbe-8839-4e4c-886f-c4d0b6355d65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af83dbe9-9ae3-4f3a-9e12-a779364e7d1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc47f7f2-753e-4a5e-a68e-c68b0f7a8d26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7800aba7-bde4-4fe5-8ea8-3a53b7a12260
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 533d3cbc-71e9-4a89-8be2-91735015969c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c53e6562-3cde-4b43-8d23-9f7cc744e68a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9665d68-5c00-4acb-8b20-9583d2715b30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 242853a1-ef58-4a2c-b301-33ba2b2558da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5d19eaa-86a6-4aa0-b771-4204b15856a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c189150-1932-4b1e-9ef7-7931bad128f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4a323f4-366b-421b-a86b-98c9ee8ce95f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf829493-4401-4e59-afe4-6783945e1296
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a8afc33-979e-4b82-8acd-9f2e9a04233e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc6289ba-1076-4da1-afd0-5b3d16bc284a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c56fd2a-713f-4457-8a92-e0c41e31c5a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0e9b933-eafa-4ab8-b4a7-2c86915bfd4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25bf145b-5d41-4178-8099-ff22a6123943
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83d77347-0c64-4183-bca8-6cceb9d93080
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0936e03-9b37-497e-97d6-853e8493ea6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e59e9903-56e6-44f0-8e35-81c773c6d93d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f9f9c46-65e4-4454-8231-ba5c2a8cf882
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1eb02072-dd79-43ba-946a-7d69bb16077b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ae4d9d8-d02a-4690-8055-fcf25c29777e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61088794-6ae0-478c-8026-dd0b5e21e564
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 875f13b3-0baf-4b2d-9114-2e9983677c8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b76de695-d0ba-49dc-95cd-8ed48c726f7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a24aa66-993a-431e-8e1f-2cb0f228a714
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94d97318-0873-4bd6-a003-0113cf7f10ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84647afb-1e02-4b31-a272-8b494b5ada93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46bd5bc4-9271-4e26-8753-955afef561b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba618d20-5152-44f6-87d8-5ee833a2682d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9529e238-2a2b-4689-9106-61f23b2751c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bcb06e34-b3e7-42c0-b7fc-3db7ce5a9d29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc7a3f8f-5bd1-4a3e-87ad-51e970eb6e6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a13cadbb-6e6b-47f1-8765-fb3f600befea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa27970d-51e8-47c1-b0e1-19a31ef68b75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06886d65-6a33-49da-b44c-3291162b686a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f26049f5-3004-45ec-a0ae-d2a7f257f31f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0d022e6-c51f-4d5a-97b4-57f628b702c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62dc67eb-787a-4dcb-99e5-ae31ed1915bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3e73476-6a91-47e9-8fc2-73564300fac4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f0a4989-43b0-439a-bd66-c7f7caff1aec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a8e6403-b218-4485-83e3-f87b98712ba0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f8980bc-6324-403d-a041-cb58ff5cd942
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bda4f63-cb21-45a5-b52c-7794dbb763d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edab2221-84f3-4b41-94d6-4e158c24d4dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40950b52-2c18-4c70-a7d1-4cf677f40646
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ea4a646-6e9b-4a34-9c94-022ece87cc73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd0ac1ad-19b9-44cc-bc76-5cd0bfdc2b1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f38b3d2-a468-4a2c-ae98-b41d4431040b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a7747b5-7e06-4535-9629-615bed6314e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2136022d-b53b-45cc-a3d9-107cfdca3bf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55f62e10-71ac-4595-ba5f-28146ceb98e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 400f5856-6ad0-4696-afef-a98799a4f27f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66ac11d6-bc7e-4e6b-804d-437bf37f9b8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a6c16df-64dc-4c64-8a71-bd2bf67bd381
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2ae55bd-dfdf-4a50-92e4-ab1f963144c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c6b3ba3-8835-4592-b85e-6d1a12d2df7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74094b8d-4b96-43d4-adfd-ad5280fbc341
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb69ca26-c379-4ae5-9ace-a98085f927cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67368b20-293d-4444-8aba-437ebc85efe2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1be4b0d7-e0c1-4b6f-aee5-f68fb89800a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad1c6ab6-31ae-4411-8e11-5635081459ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09e890a8-2393-4da1-bbe7-79caf0e3f1b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63a4c451-e8d9-4397-bdfc-3c2d289f12e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1344acb5-adaa-4a11-91fd-6ea45411ce16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2275c25-7667-422d-a741-312103ec9671
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 202a2476-acf8-418b-9237-aa9e0aa939a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 224a2408-0d84-40de-933b-5d778cf276ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1dca96b8-a5fb-4bc2-9e32-247b37c87652
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc75c51e-2371-4e7d-a146-2d511299f54d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5906000b-184a-4e70-b74d-e81344619aa4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d29b9df6-6402-40c3-b0ae-c894409aa6ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 885c4538-100b-48b0-b2f1-7dbae65393ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03d65545-3d68-4e95-96d4-b08ae97bda98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca7371f2-99d0-42a2-8398-0a14b7919ac9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b548665b-e300-407b-b93e-b2822eaa9ab2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e344cf3f-5e68-4a8b-8c82-4a1fbeedd8e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a490cbdc-8243-483a-aba2-1426c326127b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 149ef255-aced-497f-8331-442c3c5d417a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99ece585-ee4d-479d-8926-aa68d32e0cb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79596e6f-4a76-4a76-b8c7-35282ab79665
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cc04c4e-05a6-4446-9ec1-d2d1df794053
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc309c34-f302-4fd2-8db9-aec7067828d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2cfa2ee1-baca-4513-becd-110ff3bad48c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2087d34b-d730-444c-b34a-4b4cafe7e7ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56a23918-6471-493e-9467-594b95533080
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f4bfd36-b4c4-4e0d-a344-95680a2a6393
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07e1528c-2476-417d-9358-a5ec5939be98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e83cb2ee-e46a-4b7e-904b-63709d49e252
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af99fa15-cb09-4086-85a5-533f86ae3c7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56d402b9-4899-4ea7-a2b9-2d78557ab8b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a500cb78-87da-42af-95e0-69aca3157c3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 244471ee-9c8c-46a8-ba6e-47b0818a3434
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a88b705-5c6f-4556-a586-a6df7e0b371e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e80293dd-c764-49bf-bbf4-6889b6076086
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message beebaebb-9bca-4ad3-9b46-c410a555e3b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0824ff63-e9ea-4731-acdb-0c85dce60b44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eaa35704-7c65-405e-9840-27c29933f244
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb3ff59b-bb4b-4788-983a-639091a45f7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69bfb28a-d844-4358-9e5d-653cdba3bdcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aed5bbb8-fd21-4a9e-a569-bdc581f7be77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35dc5d84-fb85-465a-9580-bf37248edfa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 814d1909-ca12-4f49-9ea0-ea02d07c7890
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83cb2bbf-c2fe-4b66-8ee4-4b2dc556c23e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12c8fb8e-f031-4678-b918-c87e362e1aaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64df3cd1-1fc8-4062-a37a-d95b3b31af60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9896c27-707d-4003-b6ee-80f74a2a29b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9c09a54-67e6-401c-b0b9-a599b6773381
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bddd04e-b346-4e57-b5f6-69f5c509b0dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9fce00e-b880-4109-a636-cddd985e94a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52c6f9be-3973-4359-99ae-7d7182beab49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19d846af-d90e-4fb9-b29b-dda73cf2e5ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81d49d0b-d7db-4dd8-8c47-6d99d9c6cb1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b12fe67-e685-4377-8042-a8d5c456faae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebb18dce-e580-4aeb-9849-aaff3a1b6aef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95872781-b58a-47bd-bad3-e558ba4ec5b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c933a40-8dca-4d36-a85e-fc7930d1774a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c83e5eb7-db05-4be7-b4c5-205dd6f1e97d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f26328d0-65c1-4201-a1b3-476212512f95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e0c736d-fbb9-4274-9bb8-337745b3eec0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f971a331-490b-4807-aaca-45e2d2205829
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95fdf6e1-0ac9-4aad-b988-682a24017590
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08a0501c-97e1-4d8c-bbe6-c2e8839509f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 813ada60-cc5a-4e48-820d-aca28e8e1c4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c577065-3e0d-4339-b179-61d88b77ce00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 030b0262-1e1b-4b39-afdf-9cb2bcc18a13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39117f24-5e03-4075-86d4-a86b8a07ddfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0496b6ef-fe42-4353-99fe-92add00e19e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a71989cd-436f-437e-88eb-a32fafe95d7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b365915-361b-419a-8f03-90171c43c5f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62287142-c9c9-4667-9c37-b438f3839c30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04338fbf-de95-4ce2-9b5a-ae06460b189a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1de5e55-1a7d-45b8-9f55-17cdbb9f5cc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 774626f3-9dfb-4087-8ff0-3129ded0a8d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84a68b1b-e7ce-4a72-b9e5-d79814d571de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98ea8ef8-339c-406c-8d6d-1b1a8c323fff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4899230a-b8e2-45a2-af44-89e31a8b24b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64e8a73c-730e-418c-95a0-5c3f596fb8e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37813173-1ad5-4270-bf41-353a260454f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9536c918-96ca-43ff-b3ff-4a6a329a3f68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae6cf3ea-1789-483e-9619-d4ef034566a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a3c8918-2760-4e49-b56b-50418e842245
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b5a2768-bec2-4f38-b798-4017fc85e735
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60218aa5-4a59-430d-ad13-03fea14cfa28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ec30157-297f-4d6d-b3d4-51505dc776f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7abc4fd3-a760-49f8-8238-22fef256a5cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2596a37b-c041-4ade-bc90-e787dfde296d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33a0177c-6676-4477-a34a-235b03f57b7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f1ba1d6-be71-494d-b7fa-134195353d0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85c795ca-0fe6-4751-9c86-7543420c8f60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a7d3fc4-941f-4941-bccd-859b4d1ed281
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13fb46ca-bc46-4654-ba27-e3572aabbfdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc1591dc-5568-4558-a8d2-49fc3b0d0785
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 093eb30b-deae-4b6f-8686-933f258eecd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a33703c-47d2-4667-907e-da16878c8205
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8e42be9-ef45-4ae7-8e45-964d3d0ef379
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e5d3546-fb3b-4fda-a410-7410bc17025e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef806e87-d278-4d54-b432-b15ee6471a3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fdf7c91-116f-460e-8db7-6981671052de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca854592-fff6-4af2-8f4f-415dc379ceed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f2b06a6-d7e6-4995-9e41-4343453285a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10e38495-a9f6-4482-bd52-90f2e7c9c3ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be271831-d3a2-40c2-a399-b97c4460ff79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6436078-f24c-4ca3-9dbf-7180cd39dcd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6c2a500-2212-425b-8762-4b36fe8e3a0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd6533f7-9f77-44ba-b7ac-7114add3d44a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e558320b-2925-4724-a72f-4de6500e6bf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1090dff-2fb1-4fd1-a1ab-634d42449877
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4892e64-5d1e-4814-b340-a3af51640ab0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c54805ad-97c4-49bf-86a2-8966d2af182f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5404e410-a276-42d5-8cdd-084144a97775
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bda3620-41ba-4925-acd3-42de0a187b49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4fbd672-2346-4e34-a32f-13d6bfd25e02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3a60ee0-e509-4445-bb86-d551f4909c73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35ac017d-b49a-44fa-9736-9c835419fee6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f243afa0-f3b4-438c-941e-1d270a99d215
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb9beaf8-6d50-4898-9136-71382ede3a1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c02e8f30-25b3-4fc2-8a1d-a08d5329de11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3892c6dc-94e5-4a25-aac4-4bb321f1ce01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4de4d75b-3427-4e00-bc08-7cafa5b54e68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 071d8717-7831-4c5b-ac28-6ede8ec51cd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d21a000f-c486-4d09-b01c-04a2077e617b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45e11b3d-bcb1-41a6-8e57-a57f2eb15d0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b889797-7acc-4a1c-8d10-dfb1b1fce65e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0cb35b2-d1e7-4b38-9d65-7ea1af97bdda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d2497ad-ad0b-4434-abac-d160c8d7d32b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2856c713-a886-460c-b2e1-70ffbe0e44d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8de7383-d122-4209-a4a1-870303a84503
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5921a60e-4e7e-4152-923f-584332d677af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd3ee75c-a520-4060-a765-2f545037fd4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94325fa3-4f8e-42d6-98cc-14a9b54b3fa0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8bd08135-17c6-4630-9cc6-1475777321f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9d77ce9-1676-4df5-8b86-fe8d917faf86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd3bf916-cc0a-4f19-9587-2de5b2ce1eae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d139909-b91d-46fd-95d1-05bb1d5b1047
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cfdef54-8a48-41a4-a528-2da862addd2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8959a167-5ad9-4ea9-9ec8-e5db9e454d41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9160161-fed7-44f5-9ceb-21016cfcc20d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f442febc-951f-4232-bc05-d816726ee488
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29ee4e8b-3d5f-4899-be99-49f0474ccde5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82fa30f3-c314-476f-a584-66c73e416d8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa6fcb52-36fa-4430-805d-e7424e6bd73e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2850b62-9caa-4b88-b93b-d9224e07b2f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 052fd6c9-1a5a-4de4-b6e4-2da27e6e0e40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39511a46-fc2c-4713-b5a2-01bbef1f7896
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0376fe21-33a8-4ea5-812c-11a2dfcb9d58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe2bb891-ada7-49ae-8e80-11c0f22b009d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3496283-2d1b-4805-b50b-c1b97d49f7d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 182d148f-af8b-4ceb-9032-f033e3d04c31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e558801-2c29-436d-8ad2-894a11796386
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f489848-22cf-462b-8376-67560f0def16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30a68387-b672-4b8f-bd0d-58b0d0563bf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64cb1d2d-7b5f-4d03-a942-b9fa97f1134d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84bbbd07-3e88-4e49-ba84-4658144f6188
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7236f975-d0d1-4317-8b60-cd0eb4ab2d8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2129abb-f6a9-45ae-a665-1a8fe51e176d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d04509a-7ac4-4e12-b30a-b2ed54a2df07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f4aa344-d1c6-4083-98f1-761c15aea3dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8caa90f7-1483-4da1-a7b5-01ba6cbcb7b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27f58ffc-1e33-44a9-8633-96dbd2354d77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 414487ec-306d-4ffb-9e6d-47184eb89fc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f144447-a5b7-4b89-bbce-926df6e30c71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4764710f-9ab7-4eea-8284-084676bc3adf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8d99de5-c7a3-4702-b9c5-097b712e01b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a84eed3-62c5-4d5b-b26a-de415520b008
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6ff0447-e745-465e-9aa9-704ddaa89fc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a97526f-60b8-45e5-ab32-312e8254ba71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6101efee-985b-465b-8eba-98889e427ab4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f685490f-5188-4b33-9685-f27846f7bf75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13539ce9-a63e-4cee-84df-9394c1863f9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ced1fa71-c8b6-4d0e-b523-c76cbc60cae9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c66c0f27-22c7-4e13-ae62-88c5daef1f62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7fd67ba-b804-4b1f-89cd-036c58ae43f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69b85577-14ec-44a3-9e84-03d1d2e63751
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e88d2d17-b92a-43c8-91e6-f13be9e1a919
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 262e0872-af8f-4d3d-a470-3da4c4f6d680
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a41fc09d-6ca8-4ba5-a34f-f2df3a8f5e08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70ff0840-84e4-4dc0-acc3-fe603db2fad6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2eca036-74a5-465a-9100-cbbdc734093c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a82ac40b-efe9-40bf-b0c2-aa79c7b980b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6590771-9986-4256-bd73-7976b535c9f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4644b0a6-6f82-4c8b-8ccb-32e5572f2bda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f41e9ce-2f33-4dc1-8bb5-74f2ce751be1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abdfb374-5e86-44ce-a354-5ca5a6c97e00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 272a0c0a-f189-45f8-ac9e-ee1bea7c55f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d47308ed-9b4a-4fb9-a124-d10e558c8ba0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 793fc63c-6e91-42c2-831d-9d38ddecac28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f204e89-1dcd-4dfa-ba59-1d08a8626665
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e3ff59e-9263-47cf-8076-b197d6a4eb1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06359d71-3601-48d2-9576-afe42947f2a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f479f15-b1ed-44ee-a50b-6ef61e7d7954
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41a6bbdc-b650-4330-b3cc-04aaf158fac3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20d2c6c2-50c3-4cb3-bfd9-941df437e806
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ab6370a-665b-4ec0-a671-0a7df6a004d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 872718c2-2a1b-4bd0-babb-e171cdbc8222
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 612a1476-fb3e-4101-9233-a53037ed6dcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c15e90e-ad12-4603-aa03-0577a4b39300
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7180908-2235-4a4f-9503-67cfee3e0554
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22a81cc1-758b-49a2-a34e-4b0fb61e6317
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecf33e76-a6af-42ad-8210-acfa3424b0c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 929e1f2a-0681-4dd6-af47-57654d03a4c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31d1dfaf-48d3-4bb4-97fa-a60bb2e01f95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29bb74a5-b770-4e86-8703-52fe51f519b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 864fbd61-d360-424f-9858-5efd760c7f85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7d15645-9018-4c0a-b9d6-43e38e05803b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1c919ed-c42b-4550-aded-785b89df23b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message adc502cb-44ac-4579-836f-54221934dd19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b2a46fb-8f87-443d-bce6-08ab4bb5a75c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d990c4b-d722-4348-978f-644b543d9591
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89152969-e2f9-45fa-a57b-479fb82e13c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a80be9b-fdea-419e-a97f-a038c10dadcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87d65b4b-3f5d-4285-91b5-879d26627384
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42db59f0-11ea-4ce6-98bd-757b21d3ee02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1c846e2-e612-437b-85a5-81e3d3eef6d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa52fe2e-3c67-4849-9404-cf7cc8f14d19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f7571ac-6b20-4cca-8e2a-69c5afd6fba1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 491e8d74-18bc-4c0f-818d-4bb8cc440aca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6330992e-06b5-44c5-bf06-84c616c11cf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d40f8b8c-2a2f-4285-b69d-8e331df02a4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea8a8c0a-e1e1-439b-8975-714b6f6aab2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6420d9ac-9cdc-4b3c-8ac5-ae0a11cfe9be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21bf8ae5-a9ab-45c3-8074-b300ff7b8faa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f46dcf3a-6ff6-46e9-bd6d-fab7cc813411
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4e7712a-c241-425f-8560-1b38bed570b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 132e9359-9b21-4fe4-9a39-0649964d3374
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1ccba8c-f785-465f-961e-25395f8e3d40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5a13c54-73fd-45f8-945b-b7f06c79a0b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 171de1f5-574d-4a3c-8620-e03dba240109
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34d9f9cd-622a-411e-a8be-323662db0e30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf83bfe8-abff-4fbd-be98-0c494324a59c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa45221d-1914-472c-9927-1a19db171deb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 657b36b4-14cb-4862-8bde-a1efe2720949
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 514c047c-4092-4254-9df2-bda5fb16b5d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02313995-93cc-4149-9007-a3feb9ef75c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84789125-9f27-4f92-8c7f-822fe874828c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df9e5443-cf87-4ff9-a02a-a8448e4cc6d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aaa09d8c-edc9-4885-913d-f05e52f8123c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bef46d9f-7250-4f7c-93f2-1df34a5b8089
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03a6c03f-a802-4c3f-a2f1-2d00bd27cee4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e822464b-cb64-4094-b4af-91f73d0fb6a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d952f0a-dd87-45fb-845a-fa66dcb29926
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edeebabf-9f9e-40b4-85f7-bf3e40f4d8ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a1e18bb-ac77-49ea-bb62-711508cb1c98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c8b667a-8748-439d-8cd1-344999c9d1f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5b5a396-07ec-44c0-9475-da72a8cd0202
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 414c279a-3da5-4b48-b439-cd75a27659b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bd23627-9cc7-41e4-94c3-2d5828f73bc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0351a2f-602e-474d-b51d-5b1cb437ec09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7eb2be13-ef41-4a63-95e0-9032b5d0b647
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cba4ad69-dd00-411b-8d10-feb2cbf9de55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eac62cd2-902a-4eec-b6e9-72f0424c4612
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 439d8349-ef72-4783-a764-d84c9e35185a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 202fcf24-bb2f-4ab7-8463-a626ba199593
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a95873e-52b3-4405-9c45-adac9202d7b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7539e44-6003-447f-a7de-3efd21482b02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9046e297-f8ea-49a9-a381-5d0812fb7260
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f1341f4-8d23-428e-8ea7-603794c7ec21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message add2b0f2-b04d-4453-965a-07c72a7c9533
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a2f2261-5535-4f17-bfa9-c97c3b8a91f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb1b08cb-a805-45f1-909e-f3f68e7ba34f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72af194a-10be-4b09-8f6c-88880c7a7868
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fbb5fb0-c13d-4db9-b315-89327c506bf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 518187e8-f199-4241-8426-1d74fe0522d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 989d9752-bec9-473b-90e8-aa50889e6c48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20a4cb25-453b-4a16-a6a9-56c707aa861e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe90d01e-3d74-42f4-a87a-5c8888a18347
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b88104ab-3dd0-4637-95da-2d618b357d69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8003ddc-21da-4101-a4aa-1c64bfa7d8ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 926e4f46-030c-468b-a3a7-ee1ef9532391
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29bd3f2d-ebee-4dc7-97c4-c0dbca174269
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f313ba3c-fbf6-48d9-abc0-fc73164daf71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4382400-d30b-4c28-bfa3-0e8f9babbd72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cef4b5ff-0e31-4c12-94ed-db93b2719146
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed76f496-749a-4b0c-931c-44c0e24e25b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4c3410d-c768-48be-88a4-fada3cfda488
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e0fddd4-8927-4218-be4e-c58236b1799b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14833efe-c801-4e0d-a271-0695871d0716
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5a5303e-6afc-43d9-8cab-ba2a0e6fc7dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2f46e62-a0be-4663-bbef-f94621bec096
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78d7fa0c-5098-4d1a-b31b-04eff013624b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0461d792-c7c9-48b4-ac8f-c5f50fd5eeea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36199e1b-0e22-41af-b29a-2ee7bea0c691
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d73f0d8-d7b1-409d-9e69-4cbaf8ec4c78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05e818a5-1d9b-41ff-b796-6f1b6518530b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25f3b104-02a1-4948-b9b7-f28aba3481c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53edfaf6-510d-4279-86f7-ca6e9db0210b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c10f23b4-2531-4967-ad56-dd36c2dc78d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2806315-afd8-471d-9139-0123f563a984
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4c7fe25-98cc-4292-9d27-6ab9d02ef3c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74525bf8-ba8b-4989-ae1e-715f928232bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bea9f72-4dd3-4716-a6d2-deb3930d9678
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da1d9de0-7ca5-406c-ad5e-545c4c4bc9fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 443afb30-e1b2-4a30-bb62-001f9f5e9837
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ac7128e-9b7a-4e98-8fed-c29a6b81ea83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1eba2f6-597a-468f-9f6a-786b0f88f044
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a98001a-044d-4b04-bb7e-328d529aebf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d9389a8-8b26-4b19-94f0-8ff41729f7ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4a7fc67-cdf7-4140-a6c5-a7187f01b6fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35f229ca-88bf-4560-814d-e48956dd2872
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6962b57d-1ef1-4b25-a9b0-63fc2d7ef9cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 634da161-6649-4ea4-9e48-5d0e31ece07f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a95b66c6-9122-40b6-9b03-8b83e24a320d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d5c3d72-febe-4d63-800a-364353e59683
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 271dc1f2-f996-49b6-87b6-f097a6c5c69d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff5ef49a-a0ef-40d1-89e9-41eb08a9656e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46853692-9a17-4e3f-a43f-9ea41187a76f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b1cc611-25d4-4672-9e74-6365ca1a5c64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa50c9b1-1d0b-492a-b42d-82859a50a826
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ffdfdf0-0de4-4608-93d6-c9dc4a50af7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99dbb740-143e-4f37-b06d-164c04350fe6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83325220-126e-4ad3-9b6d-3729084f55d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53c55217-32fa-4a31-bc1b-97556c849127
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6d82e55-6e0d-488f-8721-a5d03eac5f77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f9d3fdd-f811-4b5d-926d-b12ac8a370c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f06f7785-8260-4744-8f3d-534e66758f9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fcb5e27-531e-4354-b08c-274e5b01c09b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffb1e435-a13b-4500-9d23-a8c3a80d45d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a9c11b2-5330-47fb-b06b-05f92848af07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 094af9fd-9b0a-407c-9c97-c8d84f137b57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbbe8c01-6b39-4e54-878d-a5668a18ba7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fd9d91a-9405-4293-a989-02d47587700c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8aa662e-e103-4187-a428-5a55dbb0bdf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee1d334a-fe62-43a6-8252-e9dd8bd5b67a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f16f6816-b8cf-4e59-a2ed-143a604deaa7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61ff67df-aa51-4af6-bf97-edcd1769d9ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2972cc2a-e6d0-4b4b-854e-2da7d7de270b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d35919db-4673-415b-8fa6-2f2ac4fa4ee8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55a1a10f-7e73-40b7-baad-1f4cdcbc8443
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52562dc7-6c56-4c7c-b5a9-2ceae99ffa67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14aab2da-e584-4b5e-8ab0-e13ce80ddea4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b8adbfd-cade-4a0b-af9a-b962366cf734
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5cefece-c5a0-45c1-9f9b-ecf35391d641
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1b60587-1d99-4498-ae8e-46ea083f057c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 149fd954-462b-4e3c-99ef-6f48617e53e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0a46550-b6cf-475a-bb9a-295b8f5f892c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0b7a998-b4e2-4e9c-a5c6-73e0082d8886
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2271f304-29c1-4f50-a5c5-89e3e62a85b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d38587e3-f155-49d2-8623-e533b1385279
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af56c203-85de-4dcc-9498-a92c4ae5edb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7f207f9-e30c-4605-8907-87b1a0aac776
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21fec997-4ac2-4a4a-893e-05649c392725
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c37b0591-4f6f-448c-84b3-f73e5f948297
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 479c9383-7d70-4cc3-87f7-b623a796dbd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77874707-37cc-4610-a4c1-c283b034193e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12e7192f-8e18-4b92-8a19-5ea23b9a2d91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bdc08d30-8781-4714-a491-dac1e12f03f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6be7da98-56fd-4171-854e-c0d2cb36133e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 949980d1-6cd1-472b-9554-99dacb4fa597
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96fb416e-b093-4df8-bb71-1959eff176c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ca0d56b-8b23-4508-9ada-fbb50ac3943c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f044a88-38c8-48c3-9f79-f7939d790f7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49c5bc83-8f7a-4cab-9ac8-791d4d3e9d66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a893c84a-1e15-4075-8106-583b5dddad0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b4df229-7264-43a7-872e-926d65a2824e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 081aac78-eb60-4b30-b4c3-d508208b9ca1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7e1c9f1-7086-466c-beb7-df6d5765f537
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message acf81f80-6175-441c-b211-fdc0a5871e7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1a826cf-f86a-4010-a11c-25136cbd9572
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f95f0d6e-a095-4a81-86ee-a4b914785607
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22c6441a-f8f9-45f8-b373-f3120675f03d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddba192b-2700-46ac-880e-a499e43cd27e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7086fd2-3f78-447d-88b4-92bb06c442f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96c0abe5-355c-4f94-82a6-8554b5d0edcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb0534a3-93a1-4661-bc52-c6e82e738558
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af36c0c1-3dc4-4dc7-82ff-3cfa339d1c6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85891d3f-c491-4111-84b7-e5f70a49e2e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8532662d-66be-4283-83b6-37b598d0f8ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54264e78-77dc-4190-81be-61238c120dfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0082977-507a-4a44-9cd3-9e6ec051aaca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 091878a5-41cb-4728-b054-691f18fdd540
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f68fac4-8eb6-49b4-80c6-9e797b65b648
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e6db2a6-947e-4666-be15-c7dd7c876c81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 265f9ead-4da3-4018-879c-e558388b92e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 761fd3cf-eafd-45f6-93c5-953c1eeaee94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41121218-e541-41b2-a866-c91d77b77a2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59161013-45d6-44bc-8122-d6b0feb39e65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 020eaf9a-4eb7-42d1-bf95-a67e409a49d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5b49a66-d2c6-4552-84ac-159cd1901f84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 610b9008-0c3b-47d3-ae10-c92852dad22a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca381873-9300-49f2-819a-41ade8eb7aba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5655074c-8fae-4493-8b75-05042d99bf4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4febe04c-dc35-47ba-9b1b-88a70c67cec3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69144802-a060-4089-8ab4-b5f8d0c1c101
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9a9971e-c00e-4f2a-9fd4-85716f32d6aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e5accc4-955c-46ab-a9a5-3589a846816f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b103a3d8-9b18-4b5d-8e38-7d34bb6048a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00bba5c1-cab5-4a72-8883-d00643bb30c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ca50896-5ac4-4054-8003-da8bdd5a31d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cff9fa91-a0f8-4ba0-aeb6-812e2566018e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58a55b33-e8ff-42fa-8c18-b852539a0151
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 241b5bcf-2fb8-409c-b4a4-62f8d1940e42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db1eeb66-e05a-4c42-8f6c-dc6efced2841
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c5ae2d9-219c-4c56-85a2-0a8411128107
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a829982c-20c8-4e0d-9d86-b46c4e9371cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8bbb63ea-8bac-41fd-9e27-d5474823576b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15add31d-a9b8-4e0e-9e5d-a26d7d5b5caa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89633e7f-fd0f-4e9f-ab16-fbf88f923cdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec2a8378-2b9a-4997-a002-c32f7c0319db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98eef9b1-bfbb-4b16-939d-ef90105b2dce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2afabea-97f5-4250-90ec-c124dd58777b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9638abe7-3e82-49d9-a24b-6e17704524b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68f9ee8e-bd47-40db-8dbd-9c27d21bfe92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 486ee53e-0f85-4f13-9eac-7895351bfd53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f619e35-7dfb-47a9-ad8c-b3bc3bccac23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17a5811b-cd92-44ef-a5da-9f1c3655c32d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76a7722d-2707-4619-9da6-1dfcd61bfdc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 457a9441-873f-4c99-bb6e-8f94c0b64a35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1383b01-29f4-4b7e-bdf5-7a846310427d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40d91e66-6b7e-4cc8-849d-1111fa940db6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e495dd0e-2906-45a5-be26-e2a79140556c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 962e8292-b961-44bd-a97f-47248ab6be6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56fc4670-1151-43c4-90d8-a57a0d24c56f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1da42eec-a89a-4eb0-972b-c3a354b4a93a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ded973d-336e-492f-8643-9c493cc99ecd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 120f9c75-c317-402a-8fbe-1883f6e1ba09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31180a5c-a9dc-4368-a70f-f9cc1f6c1e42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b122ca28-2f1a-40ef-a0fe-19d81d948d73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 254e2e75-65e6-4d51-8b1c-457f28eb3730
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 286d4cb4-18dd-42f8-a3ca-26efee60f6ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4d74cb2-a93b-4961-81b4-33bb1d4b6702
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c31a097-29ae-4476-936e-6d95aaf75adf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 373351cb-e7b8-486b-8d89-ffe2eccb2cf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93a61ea0-ce29-4d00-afd4-90a494778c09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ee04d20-3923-4ef3-b7fa-55157102cb4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e54f3c0-7388-4658-a4ab-e1cbaf70e0df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 795ba9de-6aaa-4b1f-b634-0311091a510b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b0d67cc-00bc-49cd-b0f3-ee7b21931e40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e46ee8b0-7c81-4aa0-820c-f3e752691f5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4af09ee4-d5b4-4211-81db-8aa2a503ef24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f1a5339-7559-4f50-b95d-fdde6abba3e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7bda9f36-9036-4e24-9d2f-61adc4563be8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aaf14f0d-ebf9-430f-af6a-940f954518fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a18bf1ab-ecf9-44b6-a005-46baad7688c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f62400c6-6df8-4295-8d09-cfbfeb69e969
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6ce4b2a-6502-47d0-8704-bea61cda65c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06d6bd66-8d93-4f4c-8d1c-b1935c3ce064
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 255599db-8b58-4587-a374-ed3c1698193d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 267b5b36-0e9a-4287-a89c-64c68cff0353
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7f3d45d-5469-4aa5-95d4-81cd06461fd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f76812e5-dace-48c3-9cf4-b862c7ba4536
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acd88868-e488-4e66-8c97-3035d83cbfc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7cd3712-214e-42b5-86fb-97e856d7e689
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 580a70bc-4e6b-4ef3-9dc4-5ded36221777
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89fe7e17-6132-47e0-aee0-642444e63cdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9b89cd4-8312-4f28-9922-54d1f539d2ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebfe8f6d-7674-41e3-afe2-472e54b207b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b0c6518-1428-4f34-ac64-365b0f5f4735
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c6bae09-872a-4c0f-be8b-aa0d90bc5541
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2e5385d-c0bb-46d2-9608-042f2da0ff2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0d1abce-ec69-4489-beec-271b5ce4b9d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b966fe5-2687-47e3-9401-704168183f0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b91e531-0472-4ef3-a646-d960fa6b436e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74984652-adf4-4b4b-8eac-37374522b784
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_5
Server: localhost:8686
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_5
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_5/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_5/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_5/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_5/test_labels.txt

📊 Raw data loaded:
   Train: X=(5354, 24), y=(5354,)
   Test:  X=(1339, 24), y=(1339,)

⚠️  Limiting training data: 5354 → 800 samples
⚠️  Limiting test data: 1339 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_5 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 1 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.2370, val=0.0903 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0875, val=0.0856 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0806, val=0.0851 (↓), lr=0.001000
   ✓ Epoch   4/100: train=0.0808, val=0.0842 (↓), lr=0.001000
   • Epoch   5/100: train=0.0805, val=0.0843, patience=1/15, lr=0.001000
   📉 Epoch 10: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0794, val=0.0850, patience=7/15, lr=0.000500
   📉 Epoch 18: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 1 Summary - Client client_5
   Epochs: 19/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0090
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0144
============================================================


📊 Round 1 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2609, R²: -0.0021

============================================================
🔄 Round 3 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0748 (↓), lr=0.000250
   • Epoch   2/100: train=0.0831, val=0.0748, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0830, val=0.0749, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0829, val=0.0750, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0828, val=0.0751, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0824, val=0.0752, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 3 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0012
   Val:   Loss=0.0748, RMSE=0.2735, R²=-0.0044
============================================================


============================================================
🔄 Round 6 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0829 (↓), lr=0.000063
   • Epoch   2/100: train=0.0812, val=0.0830, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0812, val=0.0831, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0812, val=0.0831, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0812, val=0.0830, patience=4/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0810, val=0.0830, patience=10/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 6 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=-0.0009
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0110
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2605, R²: 0.0014

============================================================
🔄 Round 8 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0824 (↓), lr=0.000016
   • Epoch   2/100: train=0.0815, val=0.0826, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0814, val=0.0828, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0813, val=0.0830, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0812, val=0.0831, patience=4/15, lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0811, val=0.0835, patience=10/15, lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 8 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0077
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0100
============================================================


============================================================
🔄 Round 10 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0867 (↓), lr=0.000004
   • Epoch   2/100: train=0.0806, val=0.0867, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0806, val=0.0867, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0805, val=0.0867, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0805, val=0.0867, patience=4/15, lr=0.000004
   📉 Epoch 7: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0805, val=0.0867, patience=10/15, lr=0.000002
   📉 Epoch 15: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 10 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0034
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0067
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0008

============================================================
🔄 Round 12 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 12 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0044
   Val:   Loss=0.0751, RMSE=0.2740, R²=-0.0035
============================================================


============================================================
🔄 Round 13 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 13 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0044
   Val:   Loss=0.0754, RMSE=0.2745, R²=-0.0456
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0010

============================================================
🔄 Round 14 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 14 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0052
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0386
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0008

============================================================
🔄 Round 17 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 17 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0031
   Val:   Loss=0.0906, RMSE=0.3010, R²=-0.0048
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0010

📊 Round 17 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0010

============================================================
🔄 Round 19 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 19 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0033
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0119
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0010

============================================================
🔄 Round 20 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 20 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=-0.0050
   Val:   Loss=0.0844, RMSE=0.2904, R²=0.0012
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0010

============================================================
🔄 Round 21 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0690 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0690, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0690, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0690, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0690, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0691, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0690)

============================================================
📊 Round 21 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0042
   Val:   Loss=0.0690, RMSE=0.2627, R²=-0.0099
============================================================


============================================================
🔄 Round 22 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 22 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0028
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0132
============================================================


============================================================
🔄 Round 24 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 24 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0033
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0084
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

============================================================
🔄 Round 27 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 27 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0027
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0138
============================================================


============================================================
🔄 Round 28 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 28 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0026
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0079
============================================================


============================================================
🔄 Round 32 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 32 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0023
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0126
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

============================================================
🔄 Round 33 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 33 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0045
   Val:   Loss=0.0753, RMSE=0.2743, R²=0.0014
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

============================================================
🔄 Round 34 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 34 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0025
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0157
============================================================


============================================================
🔄 Round 35 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 35 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0037
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0044
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

📊 Round 35 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

📊 Round 35 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

📊 Round 35 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

📊 Round 35 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

📊 Round 35 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

📊 Round 35 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

============================================================
🔄 Round 44 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 44 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0039
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0089
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

============================================================
🔄 Round 46 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 46 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0004
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0172
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

📊 Round 46 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

============================================================
🔄 Round 48 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 48 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0030
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0053
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

============================================================
🔄 Round 49 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 49 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0013
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0117
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

============================================================
🔄 Round 50 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 50 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0050
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0022
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

📊 Round 50 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

📊 Round 50 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

============================================================
🔄 Round 59 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 59 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0032
   Val:   Loss=0.0783, RMSE=0.2797, R²=-0.0110
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

📊 Round 59 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

📊 Round 59 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

============================================================
🔄 Round 68 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 68 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0020
   Val:   Loss=0.0738, RMSE=0.2717, R²=-0.0139
============================================================


============================================================
🔄 Round 69 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 69 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2850, R²=-0.0031
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0040
============================================================


============================================================
🔄 Round 74 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 74 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0045
   Val:   Loss=0.0797, RMSE=0.2822, R²=-0.0560
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

📊 Round 74 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

📊 Round 74 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

============================================================
🔄 Round 79 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 79 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0037
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0020
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

============================================================
🔄 Round 80 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0953 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0953, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0953, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0953, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0953, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0953, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0953)

============================================================
📊 Round 80 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=-0.0014
   Val:   Loss=0.0953, RMSE=0.3087, R²=-0.0172
============================================================


============================================================
🔄 Round 81 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 81 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0034
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0332
============================================================


============================================================
🔄 Round 82 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 82 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0051
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0462
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

============================================================
🔄 Round 83 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 83 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0048
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0194
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

📊 Round 83 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

============================================================
🔄 Round 86 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 86 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0039
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0070
============================================================


============================================================
🔄 Round 87 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 87 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0038
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0054
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

============================================================
🔄 Round 88 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 88 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0049
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0034
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

============================================================
🔄 Round 90 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 90 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0034
   Val:   Loss=0.0848, RMSE=0.2913, R²=-0.0423
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

📊 Round 90 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

📊 Round 90 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

📊 Round 90 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

📊 Round 90 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

============================================================
🔄 Round 96 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 96 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0051
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0037
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

============================================================
🔄 Round 98 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 98 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0043
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0038
============================================================


============================================================
🔄 Round 99 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 99 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0026
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0061
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

============================================================
🔄 Round 101 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 101 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=-0.0034
   Val:   Loss=0.0907, RMSE=0.3012, R²=-0.0032
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

============================================================
🔄 Round 103 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 103 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0020
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0208
============================================================


============================================================
🔄 Round 104 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 104 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0036
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0062
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

============================================================
🔄 Round 107 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 107 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0053
   Val:   Loss=0.0869, RMSE=0.2949, R²=0.0031
============================================================


============================================================
🔄 Round 108 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 108 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0056
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0016
============================================================


============================================================
🔄 Round 110 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 110 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0035
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0026
============================================================


============================================================
🔄 Round 111 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 111 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0012
   Val:   Loss=0.0826, RMSE=0.2873, R²=-0.0205
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

============================================================
🔄 Round 112 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 112 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0026
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0124
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

📊 Round 112 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

============================================================
🔄 Round 114 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 114 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0033
   Val:   Loss=0.0748, RMSE=0.2735, R²=-0.0095
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

📊 Round 114 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

📊 Round 114 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

============================================================
🔄 Round 120 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 120 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0030
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0198
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

📊 Round 120 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

📊 Round 120 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

============================================================
🔄 Round 126 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 126 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0027
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0116
============================================================


============================================================
🔄 Round 128 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 128 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0019
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0092
============================================================


============================================================
🔄 Round 129 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 129 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0010
   Val:   Loss=0.0776, RMSE=0.2785, R²=-0.0162
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

📊 Round 129 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

============================================================
🔄 Round 131 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0697 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0697, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0697, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0697, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0697, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0697)

============================================================
📊 Round 131 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0030
   Val:   Loss=0.0697, RMSE=0.2640, R²=-0.0055
============================================================


============================================================
🔄 Round 132 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 132 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=-0.0025
   Val:   Loss=0.0922, RMSE=0.3037, R²=-0.0070
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

📊 Round 132 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

📊 Round 132 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

📊 Round 132 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

📊 Round 132 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

📊 Round 132 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

📊 Round 132 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

📊 Round 132 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

📊 Round 132 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

============================================================
🔄 Round 147 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 147 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0039
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0005
============================================================


============================================================
🔄 Round 150 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 150 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0035
   Val:   Loss=0.0750, RMSE=0.2739, R²=-0.0271
============================================================


============================================================
🔄 Round 151 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 151 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0018
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0088
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

📊 Round 151 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

============================================================
🔄 Round 153 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 153 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0027
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0100
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

📊 Round 153 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0011

============================================================
🔄 Round 159 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 159 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0040
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0024
============================================================


============================================================
🔄 Round 160 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 160 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0029
   Val:   Loss=0.0758, RMSE=0.2752, R²=-0.0076
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0011

============================================================
🔄 Round 163 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 163 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0035
   Val:   Loss=0.0753, RMSE=0.2745, R²=-0.0052
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

============================================================
🔄 Round 164 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 164 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0015
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0152
============================================================


============================================================
🔄 Round 166 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 166 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0019
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0473
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0011

============================================================
🔄 Round 168 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 168 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0050
   Val:   Loss=0.0815, RMSE=0.2854, R²=0.0029
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0011

============================================================
🔄 Round 170 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 170 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0031
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0062
============================================================


============================================================
🔄 Round 171 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 171 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=-0.0057
   Val:   Loss=0.0929, RMSE=0.3047, R²=-0.0080
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0011

📊 Round 171 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0011

📊 Round 171 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0011

============================================================
🔄 Round 176 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 176 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0004
   Val:   Loss=0.0764, RMSE=0.2765, R²=-0.0178
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0011

============================================================
🔄 Round 177 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 177 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0048
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0006
============================================================


============================================================
🔄 Round 178 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 178 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0046
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0168
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0011

📊 Round 178 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0011

📊 Round 178 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0011

📊 Round 178 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0011

============================================================
🔄 Round 184 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 184 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0054
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0053
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0011

============================================================
🔄 Round 189 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 189 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0052
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0046
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0011

============================================================
🔄 Round 191 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 191 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0047
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0002
============================================================


============================================================
🔄 Round 192 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 192 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0042
   Val:   Loss=0.0794, RMSE=0.2819, R²=0.0005
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0011

============================================================
🔄 Round 194 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 194 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0071
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0239
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0011

📊 Round 194 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0011

============================================================
🔄 Round 202 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 202 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0012
   Val:   Loss=0.0788, RMSE=0.2808, R²=-0.0336
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0011

📊 Round 202 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0011

============================================================
🔄 Round 207 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 207 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2871, R²=-0.0039
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0118
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0011

📊 Round 207 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0011

📊 Round 207 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0011

📊 Round 207 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0011

============================================================
🔄 Round 213 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 213 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0029
   Val:   Loss=0.0779, RMSE=0.2790, R²=-0.0073
============================================================


📊 Round 213 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0011

============================================================
🔄 Round 215 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 215 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0058
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0135
============================================================


============================================================
🔄 Round 217 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 217 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0029
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0153
============================================================


============================================================
🔄 Round 219 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 219 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0035
   Val:   Loss=0.0770, RMSE=0.2774, R²=-0.0158
============================================================


============================================================
🔄 Round 220 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 220 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0039
   Val:   Loss=0.0735, RMSE=0.2712, R²=-0.0055
============================================================


📊 Round 220 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

============================================================
🔄 Round 223 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 223 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0042
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0004
============================================================


📊 Round 223 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

============================================================
🔄 Round 227 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 227 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=-0.0031
   Val:   Loss=0.0906, RMSE=0.3010, R²=-0.0075
============================================================


============================================================
🔄 Round 228 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 228 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0064
   Val:   Loss=0.0852, RMSE=0.2918, R²=0.0091
============================================================


📊 Round 228 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

📊 Round 228 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

============================================================
🔄 Round 232 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 232 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=-0.0032
   Val:   Loss=0.0907, RMSE=0.3012, R²=-0.0121
============================================================


============================================================
🔄 Round 233 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 233 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0025
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0074
============================================================


📊 Round 233 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

📊 Round 233 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

============================================================
🔄 Round 236 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 236 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0028
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0071
============================================================


📊 Round 236 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

📊 Round 236 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

============================================================
🔄 Round 238 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 238 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0048
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0510
============================================================


============================================================
🔄 Round 239 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 239 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0045
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0601
============================================================


📊 Round 239 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

============================================================
🔄 Round 240 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 240 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0044
   Val:   Loss=0.0750, RMSE=0.2738, R²=-0.0220
============================================================


============================================================
🔄 Round 244 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 244 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0055
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0162
============================================================


📊 Round 244 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

============================================================
🔄 Round 246 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 246 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0042
   Val:   Loss=0.0716, RMSE=0.2676, R²=-0.0148
============================================================


============================================================
🔄 Round 247 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 247 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0028
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0042
============================================================


============================================================
🔄 Round 249 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 249 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0025
   Val:   Loss=0.0748, RMSE=0.2735, R²=-0.0061
============================================================


📊 Round 249 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

📊 Round 249 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

📊 Round 249 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

============================================================
🔄 Round 256 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 256 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0043
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0067
============================================================


============================================================
🔄 Round 257 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 257 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0045
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0061
============================================================


============================================================
🔄 Round 258 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 258 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0035
   Val:   Loss=0.0731, RMSE=0.2704, R²=-0.0071
============================================================


📊 Round 258 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

============================================================
🔄 Round 259 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 259 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0012
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0159
============================================================


============================================================
🔄 Round 263 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 263 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0042
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.0007
============================================================


📊 Round 263 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

============================================================
🔄 Round 265 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 265 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=-0.0009
   Val:   Loss=0.0892, RMSE=0.2986, R²=-0.0122
============================================================


📊 Round 265 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

============================================================
🔄 Round 268 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 268 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0047
   Val:   Loss=0.0889, RMSE=0.2981, R²=0.0028
============================================================


📊 Round 268 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

📊 Round 268 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

📊 Round 268 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

📊 Round 268 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

============================================================
🔄 Round 275 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 275 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0036
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0008
============================================================


📊 Round 275 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

============================================================
🔄 Round 277 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 277 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0031
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0427
============================================================


📊 Round 277 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

============================================================
🔄 Round 278 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 278 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=-0.0023
   Val:   Loss=0.0895, RMSE=0.2991, R²=-0.0120
============================================================


📊 Round 278 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

============================================================
🔄 Round 280 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 280 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0022
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0087
============================================================


📊 Round 280 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

============================================================
🔄 Round 282 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 282 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0024
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0062
============================================================


============================================================
🔄 Round 284 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 284 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0067
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0013
============================================================


📊 Round 284 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

============================================================
🔄 Round 287 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 287 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0026
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0048
============================================================


📊 Round 287 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

============================================================
🔄 Round 288 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 288 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0028
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0144
============================================================


📊 Round 288 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

📊 Round 288 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

============================================================
🔄 Round 291 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 291 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0044
   Val:   Loss=0.0737, RMSE=0.2715, R²=0.0032
============================================================


📊 Round 291 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

============================================================
🔄 Round 292 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 292 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0051
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0092
============================================================


📊 Round 292 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

============================================================
🔄 Round 293 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 293 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0029
   Val:   Loss=0.0841, RMSE=0.2901, R²=-0.0037
============================================================


📊 Round 293 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

============================================================
🔄 Round 296 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 296 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=-0.0037
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0042
============================================================


📊 Round 296 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

============================================================
🔄 Round 301 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 301 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0015
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0096
============================================================


📊 Round 301 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

============================================================
🔄 Round 302 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 302 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0022
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0087
============================================================


============================================================
🔄 Round 305 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 305 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0019
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0081
============================================================


📊 Round 305 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

============================================================
🔄 Round 306 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 306 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0047
   Val:   Loss=0.0776, RMSE=0.2785, R²=0.0026
============================================================


============================================================
🔄 Round 307 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 307 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0012
   Val:   Loss=0.0765, RMSE=0.2765, R²=-0.0118
============================================================


📊 Round 307 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

📊 Round 307 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

📊 Round 307 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

📊 Round 307 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

📊 Round 307 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

============================================================
🔄 Round 313 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 313 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0017
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0136
============================================================


============================================================
🔄 Round 314 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 314 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0040
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0005
============================================================


📊 Round 314 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

📊 Round 314 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

============================================================
🔄 Round 319 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 319 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=-0.0027
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0081
============================================================


============================================================
🔄 Round 321 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 321 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0036
   Val:   Loss=0.0752, RMSE=0.2743, R²=-0.0059
============================================================


📊 Round 321 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

============================================================
🔄 Round 323 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 323 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0038
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0049
============================================================


============================================================
🔄 Round 324 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 324 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0019
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0107
============================================================


============================================================
🔄 Round 325 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 325 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0032
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0031
============================================================


📊 Round 325 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

============================================================
🔄 Round 326 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 326 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0013
   Val:   Loss=0.0833, RMSE=0.2885, R²=-0.0110
============================================================


📊 Round 326 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

📊 Round 326 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

============================================================
🔄 Round 329 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 329 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0046
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0037
============================================================


📊 Round 329 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

📊 Round 329 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

============================================================
🔄 Round 332 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 332 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0031
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0025
============================================================


📊 Round 332 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

============================================================
🔄 Round 336 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 336 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=-0.0031
   Val:   Loss=0.0906, RMSE=0.3011, R²=-0.0039
============================================================


============================================================
🔄 Round 337 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 337 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0037
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0003
============================================================


📊 Round 337 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

============================================================
🔄 Round 340 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 340 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2871, R²=-0.0053
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0054
============================================================


📊 Round 340 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

📊 Round 340 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

📊 Round 340 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

============================================================
🔄 Round 345 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 345 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0038
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0122
============================================================


📊 Round 345 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

============================================================
🔄 Round 346 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 346 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0072
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0449
============================================================


📊 Round 346 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

============================================================
🔄 Round 348 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 348 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=-0.0039
   Val:   Loss=0.0890, RMSE=0.2984, R²=-0.0058
============================================================


============================================================
🔄 Round 351 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 351 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0044
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0005
============================================================


============================================================
🔄 Round 352 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 352 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0061
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0026
============================================================


📊 Round 352 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

📊 Round 352 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

============================================================
🔄 Round 354 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 354 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0040
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.0016
============================================================


📊 Round 354 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

============================================================
🔄 Round 356 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 356 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0030
   Val:   Loss=0.0784, RMSE=0.2801, R²=-0.0033
============================================================


============================================================
🔄 Round 358 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 358 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=-0.0045
   Val:   Loss=0.0917, RMSE=0.3029, R²=-0.0203
============================================================


📊 Round 358 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

============================================================
🔄 Round 359 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 359 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0022
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0065
============================================================


============================================================
🔄 Round 360 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 360 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0041
   Val:   Loss=0.0769, RMSE=0.2773, R²=-0.0032
============================================================


============================================================
🔄 Round 361 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 361 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0048
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0016
============================================================


📊 Round 361 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

============================================================
🔄 Round 364 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 364 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0045
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0038
============================================================


📊 Round 364 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

============================================================
🔄 Round 370 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 370 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0044
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0420
============================================================


============================================================
🔄 Round 371 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 371 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0008
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0151
============================================================


📊 Round 371 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

============================================================
🔄 Round 375 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 375 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0043
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0112
============================================================


📊 Round 375 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

============================================================
🔄 Round 378 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 378 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0066
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0103
============================================================


============================================================
🔄 Round 380 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 380 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=-0.0043
   Val:   Loss=0.0743, RMSE=0.2725, R²=0.0024
============================================================


📊 Round 380 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

📊 Round 380 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

============================================================
🔄 Round 385 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 385 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0022
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0059
============================================================


📊 Round 385 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

📊 Round 385 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

📊 Round 385 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

============================================================
🔄 Round 388 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 388 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0028
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0055
============================================================


============================================================
🔄 Round 390 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 390 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0030
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0042
============================================================


📊 Round 390 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

📊 Round 390 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

📊 Round 390 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

============================================================
🔄 Round 393 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 393 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0039
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0248
============================================================


📊 Round 393 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

============================================================
🔄 Round 394 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 394 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0036
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0004
============================================================


============================================================
🔄 Round 395 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 395 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0030
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0028
============================================================


============================================================
🔄 Round 399 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 399 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0029
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0032
============================================================


📊 Round 399 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

📊 Round 399 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

============================================================
🔄 Round 401 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0706 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0706, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0706, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0706, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0706)

============================================================
📊 Round 401 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0023
   Val:   Loss=0.0706, RMSE=0.2658, R²=-0.0071
============================================================


============================================================
🔄 Round 402 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 402 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0046
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0038
============================================================


============================================================
🔄 Round 404 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 404 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0046
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0036
============================================================


============================================================
🔄 Round 405 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 405 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0016
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0107
============================================================


📊 Round 405 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

📊 Round 405 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

============================================================
🔄 Round 408 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 408 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=-0.0032
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0083
============================================================


============================================================
🔄 Round 409 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 409 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0023
   Val:   Loss=0.0807, RMSE=0.2842, R²=-0.0060
============================================================


============================================================
🔄 Round 411 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 411 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0058
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0124
============================================================


📊 Round 411 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

============================================================
🔄 Round 412 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 412 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=-0.0035
   Val:   Loss=0.0922, RMSE=0.3036, R²=-0.0012
============================================================


============================================================
🔄 Round 413 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 413 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0001
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0159
============================================================


📊 Round 413 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

📊 Round 413 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

============================================================
🔄 Round 417 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0696 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0696, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0696, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0696, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0696, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0696, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0696)

============================================================
📊 Round 417 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0044
   Val:   Loss=0.0696, RMSE=0.2639, R²=0.0026
============================================================


📊 Round 417 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

📊 Round 417 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

📊 Round 417 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

📊 Round 417 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

📊 Round 417 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

📊 Round 417 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

📊 Round 417 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

============================================================
🔄 Round 426 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 426 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0018
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0079
============================================================


📊 Round 426 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

📊 Round 426 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

📊 Round 426 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

============================================================
🔄 Round 431 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 431 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=-0.0041
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0012
============================================================


📊 Round 431 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

📊 Round 431 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

📊 Round 431 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

============================================================
🔄 Round 440 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 440 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0039
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0220
============================================================


📊 Round 440 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

📊 Round 440 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

============================================================
🔄 Round 443 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 443 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=-0.0043
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0007
============================================================


📊 Round 443 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

============================================================
🔄 Round 444 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 444 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0017
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0215
============================================================


📊 Round 444 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

============================================================
🔄 Round 447 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 447 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0045
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0015
============================================================


📊 Round 447 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

📊 Round 447 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

============================================================
🔄 Round 449 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 449 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=-0.0044
   Val:   Loss=0.0918, RMSE=0.3030, R²=-0.0025
============================================================


📊 Round 449 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

📊 Round 449 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

============================================================
🔄 Round 451 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 451 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0034
   Val:   Loss=0.0738, RMSE=0.2717, R²=-0.0009
============================================================


📊 Round 451 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

============================================================
🔄 Round 452 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 452 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0038
   Val:   Loss=0.0762, RMSE=0.2761, R²=-0.0088
============================================================


📊 Round 452 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

📊 Round 452 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

📊 Round 452 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

📊 Round 452 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

============================================================
🔄 Round 457 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0690 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0690, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0690, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0690, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0690, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0690, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0690)

============================================================
📊 Round 457 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=-0.0031
   Val:   Loss=0.0690, RMSE=0.2626, R²=-0.0095
============================================================


📊 Round 457 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

📊 Round 457 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

============================================================
🔄 Round 459 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 459 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0031
   Val:   Loss=0.0784, RMSE=0.2799, R²=-0.0063
============================================================


📊 Round 459 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

============================================================
🔄 Round 460 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 460 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0022
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0137
============================================================


📊 Round 460 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

============================================================
🔄 Round 461 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 461 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0063
   Val:   Loss=0.0774, RMSE=0.2783, R²=-0.0144
============================================================


============================================================
🔄 Round 463 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 463 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0042
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0004
============================================================


============================================================
🔄 Round 464 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 464 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0043
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0302
============================================================


📊 Round 464 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

============================================================
🔄 Round 467 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 467 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0011
   Val:   Loss=0.0769, RMSE=0.2773, R²=-0.0112
============================================================


============================================================
🔄 Round 468 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 468 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0019
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0092
============================================================


============================================================
🔄 Round 469 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 469 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0022
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0058
============================================================


📊 Round 469 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

📊 Round 469 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

============================================================
🔄 Round 471 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 471 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0035
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0080
============================================================


📊 Round 471 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

📊 Round 471 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

============================================================
🔄 Round 474 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 474 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0036
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0013
============================================================


📊 Round 474 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

📊 Round 474 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

📊 Round 474 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

============================================================
🔄 Round 479 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 479 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=-0.0035
   Val:   Loss=0.0890, RMSE=0.2984, R²=-0.0044
============================================================


📊 Round 479 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

============================================================
🔄 Round 480 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 480 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0065
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0010
============================================================


📊 Round 480 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

📊 Round 480 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

============================================================
🔄 Round 483 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 483 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0047
   Val:   Loss=0.0840, RMSE=0.2899, R²=0.0038
============================================================


📊 Round 483 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

============================================================
🔄 Round 485 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 485 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0036
   Val:   Loss=0.0794, RMSE=0.2817, R²=-0.0066
============================================================


📊 Round 485 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

============================================================
🔄 Round 487 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0707, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0707, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0707, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0707, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 487 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0026
   Val:   Loss=0.0707, RMSE=0.2658, R²=-0.0083
============================================================


📊 Round 487 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

============================================================
🔄 Round 489 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 489 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=-0.0042
   Val:   Loss=0.0822, RMSE=0.2868, R²=0.0020
============================================================


📊 Round 489 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

============================================================
🔄 Round 490 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 490 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0019
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0102
============================================================


📊 Round 490 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

============================================================
🔄 Round 496 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 496 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0036
   Val:   Loss=0.0826, RMSE=0.2875, R²=-0.0001
============================================================


============================================================
🔄 Round 497 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 497 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0033
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0017
============================================================


============================================================
🔄 Round 498 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 498 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0008
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0115
============================================================


📊 Round 498 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

============================================================
🔄 Round 499 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 499 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0053
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0081
============================================================


📊 Round 499 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

📊 Round 499 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

📊 Round 499 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

============================================================
🔄 Round 503 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 503 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0035
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0005
============================================================


📊 Round 503 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

============================================================
🔄 Round 506 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 506 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0046
   Val:   Loss=0.0727, RMSE=0.2696, R²=-0.0015
============================================================


============================================================
🔄 Round 507 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 507 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0065
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0039
============================================================


📊 Round 507 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

📊 Round 507 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

📊 Round 507 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

============================================================
🔄 Round 514 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 514 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0058
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0037
============================================================


📊 Round 514 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

============================================================
🔄 Round 519 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 519 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2836, R²=-0.0037
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0020
============================================================


📊 Round 519 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

============================================================
🔄 Round 521 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 521 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0065
   Val:   Loss=0.0877, RMSE=0.2962, R²=0.0051
============================================================


============================================================
🔄 Round 522 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 522 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0012
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0104
============================================================


============================================================
🔄 Round 523 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 523 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0052
   Val:   Loss=0.0809, RMSE=0.2843, R²=0.0032
============================================================


============================================================
🔄 Round 524 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 524 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0039
   Val:   Loss=0.0784, RMSE=0.2799, R²=0.0016
============================================================


📊 Round 524 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0013

============================================================
🔄 Round 527 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 527 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0035
   Val:   Loss=0.0898, RMSE=0.2996, R²=-0.0015
============================================================


📊 Round 527 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0014

📊 Round 527 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0014

📊 Round 527 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0014

============================================================
🔄 Round 531 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 531 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0031
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0075
============================================================


📊 Round 531 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0014

============================================================
🔄 Round 532 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 532 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0027
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0059
============================================================


============================================================
🔄 Round 533 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 533 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0044
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0003
============================================================


📊 Round 533 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0014

📊 Round 533 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0014

📊 Round 533 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0014

============================================================
🔄 Round 538 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 538 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0033
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0089
============================================================


📊 Round 538 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

============================================================
🔄 Round 540 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 540 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0040
   Val:   Loss=0.0758, RMSE=0.2754, R²=0.0009
============================================================


📊 Round 540 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

============================================================
🔄 Round 541 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 541 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0041
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0005
============================================================


============================================================
🔄 Round 542 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0708 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0708, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0708, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0708, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 542 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0055
   Val:   Loss=0.0708, RMSE=0.2660, R²=-0.0008
============================================================


📊 Round 542 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

============================================================
🔄 Round 546 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 546 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0040
   Val:   Loss=0.0737, RMSE=0.2715, R²=-0.0110
============================================================


============================================================
🔄 Round 547 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 547 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0040
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0002
============================================================


📊 Round 547 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

📊 Round 547 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

============================================================
🔄 Round 552 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 552 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0029
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0068
============================================================


📊 Round 552 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

============================================================
🔄 Round 555 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 555 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0000
   Val:   Loss=0.0760, RMSE=0.2758, R²=-0.0156
============================================================


📊 Round 555 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

============================================================
🔄 Round 556 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0954 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0954, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0954, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0954, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0954, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0954, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0954)

============================================================
📊 Round 556 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=-0.0007
   Val:   Loss=0.0954, RMSE=0.3089, R²=-0.0111
============================================================


============================================================
🔄 Round 557 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 557 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0051
   Val:   Loss=0.0892, RMSE=0.2986, R²=0.0002
============================================================


📊 Round 557 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

📊 Round 557 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

============================================================
🔄 Round 561 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 561 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0041
   Val:   Loss=0.0751, RMSE=0.2741, R²=0.0031
============================================================


📊 Round 561 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

📊 Round 561 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

📊 Round 561 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

📊 Round 561 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

============================================================
🔄 Round 567 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 567 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0022
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0052
============================================================


============================================================
🔄 Round 569 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 569 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=-0.0030
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0029
============================================================


============================================================
🔄 Round 571 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 571 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=-0.0021
   Val:   Loss=0.0939, RMSE=0.3064, R²=-0.0090
============================================================


📊 Round 571 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

============================================================
🔄 Round 573 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 573 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0007
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0168
============================================================


📊 Round 573 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

============================================================
🔄 Round 577 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 577 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=-0.0033
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0056
============================================================


📊 Round 577 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

============================================================
🔄 Round 579 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 579 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=-0.0053
   Val:   Loss=0.0726, RMSE=0.2694, R²=0.0086
============================================================


📊 Round 579 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

📊 Round 579 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

============================================================
🔄 Round 582 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 582 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0045
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0041
============================================================


📊 Round 582 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

============================================================
🔄 Round 583 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 583 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0037
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0112
============================================================


============================================================
🔄 Round 585 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 585 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0025
   Val:   Loss=0.0761, RMSE=0.2758, R²=-0.0073
============================================================


📊 Round 585 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

============================================================
🔄 Round 586 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 586 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0033
   Val:   Loss=0.0862, RMSE=0.2937, R²=-0.0006
============================================================


============================================================
🔄 Round 588 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 588 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0027
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0037
============================================================


📊 Round 588 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

📊 Round 588 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0015

📊 Round 588 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0015

============================================================
🔄 Round 593 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 593 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=-0.0007
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0155
============================================================


============================================================
🔄 Round 594 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0971 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0971, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0972, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0972, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0972, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0973, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0971)

============================================================
📊 Round 594 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=-0.0054
   Val:   Loss=0.0971, RMSE=0.3116, R²=-0.0193
============================================================


📊 Round 594 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0015

============================================================
🔄 Round 595 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 595 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0034
   Val:   Loss=0.0752, RMSE=0.2743, R²=0.0001
============================================================


📊 Round 595 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0015

📊 Round 595 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0015

============================================================
🔄 Round 599 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 599 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0037
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0006
============================================================


============================================================
🔄 Round 600 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 600 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0051
   Val:   Loss=0.0727, RMSE=0.2696, R²=-0.0040
============================================================


============================================================
🔄 Round 604 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 604 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0021
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0066
============================================================


📊 Round 604 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0015

📊 Round 604 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0015

📊 Round 604 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0015

📊 Round 604 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0015

📊 Round 604 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0015

============================================================
🔄 Round 612 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 612 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0026
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0030
============================================================


📊 Round 612 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0015

============================================================
🔄 Round 613 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 613 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0040
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0018
============================================================


📊 Round 613 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0015

============================================================
🔄 Round 614 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 614 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=-0.0023
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0103
============================================================


============================================================
🔄 Round 616 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 616 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0017
   Val:   Loss=0.0871, RMSE=0.2950, R²=-0.0079
============================================================


============================================================
🔄 Round 619 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 619 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0042
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0028
============================================================


📊 Round 619 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0015

============================================================
🔄 Round 620 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 620 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0028
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0027
============================================================


📊 Round 620 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0015

============================================================
🔄 Round 621 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 621 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0041
   Val:   Loss=0.0842, RMSE=0.2901, R²=0.0007
============================================================


============================================================
🔄 Round 622 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 622 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0048
   Val:   Loss=0.0776, RMSE=0.2785, R²=0.0060
============================================================


📊 Round 622 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0015

============================================================
🔄 Round 623 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 623 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0043
   Val:   Loss=0.0756, RMSE=0.2749, R²=-0.0008
============================================================


============================================================
🔄 Round 624 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 624 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0040
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0021
============================================================


📊 Round 624 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0015

============================================================
🔄 Round 626 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 626 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0044
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0072
============================================================


============================================================
🔄 Round 627 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 627 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0031
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0036
============================================================


📊 Round 627 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0015

📊 Round 627 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0015

============================================================
🔄 Round 631 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 631 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0039
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0261
============================================================


============================================================
🔄 Round 632 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 632 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2850, R²=-0.0017
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0112
============================================================


📊 Round 632 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0015

============================================================
🔄 Round 636 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 636 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0001
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0154
============================================================


📊 Round 636 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0015

============================================================
🔄 Round 637 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0694 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0694, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0694, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0694, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0694, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0694, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0694)

============================================================
📊 Round 637 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0022
   Val:   Loss=0.0694, RMSE=0.2634, R²=-0.0085
============================================================


📊 Round 637 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0015

📊 Round 637 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

============================================================
🔄 Round 642 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 642 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0043
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0120
============================================================


📊 Round 642 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

📊 Round 642 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

📊 Round 642 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

============================================================
🔄 Round 646 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 646 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=-0.0046
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0065
============================================================


📊 Round 646 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0014

============================================================
🔄 Round 649 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 649 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0031
   Val:   Loss=0.0794, RMSE=0.2817, R²=-0.0015
============================================================


============================================================
🔄 Round 650 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0663 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0664, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0664, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0664, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0664, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0665, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0663)

============================================================
📊 Round 650 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0082
   Val:   Loss=0.0663, RMSE=0.2576, R²=-0.0036
============================================================


📊 Round 650 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0014

============================================================
🔄 Round 651 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 651 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0027
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0091
============================================================


============================================================
🔄 Round 652 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 652 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=-0.0022
   Val:   Loss=0.0937, RMSE=0.3061, R²=-0.0058
============================================================


📊 Round 652 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

📊 Round 652 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

📊 Round 652 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

============================================================
🔄 Round 658 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 658 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0006
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0144
============================================================


📊 Round 658 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

📊 Round 658 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

📊 Round 658 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

============================================================
🔄 Round 662 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 662 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0022
   Val:   Loss=0.0859, RMSE=0.2930, R²=-0.0132
============================================================


📊 Round 662 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

============================================================
🔄 Round 666 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 666 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0050
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0074
============================================================


📊 Round 666 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

============================================================
🔄 Round 667 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 667 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0023
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0049
============================================================


============================================================
🔄 Round 668 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 668 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0010
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0096
============================================================


📊 Round 668 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

📊 Round 668 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

📊 Round 668 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

============================================================
🔄 Round 673 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 673 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0034
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0292
============================================================


============================================================
🔄 Round 674 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 674 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=-0.0037
   Val:   Loss=0.0893, RMSE=0.2989, R²=0.0005
============================================================


============================================================
🔄 Round 675 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 675 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0047
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0006
============================================================


============================================================
🔄 Round 676 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 676 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0019
   Val:   Loss=0.0752, RMSE=0.2743, R²=-0.0063
============================================================


============================================================
🔄 Round 677 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 677 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0018
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0085
============================================================


📊 Round 677 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

============================================================
🔄 Round 679 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 679 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0010
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0125
============================================================


📊 Round 679 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

============================================================
🔄 Round 680 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 680 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0035
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0030
============================================================


📊 Round 680 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

============================================================
🔄 Round 683 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 683 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=-0.0028
   Val:   Loss=0.0741, RMSE=0.2723, R²=-0.0020
============================================================


============================================================
🔄 Round 684 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 684 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=-0.0023
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0046
============================================================


📊 Round 684 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

============================================================
🔄 Round 685 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 685 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0018
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0130
============================================================


📊 Round 685 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0015

📊 Round 685 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0015

============================================================
🔄 Round 688 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 688 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0015
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0073
============================================================


📊 Round 688 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0015

============================================================
🔄 Round 689 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 689 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0031
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0268
============================================================


📊 Round 689 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

============================================================
🔄 Round 692 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 692 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0049
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0019
============================================================


📊 Round 692 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

============================================================
🔄 Round 695 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 695 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0032
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0011
============================================================


📊 Round 695 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

============================================================
🔄 Round 697 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 697 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0024
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0212
============================================================


📊 Round 697 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

============================================================
🔄 Round 698 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 698 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0034
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0052
============================================================


📊 Round 698 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

============================================================
🔄 Round 699 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 699 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0038
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0025
============================================================


📊 Round 699 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

============================================================
🔄 Round 700 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 700 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0023
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0190
============================================================


============================================================
🔄 Round 703 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 703 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0048
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0056
============================================================


📊 Round 703 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

============================================================
🔄 Round 706 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 706 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0058
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0302
============================================================


📊 Round 706 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

📊 Round 706 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

============================================================
🔄 Round 710 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 710 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=-0.0041
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0019
============================================================


📊 Round 710 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

📊 Round 710 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

📊 Round 710 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

============================================================
🔄 Round 715 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 715 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0036
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0001
============================================================


============================================================
🔄 Round 716 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 716 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0033
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0120
============================================================


📊 Round 716 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

============================================================
🔄 Round 717 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 717 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0032
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0192
============================================================


============================================================
🔄 Round 718 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 718 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=-0.0022
   Val:   Loss=0.0733, RMSE=0.2707, R²=-0.0059
============================================================


============================================================
🔄 Round 721 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 721 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2829, R²=-0.0019
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0054
============================================================


📊 Round 721 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0015

============================================================
🔄 Round 722 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 722 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0018
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0083
============================================================


📊 Round 722 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0015

============================================================
🔄 Round 723 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0946 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0946, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0946, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0946, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0946, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0946)

============================================================
📊 Round 723 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=-0.0011
   Val:   Loss=0.0946, RMSE=0.3076, R²=-0.0085
============================================================


============================================================
🔄 Round 730 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 730 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0021
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0200
============================================================


============================================================
🔄 Round 732 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 732 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=-0.0026
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0114
============================================================


============================================================
🔄 Round 733 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 733 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0044
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0034
============================================================


📊 Round 733 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0015

============================================================
🔄 Round 735 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 735 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0011
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0095
============================================================


📊 Round 735 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

============================================================
🔄 Round 745 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 745 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0026
   Val:   Loss=0.0841, RMSE=0.2901, R²=-0.0033
============================================================


============================================================
🔄 Round 749 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 749 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0001
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.0137
============================================================


============================================================
🔄 Round 750 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 750 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0016
   Val:   Loss=0.0789, RMSE=0.2808, R²=-0.0072
============================================================


============================================================
🔄 Round 753 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 753 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0045
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0046
============================================================


📊 Round 753 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0015

📊 Round 753 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0015

============================================================
🔄 Round 756 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 756 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0033
   Val:   Loss=0.0748, RMSE=0.2736, R²=-0.0036
============================================================


📊 Round 756 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0015

📊 Round 756 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0015

============================================================
🔄 Round 758 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 758 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0023
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0042
============================================================


============================================================
🔄 Round 762 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 762 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0023
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0044
============================================================


📊 Round 762 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

============================================================
🔄 Round 765 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 765 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0052
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0068
============================================================


📊 Round 765 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0015

📊 Round 765 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

📊 Round 765 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

============================================================
🔄 Round 770 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 770 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0032
   Val:   Loss=0.0882, RMSE=0.2971, R²=-0.0008
============================================================


📊 Round 770 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

============================================================
🔄 Round 771 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 771 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0022
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0147
============================================================


📊 Round 771 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

📊 Round 771 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

📊 Round 771 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

============================================================
🔄 Round 777 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 777 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0027
   Val:   Loss=0.0891, RMSE=0.2986, R²=-0.0027
============================================================


============================================================
🔄 Round 778 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 778 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=-0.0018
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0087
============================================================


📊 Round 778 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

📊 Round 778 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

📊 Round 778 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

============================================================
🔄 Round 781 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 781 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0030
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0036
============================================================


📊 Round 781 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

📊 Round 781 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

============================================================
🔄 Round 787 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 787 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0020
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0133
============================================================


📊 Round 787 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

📊 Round 787 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

============================================================
🔄 Round 790 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 790 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0041
   Val:   Loss=0.0748, RMSE=0.2734, R²=-0.0110
============================================================


============================================================
🔄 Round 791 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 791 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0048
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0010
============================================================


📊 Round 791 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2606, R²: 0.0014

📊 Round 791 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2605, R²: 0.0014

============================================================
🔄 Round 794 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 794 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0007
   Val:   Loss=0.0907, RMSE=0.3011, R²=-0.0181
============================================================


📊 Round 794 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2605, R²: 0.0014

============================================================
🔄 Round 796 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 796 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0041
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0119
============================================================


📊 Round 796 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2605, R²: 0.0014

📊 Round 796 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2605, R²: 0.0014

📊 Round 796 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2605, R²: 0.0014

============================================================
🔄 Round 801 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 801 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0046
   Val:   Loss=0.0751, RMSE=0.2741, R²=0.0022
============================================================


📊 Round 801 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2605, R²: 0.0014

📊 Round 801 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2605, R²: 0.0014

============================================================
🔄 Round 805 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 805 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0059
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0079
============================================================


📊 Round 805 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2605, R²: 0.0014

============================================================
🔄 Round 807 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 807 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0025
   Val:   Loss=0.0710, RMSE=0.2665, R²=-0.0067
============================================================


============================================================
🔄 Round 808 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 808 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=-0.0011
   Val:   Loss=0.0841, RMSE=0.2901, R²=-0.0126
============================================================


❌ Client client_5 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_message:"Socket closed", grpc_status:14}"
>
