[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31ce401d-1ff2-4c32-925b-59b5fd3e9a08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20346ce9-6ef2-412d-8494-4f6dd608e023
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4a80957-4984-4b4e-9ed5-835d1ca42324
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1792f90-7d98-4810-ab6c-ddb08104d358
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 784eed6b-b635-437b-877e-410c6b26de50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ce7a007-f90f-4998-9857-c19b4db1ede7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb02b6ba-cfd6-4122-b6fb-379b1ed502af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e752695-fb7a-4833-8181-5b34d82ee3e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edb42911-f8d8-4187-a0b1-0d029e0e660f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bb5c519-ea38-4060-8289-e80f897083a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e507afc1-7671-48e4-ad91-74dbfd9ecddc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbddcae3-9eed-42fc-a95d-0fd7b295b840
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b46ecc45-ed3f-4b66-9f83-cc0678058dc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d9bdfab-e4ef-4942-8757-0448ef10aad4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05779efc-ea98-4ce6-8f31-695ce5efecc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07cafb51-564b-4eb5-be7e-35fb4126a752
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20ef480e-aebc-467e-867f-b9366c8fbb18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93e38429-8317-414d-b7d4-613c7d919c74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03f8cc48-cb40-4cf1-85d1-c154ce460e68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32b843d9-30a4-40f3-8f58-ca399f45509e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2ffe4ad-de6e-4b8b-8fdc-a7977df48d2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9dc49d46-3c2a-4e75-972e-1bfcfda0e121
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6920c5d2-d03a-4266-9401-66954fe8cfc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35d5798c-4e93-4bb3-9fcb-4bfbb10b70a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 599f2d94-ad79-4c3a-beb5-431b4205d496
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 611cadb0-995d-410e-addb-6912059072d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4dd9207-ceb5-4870-943b-599c2615bfd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb70fb87-19b6-4282-8f3e-a7f3a3d1f1df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d7fd555-42bb-4a59-a4fb-9a63e249d392
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63377e9e-c4be-4034-9b3a-c3b6474f08f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 809e1841-f116-4975-acf8-6c5a1eba3294
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58ac1f07-5cc3-466e-86ea-47192f5bd1d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1708690-7d46-4a5e-b7ad-95e1a8e87b7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7af7a92-194f-498b-ab85-0e85e90468ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4061a45-bcb6-437b-8453-5f4e06cb0b8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a2c0cfb-34e8-4973-9aa0-ace6aa34ab46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffa36038-414f-48eb-b5c1-1299e2d9ee1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5da2f1e-545a-44ea-bf0f-6e0564f0fec8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60cfd8c9-a933-4180-981e-20b4d7ebe9c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22687099-2c06-4304-b24c-cf31548da605
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6ffbb90-ed82-47db-afb9-1b49cbfacc59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a14341b9-f5f8-4d35-babc-781f5fbba4b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d3b4bd8-d717-4acd-ab25-4c226ca10773
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a679f4a-8d7d-4a85-af7f-b1e500b1e055
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a182790-99bf-4132-b89a-8c09d5334032
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 455d22bd-c3e5-45a1-b2f5-18d8965f784a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab3e7d1d-e07c-42d8-ade9-7ca541b4219a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d85ad0a-02e7-40de-8c57-b028fff74ee4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f8fa1cc-1473-4ce0-b391-25e5378e7669
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd7f3d05-6479-4268-853c-eb81606de0bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b862c6b-2a72-4420-b1f4-3142bc68d921
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8ce738a-9dd5-44cc-94cf-85e79fb6b555
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d1988e4-da33-4fe7-8196-de42aca82b6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eef7c915-2217-41f1-8af7-fc376750932f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7676b6d9-480f-4557-98d2-b91337367f66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f69aeee-0fee-4da6-880c-93f1c3808d7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c632335b-b808-4a98-8e13-e3ec022fa5e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 013eacd7-ac16-4329-9de4-bf04a032aa88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca69110b-3d1c-4703-935a-5c4850047d71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f4e8c51-51ae-4d54-9d69-079006768a5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43ae6040-55b6-408c-bfa4-94a6ac87d4b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff9cc9c1-280a-40d3-854c-e5a4c5b70292
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c65b1560-2e26-4394-85b0-faec05335d14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aeb6e7f7-9ffd-41e1-a063-0946a4bdf35a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99bd388a-5816-4b2a-9401-0b2e40a48056
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70f8e315-66fe-47b5-8a8b-0c0d232d74af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2434c6f-9057-426f-a1f5-61d5b5a7c1ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5968350-674f-4d25-8d4e-5de8c4e39b1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e133728-bfda-48fd-a751-64645baf18f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 773d460a-250f-446a-b0dd-60004678ef87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f70ad601-281b-41d4-8e3f-60d65756bfb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf1ab4c9-05e0-49bb-b0c4-0737db54802a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70526bca-8ca8-4542-9479-dcc54267e33a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f63ecb4-3179-4ab1-a43d-279010796660
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3da33497-3ba8-40c5-a76d-d1fc72d77b3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8e10fd2-3942-45bd-97af-a87574f27ec4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 422d61a8-d585-406a-bff8-70fb9e9892a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 151d6f5e-8c8a-430e-a6cd-be19e1354988
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e106e9c-d4ce-489e-b12a-3908334f7aa7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53afeb61-3a2e-48db-b58a-115da75c06bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d650076e-0404-43ac-a52f-453dba455b1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b322e204-dd59-4245-adf6-94dffd126f0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04e925d3-6e1e-410b-9acd-65858942697a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 940e13a5-d7c6-481c-a185-e081eedb67c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff8e0fba-68bb-43c7-9e05-9f164afc6a8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd3131c8-eb9d-440f-8e18-aedabca6d480
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6243922-9aca-42a2-9c66-6c3fa4507d2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb5fa96a-f2e5-4b47-bd70-b4aa8076bdea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bca162a1-961c-4880-8593-4937937404e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba848c5a-a993-407c-9e18-9d45761f3d1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09c54340-0e72-4e51-a376-86e6e9579135
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4362d52-40a1-4df2-b02c-a79a2b6cb278
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 249cc04e-e5f8-4712-ab47-2ff9e0b9a12e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4ebdb86-ee5c-4dad-9d90-f816643ff6e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4377af45-79a5-4710-ae9a-db86a7ff44b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c915392-99db-4422-a11c-79fc5f1c6c47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71b6fedc-2b8f-4532-8f95-13700b6d0907
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c79c8a6-96d3-43a1-9f8c-b8209d800935
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba0451f8-d334-47a0-9cdd-59b015303d6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55d3dca8-3182-4a97-b7c1-8274b6cc1ae7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99b090d9-06ae-4a6a-8e03-d7fa1a1b432a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37e9ff88-cbb3-44c8-9eba-261e1caeb618
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6968708-a6a4-4512-bfd5-6b2f7c5dae15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 182afdc4-1f17-4214-bdaf-316e773daf48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b3394ae-9f7f-408c-a67d-6296f22c193e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71c9811d-860c-419a-8bf2-c5a4d8ffd6a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74b4bc56-51a5-4e59-b8bd-529d48a6aab0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d00260b-6649-4ef4-a002-687dac5e7322
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58efbbf1-6fd9-47a8-a077-91af0bfa2133
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3284c803-dbb5-4a43-a9e6-554a0999d8e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9368aa76-ebad-4a55-bfb6-68fe9c5c40bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7cd1463-3403-47e9-a255-f7f430d6fdbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efc90c1f-718d-40b2-8010-a2d9d7475c81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af696676-755b-4f5d-82b5-24bb773bd7bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b41ae33f-5051-4b9b-a606-099863ba55bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13de6678-6858-4a65-a5b3-9f3e972e1020
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6d05683-363d-4891-b37e-2281fc09cd81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d337851c-66b8-409f-8ab6-95640937917a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f9af075-9493-448e-8e38-3ab0a3cd6756
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 216f783b-c167-4715-91e3-b28b4f046dce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4774fb5-1ba8-4580-9fa1-167f76df0456
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92ed95b0-693a-49d2-9a2d-2a4e2485a1fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0457a781-2b91-419f-83b2-1feb2a9b1f70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa708477-3db8-4790-81d3-df18b93b588c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94665c59-e43f-4975-bbfc-f617571475ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb24f80d-d04d-4a87-8cf4-7426c2eb2535
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b488978-11fb-4250-b5eb-7c4eb47d4421
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f25298b6-6825-4604-a035-9638c1d7d863
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 654b0f6f-bf94-4274-888e-d38df4109e7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6396a8d3-8737-4a52-86a7-24f0eae8c48c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4318598-309f-4ef3-a71e-1e1d3dbc88c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e95683c-956e-452e-8053-23f64225fabf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c8fa85c-c321-45ec-b56c-85a5bc27bf52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1f0166d-5d92-4d50-9f30-7103d7e90829
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc032e59-54ee-4baf-85c9-20a36d1de677
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d1d6a56-c3a8-43a0-9ffb-953e25e382d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b9264ff-e872-4d6a-bcf9-75f775128599
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10b80482-070e-4fd8-bdfe-ac68096edad8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 876e211e-ede4-4098-b3a0-7692b7400fbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd215e40-0f76-404b-9826-066c2781c986
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e57e022-e113-43fa-92fd-ef071bcb4d1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ecd6ff9-0e6b-47e4-ac1d-56bf731526dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18c54d10-2886-426e-bca0-3b12b11fc946
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8431ad9c-8c15-43b5-a6d6-2ed36bc2be5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2b4a01d-b7bf-4ebb-980a-4139ca549fdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bce9e6f-1d61-43ff-97cd-d4c8968686e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35c79f58-624b-49a2-99df-3f280b3ee73f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 591b2723-641f-44de-aa01-a8153b8944d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7824e70-82ae-4c01-9dd6-8402c23ebf62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1c422ba-57dd-4702-b84a-b5ed43b5059c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1e901a9-8abd-4747-b329-b64880b25037
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0eb70959-7b38-4241-8c05-acd16c20a623
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c98a14b3-912f-445e-9aaa-580a5e54e346
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8abcdee3-3250-4009-9042-724f6b9b67f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1cf49d7-a67f-432b-9a02-51f66c8271d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbd015dd-b888-4cca-89a6-b8cc67b9115a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a940e682-dfef-4fd3-9dd1-03b00939bb5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df5aefbd-3815-4d2f-b123-65949dad30fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 567b88e4-628a-47c1-b9bd-0f5f90e62908
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ec6e2b1-3346-4317-b5c6-1f8454b17b76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73086858-760a-4028-9060-e0917bb838fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ad60639-33d8-459a-ac9c-956fdd3963d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72bbd23c-d63b-4179-8dca-c819a088ec66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb0801c5-e118-4243-bda4-26acfb339dbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f2ffb40-d7f5-45b6-b223-1b6348cf92d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1c8d9cb-9300-4883-8fd9-9aa4c641b396
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6201983-09ee-4a99-96dc-bf5056c0b458
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0095bee5-d24e-41a8-9489-d03e1beb5305
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad3d933d-1a54-4f8d-b7f6-01efe38e11ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b104b6d-a4e8-4cfd-a273-2b59da94b3d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c0e20d7-27c3-402e-aa9d-4ddee58eaa6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87501fa3-3be4-4b4e-8700-a8b9ba6256d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f73330f2-ab9f-4861-860a-b7cbe56c7fcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77e49e98-dbd4-4c42-aef7-1f11bdf48b23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ded7fc1-39ec-42ee-8254-744f198ce565
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 453535ee-a41f-4cff-81b8-2a3ad54e3f88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad4c3263-3e89-44d7-b33e-1109ef8343f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98a04858-c197-4e28-be8c-2d609d64dbde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35f324c6-6301-4a7c-b4b1-f7b5d6e7d21d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4731f67-3d88-4741-b2cc-bc5fad23ff94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bfdca8e-d31f-46a9-83b4-91ab4783ac81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1fae5b7-1f19-484b-b4e2-8e4198d8faab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93ea43a2-dca1-48c5-9f67-dc3ad4bf86ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1191f2a7-40d6-4418-b7c0-55aa755379c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a2888e8-f040-4fb4-8b79-1e07390e7b4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e785de30-42fa-4889-8f31-bef39e3cf837
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c08d127f-4a32-4618-874c-5a917600cd23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39ec7452-8181-4cd2-91d7-1f3ad7c0aeec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 582c2078-a59b-406d-beac-9fc62e9992cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31834a8b-b0b2-41ed-9f64-87791834d687
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ffb86ca-bbee-4ccc-b4e4-59b97a1dc261
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8263f14-9918-46ed-9e8e-1f0f9177d7d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48e98cd1-6318-46fe-b904-1960409ad5bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc520faf-5688-4b34-b7b0-cc9e2873e02f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a842cb7-7096-43d4-a432-fa3b6381e7c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04e6e700-bf43-4abb-9cb4-8ab8f7570697
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 179d8112-fb8d-4fc7-80fc-5b9c924e173f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 586885c7-d588-45c7-be35-a6b09260bb4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3921a5ae-16a4-4b7c-9ab1-819b13d03b0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16a1fbae-be9a-4355-8b9c-fd370dcd8a2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b3008ee-c68d-468e-9c9c-994e08b00603
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43f9c329-8c04-441d-9e11-96a1fd477703
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 317297a7-3a8b-458d-8587-0de870c9f745
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d984d68f-7a2b-4fa1-97f7-84b837955b85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c06fab3-f409-4c68-a434-24fbd2cd5331
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b64788b7-fd9f-423b-8b3d-ee21bca1e024
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7b47729-a363-4971-b74c-e0b5cfc26694
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9a7ee1e-41bc-4be7-8bd1-4cf2f8003012
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 009191b4-865c-41e8-9596-4b22deea44bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33a99a4b-6b91-4345-b5ec-ea1decc35d52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ee80b53-7de4-43df-b756-8057a51844b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 185d6bc0-e214-44c0-86a0-09bedaba7f05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fda7377-7923-4453-b48b-298986fece5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f457437-b4b9-42a3-9d75-b5a227c6992f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f834b021-1f19-4299-8db5-748953673310
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10d946ee-5255-48e3-bc92-8392cd0f28ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96bd896d-5237-4a61-9830-aceefb47c1c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1b5dbc6-f38a-485d-bd14-9a3c370b1246
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6bfc1e4-30ea-4da3-b967-c8e466e1f1be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ebb90c4-131e-449c-bf67-4ebab8b61533
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43565e2d-4cfe-430d-85e4-a7ee8c6f2b7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edc0540a-cd6d-4d68-94d5-b8810e855cfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ac0f00a-d8f8-48ad-84f3-58720c1235f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 768ad2d7-a530-46c0-93e7-414d7b6e1e1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ce879a6-4239-42ce-9674-235f6298aace
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2df02ca7-aa53-4432-adcc-9ac75e003ced
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6cad836a-4386-49a2-93ca-a34e0a6d444a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4800add-55a0-41ed-b41e-e2e7746772f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66295bb9-acbf-4756-8f2d-7cdc0595dde0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12f856a1-f322-4c5c-b59a-1a40df4abbbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 342c37db-a4c8-4ac0-aeab-c0d685b6976e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9ca7d62-9bc4-417c-9f9c-96d8c73d1ab0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1adf2b7-cd12-4d2c-a1be-054b4c152d60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6727b013-3642-419d-af23-060846c7d17e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 068a0e34-28f8-419c-99fb-5a1c8b0ffbb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04ad6f84-6d70-4d5d-b2b7-775296d8d988
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db95bfb0-48b3-4ce6-9492-ce3e5e1ea7fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21b0feb8-644e-491c-8596-40335d964550
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc6fbe26-d2de-4dc1-a148-d1edff986d44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d744511e-e8a2-42c1-944a-6867e032d4f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c89807d9-12e8-4ad2-8377-aed4ea9e37eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c907cf8-aefc-40ea-ac58-12796d77c126
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 857585a2-7297-4510-aa1f-97c5ef2d8eb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b135478e-a9b6-4338-a016-210e6ce3e42f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c91221e-0a42-46b9-a40b-ef982de2fd8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb288d1d-4bbb-4b1e-aa86-17bbd4993778
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cb04924-2258-4609-b653-a238657100cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bdd5b03-1c39-4e86-837c-6655faee5b8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 513d7cc4-227d-4c2d-bb5d-9c8b5a0f7b3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f3ad8ee-08e4-4368-a4c6-6db0fbf2d2a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5359fcca-839d-4e08-bb96-26fbb2eb7773
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9cbb1609-a3ff-4aed-884d-8146d0162f5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9f74d22-e5cf-499e-b338-c43afde77065
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a653a53-9a70-4f1a-9d48-89ba60131971
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fec20ac-a90d-438c-aac8-a9f7b9962416
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1364273f-f56a-47f3-ac08-ae40441a436d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df530735-cdd2-47c6-8dbb-58c8120ef1a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f44dacb-2047-445a-a09b-355681af39aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b033921-eac3-4afb-9768-21b3db3aff25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de7a3a03-8bc2-4623-a689-5a1c6735736c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4257972a-5701-4140-acac-b0cbadbe175d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f485df5-2e16-4fa7-8166-c6cd1ea38fcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd5a41ff-a5dd-4f55-a392-69f28e0769a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e01d837-f471-4f06-a261-6850008f6580
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a94ede4-310d-458d-a9ef-fe811383de6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3156e60b-421a-438e-8143-87f13102f2cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90815299-064b-4703-b9fb-fa3f8984b86f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0cfffaa2-4006-489b-94fa-83adcf326834
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cda68f3-c87f-4fc1-bf0e-3872871659ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d579461-e09f-4b3b-9f8b-90d3bfd05d1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70d5005f-66bc-48ba-ada8-0d33142f5c19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74090d22-c3c6-4113-b114-e96fdaee14de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6122662c-2273-455d-a041-c772474dd83f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34632d67-ee3c-4f4c-bd87-0d35d5c02f74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74cb8415-1f18-4ad4-874f-7517417b9821
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcd34463-38de-4d11-9b37-57b1e9ca2a76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05a1ef3a-bfac-42dd-a72e-3de178fec834
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f015399e-7e25-4f45-a9b8-0f7197860d72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a678e286-c538-4492-b4a0-a05e34fe29ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4803014-68af-4bba-a0eb-1f75ca7926b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 208e03c1-99da-400f-943a-250d7bdfa309
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54818499-ad34-44b1-996c-7f4a04ad1761
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 545e3abb-6ebb-4ff8-aac2-a6a917247d80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2200c9c5-596f-4a9a-8092-7635c6c670af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf13ae23-6254-45f6-a674-38f176e95b7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e9e9395-2508-4444-9ae5-d25e9daaf46c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e6029a6-5199-4b40-a7bd-903bff431b5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5b3a413-a336-44ba-8072-710a58e0d94e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3906bbfd-a597-4094-bf4c-5183a4188b44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 353130e4-a2a9-4b9a-a173-95bc9bfbf3b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f2a2b8b-812a-4c62-9512-139b633742eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 068ed206-7645-46ec-8018-cd980a050e4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf5aaa98-ae89-43f1-bfc9-00432f563ac1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 248cfee7-1cfe-4c2a-9897-017d4ef7f112
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b473d71-1335-4eb9-b712-c82e7642a854
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a214b2bd-b626-45d4-aa30-d1fdba41cb42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c08475b-5a18-469b-8d1c-31e840100b28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5dd5aef8-cd6c-4157-a6f6-f171cd43edfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message adb9ca88-e68f-4589-9ab2-cb10e21ea702
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5338e6c-9beb-4642-a8f6-6ad9fbcc99ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cf951a0-cc73-4ee1-9929-96df3f632704
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3386294-7e75-4f0e-b70d-8da857074e51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 460cd354-d543-47eb-b778-8b2bb3292110
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8572e2c-7362-4b52-ba81-beda66e4b20f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a0639b6-779a-4f59-b3e2-1c0b50be7e0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5662361e-ac46-4f55-8d99-f3eeb9341bcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86454220-b7f0-45c7-bd13-0340a9ec0830
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94413740-8201-4f2b-a36c-4461b553718e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 861fd571-e27d-498c-be5e-f7431b1c9124
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bc5e950-baa0-4e32-98d8-a58100fa5f02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57311119-e6b2-4152-b341-df5834970aac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5ecea3f-9c56-42b1-83ee-5dd7c06ea315
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a62f1ea0-90f8-49c3-a727-4e6dd2656abb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b340d4d5-de41-4b3e-8968-d9024df35679
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fb34dd2-5669-476b-923e-0725ae4650f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f8523af-a1ac-42dc-873c-52d5bd85cbd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b673cc7-69d3-4f47-8c08-6f8c1c2e7b81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ab654a1-7045-4cdc-bbd2-8b16b5ef2b13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f7c99d0-bb23-450d-9443-919fecbe99a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f382f9f8-1eaf-4b87-8098-bf0039e6b44a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb6bebda-aadc-4adf-89ab-456a2826b213
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07b217ae-f874-4002-a75b-d473b1c58a67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f0b823e-f602-460f-8c87-f54cc8841e1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f60aa31-cfd6-44bb-8b86-0413b69befa3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d58069f-8c4b-442e-a970-103bd1d2aa04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae603f9a-0b81-42a8-bbe8-bc400bf937f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e0aac58-d15c-4eb7-aca7-b5708d511b87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 221ac6a9-1104-4299-9eac-d70f2a6dd3ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 182a5ebc-dd4b-4d74-a636-a90f71d89c23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 715f8015-3263-4f13-b279-50ad66e5015f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 558ec35f-cb8c-4ea2-ba86-7bd764ca84d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fcfae5b-03e6-4a29-86de-7e3f4d5e16fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74b89b76-1e86-47a1-8e37-e6a416467e2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4f35c39-6944-4457-947a-37e193657fc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b019661a-f2b1-4689-a2fe-36e9a538fcb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c07a491e-d748-4ced-a3e0-df6dfe08fa09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fe0903f-2092-42e8-967a-965f4e4d66f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc368308-8305-4fd7-b5a6-7a9e33903a14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57477465-cf78-467b-b62a-4eaa173ad64d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9a75240-6dc0-4fc7-af92-9292308c9bfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 504d1897-1617-4e32-b3c2-fda6fc197076
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fcfd551-34d6-4cc9-bf89-637774bc528c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f86a46bf-353a-4229-b67b-a797e83ccdeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77709de8-ae32-4788-a357-7398e45ddc63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f3e0023-3c74-4d24-8bc7-8efdc20b37b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afbacde7-eec8-4241-afa6-f7672fa9feb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee2508bb-2f94-4357-b461-30211384d6dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b770f7fa-6838-4491-a671-78fe1a753915
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f10d883e-efe1-4558-ae56-af02a816eb07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c01e9d9-8141-4166-a21d-0ec0632b528f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7a3fe2e-c8a4-496f-8cf7-e2b3e89311c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c4e23a3-f333-49d8-b31e-1b96fa162e9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 164b9b8a-40ca-4fb1-a718-132312edac1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f137a77-be51-48c9-9a12-d1c12cf15faa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66744567-9d97-48f5-bcac-fa6c54f582db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f3fb0c0-63fe-477c-b41a-c9259bdc2b1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 799aefac-fb79-47e7-88cc-28faf8c20971
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15035cf2-9d04-4a3f-a6ef-7a50493e96a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce633b2e-240b-4ef1-bd3c-a1a95a6ad84a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3835fd8-a217-44d4-8ffa-741195032f3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cc92a1c-0e3a-4450-934b-9117d8d3b2dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e489d337-81d5-4e7c-bbf6-8af5e296118e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59ba71a5-27dc-4144-80fe-f3434d6338bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3c808b3-caa4-444f-b50e-15c9f195d37e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f0b2aaf-41a8-4926-b402-7f0955663631
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3811a097-8260-4782-9666-bb5068166fa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e764092d-838b-40ef-9f1a-a62be06bc728
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6eace898-b8c1-4cc6-b0f8-155d49591db0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60bed057-51fa-4823-9abe-c7607f8aac60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b87cf2e4-ac0d-4d34-8fec-04f64042abbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c0ad967-b156-4513-b056-f6467fc2c282
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1537432c-dabb-404b-8dc8-1facfc05c09e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ff7ba6e-06b3-4150-a04e-add03b2d701d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9f4d124-1891-440c-82cd-1d0323852b58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 537d7bd4-08cf-4af8-8065-2f4722632cf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4b0823d-16c6-4638-98da-57d4e3996cd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e4737a5-baf2-4aad-b043-99be6953932a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44500c20-dbc1-452b-b69b-c7084eabc8e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd256e6b-e3bf-4524-aeef-d8cfc42e2094
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0945bce-5a3b-4297-b9b9-98b36107c431
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c5875c7-5692-4dde-80e7-6180af14d7b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2827b20e-5049-43be-a6af-44fae753fde6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb3ba10a-53aa-4af7-ad94-7f1abb3542ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 597cab56-a6b8-4d61-884d-8bbce0f19510
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bcd6f615-f71c-4f0f-9d14-b25d2a1cdaa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58f975d6-a5c9-4fe3-842b-d2f78207d030
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 249e020d-2cba-4a52-8b3c-c1ac6f5000bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b87e1198-18ca-47e3-928a-fc40d8309a1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38be1d7b-9f73-43ac-bd9a-8efd21e0961e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa9798da-1aa2-49eb-b97f-a770f673531c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 813edacf-dd21-4e69-b384-a172814e879e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6dcb3fd-5485-4e35-a44c-f8409db34b60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02e6d1d7-a15e-4913-8e58-a2db174751b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15aa5e29-8248-4c70-83a9-22db792b3801
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6016f6e-5d3f-4ad8-afe7-4ce4056ff60a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6af692c-c6a2-4f83-a0fb-99532f7aa4eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eee93964-6454-464c-b5be-da43ce5c73bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 720500da-46dd-40f5-b00b-8f2c7081f4c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5c6b8db-e5ca-447a-9e6b-1bee1d66431d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4139b0a1-0ede-4724-b200-2677f47428a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f64f52c9-4041-4a15-9452-9a4eef97492a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f149cf8a-c5d3-4c2b-8fdc-021c1cc45367
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3dc45571-c7d1-4341-bf00-7f0e121165a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80b82d36-c12c-4fe9-9e34-7c06175287d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce0f57ca-e66d-4b03-9fb7-d062bee912a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acac05af-5de4-465e-b058-7bb2a5f93d74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d97c7ded-4262-4c3c-9d0f-42f6efe8b932
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 960edfea-c4f9-4bab-86d6-b8a3324d27d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1045265-6298-4d7f-9db4-0e313fd6254a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa0fbd3b-efd8-433e-a776-978071f9c645
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 418b6a98-b08b-4c6c-b67d-5ab32ecd0137
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8d94d0b-da6d-4cef-b164-3d8992d82eff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6be08e92-079b-44f1-a528-24ca90280207
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 204910dd-b53a-4c4b-bcca-0b963d4074c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f40ccee-cdbb-4c19-a8b9-436fc1cff2dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1d4144f-25dc-404b-8c4c-0186ae5fcfe1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22747670-8595-4042-a0c7-f65b2ed4d62a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5dcaae48-2bce-486e-83c1-2cd9b531be6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65ff6cd4-5e18-4a57-9c66-aa8e27a2d171
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4b02ae9-f070-4fae-b462-84254988e1f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 276f779e-6c51-4174-bed1-3e203066d326
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b597867d-8362-492f-8e02-5ad1445b48fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b48d71cf-c553-472d-8a8d-78902ff12814
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a76f64f-4dd3-4901-9ff9-b500354429c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1eb90081-ec33-43bd-8390-d7ec40980b91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cce8433-8b35-4e0e-90b7-eed3ff0e4ab6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64decaac-d667-4b5a-96db-0832870c11ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2b99a7f-7cbc-430c-bc17-e0c7b6a3cc99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1563f21f-73c1-4136-a919-72b0e195bd8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42e3ceda-ff07-4ba8-a798-545cb42de031
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bed6bb46-f0dc-482d-bb03-5c69c1780e21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be618d65-b4fc-4f16-9dff-9705d651bb23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8473544-1a20-4e7a-bfd0-fe1dca1b5213
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4d68633-ac1d-446c-9586-17c230371f89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f858f581-8496-40a8-87cc-37ce30b990ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9078860e-1448-4730-bd2d-c686db04742a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 626e9e98-7ebf-496f-9ad2-d62afcc2ffd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0912d3cd-0d82-431a-b6a9-2642ec7c0926
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67d5584e-2b3b-40f4-937e-925c06a5fde9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce566a8f-e857-4239-9972-3c3b3e95508f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 895eeb30-d092-4791-ba56-be7d84e82f33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f65a1d3e-be29-4128-8a4d-bde186cb1501
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14203f4e-aca2-4f8d-91b3-7bcce1167337
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd7e57d8-db4a-4781-a1c3-f811053ffa31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80e9b48b-faa9-4f90-b935-5780c911364c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bb16407-b58b-44c4-b6bd-5bbd3260520e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75410310-b740-4d67-9a64-c6f4e47c6a6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbbeca2b-5287-4087-be77-aa01d152a828
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7fc7a0b-e078-4abb-bcf1-ca73707ab29c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d466f9b-3f5e-4ec0-ae05-2592efda317a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c8bafa2-2ea6-40db-8e1d-71aea6d48466
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a9afcb6-ac0d-4fd0-807c-9956c052279c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3afcfb05-3880-4d29-a478-1e950c78be35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4743179-db3b-4900-b586-86c0149281d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ebe2693-3214-4b05-a37b-8e1c18dba4d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc2d2124-f325-410d-9933-6e25322e91c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f180b32c-22e0-4fc5-8b15-53e315965619
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5378c254-fef8-4e19-9de1-46699489ba8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8fc6b74-a12f-410d-be6c-bd8755fb3fb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3230e5b2-d124-4876-aef4-360ceb9c6553
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7529721-de82-49c6-82b7-e9fb3dc236f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d6e3ee4-71ae-4dcf-9b6c-4734cf6bdf11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 745cc7b7-b419-4430-bbee-ef5854ad84db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6266cb11-2008-4537-9dad-ae49d77b8348
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f612b5b0-fb68-436f-a346-7f544af63a20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a73a05b6-77c8-457c-ae7c-43b8e050437f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 836d39ba-2e6e-438c-8f79-65ca6b9d62bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73ca8e02-fbd8-42c2-b272-cb5c8c981936
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c38e7019-c2df-400f-ac76-cf3d58820bd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bcbd85f-b065-4429-9051-8e0d98bab611
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e819bacd-27b0-4b95-97ee-636b1486f862
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29add8b3-bcd5-4871-bec2-895e267e35fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00a1c90a-9a34-4b00-bc25-e860b859c614
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0dd325b-488a-44f5-a6b9-972ad28a5a4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b7ea9d8-f08c-4fef-b3b7-10aab3c4a725
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa709a0f-de58-49c3-b53a-045c62e7890f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93d60482-694e-4a76-87d8-c6ef59c88ffb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a0f24ba-bb2c-487d-9d23-1dba1b338886
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd8c449c-3d68-42c6-9153-605dd7ed9876
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed7d2b7d-88db-4a2a-8322-533f459e509d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66d670fc-3dfc-4ac6-b5b9-f073472d59c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00222a93-ff46-4453-aa7d-b393978a2da5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce20bce0-578d-4997-9bdc-96c6ddd9191b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81217508-55b1-4668-9056-e38d1a5fe2d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d055da5e-4fb3-4e2e-b8b5-100f88f08897
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77131ff4-190d-4983-a904-403b3b2a20f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77a4892e-95df-40d5-b4ac-c3325c7c379c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9d431ce-6220-443f-9083-0ddafec83f76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd30b9a2-f6de-41d2-899b-9148f30f6575
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bb580e5-f884-4d8b-b2bc-c5a5333d6cf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e51e41d-f693-40d5-85f4-dbd794ff679e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ff14456-5a89-4c5b-bf85-4529dd20d25a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4e5b239-6f22-48be-a91b-68190de8cca9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f58215a4-d884-4292-8026-ab84a1fc2be2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f58c881f-4b61-434c-bf30-ead4622725c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6ef6e30-61c6-48d9-a01c-bed4249eebae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab892a57-88a0-4fb6-acb5-3a1a46596518
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd511b0a-6721-4087-b88a-45d98bc56679
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a94cf3b6-c974-4e7f-a679-7a28dfd0534c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df6349fc-158d-4bb8-b264-f5635d5d6608
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b349d378-8b6d-4abc-b596-858fcbcf4eaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b83f6954-71bb-4413-946f-c1655f59223a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8294599d-4425-4dfd-a408-3abd4d190b7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8dc3a562-623a-49b8-a314-a9c17b982059
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77770b61-1af0-4ab5-a918-988ebd59f4ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b78a5f0-c109-4224-98e5-a56e71917462
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34d22321-dd9b-4745-a913-9598d30f814b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c594d0d6-7c94-4ec0-a448-69b0d42a6169
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d71d577-e176-452d-92e3-bd5d92a7c79b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f2ad339-9d37-435e-9bb9-4d01a599d22e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0585e1f3-158f-4728-b7c0-5265695acd7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1a5395f-9478-46f4-9729-fc0ef3391d48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4fa57170-144a-42f6-9102-b49cf3fa7b0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7e1f47a-e951-4655-bee1-412645348eaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ed78008-2d29-4a14-b6f9-a6f47a1bd6c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d1ad7a2-6ce1-4062-b129-882b28a560bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50829960-b9b4-4e32-bdba-81c14e7e4451
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61c5ca27-4319-4891-a619-098b6684faf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4efca3bd-fc10-45e6-bd97-cacc45ef5733
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ded372ae-6f09-426e-9732-502cacfdf626
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f8c1992-a3ff-4084-b6c9-cd911d6fb229
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2ff1bfc-04ec-4707-9e2c-492aed1880f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5477bd3-b5a4-464d-adf5-0f44246d8922
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0856b77-6944-422f-880a-d80bd059376e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be010973-684e-4490-b14c-0abfcbfa82bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e1e0301-1a74-4ecb-b968-05cc55fc958f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec0e073d-ac0d-4efa-a8d1-ad9159628545
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 436bdb8e-ba91-4b96-af98-d7664d179985
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9f78932-70af-4bc7-a494-d3cf4a760a5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e87f322-1d26-4084-94ef-e4a1d71e08a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 416c9b16-6044-4165-9c72-f81ea2e57992
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47fa789b-e5de-42c2-b936-e74b163d18ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8fda255-1b71-4b47-98eb-85a18b26ed52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7de2877-2b52-4ebd-9511-17de90ee3176
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33dfc6e9-7266-4f2c-ae58-2a9710e489ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9acd01fb-316d-4b40-b7e8-d5a8348153ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4597822-8db1-41bd-9e80-6eaca487f392
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8bbbc155-6a85-4350-ace9-38c98a30383e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d45dda65-2575-4080-aa15-994fc9896580
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85573fd7-5930-4d18-95e6-9dd379b0f009
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 804a0ad8-33f0-441a-a56a-e9163ee37e33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7fd139d-e803-4a16-abd3-ade9e4e10886
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bea002cc-85a4-4962-b609-09556e249022
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5611555b-7a7f-4534-b648-316f60237898
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d685000-24f6-498e-b17d-5c47ac7a99d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21d0e65a-fe90-4219-be12-a0ac1e6d63f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 645ac706-f9ab-4f7f-a003-7664279c4df7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 690908e1-2422-44d0-979d-ec584297fa49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82a05453-6088-4035-9240-4d690c3e8fab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25db5adb-b565-41cc-9ae7-ca702641734b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c269319-40e9-4d89-89cf-0830ea01b479
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2bc3254-c2a8-4956-9b27-e0d19f2dd1c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57476fc5-68e2-47d2-af2a-7c2fa60137e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6bec574-fe4e-4a2d-86f6-2af9b651881a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e9d32df-b75a-48d1-9a3f-46bdfdd51a3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72ecc46f-7824-42b7-b2bd-41153e21c541
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 620f01a2-3701-42ea-913b-890dcdb6b443
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c13db6a6-7b22-4e91-b384-ef6d6ff67d82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 707b7efa-dfcd-4087-b771-c1c6ed6d7bc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57a67df2-0c51-41a3-a864-88ca21a35289
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45668d06-2fb2-4fe7-862f-9298e5d85e18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c8d98d6-2326-4edd-a8a8-e258487c07d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4237ca2b-84a5-4365-981c-10e75a6a7472
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe3a8fe7-b3e3-4e1f-853b-779de5e8bcb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80d3ce32-fd6f-4b77-a0d1-97f54005498b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3015a3f2-ef21-4845-a126-3dc17cac6422
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47d16c8f-8ec3-4184-bdbd-cd915c71efd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c556b28-b076-4ca9-8664-efc942ece227
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5a0bbe9-7a59-4118-b6f5-1239efc1aafe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be9a5204-969f-4173-b666-2e5a01fb4e1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f713ca60-c873-46e5-b29c-3d79d299b871
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f336e18-a7be-4db2-a6be-c3b0662fcdd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df2f113b-d5fb-4902-af08-c1feeacf47c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26dec7e8-22a9-45f0-b36d-5f16c374ecee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71e99c16-1f75-47d5-b1a5-4653e413208f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89fe203f-4d25-43be-8fc9-fc3b56827454
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51477f11-fb48-4891-8de6-3126b767cf57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10711fae-6d86-49c0-8cbf-143a05709ef7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff21e4d7-26c1-4be9-96c6-7c98b4613009
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfaf842c-87b6-4b41-8d8e-e4bfeb62bd24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99d775c2-5f20-4a58-b79f-54ed49e23d43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df6acea7-196e-475f-857a-783cc5b8e1ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b2527ab-b5eb-49df-93c6-a767c8cd12c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fd0dadd-feaa-4432-9a95-f323d56395b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94bd62ce-cc19-49cb-9659-40630c06ce96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16cac2bb-2533-45cc-8a02-14b5d19afa08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e882c477-1254-497b-ad1f-e349447e3992
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message adc00829-c102-4e64-ae69-10289bc2ec25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b59051c9-471f-47b8-a1f1-452e59349f2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f18a435-a285-4506-aa67-24103a3e4f25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78555d5b-1d64-4355-a81c-f270942f7c6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02127e12-1586-41c5-8dc5-08d1bf5c8c70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b1292ed-95da-4a16-955d-fa26a0b10a37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4e745fb-452c-43f7-978d-b7da1a65c413
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1bb0757-0f55-46d7-a0dd-4e2bd762dbc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f20b582e-1df5-4809-a8a2-6d7e331f50e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aea06353-7675-4078-a791-a5bb45401654
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 904b1656-6654-41b5-a072-7b41d8502e08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30b7c2f5-e804-48b8-adb8-885fe1f4553f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a5c25d2-c52c-46ae-8566-2c949f831539
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70d051bd-d502-4059-a92b-6ff41596db21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7aad9975-82f6-4e65-8920-19a6ff611ef2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6372287d-e662-48e3-99b3-d38de95def81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 602bd7ff-14d5-4579-9a12-f0e9c149083a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab2fb7b8-03a5-42fb-a28d-575afd1d0d07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae906ef5-d2db-444f-8377-cb2695b53057
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9d6da2b-ba47-498f-83ed-be8d7383206b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce56564e-29ba-4980-addd-9fc32a13b16f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b163ed1c-542e-4cc5-858a-3adf1ca51bd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa06e510-f721-48e2-aae7-f11c5818f692
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25928d15-4129-4977-a2fa-eced1b035dbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 070259e5-0082-449a-b067-72daa1db7e1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80e5b28d-6376-43c2-bf5a-0a6ce064bc0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb21f7ef-05ec-4c8a-94f6-267e42b28363
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55f266de-bf87-4955-b7e3-f05426d32a57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 354820df-bc3a-420b-846d-11853954125e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8cab367e-131b-480d-93d2-5a6a8dd47442
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94fe6908-f2c0-461f-a3bb-d2ab1b1a92a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2f68960-0466-495e-afde-ab4b266e0c58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18eef2d7-4b31-41ce-a29b-532d1010c699
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8d91895-0fd8-4f99-94ae-5502c0f7ccbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fddc881-92bd-47bc-bdf1-337b28c51f3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82c6a961-9314-4e53-9d83-dcc064d51a60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a208cad-1790-4948-a923-fe222feb5eb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 506fdbfd-ce31-4c51-9e6e-e88872a72355
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4eb29a75-1bd9-40f7-a35a-4ae7c7f84719
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a946b25-59ba-49a5-8fca-95d49f77654f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7776198d-6f0a-4278-8645-2653f9e7326c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e312ad0-e2c1-41c2-b3f5-5315689783fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0db747f-4e8b-4f63-9590-93e64436cea9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ca5fcd1-d818-4639-b218-e9f5e42afe55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f24e0edb-5f70-445f-87b4-07c96c4da51d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a13d12e0-1f5d-4c11-a579-0df1eec42d13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88b5272b-fe3e-46a5-aeee-ea7017ff24b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f9751f9-2433-4049-9fa2-cab7ea817ea8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a9b70f4-faa7-4ed5-a291-fd5d085eb8f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9aab99f-b3a2-46cd-9878-0fc9302d9803
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 922f5be6-5aab-46c3-a5d1-fd85dc0045d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b85b4ce1-87ab-45db-b585-c847eaf14259
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 368d5515-b717-4321-be29-657516b2a1a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6393f09a-6dd3-423c-b568-5f78623db355
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63c4c0b6-0ace-41be-9082-7a13af530002
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa838cda-9ce7-448f-88f4-f10d00f003fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 946935df-12f4-428f-8dc4-7d495c427754
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 141edf62-d7b3-44b8-afb0-4eab47ce62fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d863b69-2811-482b-bc80-9a6d9fb69ab2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fc07603-241d-4121-8774-786288a57354
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26170000-9360-48fd-869b-9e7b60fc325c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01ba6c07-d02a-4a18-8104-b1630b1de157
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a13af23e-27e0-4408-9b53-2472833563ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd392c5f-7ac3-4a1e-82ba-5f031eff1339
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 684b4aa6-51e2-4f0c-b596-3bcc5822a109
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91435824-0190-4b90-8e4d-b374c8f48162
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ece29f9-207b-4165-a227-b8855bee8639
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30bdd3f5-5437-4e65-a610-cae936a273aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89792180-bdd7-4e90-af60-54ff670a5690
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 292c093f-a148-4c8b-a2f9-5f293f7a5207
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4a54a68-09c7-464a-9388-c6bb1cb7057a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ed923e4-a4ff-455b-bec3-cdeca76d6fdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c125b538-9028-4e9a-a4a6-3a2484408695
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f90f3be-ed3f-499d-9362-1a6a9a101e53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ed3f520-61d7-4068-9ff0-119608a6b1c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6acd3eb-c470-4cbe-8855-dbb0abc7f4ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45ae25a6-f2d6-453c-bfd3-ff70a93d0ee8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0f074f1-5dab-447e-902e-ee3a20a5905a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39cea04d-07fb-4589-9170-30ebaf5b8a3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3422a7c-b7b5-41f3-88d4-25e7f6fc6d5e
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_6
Server: localhost:8686
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_6
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_6/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_6/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_6/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_6/test_labels.txt

📊 Raw data loaded:
   Train: X=(4759, 24), y=(4759,)
   Test:  X=(1190, 24), y=(1190,)

⚠️  Limiting training data: 4759 → 800 samples
⚠️  Limiting test data: 1190 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_6 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 2 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0755 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0833, val=0.0747 (↓), lr=0.001000
   • Epoch   3/100: train=0.0831, val=0.0747, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0829, val=0.0747, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0826, val=0.0747, patience=3/15, lr=0.001000
   ✓ Epoch  11/100: train=0.0796, val=0.0734 (↓), lr=0.001000
   • Epoch  21/100: train=0.0686, val=0.0686, patience=3/15, lr=0.001000
   📉 Epoch 25: LR reduced 0.001000 → 0.000500
   • Epoch  31/100: train=0.0632, val=0.0714, patience=13/15, lr=0.000500
   📉 Epoch 33: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0684)

============================================================
📊 Round 2 Summary - Client client_6
   Epochs: 33/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0689, RMSE=0.2625, R²=0.1739
   Val:   Loss=0.0684, RMSE=0.2615, R²=0.0744
============================================================


============================================================
🔄 Round 5 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0764 (↓), lr=0.000250
   • Epoch   2/100: train=0.0816, val=0.0763, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0815, val=0.0763, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0814, val=0.0762, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0813, val=0.0762, patience=4/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0809, val=0.0761, patience=10/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 5 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0156
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0050
============================================================


============================================================
🔄 Round 7 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0853 (↓), lr=0.000063
   • Epoch   2/100: train=0.0794, val=0.0851, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0793, val=0.0850, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0793, val=0.0850, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0793, val=0.0850, patience=4/15, lr=0.000063
   📉 Epoch 8: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0791, val=0.0850, patience=10/15, lr=0.000031
   📉 Epoch 16: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 7 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0144
   Val:   Loss=0.0853, RMSE=0.2920, R²=0.0074
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0126

============================================================
🔄 Round 9 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0808 (↓), lr=0.000016
   • Epoch   2/100: train=0.0800, val=0.0808, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0800, val=0.0808, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0800, val=0.0808, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0800, val=0.0809, patience=4/15, lr=0.000016
   📉 Epoch 8: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0799, val=0.0809, patience=10/15, lr=0.000008
   📉 Epoch 16: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 9 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0141
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0111
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0127

📊 Round 9 Test Metrics:
   Loss: 0.0774, RMSE: 0.2783, MAE: 0.2384, R²: 0.0122

============================================================
🔄 Round 11 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0827 (↓), lr=0.000004
   • Epoch   2/100: train=0.0798, val=0.0827, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0798, val=0.0827, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0798, val=0.0827, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0798, val=0.0827, patience=4/15, lr=0.000004
   📉 Epoch 8: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0798, val=0.0827, patience=10/15, lr=0.000002
   📉 Epoch 16: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 11 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0131
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0191
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0127

📊 Round 11 Test Metrics:
   Loss: 0.0774, RMSE: 0.2783, MAE: 0.2384, R²: 0.0124

📊 Round 11 Test Metrics:
   Loss: 0.0774, RMSE: 0.2783, MAE: 0.2384, R²: 0.0124

============================================================
🔄 Round 16 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 16 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0172
   Val:   Loss=0.0733, RMSE=0.2707, R²=0.0023
============================================================


============================================================
🔄 Round 17 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 17 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0143
   Val:   Loss=0.0844, RMSE=0.2904, R²=0.0124
============================================================


============================================================
🔄 Round 19 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 19 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0133
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0129
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2384, R²: 0.0127

============================================================
🔄 Round 20 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 20 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0171
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0043
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2384, R²: 0.0127

============================================================
🔄 Round 21 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 21 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0149
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0158
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2384, R²: 0.0127

============================================================
🔄 Round 22 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 22 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0132
   Val:   Loss=0.0731, RMSE=0.2703, R²=0.0203
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2384, R²: 0.0127

============================================================
🔄 Round 23 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 23 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0131
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0195
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2384, R²: 0.0127

📊 Round 23 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2384, R²: 0.0127

============================================================
🔄 Round 25 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 25 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0152
   Val:   Loss=0.0885, RMSE=0.2976, R²=0.0145
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2384, R²: 0.0126

============================================================
🔄 Round 28 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 28 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0134
   Val:   Loss=0.0865, RMSE=0.2942, R²=-0.0215
============================================================


============================================================
🔄 Round 29 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 29 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0115
   Val:   Loss=0.0834, RMSE=0.2887, R²=0.0030
============================================================


============================================================
🔄 Round 31 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 31 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0130
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0155
============================================================


============================================================
🔄 Round 32 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 32 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0141
   Val:   Loss=0.0779, RMSE=0.2792, R²=0.0136
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2384, R²: 0.0126

============================================================
🔄 Round 33 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 33 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0144
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0056
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2384, R²: 0.0126

============================================================
🔄 Round 36 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 36 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0123
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0174
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2384, R²: 0.0126

📊 Round 36 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2384, R²: 0.0127

============================================================
🔄 Round 40 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 40 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0158
   Val:   Loss=0.0886, RMSE=0.2977, R²=0.0120
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2384, R²: 0.0126

============================================================
🔄 Round 42 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 42 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0147
   Val:   Loss=0.0749, RMSE=0.2736, R²=0.0058
============================================================


============================================================
🔄 Round 44 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 44 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0159
   Val:   Loss=0.0868, RMSE=0.2947, R²=0.0107
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2384, R²: 0.0126

============================================================
🔄 Round 46 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 46 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0166
   Val:   Loss=0.0792, RMSE=0.2815, R²=0.0079
============================================================


============================================================
🔄 Round 47 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 47 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0165
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0094
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2384, R²: 0.0126

============================================================
🔄 Round 50 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 50 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0148
   Val:   Loss=0.0750, RMSE=0.2738, R²=-0.0000
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2384, R²: 0.0126

============================================================
🔄 Round 53 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 53 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0145
   Val:   Loss=0.0838, RMSE=0.2896, R²=-0.0028
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2384, R²: 0.0126

📊 Round 53 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2384, R²: 0.0126

📊 Round 53 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2384, R²: 0.0126

📊 Round 53 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2384, R²: 0.0126

============================================================
🔄 Round 57 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 57 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0171
   Val:   Loss=0.0894, RMSE=0.2989, R²=0.0078
============================================================


============================================================
🔄 Round 58 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 58 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0150
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0125
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2384, R²: 0.0126

============================================================
🔄 Round 59 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 59 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=0.0132
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0212
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2384, R²: 0.0126

📊 Round 59 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2384, R²: 0.0126

============================================================
🔄 Round 62 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 62 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0143
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0170
============================================================


============================================================
🔄 Round 63 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 63 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0147
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0134
============================================================


============================================================
🔄 Round 64 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0949 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0949, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0949, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0949, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0949, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0949, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0949)

============================================================
📊 Round 64 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0153
   Val:   Loss=0.0949, RMSE=0.3081, R²=0.0123
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2384, R²: 0.0126

============================================================
🔄 Round 67 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 67 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0156
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0064
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2384, R²: 0.0126

============================================================
🔄 Round 68 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 68 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0133
   Val:   Loss=0.0718, RMSE=0.2680, R²=0.0223
============================================================


============================================================
🔄 Round 70 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 70 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0153
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0029
============================================================


============================================================
🔄 Round 71 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 71 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0135
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0210
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2384, R²: 0.0126

============================================================
🔄 Round 72 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 72 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0177
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0032
============================================================


============================================================
🔄 Round 76 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 76 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0146
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0109
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2384, R²: 0.0126

📊 Round 76 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2384, R²: 0.0126

============================================================
🔄 Round 79 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 79 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0153
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0141
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2384, R²: 0.0126

📊 Round 79 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2384, R²: 0.0126

============================================================
🔄 Round 82 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 82 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=0.0155
   Val:   Loss=0.0724, RMSE=0.2690, R²=0.0130
============================================================


============================================================
🔄 Round 83 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 83 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=0.0135
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0155
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2384, R²: 0.0126

📊 Round 83 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2384, R²: 0.0125

📊 Round 83 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2384, R²: 0.0126

📊 Round 83 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2384, R²: 0.0125

============================================================
🔄 Round 89 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 89 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0122
   Val:   Loss=0.0748, RMSE=0.2735, R²=0.0180
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2384, R²: 0.0126

============================================================
🔄 Round 93 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 93 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0143
   Val:   Loss=0.0764, RMSE=0.2765, R²=0.0116
============================================================


============================================================
🔄 Round 96 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 96 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0121
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0239
============================================================


============================================================
🔄 Round 97 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 97 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0148
   Val:   Loss=0.0883, RMSE=0.2971, R²=0.0021
============================================================


============================================================
🔄 Round 98 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 98 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0126
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0135
============================================================


============================================================
🔄 Round 99 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 99 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0144
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0160
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2384, R²: 0.0125

📊 Round 99 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2384, R²: 0.0125

============================================================
🔄 Round 103 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 103 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0158
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0081
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2384, R²: 0.0125

📊 Round 103 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2384, R²: 0.0125

============================================================
🔄 Round 105 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 105 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0113
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0197
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2384, R²: 0.0125

📊 Round 105 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2384, R²: 0.0125

============================================================
🔄 Round 109 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 109 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0145
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0141
============================================================


============================================================
🔄 Round 110 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 110 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0134
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0047
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2384, R²: 0.0126

📊 Round 110 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2384, R²: 0.0126

📊 Round 110 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2384, R²: 0.0125

============================================================
🔄 Round 113 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 113 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0147
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0168
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2384, R²: 0.0125

============================================================
🔄 Round 114 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 114 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0133
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0174
============================================================


============================================================
🔄 Round 115 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 115 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0156
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0117
============================================================


============================================================
🔄 Round 117 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 117 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=0.0146
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0163
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2384, R²: 0.0125

============================================================
🔄 Round 119 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 119 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0133
   Val:   Loss=0.0756, RMSE=0.2750, R²=0.0222
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2384, R²: 0.0125

============================================================
🔄 Round 121 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 121 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0179
   Val:   Loss=0.0743, RMSE=0.2726, R²=-0.0308
============================================================


============================================================
🔄 Round 124 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 124 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0137
   Val:   Loss=0.0775, RMSE=0.2783, R²=0.0183
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2384, R²: 0.0125

============================================================
🔄 Round 126 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 126 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0142
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0072
============================================================


============================================================
🔄 Round 127 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 127 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0169
   Val:   Loss=0.0855, RMSE=0.2925, R²=0.0047
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2384, R²: 0.0125

============================================================
🔄 Round 130 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 130 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0137
   Val:   Loss=0.0736, RMSE=0.2714, R²=0.0066
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2384, R²: 0.0125

📊 Round 130 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2384, R²: 0.0125

============================================================
🔄 Round 132 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 132 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0157
   Val:   Loss=0.0718, RMSE=0.2680, R²=0.0060
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2384, R²: 0.0124

============================================================
🔄 Round 136 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 136 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0167
   Val:   Loss=0.0810, RMSE=0.2847, R²=0.0087
============================================================


============================================================
🔄 Round 138 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 138 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0140
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0187
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2384, R²: 0.0125

============================================================
🔄 Round 140 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 140 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0149
   Val:   Loss=0.0770, RMSE=0.2774, R²=-0.0042
============================================================


============================================================
🔄 Round 143 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 143 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0136
   Val:   Loss=0.0745, RMSE=0.2729, R²=0.0206
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2384, R²: 0.0125

============================================================
🔄 Round 144 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 144 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0148
   Val:   Loss=0.0770, RMSE=0.2774, R²=0.0150
============================================================


============================================================
🔄 Round 145 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 145 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0153
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0142
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2384, R²: 0.0125

📊 Round 145 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2384, R²: 0.0125

============================================================
🔄 Round 149 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 149 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0147
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0152
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2384, R²: 0.0125

============================================================
🔄 Round 152 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 152 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0166
   Val:   Loss=0.0906, RMSE=0.3010, R²=0.0101
============================================================


============================================================
🔄 Round 153 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 153 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0170
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0056
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0126

============================================================
🔄 Round 156 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 156 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0172
   Val:   Loss=0.0822, RMSE=0.2866, R²=0.0071
============================================================


============================================================
🔄 Round 158 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 158 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0147
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0173
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0126

📊 Round 158 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0126

📊 Round 158 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0126

📊 Round 158 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0126

📊 Round 158 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0126

============================================================
🔄 Round 167 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 167 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0142
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0148
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0126

📊 Round 167 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0126

📊 Round 167 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0126

📊 Round 167 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0126

📊 Round 167 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0126

============================================================
🔄 Round 175 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 175 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0145
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0143
============================================================


============================================================
🔄 Round 176 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 176 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0147
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0055
============================================================


============================================================
🔄 Round 177 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 177 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0139
   Val:   Loss=0.0736, RMSE=0.2712, R²=0.0191
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0126

📊 Round 177 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0126

📊 Round 177 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0126

============================================================
🔄 Round 181 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 181 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0151
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0155
============================================================


============================================================
🔄 Round 183 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 183 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2857, R²=0.0150
   Val:   Loss=0.0751, RMSE=0.2741, R²=0.0151
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0126

============================================================
🔄 Round 185 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 185 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0159
   Val:   Loss=0.0826, RMSE=0.2873, R²=0.0121
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0126

============================================================
🔄 Round 187 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 187 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0141
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0193
============================================================


============================================================
🔄 Round 190 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 190 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0147
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0170
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0126

============================================================
🔄 Round 191 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 191 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0164
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0079
============================================================


============================================================
🔄 Round 194 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 194 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0159
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0105
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0126

============================================================
🔄 Round 197 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 197 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0164
   Val:   Loss=0.0849, RMSE=0.2913, R²=0.0091
============================================================


============================================================
🔄 Round 200 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 200 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0133
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0162
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0126

============================================================
🔄 Round 202 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 202 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0190
   Val:   Loss=0.0915, RMSE=0.3025, R²=0.0017
============================================================


============================================================
🔄 Round 203 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 203 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0135
   Val:   Loss=0.0740, RMSE=0.2721, R²=0.0166
============================================================


============================================================
🔄 Round 204 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 204 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0146
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0126
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0127

============================================================
🔄 Round 205 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 205 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0129
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0216
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0126

============================================================
🔄 Round 208 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 208 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0141
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0117
============================================================


============================================================
🔄 Round 210 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 210 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0148
   Val:   Loss=0.0811, RMSE=0.2847, R²=0.0151
============================================================


============================================================
🔄 Round 212 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 212 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0170
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0065
============================================================


============================================================
🔄 Round 213 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 213 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0142
   Val:   Loss=0.0730, RMSE=0.2701, R²=0.0155
============================================================


============================================================
🔄 Round 214 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 214 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0164
   Val:   Loss=0.0855, RMSE=0.2925, R²=0.0097
============================================================


📊 Round 214 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0127

============================================================
🔄 Round 215 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0673 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0673, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0673, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0673, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0673, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0674, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0673)

============================================================
📊 Round 215 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0148
   Val:   Loss=0.0673, RMSE=0.2595, R²=0.0112
============================================================


============================================================
🔄 Round 216 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 216 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0157
   Val:   Loss=0.0797, RMSE=0.2822, R²=0.0029
============================================================


📊 Round 216 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0128

============================================================
🔄 Round 217 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 217 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0171
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0076
============================================================


============================================================
🔄 Round 218 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 218 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0164
   Val:   Loss=0.0769, RMSE=0.2774, R²=0.0095
============================================================


============================================================
🔄 Round 219 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 219 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0127
   Val:   Loss=0.0709, RMSE=0.2663, R²=0.0203
============================================================


============================================================
🔄 Round 221 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 221 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0141
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0195
============================================================


📊 Round 221 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0128

📊 Round 221 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0128

📊 Round 221 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0128

============================================================
🔄 Round 225 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 225 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0141
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0202
============================================================


📊 Round 225 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0128

============================================================
🔄 Round 227 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 227 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0144
   Val:   Loss=0.0797, RMSE=0.2822, R²=0.0165
============================================================


📊 Round 227 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0128

============================================================
🔄 Round 228 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 228 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0149
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0049
============================================================


📊 Round 228 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0128

📊 Round 228 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0128

============================================================
🔄 Round 232 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 232 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0140
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0019
============================================================


📊 Round 232 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

============================================================
🔄 Round 237 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0658 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0658, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0658, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0658, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0658, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0658, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0658)

============================================================
📊 Round 237 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0149
   Val:   Loss=0.0658, RMSE=0.2564, R²=0.0022
============================================================


============================================================
🔄 Round 239 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 239 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0190
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0018
============================================================


📊 Round 239 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

============================================================
🔄 Round 241 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 241 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0151
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0160
============================================================


============================================================
🔄 Round 243 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 243 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0134
   Val:   Loss=0.0738, RMSE=0.2717, R²=-0.0208
============================================================


============================================================
🔄 Round 244 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 244 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0147
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0176
============================================================


============================================================
🔄 Round 245 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 245 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0164
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0080
============================================================


📊 Round 245 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0128

============================================================
🔄 Round 246 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 246 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0121
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0275
============================================================


============================================================
🔄 Round 247 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 247 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0138
   Val:   Loss=0.0739, RMSE=0.2719, R²=0.0033
============================================================


📊 Round 247 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

📊 Round 247 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0128

============================================================
🔄 Round 252 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 252 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2813, R²=0.0151
   Val:   Loss=0.0851, RMSE=0.2916, R²=0.0119
============================================================


============================================================
🔄 Round 253 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 253 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0148
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0105
============================================================


============================================================
🔄 Round 254 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0692 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0692, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0692, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0692, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0692, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0693, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0692)

============================================================
📊 Round 254 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0138
   Val:   Loss=0.0692, RMSE=0.2631, R²=0.0188
============================================================


============================================================
🔄 Round 256 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0659 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0659, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0659, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0659, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0659, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0659, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0659)

============================================================
📊 Round 256 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0148
   Val:   Loss=0.0659, RMSE=0.2567, R²=0.0138
============================================================


📊 Round 256 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0128

📊 Round 256 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0128

============================================================
🔄 Round 258 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 258 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0155
   Val:   Loss=0.0727, RMSE=0.2696, R²=0.0108
============================================================


📊 Round 258 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0128

============================================================
🔄 Round 259 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 259 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0143
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0182
============================================================


============================================================
🔄 Round 260 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 260 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2803, R²=0.0165
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0096
============================================================


📊 Round 260 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0128

============================================================
🔄 Round 262 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 262 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0134
   Val:   Loss=0.0787, RMSE=0.2804, R²=-0.0003
============================================================


📊 Round 262 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0128

============================================================
🔄 Round 263 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 263 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0146
   Val:   Loss=0.0788, RMSE=0.2808, R²=0.0106
============================================================


📊 Round 263 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0128

============================================================
🔄 Round 264 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 264 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0133
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0117
============================================================


============================================================
🔄 Round 265 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 265 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2813, R²=0.0130
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0223
============================================================


📊 Round 265 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0128

📊 Round 265 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0127

📊 Round 265 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0127

============================================================
🔄 Round 270 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0687 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0687, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0687, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0687, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0687, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0687, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0687)

============================================================
📊 Round 270 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0150
   Val:   Loss=0.0687, RMSE=0.2622, R²=0.0165
============================================================


============================================================
🔄 Round 274 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 274 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0128
   Val:   Loss=0.0730, RMSE=0.2701, R²=0.0232
============================================================


============================================================
🔄 Round 276 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0697 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0697, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0697, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0697, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0697, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0697)

============================================================
📊 Round 276 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0156
   Val:   Loss=0.0697, RMSE=0.2640, R²=0.0135
============================================================


📊 Round 276 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0128

📊 Round 276 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0128

📊 Round 276 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0128

============================================================
🔄 Round 279 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 279 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0171
   Val:   Loss=0.0834, RMSE=0.2889, R²=0.0053
============================================================


============================================================
🔄 Round 280 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 280 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0163
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0113
============================================================


📊 Round 280 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0128

📊 Round 280 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0128

============================================================
🔄 Round 282 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 282 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0140
   Val:   Loss=0.0752, RMSE=0.2742, R²=0.0125
============================================================


============================================================
🔄 Round 283 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 283 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0151
   Val:   Loss=0.0738, RMSE=0.2716, R²=0.0116
============================================================


📊 Round 283 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0128

📊 Round 283 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0128

============================================================
🔄 Round 286 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 286 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0134
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0210
============================================================


📊 Round 286 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0128

📊 Round 286 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

📊 Round 286 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

📊 Round 286 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

============================================================
🔄 Round 294 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 294 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0155
   Val:   Loss=0.0863, RMSE=0.2937, R²=0.0119
============================================================


📊 Round 294 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

📊 Round 294 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0128

============================================================
🔄 Round 296 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 296 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0167
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0069
============================================================


📊 Round 296 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0128

📊 Round 296 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0128

============================================================
🔄 Round 302 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 302 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0155
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0090
============================================================


📊 Round 302 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0128

📊 Round 302 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

📊 Round 302 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

============================================================
🔄 Round 305 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 305 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0123
   Val:   Loss=0.0914, RMSE=0.3023, R²=0.0228
============================================================


📊 Round 305 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

============================================================
🔄 Round 306 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 306 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0152
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0051
============================================================


============================================================
🔄 Round 309 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 309 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0152
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0025
============================================================


📊 Round 309 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0128

============================================================
🔄 Round 311 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 311 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0132
   Val:   Loss=0.0861, RMSE=0.2935, R²=0.0194
============================================================


📊 Round 311 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0127

============================================================
🔄 Round 312 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 312 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0160
   Val:   Loss=0.0741, RMSE=0.2721, R²=0.0102
============================================================


📊 Round 312 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0128

📊 Round 312 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0127

📊 Round 312 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0127

============================================================
🔄 Round 320 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 320 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0129
   Val:   Loss=0.0760, RMSE=0.2756, R²=-0.0262
============================================================


📊 Round 320 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0128

📊 Round 320 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0128

📊 Round 320 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0128

============================================================
🔄 Round 325 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 325 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0157
   Val:   Loss=0.0908, RMSE=0.3013, R²=0.0142
============================================================


📊 Round 325 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0128

============================================================
🔄 Round 327 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 327 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0145
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0008
============================================================


📊 Round 327 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

============================================================
🔄 Round 328 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 328 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0142
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0102
============================================================


📊 Round 328 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

📊 Round 328 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

============================================================
🔄 Round 334 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 334 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0150
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0166
============================================================


📊 Round 334 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

📊 Round 334 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

📊 Round 334 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0130

============================================================
🔄 Round 339 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 339 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0133
   Val:   Loss=0.0756, RMSE=0.2749, R²=0.0204
============================================================


📊 Round 339 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0130

============================================================
🔄 Round 341 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0687 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0687, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0687, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0687, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0687, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0688, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0687)

============================================================
📊 Round 341 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0142
   Val:   Loss=0.0687, RMSE=0.2621, R²=0.0034
============================================================


📊 Round 341 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

============================================================
🔄 Round 342 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 342 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0151
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0167
============================================================


============================================================
🔄 Round 345 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 345 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0149
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0069
============================================================


📊 Round 345 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0130

============================================================
🔄 Round 346 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 346 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0165
   Val:   Loss=0.0771, RMSE=0.2776, R²=-0.0081
============================================================


📊 Round 346 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0130

📊 Round 346 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0130

📊 Round 346 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0130

============================================================
🔄 Round 352 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 352 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0157
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0049
============================================================


============================================================
🔄 Round 353 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 353 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0134
   Val:   Loss=0.0742, RMSE=0.2725, R²=0.0134
============================================================


============================================================
🔄 Round 354 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 354 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0155
   Val:   Loss=0.0733, RMSE=0.2707, R²=0.0128
============================================================


📊 Round 354 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

📊 Round 354 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

📊 Round 354 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

============================================================
🔄 Round 360 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0689 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0689, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0689, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0689, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0689, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0689, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0689)

============================================================
📊 Round 360 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0151
   Val:   Loss=0.0689, RMSE=0.2624, R²=0.0169
============================================================


============================================================
🔄 Round 361 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 361 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0168
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0072
============================================================


📊 Round 361 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

============================================================
🔄 Round 362 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 362 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0151
   Val:   Loss=0.0747, RMSE=0.2732, R²=0.0060
============================================================


============================================================
🔄 Round 363 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 363 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0148
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0147
============================================================


📊 Round 363 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

📊 Round 363 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

📊 Round 363 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

============================================================
🔄 Round 367 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 367 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0159
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0136
============================================================


📊 Round 367 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

📊 Round 367 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

============================================================
🔄 Round 370 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 370 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0162
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0094
============================================================


============================================================
🔄 Round 372 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 372 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0146
   Val:   Loss=0.0872, RMSE=0.2953, R²=0.0175
============================================================


📊 Round 372 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

============================================================
🔄 Round 375 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 375 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=0.0132
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0139
============================================================


📊 Round 375 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

============================================================
🔄 Round 379 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 379 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0149
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0165
============================================================


============================================================
🔄 Round 380 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 380 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0148
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0179
============================================================


📊 Round 380 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

📊 Round 380 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

============================================================
🔄 Round 383 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 383 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0166
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0005
============================================================


📊 Round 383 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

============================================================
🔄 Round 385 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 385 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0171
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0080
============================================================


📊 Round 385 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

============================================================
🔄 Round 386 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 386 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0162
   Val:   Loss=0.0785, RMSE=0.2803, R²=0.0105
============================================================


============================================================
🔄 Round 387 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 387 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=0.0163
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0113
============================================================


📊 Round 387 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

📊 Round 387 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

📊 Round 387 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0130

============================================================
🔄 Round 392 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 392 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0158
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0119
============================================================


📊 Round 392 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

============================================================
🔄 Round 397 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 397 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0146
   Val:   Loss=0.0740, RMSE=0.2721, R²=0.0187
============================================================


📊 Round 397 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

📊 Round 397 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

============================================================
🔄 Round 402 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0697 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0697, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0697, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0697, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0698, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0697)

============================================================
📊 Round 402 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0133
   Val:   Loss=0.0697, RMSE=0.2639, R²=0.0015
============================================================


============================================================
🔄 Round 403 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 403 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0150
   Val:   Loss=0.0725, RMSE=0.2693, R²=0.0103
============================================================


📊 Round 403 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

============================================================
🔄 Round 404 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0694 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0694, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0694, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0694, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0694, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0695, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0694)

============================================================
📊 Round 404 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=0.0145
   Val:   Loss=0.0694, RMSE=0.2635, R²=0.0162
============================================================


📊 Round 404 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0130

============================================================
🔄 Round 406 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 406 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0141
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0174
============================================================


📊 Round 406 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0130

============================================================
🔄 Round 410 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 410 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0164
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0114
============================================================


============================================================
🔄 Round 413 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 413 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0164
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0111
============================================================


📊 Round 413 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0128

============================================================
🔄 Round 415 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 415 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0162
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0123
============================================================


============================================================
🔄 Round 417 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 417 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0108
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0034
============================================================


📊 Round 417 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0128

============================================================
🔄 Round 418 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 418 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0167
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0081
============================================================


============================================================
🔄 Round 420 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 420 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0145
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0013
============================================================


📊 Round 420 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0128

📊 Round 420 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0128

============================================================
🔄 Round 423 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 423 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0155
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0148
============================================================


📊 Round 423 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

============================================================
🔄 Round 424 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 424 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0131
   Val:   Loss=0.0787, RMSE=0.2806, R²=0.0213
============================================================


📊 Round 424 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

============================================================
🔄 Round 425 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 425 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0153
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0077
============================================================


📊 Round 425 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

📊 Round 425 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

📊 Round 425 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

============================================================
🔄 Round 430 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 430 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0128
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0261
============================================================


============================================================
🔄 Round 431 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 431 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0159
   Val:   Loss=0.0893, RMSE=0.2988, R²=0.0127
============================================================


📊 Round 431 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

📊 Round 431 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

============================================================
🔄 Round 437 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 437 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0165
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0050
============================================================


📊 Round 437 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

📊 Round 437 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

============================================================
🔄 Round 442 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 442 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0126
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0201
============================================================


📊 Round 442 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

============================================================
🔄 Round 443 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 443 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0156
   Val:   Loss=0.0830, RMSE=0.2882, R²=0.0108
============================================================


📊 Round 443 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0128

============================================================
🔄 Round 445 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 445 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0130
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0162
============================================================


============================================================
🔄 Round 446 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 446 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0170
   Val:   Loss=0.0714, RMSE=0.2671, R²=-0.0006
============================================================


📊 Round 446 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0128

📊 Round 446 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0128

📊 Round 446 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0128

============================================================
🔄 Round 450 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 450 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0143
   Val:   Loss=0.0912, RMSE=0.3019, R²=0.0158
============================================================


============================================================
🔄 Round 453 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 453 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0155
   Val:   Loss=0.0860, RMSE=0.2932, R²=0.0111
============================================================


============================================================
🔄 Round 455 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 455 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0166
   Val:   Loss=0.0764, RMSE=0.2763, R²=0.0091
============================================================


📊 Round 455 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0128

📊 Round 455 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0128

============================================================
🔄 Round 460 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 460 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0139
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0062
============================================================


📊 Round 460 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0128

============================================================
🔄 Round 461 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 461 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0162
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0035
============================================================


📊 Round 461 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0128

📊 Round 461 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0127

📊 Round 461 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0128

============================================================
🔄 Round 467 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 467 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0150
   Val:   Loss=0.0785, RMSE=0.2801, R²=0.0039
============================================================


📊 Round 467 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0127

📊 Round 467 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0127

📊 Round 467 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0127

============================================================
🔄 Round 471 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 471 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2792, R²=0.0181
   Val:   Loss=0.0899, RMSE=0.2999, R²=0.0036
============================================================


📊 Round 471 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0127

============================================================
🔄 Round 473 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 473 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0150
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0101
============================================================


📊 Round 473 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0128

📊 Round 473 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0127

📊 Round 473 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0128

📊 Round 473 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0128

============================================================
🔄 Round 482 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 482 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0162
   Val:   Loss=0.0899, RMSE=0.2999, R²=0.0130
============================================================


📊 Round 482 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0128

============================================================
🔄 Round 484 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 484 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2783, R²=0.0163
   Val:   Loss=0.0918, RMSE=0.3030, R²=0.0082
============================================================


📊 Round 484 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0128

📊 Round 484 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0128

📊 Round 484 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0128

============================================================
🔄 Round 487 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 487 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0155
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0149
============================================================


📊 Round 487 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

📊 Round 487 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

============================================================
🔄 Round 490 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 490 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0170
   Val:   Loss=0.0784, RMSE=0.2799, R²=0.0086
============================================================


📊 Round 490 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

📊 Round 490 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

📊 Round 490 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

============================================================
🔄 Round 495 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 495 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0149
   Val:   Loss=0.0727, RMSE=0.2697, R²=0.0175
============================================================


📊 Round 495 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0130

📊 Round 495 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0130

📊 Round 495 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

============================================================
🔄 Round 499 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 499 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0145
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0193
============================================================


📊 Round 499 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

============================================================
🔄 Round 500 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 500 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0148
   Val:   Loss=0.0721, RMSE=0.2686, R²=0.0154
============================================================


📊 Round 500 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

📊 Round 500 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

📊 Round 500 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

============================================================
🔄 Round 504 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 504 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0122
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0107
============================================================


============================================================
🔄 Round 506 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 506 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0168
   Val:   Loss=0.0844, RMSE=0.2904, R²=0.0035
============================================================


📊 Round 506 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

============================================================
🔄 Round 510 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 510 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0161
   Val:   Loss=0.0713, RMSE=0.2670, R²=0.0084
============================================================


============================================================
🔄 Round 511 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 511 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0158
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0141
============================================================


📊 Round 511 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0130

============================================================
🔄 Round 512 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 512 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0170
   Val:   Loss=0.0884, RMSE=0.2972, R²=0.0102
============================================================


📊 Round 512 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0130

============================================================
🔄 Round 513 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0712 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 513 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0152
   Val:   Loss=0.0712, RMSE=0.2668, R²=0.0147
============================================================


============================================================
🔄 Round 514 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 514 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0136
   Val:   Loss=0.0723, RMSE=0.2688, R²=0.0243
============================================================


📊 Round 514 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

============================================================
🔄 Round 515 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 515 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0151
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0121
============================================================


📊 Round 515 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

============================================================
🔄 Round 516 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 516 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0153
   Val:   Loss=0.0920, RMSE=0.3034, R²=0.0115
============================================================


📊 Round 516 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

============================================================
🔄 Round 518 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 518 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0172
   Val:   Loss=0.0722, RMSE=0.2687, R²=-0.0036
============================================================


📊 Round 518 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

📊 Round 518 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

📊 Round 518 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

============================================================
🔄 Round 523 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 523 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0161
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0125
============================================================


📊 Round 523 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

============================================================
🔄 Round 525 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 525 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0172
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0077
============================================================


============================================================
🔄 Round 526 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 526 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0162
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0117
============================================================


📊 Round 526 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0130

📊 Round 526 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0130

📊 Round 526 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0130

============================================================
🔄 Round 531 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 531 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0165
   Val:   Loss=0.0763, RMSE=0.2761, R²=0.0060
============================================================


============================================================
🔄 Round 534 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 534 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0162
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0126
============================================================


============================================================
🔄 Round 536 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 536 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0162
   Val:   Loss=0.0906, RMSE=0.3010, R²=0.0037
============================================================


📊 Round 536 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0130

============================================================
🔄 Round 537 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 537 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0125
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0199
============================================================


============================================================
🔄 Round 539 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 539 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0151
   Val:   Loss=0.0767, RMSE=0.2769, R²=-0.0001
============================================================


📊 Round 539 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0131

📊 Round 539 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0131

============================================================
🔄 Round 542 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 542 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=0.0146
   Val:   Loss=0.0882, RMSE=0.2969, R²=-0.0030
============================================================


📊 Round 542 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0131

============================================================
🔄 Round 543 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 543 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0131
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0055
============================================================


📊 Round 543 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0131

📊 Round 543 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0131

============================================================
🔄 Round 547 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 547 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0176
   Val:   Loss=0.0737, RMSE=0.2715, R²=-0.0058
============================================================


============================================================
🔄 Round 550 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 550 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0141
   Val:   Loss=0.0765, RMSE=0.2765, R²=0.0168
============================================================


📊 Round 550 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0131

============================================================
🔄 Round 553 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0933, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 553 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0148
   Val:   Loss=0.0933, RMSE=0.3055, R²=0.0149
============================================================


============================================================
🔄 Round 554 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 554 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0167
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0095
============================================================


============================================================
🔄 Round 555 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 555 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0122
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0277
============================================================


📊 Round 555 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0131

📊 Round 555 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0131

============================================================
🔄 Round 560 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 560 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0162
   Val:   Loss=0.0830, RMSE=0.2880, R²=0.0006
============================================================


📊 Round 560 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0131

============================================================
🔄 Round 561 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 561 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2835, R²=0.0158
   Val:   Loss=0.0802, RMSE=0.2831, R²=0.0150
============================================================


============================================================
🔄 Round 562 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 562 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0180
   Val:   Loss=0.0873, RMSE=0.2955, R²=0.0049
============================================================


============================================================
🔄 Round 564 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 564 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0164
   Val:   Loss=0.0826, RMSE=0.2875, R²=0.0119
============================================================


============================================================
🔄 Round 566 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 566 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0163
   Val:   Loss=0.0798, RMSE=0.2826, R²=0.0129
============================================================


============================================================
🔄 Round 569 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 569 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0152
   Val:   Loss=0.0844, RMSE=0.2904, R²=0.0121
============================================================


📊 Round 569 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0131

📊 Round 569 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0131

============================================================
🔄 Round 574 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 574 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0192
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0033
============================================================


📊 Round 574 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0131

============================================================
🔄 Round 577 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 577 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0159
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0144
============================================================


============================================================
🔄 Round 578 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 578 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0164
   Val:   Loss=0.0733, RMSE=0.2707, R²=0.0054
============================================================


📊 Round 578 Test Metrics:
   Loss: 0.0774, RMSE: 0.2781, MAE: 0.2383, R²: 0.0131

============================================================
🔄 Round 579 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 579 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0147
   Val:   Loss=0.0866, RMSE=0.2942, R²=0.0157
============================================================


============================================================
🔄 Round 580 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 580 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0153
   Val:   Loss=0.0752, RMSE=0.2743, R²=0.0171
============================================================


📊 Round 580 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0131

============================================================
🔄 Round 581 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 581 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0118
   Val:   Loss=0.0866, RMSE=0.2942, R²=0.0244
============================================================


📊 Round 581 Test Metrics:
   Loss: 0.0774, RMSE: 0.2781, MAE: 0.2383, R²: 0.0131

============================================================
🔄 Round 582 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 582 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0143
   Val:   Loss=0.0826, RMSE=0.2873, R²=0.0177
============================================================


============================================================
🔄 Round 585 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 585 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0150
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0071
============================================================


📊 Round 585 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0131

📊 Round 585 Test Metrics:
   Loss: 0.0774, RMSE: 0.2781, MAE: 0.2383, R²: 0.0132

============================================================
🔄 Round 591 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 591 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0158
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0131
============================================================


📊 Round 591 Test Metrics:
   Loss: 0.0774, RMSE: 0.2781, MAE: 0.2382, R²: 0.0132

📊 Round 591 Test Metrics:
   Loss: 0.0774, RMSE: 0.2781, MAE: 0.2382, R²: 0.0132

============================================================
🔄 Round 594 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 594 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0149
   Val:   Loss=0.0864, RMSE=0.2940, R²=0.0086
============================================================


📊 Round 594 Test Metrics:
   Loss: 0.0774, RMSE: 0.2781, MAE: 0.2382, R²: 0.0132

============================================================
🔄 Round 597 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 597 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2790, R²=0.0140
   Val:   Loss=0.0901, RMSE=0.3001, R²=0.0208
============================================================


📊 Round 597 Test Metrics:
   Loss: 0.0774, RMSE: 0.2781, MAE: 0.2382, R²: 0.0132

============================================================
🔄 Round 600 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 600 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0131
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0258
============================================================


📊 Round 600 Test Metrics:
   Loss: 0.0774, RMSE: 0.2781, MAE: 0.2382, R²: 0.0132

============================================================
🔄 Round 605 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 605 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0165
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0123
============================================================


📊 Round 605 Test Metrics:
   Loss: 0.0774, RMSE: 0.2781, MAE: 0.2382, R²: 0.0132

============================================================
🔄 Round 606 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 606 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.0141
   Val:   Loss=0.0923, RMSE=0.3038, R²=0.0102
============================================================


📊 Round 606 Test Metrics:
   Loss: 0.0774, RMSE: 0.2781, MAE: 0.2382, R²: 0.0132

============================================================
🔄 Round 609 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 609 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0161
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0027
============================================================


📊 Round 609 Test Metrics:
   Loss: 0.0774, RMSE: 0.2781, MAE: 0.2382, R²: 0.0132

============================================================
🔄 Round 610 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 610 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0161
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0109
============================================================


============================================================
🔄 Round 612 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 612 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0140
   Val:   Loss=0.0806, RMSE=0.2840, R²=0.0211
============================================================


📊 Round 612 Test Metrics:
   Loss: 0.0774, RMSE: 0.2781, MAE: 0.2383, R²: 0.0132

📊 Round 612 Test Metrics:
   Loss: 0.0774, RMSE: 0.2781, MAE: 0.2382, R²: 0.0132

============================================================
🔄 Round 615 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 615 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0164
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0128
============================================================


📊 Round 615 Test Metrics:
   Loss: 0.0774, RMSE: 0.2781, MAE: 0.2383, R²: 0.0132

📊 Round 615 Test Metrics:
   Loss: 0.0774, RMSE: 0.2781, MAE: 0.2383, R²: 0.0132

📊 Round 615 Test Metrics:
   Loss: 0.0774, RMSE: 0.2781, MAE: 0.2382, R²: 0.0132

============================================================
🔄 Round 621 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 621 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0169
   Val:   Loss=0.0826, RMSE=0.2875, R²=0.0103
============================================================


📊 Round 621 Test Metrics:
   Loss: 0.0774, RMSE: 0.2781, MAE: 0.2383, R²: 0.0131

============================================================
🔄 Round 623 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 623 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2797, R²=0.0169
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0033
============================================================


============================================================
🔄 Round 625 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0703 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0703, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0703, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0703, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0703)

============================================================
📊 Round 625 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0160
   Val:   Loss=0.0703, RMSE=0.2652, R²=0.0142
============================================================


============================================================
🔄 Round 626 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 626 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0159
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0120
============================================================


📊 Round 626 Test Metrics:
   Loss: 0.0774, RMSE: 0.2781, MAE: 0.2382, R²: 0.0132

============================================================
🔄 Round 628 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 628 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0151
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0129
============================================================


============================================================
🔄 Round 630 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 630 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0170
   Val:   Loss=0.0752, RMSE=0.2742, R²=0.0075
============================================================


============================================================
🔄 Round 631 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 631 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0151
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0162
============================================================


📊 Round 631 Test Metrics:
   Loss: 0.0774, RMSE: 0.2781, MAE: 0.2382, R²: 0.0132

============================================================
🔄 Round 634 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 634 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0148
   Val:   Loss=0.0911, RMSE=0.3018, R²=0.0158
============================================================


📊 Round 634 Test Metrics:
   Loss: 0.0774, RMSE: 0.2781, MAE: 0.2383, R²: 0.0131

📊 Round 634 Test Metrics:
   Loss: 0.0774, RMSE: 0.2781, MAE: 0.2383, R²: 0.0131

📊 Round 634 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0131

📊 Round 634 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0130

============================================================
🔄 Round 643 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 643 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0148
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0149
============================================================


📊 Round 643 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0130

📊 Round 643 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0130

============================================================
🔄 Round 646 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 646 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0129
   Val:   Loss=0.0723, RMSE=0.2690, R²=0.0119
============================================================


============================================================
🔄 Round 647 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 647 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0135
   Val:   Loss=0.0874, RMSE=0.2957, R²=0.0223
============================================================


📊 Round 647 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

============================================================
🔄 Round 649 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 649 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0133
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0235
============================================================


📊 Round 649 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

============================================================
🔄 Round 650 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 650 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0150
   Val:   Loss=0.0725, RMSE=0.2692, R²=0.0175
============================================================


============================================================
🔄 Round 651 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 651 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0142
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0056
============================================================


📊 Round 651 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

============================================================
🔄 Round 652 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 652 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0166
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0109
============================================================


📊 Round 652 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0130

============================================================
🔄 Round 654 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 654 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0158
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0120
============================================================


============================================================
🔄 Round 655 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 655 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0145
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0155
============================================================


============================================================
🔄 Round 657 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 657 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0163
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0121
============================================================


📊 Round 657 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0130

============================================================
🔄 Round 659 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0685 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0685, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0685, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0685, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0685, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0685, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0685)

============================================================
📊 Round 659 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2885, R²=0.0156
   Val:   Loss=0.0685, RMSE=0.2617, R²=0.0158
============================================================


📊 Round 659 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0130

📊 Round 659 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0130

============================================================
🔄 Round 661 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 661 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0174
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0066
============================================================


============================================================
🔄 Round 662 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 662 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0155
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0145
============================================================


📊 Round 662 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0130

============================================================
🔄 Round 664 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 664 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0122
   Val:   Loss=0.0780, RMSE=0.2794, R²=0.0175
============================================================


📊 Round 664 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0130

============================================================
🔄 Round 665 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 665 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0142
   Val:   Loss=0.0747, RMSE=0.2732, R²=0.0179
============================================================


📊 Round 665 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0130

============================================================
🔄 Round 666 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 666 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0142
   Val:   Loss=0.0845, RMSE=0.2906, R²=0.0073
============================================================


============================================================
🔄 Round 667 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 667 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0163
   Val:   Loss=0.0886, RMSE=0.2977, R²=0.0135
============================================================


============================================================
🔄 Round 668 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 668 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0126
   Val:   Loss=0.0860, RMSE=0.2932, R²=0.0188
============================================================


============================================================
🔄 Round 672 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 672 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0142
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0122
============================================================


📊 Round 672 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0131

📊 Round 672 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0131

📊 Round 672 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0131

============================================================
🔄 Round 677 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 677 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0163
   Val:   Loss=0.0725, RMSE=0.2693, R²=0.0097
============================================================


📊 Round 677 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0131

============================================================
🔄 Round 679 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 679 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0149
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0142
============================================================


============================================================
🔄 Round 681 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 681 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0174
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0037
============================================================


📊 Round 681 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0131

📊 Round 681 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0131

📊 Round 681 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0131

============================================================
🔄 Round 686 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 686 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0146
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0175
============================================================


📊 Round 686 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0131

============================================================
🔄 Round 692 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 692 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0147
   Val:   Loss=0.0776, RMSE=0.2785, R²=0.0051
============================================================


📊 Round 692 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0131

📊 Round 692 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0131

============================================================
🔄 Round 698 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 698 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0187
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0016
============================================================


📊 Round 698 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0130

📊 Round 698 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0130

📊 Round 698 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0130

============================================================
🔄 Round 708 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 708 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0154
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0036
============================================================


📊 Round 708 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0130

============================================================
🔄 Round 710 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 710 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0171
   Val:   Loss=0.0874, RMSE=0.2957, R²=0.0103
============================================================


📊 Round 710 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0130

============================================================
🔄 Round 711 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 711 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0137
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0195
============================================================


📊 Round 711 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0130

============================================================
🔄 Round 713 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 713 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0126
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0267
============================================================


============================================================
🔄 Round 714 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 714 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0166
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0106
============================================================


============================================================
🔄 Round 715 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 715 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0148
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0247
============================================================


============================================================
🔄 Round 717 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 717 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0144
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0178
============================================================


📊 Round 717 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0130

============================================================
🔄 Round 718 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0707, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0707, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0707, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0707, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 718 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0171
   Val:   Loss=0.0707, RMSE=0.2659, R²=-0.0013
============================================================


📊 Round 718 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0131

============================================================
🔄 Round 719 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 719 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0153
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0168
============================================================


📊 Round 719 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0131

📊 Round 719 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0131

============================================================
🔄 Round 723 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 723 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0142
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0194
============================================================


📊 Round 723 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0131

📊 Round 723 Test Metrics:
   Loss: 0.0774, RMSE: 0.2781, MAE: 0.2382, R²: 0.0132

📊 Round 723 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0131

📊 Round 723 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0131

📊 Round 723 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0131

📊 Round 723 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0131

📊 Round 723 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0131

============================================================
🔄 Round 735 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 735 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0139
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0225
============================================================


============================================================
🔄 Round 736 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 736 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0166
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0050
============================================================


📊 Round 736 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0131

============================================================
🔄 Round 738 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 738 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0161
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0090
============================================================


============================================================
🔄 Round 739 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 739 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0152
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0173
============================================================


📊 Round 739 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0131

============================================================
🔄 Round 741 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 741 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=0.0148
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0165
============================================================


📊 Round 741 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0131

============================================================
🔄 Round 744 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0627 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0627, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0627, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0627, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0627, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0627, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0627)

============================================================
📊 Round 744 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0154
   Val:   Loss=0.0627, RMSE=0.2504, R²=0.0164
============================================================


📊 Round 744 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0130

============================================================
🔄 Round 747 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 747 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0138
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0230
============================================================


📊 Round 747 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0130

📊 Round 747 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0130

============================================================
🔄 Round 750 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 750 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0166
   Val:   Loss=0.0729, RMSE=0.2700, R²=0.0021
============================================================


📊 Round 750 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0131

============================================================
🔄 Round 752 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 752 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0154
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0095
============================================================


📊 Round 752 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0130

============================================================
🔄 Round 754 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 754 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0152
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0175
============================================================


📊 Round 754 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0130

============================================================
🔄 Round 755 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 755 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0152
   Val:   Loss=0.0752, RMSE=0.2743, R²=0.0172
============================================================


📊 Round 755 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0131

📊 Round 755 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0131

============================================================
🔄 Round 757 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 757 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0134
   Val:   Loss=0.0716, RMSE=0.2676, R²=0.0257
============================================================


============================================================
🔄 Round 758 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 758 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0169
   Val:   Loss=0.0887, RMSE=0.2978, R²=0.0114
============================================================


📊 Round 758 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0130

📊 Round 758 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0130

============================================================
🔄 Round 764 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 764 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0139
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0210
============================================================


📊 Round 764 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0131

============================================================
🔄 Round 767 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 767 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0157
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0158
============================================================


📊 Round 767 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0130

============================================================
🔄 Round 769 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 769 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0155
   Val:   Loss=0.0858, RMSE=0.2930, R²=0.0101
============================================================


============================================================
🔄 Round 770 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 770 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0175
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0080
============================================================


📊 Round 770 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0130

============================================================
🔄 Round 772 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 772 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0140
   Val:   Loss=0.0722, RMSE=0.2687, R²=0.0237
============================================================


============================================================
🔄 Round 773 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 773 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=0.0155
   Val:   Loss=0.0737, RMSE=0.2716, R²=0.0088
============================================================


============================================================
🔄 Round 777 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 777 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0172
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0077
============================================================


📊 Round 777 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0130

============================================================
🔄 Round 778 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 778 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2776, R²=0.0137
   Val:   Loss=0.0934, RMSE=0.3056, R²=0.0103
============================================================


📊 Round 778 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0130

============================================================
🔄 Round 780 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 780 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0185
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0119
============================================================


============================================================
🔄 Round 782 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 782 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0146
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0173
============================================================


📊 Round 782 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

============================================================
🔄 Round 784 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 784 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0174
   Val:   Loss=0.0930, RMSE=0.3050, R²=0.0021
============================================================


============================================================
🔄 Round 786 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 786 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0160
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0139
============================================================


📊 Round 786 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

============================================================
🔄 Round 787 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 787 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0172
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0089
============================================================


============================================================
🔄 Round 791 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 791 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0162
   Val:   Loss=0.0932, RMSE=0.3053, R²=0.0137
============================================================


============================================================
🔄 Round 793 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0698 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0698, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0698, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0698, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0698, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0698, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0698)

============================================================
📊 Round 793 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0134
   Val:   Loss=0.0698, RMSE=0.2641, R²=0.0241
============================================================


📊 Round 793 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

============================================================
🔄 Round 796 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 796 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0113
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0198
============================================================


============================================================
🔄 Round 797 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 797 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0162
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0124
============================================================


============================================================
🔄 Round 798 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 798 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0134
   Val:   Loss=0.0858, RMSE=0.2930, R²=0.0142
============================================================


📊 Round 798 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

============================================================
🔄 Round 800 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 800 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0152
   Val:   Loss=0.0871, RMSE=0.2952, R²=0.0139
============================================================


📊 Round 800 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0128

📊 Round 800 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

============================================================
🔄 Round 802 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 802 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0170
   Val:   Loss=0.0858, RMSE=0.2930, R²=0.0083
============================================================


📊 Round 802 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

============================================================
🔄 Round 803 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 803 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0179
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0054
============================================================


============================================================
🔄 Round 804 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 804 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0156
   Val:   Loss=0.0749, RMSE=0.2736, R²=0.0156
============================================================


📊 Round 804 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0129

============================================================
🔄 Round 806 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 806 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0160
   Val:   Loss=0.0845, RMSE=0.2906, R²=0.0054
============================================================


📊 Round 806 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2383, R²: 0.0128

❌ Client client_6 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_message:"Socket closed", grpc_status:14}"
>
