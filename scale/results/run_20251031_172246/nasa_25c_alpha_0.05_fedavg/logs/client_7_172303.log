[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3db5c7ac-0b8e-4741-9aec-128d368efe24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e38c6462-1540-49f6-bf41-fe4681aa3064
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 853ce800-1f8e-4830-843f-7c3054d2f217
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6c2ee69-6520-434a-b3aa-33555a65d023
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80fa9df3-cbb5-4bf9-bcdb-cc5e3fe3eb01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4699228f-d8b1-480f-a632-ffa05310e57b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7bd0199b-8d23-46f1-a93e-3ab8409e4e97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3b2e501-670c-4de2-b1e8-e571aaf43f54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 236cd300-7e6a-459d-bf60-b9f90eb70789
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8faf6b6c-7c39-4574-a376-30004cfb7fd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8c8a3ea-43a3-49a6-899e-2acd5fabc2f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f69dd309-5018-4b1f-97fe-f3b9142a1a4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77c52442-81ae-42a0-8e9e-8645121d150d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8f884c6-6a78-444a-bf70-7f019542c184
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c4a5bde-eaf8-4a88-9148-c68b2b20bade
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e2762cd-6029-4059-a723-929950f46595
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5e4826e-2b95-408f-8891-525e7113c124
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 712adbdb-fa7d-4150-b310-7ac42646a15b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7a82ddc-e8bf-4ea4-b01b-2da193f50e03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac6a11e4-15e6-4ce8-a61e-f1c6a0852fce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cd69595-9504-44a6-9ae8-81c03707b870
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee799f19-410d-4a2c-9cd0-50f756e44d0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d08d7f9-087f-4b70-992a-42036ba89725
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4827cd15-9f53-454b-bdeb-c283cbd4921a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70d5faec-31a0-40fd-915a-96c94272a5f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1081ced1-9ef8-4c3e-8a39-e3efbc9d0fe1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 558bedb5-725f-4ebc-bc72-d1a003c1e462
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 791e95c6-6f23-4473-aa0d-a694f62483be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9fc1a91-a3f2-40bb-8056-5a9c56acdd4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a14c6161-07ad-4a38-927a-d4759fa66d5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a49ada4d-e30a-4476-a4a4-8aea17029e98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1277b070-dadd-4107-93f9-a7ac724ffbde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60bf9a0d-a5f8-4193-a5a1-2f3b8283ae9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f355235-0512-43d4-a2c9-f9ed5bf8838a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d42ed3c2-cc6b-4899-9506-72b62bc760df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91e56848-ccf8-4895-8598-be7b0476d0ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f2a0ed6-f159-49c5-8ec8-11365dcd4822
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8e92ca9-3766-45a6-9a2a-ae20967fa42d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a14fbf34-4240-4a80-8626-b7d7a72725b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a7e16d1-946a-46d0-825f-4569cc7ac2c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb326906-9956-4caa-8d06-728a75b8eb7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e613e8c-a77f-408d-a5a1-f0c531d273d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19b1c2e7-7fc6-478a-ac22-6c44baf5400d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 857c3ae9-2c0d-4365-ad38-f3523df8bf62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b5fde72-b4be-446f-8141-a311b181a2b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f2ae5af-ba38-4706-81e1-4ad62eb2a342
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message baaec6ca-a0e4-474b-bc94-13f4f8e65030
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95b2dcd5-f2d3-45b3-bcd1-9bf391114682
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15da2410-eb75-4ae4-96f1-f654f6b1726d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67c95f8e-6fde-4b4e-8796-365d2b34ccc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 788d070d-3899-432a-a3a3-9e59f5ef47e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46806241-1ab6-4859-bd20-7ea6d64ddccd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 080d3a23-df72-4aef-b29e-55703ac51734
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86c1c636-99a8-4436-af2c-8d46c301d00d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 644ef1c5-9794-4a9d-8be8-b4d59164cc9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc5a4d96-f491-4ee4-baa9-1af4c64871da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6df058ea-d1a0-4478-9904-0a200d03d067
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d98da931-2104-4641-9a89-7e58c3c73091
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f80560b5-f82c-4ade-b402-5381f5e58271
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d49f4987-11ff-4363-9941-132c7b82e38b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1995a60e-564c-4c80-86e2-e69eee9a11a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1540e38-8538-4055-805d-ba65e06be73f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c88d7a46-b95f-40b3-ac90-ce462f76f703
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f6c1252-8403-45fd-b38e-8bef1e5d8b17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3b176d5-da0a-481f-a5e4-0b6fc9d362b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eeb6155a-f537-40c8-a85e-0ecd565393af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9617541-9f70-4d73-8855-f85faf9de2c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d13482e7-bb29-4d62-b10e-085155978609
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e268b0b-775a-4167-947c-a8401677d386
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71d3933e-4540-472f-a2bb-d9f185537ed5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a25c460-ff9c-4099-9308-6ad1ab71aed2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53576500-2d3e-4c19-b9de-85d28204c402
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 644881b4-9592-4bda-bc74-e5b4768eaa46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48282562-1e0f-4acf-b833-788c1f39786a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98c0f08d-cb60-437f-8fe5-2eb84c047b0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87d9861b-50ef-4112-b341-a9d9303e1b75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a601a451-21b7-48c9-9df9-661223d3f549
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76fd8be2-07fd-46b5-aa3e-64e3f671daa0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d3575e4-1ddc-43c4-bf8f-369c27c42819
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be23d99f-1349-4eb0-ba44-948fae15005f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3af0453-d6c0-42c3-8c49-82fc00dc2e7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80e4179c-d1bd-4e43-897a-40f505b187f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b318a4e4-9e26-42d9-8a8b-e40656603cee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49a4535a-8872-4c14-aaf0-f94f5632e4f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 371415e7-0dd4-4500-bba7-0ee1899db631
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a48686ad-bfff-404e-aee6-c8a501e7fdad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a12dc2b-ce5b-496f-ac00-85c19201168a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65e1a6dd-e838-4a43-8fb9-9dc496dcf6b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db21bb09-f663-456b-b908-f33dc3690c6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08451cfe-4d1c-4e60-9727-db4632dfc2da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f6afc12-abd1-40c1-ba44-d3af4909d399
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39b94fa6-bc96-43ac-9545-f051d14d2d35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43bf2dd0-23eb-4e0d-a128-a77848d9c77c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6aaa0ff5-ee52-42d1-919f-44b85666ab1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63227426-e98f-41a0-bb90-966c84ff42a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c81ad02-a372-482c-85e8-f6b5921e0179
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 975c637f-34e8-4b18-8b28-fd75e988bfb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c89b93a-127f-464a-9452-1aea80d9e4be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a7acb9e-edcd-4217-895e-0281011f3719
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23cef0fd-5300-47f9-9e6b-6b27d548a768
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7eeec754-fe52-4c74-b2e3-f349e8dd7adf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b6be8d3-491c-42f3-ab2e-733a8973fbc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f1fdd26-cb05-4dba-bf5d-f2adb143feb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b7111e7-2c62-48a4-b864-8a2f51efe053
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca0236ce-5f72-4c1e-bfff-4fcb96f08cf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e029abef-c1cf-4981-8f95-b2318d43323d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ba4203d-21e1-4a32-815e-eb4b8f5169bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f75eb66-1d16-4aaf-ac50-91dd3215f77d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message adebd096-d114-4ea6-aaf3-2e7d5556761e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b14fc22-effa-4222-a6ba-11c52b045cd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a37931d-f0ee-48a3-b527-cc31a1f389a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea55ba92-4733-47c0-b408-2009a295551a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc4ddde2-9f63-4d3d-b045-43ef962d279f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ed63ae9-41d4-4ce6-8d2d-68199646855f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1ffa194-472e-49af-9975-b2019604e70e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05f6107d-b89a-4d68-bab7-e4a2624d7941
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6f471d8-4ca1-4400-8a2a-65b7391330f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f4ba6bc-ff82-43aa-ae40-9575d677db5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64003de5-26dd-4d04-98cd-e08bbfe9f25d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a537cc9f-a600-43fc-a0a8-6eed677db132
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4d5ff3d-2fac-460e-8014-0c8702012ab4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9984dd1f-b53b-4622-b989-5deed4257411
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e24531de-92b8-4995-97d8-08744ae6dc84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23f55d64-41fe-4d7f-9e0a-cb38dae18f8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message add334aa-a825-43f1-aa7a-451073cbfe25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98bd10ee-2fcc-4eee-836a-f77c6dd101c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3148438d-339e-484d-a20e-640020e6429b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28ddb886-a3c3-40f0-94ab-ccb9a62dd352
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8bfbb3ca-7131-4831-87b0-bbca357a13c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4897d532-521f-4d95-b218-615e53036de0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 018ba6d9-2434-4369-bd9e-a5d994fd571a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85eb87b9-eb25-4377-8ec7-9400e375a8b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ad3825e-31c1-4fc7-af4c-73ae3d9230c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 297c7c70-85fd-4ec7-a537-958c382958b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7331c3d-3cc4-4ef2-98c8-783f0f3446d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0862130e-d5bd-469b-945f-d7a1d9fc758a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 556123b6-df44-444e-b86d-cf55d66e0710
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd0dd12a-71ab-4371-8137-d02be8a2d3d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a846397-130a-4d1d-8832-f36bd91c17bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce1ab9cc-ebe6-4cfb-abbb-af24f652fdf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4fa3e85b-1ce5-4153-a4e4-66cbd96c6105
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72537e3e-78b1-4223-878f-5e84e1d56fc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5937ea86-37ee-410b-80f4-5d27e9209a5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c2a341a-336c-416d-a778-f9b1511cfaa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b52d0fd7-478f-42b0-b59e-c9e1eac324d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a255d293-03d7-4293-a7fe-392a0262b0cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4021dd81-c1c5-499a-912e-9bc939ec5e5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54027243-8f42-4326-81ce-c76733a09ac7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48354c41-38e8-487c-adf3-893dcf93cd2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc5bc85f-3fc0-4f73-911a-f9f377969dbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aca0c392-4d21-4a12-af4b-61d958803f9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddf20492-e534-4840-b6d8-31d271462f19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1267fea-e972-4e1e-9135-6890e624f894
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a668df08-bfd5-4165-be30-51006821ecb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fcf5f05-f1b2-4e59-9bad-02f459a579bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76cf6840-9a14-4eb4-a514-a7e43310575e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a0fa2d7-3641-4538-8b67-b9a1720736b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 074d7a42-b9ad-431b-a771-a16164ebd4e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8119dd8-76eb-4798-a319-c26b0f9d39f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6858bfb-29d0-4511-93e1-5514a7386108
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a92489e5-1730-4a8f-a149-30a6156623ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 057c4b10-23f8-41c6-b668-1d4b0d3add28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dcf3042f-adc1-4c4a-9ab6-06c24f903d96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3229a9aa-317f-423c-a183-2d7e138acf5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ff69d33-5d30-4bc8-9365-d5f594abe01e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa27d962-9e10-4a41-99ac-a9647917ddd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3efede1-cb66-4a41-a03d-3d1c4e8e5efe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aee69764-f921-4b51-8663-eb2a23df03de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82a0bed7-c4d6-4748-b31c-9b47a3526922
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 467f5367-0dfe-4696-bb43-19d9493551ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0efac72d-31cc-48dd-aecd-9937283883a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d67ee06b-6758-4394-8b01-92177f3a3f31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6926ce26-5fb3-44da-a338-0ad848d3ab21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fae6c44f-ecc9-47de-9c1e-8b70d3205439
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c313c30-4966-4631-8b4f-634fc17fa93b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94045cb7-e2ca-4bf0-87b1-8f17e37e7a63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4287fc62-1998-4e70-8f44-4d35934a8653
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ce84b7a-0ae5-46ba-b50e-390bb513287e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e8c2ceb-dc4e-496f-948d-f60051250ed5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 804c3533-6e5f-4e32-a88c-2fb95efaf63b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19660af8-b0d8-46b5-8c61-115e3b1554cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fd9e4db-9250-40ec-bb1e-ce9c96285ff4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ac9c1d4-d0e4-41ef-8d9a-e226dca34c92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa647d8e-7fea-4719-b872-60475f2eace1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 007a4ee2-59ed-43ef-8c69-80695d44752a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb776e0a-54cb-4041-a5a1-7a4e32576837
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c37cd48-ecda-445b-a45c-b6cb8e76ed05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae21b996-aa2a-44a1-a4f7-3f9f82e1a32f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d713be0-decf-4aaf-a6f3-ae3a259848ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 564d5087-3eda-400a-a00d-7e88996d2389
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b125a67-c4c7-4ab4-b0ae-3d9efbfded67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3dafabd-04cb-486d-b55b-48e34444595d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f326ea0-b117-446c-acbc-7589f8409b73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a68a7a37-0cf6-4792-ae94-6fe4e1eceb09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5573a027-14ee-4d34-a629-f9c5142569a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 615fec84-4511-413d-bebb-fb49246aca30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75317fcc-b890-461f-8a1d-1d0260903352
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5063d9d2-8d38-4287-b215-87eefe7ffc4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6f079d4-ddad-4d19-a836-d2ca2ee57847
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc795e1f-7ce2-4675-8e1c-0b0f40fec413
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31a8cd27-ff10-4161-bcd6-3840faf23dd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1570764-f723-40ea-ab0c-0e19b5573913
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f950e99e-d2c0-42f2-8db8-581175d72b1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae839d55-ee8b-4357-b7b9-273b48eea6ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bf67e4f-213b-4077-a3d2-250ed83440d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 146fe997-97ff-4b60-b0cb-3fb9ea05a1f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68232fa7-3eb0-40bd-a040-1bcc62f78274
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37fc0ccb-c35b-4648-95fc-462ad470d32d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe12f3a5-4741-49af-85bf-03e8876f73e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79217a56-04c4-4286-aab5-eee760865e17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9131cd8f-7b83-42fc-9b1b-255258057173
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34fd7546-5ac6-4d68-909f-933f14134700
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ef5f1ad-74fe-40c7-b624-e88d5c15dce0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d04d14e2-e41e-4e0a-9dd5-48998bb3a59f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9317b2f1-defd-4211-9396-aa810a5c9f89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b04edae6-e9e1-4476-be5d-5cbed36049b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 134521dc-757e-4a69-a5e4-0e5dff0aea9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9265becc-4238-40ee-b530-f199c9da7604
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d29b8c5c-227d-4b3b-ba4b-72c79068a368
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52acadad-2049-413c-9bd4-3ecd277154d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9670c8f6-5405-42a4-b156-8caafc323ad2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 928f09c8-b4c1-4736-9508-9257536bde74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e38db924-8f01-4062-976e-4b3cfd36558c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6282935f-268c-4a71-b586-89ae9089b978
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c04f4f6-0f43-4772-aafa-7b00b56d1ba9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4dd50a3a-3399-4062-a5ec-12f04d841a83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60418135-6687-4bd0-8e27-feabca3a4225
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54cf367f-0401-4623-ab30-4fb3009aa98b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5079852-7acb-49d6-8dd9-aa6283e1730e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 737c4c88-e7e6-40ea-9084-63f5529fb005
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7247084c-de2e-47c0-bc52-1f9adab21954
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce1de058-74d3-4ab6-a089-5067e88bf82a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28407536-6d57-42ec-9653-1396decad2f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7139b025-3590-4830-9109-517e1d4b1397
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d271a9cb-7e62-416c-ac30-8ac59559f515
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 363b96f0-fe81-4763-b401-d566fa5af147
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f73ab58e-239e-4949-baa7-4bf01a3356c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1794a9bf-78b3-4271-bafd-7271faf82d82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 347674be-299a-4289-a14c-82fd4bf29a16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89baf8ee-c98b-46c6-845a-965feb69b036
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bd6c12d-a718-49b7-8d2a-fd6b664d5b39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fbe2572-8677-42cd-9e2d-d915c6374094
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56e2fd36-29e9-4378-b4d5-0c6320ccd622
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b96462a9-94f3-46af-b5b2-76bd64a4cc69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b19f438a-d20b-4e3c-a3d1-779d453dface
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77e6d6f7-2490-492c-b68b-74ca55499f2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68e4886e-053f-41a1-92d8-40a5828c68e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23df9658-2217-430b-8ee2-cb883648cc4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c2f13b4-d209-4999-bd0a-a96daa8e3c84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8cf762ff-d634-4c16-b947-607eabdb4689
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aba90eb0-70fc-4fef-9cbf-9762bf0a9f1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a78f4c2-4ddc-4c76-9962-5c3ccf3edfdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97e277a9-130f-4e20-b711-3ca372969748
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 524b8271-5e5a-4677-aec8-6355c42d1437
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79ea6e1e-c54e-425a-abd3-c100558eda67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c49be5a-278a-4499-ac44-3bca902b8b40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a4e0ade-2af9-40cf-9020-6d103080078f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9517633-4da2-4a52-8a86-fd3184f59b98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 356737b2-7562-418a-a374-b1f0ea2e0ac4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fb2565c-751d-47c4-aee8-0333ad07288e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9aae9b25-443b-47a8-a69b-863d8866bbbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0e1ec0e-b2ff-49c9-b727-10b27674e577
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 930fd482-5208-4cd1-a360-4198c4e9df9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84df24df-86f0-4112-a174-1bc1a46ede89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc60a80e-58c4-4982-9303-e94071a98d00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75b91c2e-59e9-437a-a6de-f62dc3dc9800
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ce3be5a-3fac-4426-b3a0-a1e4c026c778
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67d2bca5-960a-4559-8f97-c7fca54a61a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c941217-53f0-4013-95d1-d045257349d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4360bac9-e403-4519-bb23-ca472fc3294c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a6c5c0d-4b87-4452-a12d-ceab0f8bf07d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 590df248-3046-4296-98a9-9d5961e8448c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5658d54-da30-4aa1-abf9-32cd167d21be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8a5f0dd-92bf-4b85-b2cf-a9ce71a6bf1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bde4d96-c606-46d8-bd07-0ceed71528fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74732e33-ac20-47c5-acfa-5e88a61cb5e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f020ee30-abdb-459d-8ceb-f69a3dcdb61a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a841b07-b7a0-4347-811f-869d009d6315
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e9c810c-be7f-45a1-b4a6-68ebaa12cc9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 509ccb25-a6d2-4894-9984-9ad794da8496
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ff3a4c1-8836-4719-972d-19383a30c51f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8083d099-f847-4822-93bd-0b95ba7565c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17751414-611e-404f-b0de-7cfac0875847
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65d302eb-fca1-4012-9aa4-30c05b8dfd54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f939585e-fc9f-4473-8d62-01d919cee8d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24eaed38-275a-4acf-afcb-9ad3825a763a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdc928e7-3b9c-4b00-ab54-99730f5f54c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7439dee-b04f-4cec-b44a-86e8c3857f1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 006dcea0-94d1-49a0-8781-e84354f64bef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38632193-11a3-44a5-83ce-77216b1e96e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2850b7d-a90a-48be-9325-dc577665313f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1b00677-1319-4885-b460-5f1a7a009742
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c215c29e-7fe8-4fef-9010-4ea94fea1619
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1231fcd-23e9-4374-9d57-a50c11c68d93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47a984a9-b01f-4fb6-a357-3b204a56dc6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 955fcda4-fc39-44e7-9d56-d9b96dedc6e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4dfc511-77bf-49fd-b5f3-8d68d65d8c10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a9c9813-74bd-4623-a6b2-d76e7b43a40a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d994e04-187b-4028-9ca0-2963d6fc3643
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7edbbd2-bba9-45ef-a88b-03977bb92213
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 517a783a-17f1-4882-adb1-da3e5fc9c4c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3487d54e-fdc1-4235-a591-bb79f718ae92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82bfd691-af14-433c-85b5-39f61e49bdd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0368aa6-6d1b-41a0-8d20-b22a88e26cbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fd83061-dd24-4935-9e20-9d2261d99e7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff898f1b-3bb5-467a-99b1-271a4ad5d00f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e53bf05-b946-46c1-b337-36fe032054d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2453ddee-4502-4b7c-b85a-eba0550616b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0d5cbd5-70b7-4a95-a697-061a564e72ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e08526bd-0d00-499d-b385-c3983a5f5079
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b095a15d-b5d4-4e4a-8429-8d5a5b8b5381
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 822443d0-b0b7-4107-afe5-5d639f9de1d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5dc90e9b-ca2f-44cd-87b2-76efa29c66c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf65fd45-5a9a-4209-8058-10deabd23ab3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27868781-b2db-41fb-8690-04ea233d2068
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eed2ab42-a3c4-46c4-a831-d2f17cdffc65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a35d3390-0fcf-4d54-9269-8f9456454c74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c41500f-2531-44aa-bb25-67a7fdecd7bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59bcb605-e90c-4edd-a205-dbbad00a091e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4031800-77ce-4831-bd7a-64d6562ba74c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 220b5549-a689-4b00-a5c0-638fb73af424
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b9eac33-5b5f-4135-b2a0-ffd07a6acdc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ffbff20-df09-406d-bf86-45e7c7b83b58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c003f3c8-bb82-4fe4-9cf6-e65596052126
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8c0e91b-3474-445e-b011-ec1924b719e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bef3eca4-d06b-4561-9447-167565456300
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47863ff3-1e07-4f01-b5ac-4d208cad4d80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce160c5a-399c-444f-b7d8-e769f6df8960
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c9af934-a72a-4a76-85ba-d5f681933dd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d90c0aa-2633-43c5-a8e0-80c64ea6d44a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee443b69-f5f4-4b5e-93d5-6c35d3d162ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 589ae211-ba80-4a65-a375-bc8091923228
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 842147c2-3a9d-4970-946b-1383c1a7e77f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80bd77d0-70a4-49db-bd4c-0d9f1eb3ed56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3e6f08a-09db-4dd2-b1ad-940885b72cd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 747bdbf7-b6ca-4e1c-b06e-2c313e4ba83d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c241bd3d-3e4e-44da-a0ef-0677bb73ab44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be29413d-f29c-46db-a678-d18a7304a5e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c9acc58-e519-4979-825c-b34c2d9f9006
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a12aad8-4816-434c-a4f7-2e7b7793047c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 923ff647-2eb7-41ff-9d4d-f066ed8e1e87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41b155f0-afa8-48b4-a9f9-9ecbd94dc702
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b6936c2-e90c-4af0-b877-813ce8023377
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebbf3bc8-e63e-48e6-b2e9-e7d6950ceb55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2947eb1c-c19d-4c82-a334-91b5f9046fcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d56935fb-48e2-4b20-a025-0239ee72b9c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b258561-5b48-4697-89c7-79399431ed31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5a4f646-5ecb-4389-a792-ea4a391e8eb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65443347-448c-4365-96a1-5acfa6a8e22b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b104472f-c412-44a2-a9f6-0d68a415851a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4db42866-4799-4bf7-8759-16efd1f2f08c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe9b68b5-ced2-4b60-8e49-af186f0784a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22250105-a9c2-4cf1-a45d-a94af0041280
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb9f296b-520e-4f4a-904c-398571cf1da4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3b80d2a-f574-499f-b63e-858f12447ab7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 819d1a7c-4c5e-4608-a7a7-02647dc65f9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46a0b672-3822-48d6-aedb-5ff42b0c66cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d856d659-10b4-46e4-9fe1-6de8ca534b16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f707bdc-d647-4df5-bcdb-286fbea30463
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b29724c-52d7-4612-a992-250d3341e950
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f45bc4b-e3c7-4a0e-aa8f-5b0b8f40609a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b54e8bdc-e274-43e8-be82-20a3a6300eb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09c15111-3212-4d92-974c-310da18eaed2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5240037d-3b39-4536-b6b3-dd826a2d284b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f21215ad-e2f0-498b-a304-c2e64faf0d2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0e3f16c-57c2-49e8-ae39-efb95d569430
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbcfad2f-b826-40b9-bd1e-8eb9c989123f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 622456f2-bcb2-4f24-b238-5b6c1ce92968
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85ba5265-a5f6-4f15-8232-36db9ec04a3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 442b2c13-390f-4126-87b4-656354a1885f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27f37285-66ba-40b3-93dc-e8be0a24e95b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8f31c76-2f5b-424e-85bd-932dc8526a13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8365719-681d-4a64-9339-089be130b9c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5faf541-2d2a-4d39-85df-1f48227805df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b16e789-7782-4072-803d-978951b2bc48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2eb06fd-2d94-4a38-a062-16a1be0c4a66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message becd4ca1-164d-4071-a906-3c63653b267c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48a248b3-a07b-41dd-82d1-e68e9763e46a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07530391-2951-48d9-814d-c544aebcb92f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ff846c4-7dfc-4dab-a823-5e938f0174d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2409ac23-8dbd-4bc6-87e5-31ad3b2c5d0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0beec70-207f-47f5-8822-e3596232c713
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3e7c15f-7798-4089-b7c3-e449b941998e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46b6b6fc-641b-4825-b30b-65beff2621d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed189dbb-0b1f-4d68-9c67-b46eb963b7ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30053ce5-4fbe-4766-9d14-c33f8f08aabd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a710dea-6290-4465-81f0-6eb96932fa22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e960e0a6-15ff-47f4-a282-0212915fee5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fca85e3-1e26-4d58-9ee0-cbb43aa846a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fc2af5f-1950-43d4-98e4-b82473031e99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1e8ab5e-4099-41d6-bb3c-9d929d5690ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5173dbd1-a261-4a64-9cdb-32694e6a5a8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d52a8b8b-5f91-4037-b1e5-66b3636c6845
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa9dea06-5276-4d6c-a299-348090da124d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f61c78c7-2b35-4326-bada-5e501a750033
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb848e11-6e0d-48fb-af35-b736ce991120
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93bd6f1b-0c65-4c3c-96a7-d8a13fa3e7cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88ecc599-b5c1-4897-959d-556664a7644b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bee900ca-102f-45b9-b065-59728af3b583
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 790e4da2-cca5-4e47-bf49-9aa3c082de91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3da31f13-7567-4689-a4fd-a738d99b8c58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9251aa3c-cb49-48d1-9770-cb2baf20ef6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d47eb7f-3b35-4eb1-b42f-36a70f30fb3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17799bae-195e-4a53-9f11-bcf33671fffd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c85b33d4-8930-488d-94f4-e97271014a50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c048869f-5799-4a45-ad74-3f94517cba47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2be14bb9-bbc0-451f-a612-b77d07567910
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99565bc0-7dfe-4ca0-92ba-df918b096d0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf154dcd-f7d9-4bee-97fd-6c1c45837858
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ba2dc05-6c50-41ad-9473-8da70a1763f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6aace44a-7bc5-48e7-9862-940a8be46bce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96533bd4-cb93-420d-91c2-d76e13dc9151
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89cddf06-1778-4f3d-b5cb-13bfb9b9a8a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6cd3010-fa22-47f1-81dc-39779ef03c97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 654d1a63-1cb1-495f-af71-49569be9b4fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 068be841-0891-47bb-994c-ced55f0e9226
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b47ee57-fedf-4d36-9a3c-0b7a92774133
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d981fc21-0f54-47db-baae-1a5c77d831ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cdb5bbe8-19ae-40d6-98ee-565febcd17eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b329d392-43ad-4069-8d56-dd03a3d74a35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5dc0bb78-4044-4404-8a46-39627389393f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 815610e7-108c-4048-98d7-c872c734e613
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66b10ccf-6b50-4a21-9b8c-41cf1a078d69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6427a4c3-5a0d-4d30-9b09-48cbe9ddcbd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 118c0349-b7bb-47fd-b758-0787c2465704
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32e6a510-87a0-42ed-ad76-4af197274023
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcd03568-a24f-440b-a5f3-5272c138f6ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bbb4c55-300e-4c94-9bb4-e7b979d8c5f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e01c7a7-b7aa-47f0-81cf-7b4f97a095d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 413789b2-5145-4843-bcb7-bb0246dc2f99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2e02e0d-b01a-4449-9aba-d7fc61808f1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8b3e2be-0e13-4175-82c4-4e419ca82cf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23ab3246-a05d-46b1-83b5-a0e641940369
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 683d435c-26bb-4a06-ab60-ba5baf29637a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f169941b-7096-463e-af18-6f3244ea85af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e23f820-4452-4d28-9aeb-4c4e40f4cbdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0b6a6e1-ef2b-4173-9a39-ead671a70615
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 389cd7e3-197d-453c-aaed-157e59a92eef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba715c87-08df-4589-ac41-b659de3016d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9de18103-a261-4122-8d50-7ae42f6600b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3575404d-3562-4a74-9b86-ba5c1008886d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e1fed9f-d0c9-4bf3-98d8-7ba6df579ab7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a67e6f3b-602d-403e-a54a-698c8de213bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35e78bc6-aef8-416c-83e6-bbbe081e07ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5376b8a5-cdf7-439b-b82c-d42108c51e2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9184b46-0be9-49b0-ae69-c1ff16262f67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8ad8550-4b5c-4981-81bd-3fa7c9acba0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa9ada5f-c25d-439b-84ed-93c6524e1e60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bb7044f-b5f2-4d66-80ac-16743e6d66ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d3b08ca-ea3e-41ef-9f96-671548d7b3a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d967286-bf09-4b70-ab11-3616550fc3b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b950adc9-d37f-4c84-ab80-9c21f4f328d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 423baa95-93d9-4412-8994-2bf27798a8b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5062197-85d5-40ae-b310-91fb60090b52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35ffa311-326b-469c-a2c7-cf9754bf4ba4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5ab2c81-cd3e-400d-964b-80ab9ad2bc1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24b3ee99-c274-40f2-8a70-ca9f9885491a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28a33caf-d336-411c-8412-e80caa6cd47c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fbe522a-5417-4a8e-bd52-d7e540b9237b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e8c16db-4402-4d6d-a80b-88d8e86a35ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 388d71f4-4e28-4a32-994c-91ad2ce883af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef467db5-8906-42c3-a7d1-d3f439ca21dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f3e3518-798b-4da6-9daf-6f46133cccb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6c4fc59-cbb8-46d9-899e-5386f418ea0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7bfdc84c-3045-409e-b73d-f42d94a26913
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4eafb98-baef-4225-9b55-1a389531caf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5f5743a-8935-4760-a374-ed501c20c089
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b13a6710-4318-4476-95f4-2e03ac63db9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26a42717-acf8-472c-af20-d0ee7f8a03aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40d9e965-719b-4433-a6c9-5706d9fac770
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a471d54-8fff-4d86-8844-5576a24bcb8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6f9d9c3-34bd-42ed-8baa-23f105241978
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec6f44c1-0950-4a56-9ac9-110fcbaf1290
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df1065bc-d580-4f22-bb94-c0bee1545300
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2e66f10-89f7-4813-87e9-1df6ca8d4cda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 533e5148-e06d-427c-b07b-d5f40309874f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 556bab35-9bb1-4b43-9b06-45161c194c37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b743f6f-f44d-442b-b27d-7e2720182885
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7f3127e-f6c6-4b90-90c1-cab5fd902439
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c5144db-2442-48ff-a26b-b4fb92f48d9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47f8b3f3-6b24-49a1-ae01-830b9ee321ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f6d5169-3789-4d8e-803f-bd477e3e83c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e90a5537-c08a-4f1f-a90b-9dd514cfe503
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4232385f-6aea-4ef2-a9de-6f31886a99bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9eae46ac-7f52-4305-a50e-17d85504f92f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f651b6e1-a6be-43f5-9ff5-3a1b47ee1035
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 944b8193-7de2-4b06-9a78-abc223f99783
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42712c98-3f89-4aa7-b966-4d874cafdf9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bef7bd13-9a23-4b55-af9a-0ff5b58f5f58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b48a1ac1-7743-47ee-a638-cbd18138f6a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6c29628-1a13-4b0a-8541-d5474933846a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e61dadec-00a8-46e8-b972-abb7725f311f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 413b5bce-2f2a-4b22-a762-fbd0e1566ba5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdedd3a9-7568-4503-af91-af48691156f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ac17b2b-6c58-439f-b894-fe72456c680b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bb0d376-546b-4265-90b0-ff3dec5dbcde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27fc679b-9794-4993-a76f-792b61c7ed77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5159c92a-787c-4621-91d7-1c268f67a0d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bed9d51b-66f6-4122-8045-30fab1cce7c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfb78904-956e-413c-a9f5-514a499b8269
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1582866-8c9b-4152-a804-b4fd16e17ef6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0c568a2-8055-4e62-9a1e-76ed52b187d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cff11c70-37dd-4087-b79e-5c8ecf68464d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a3c9ab1-58e1-4670-9c53-6e7e985817b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3c753c8-c715-4563-8f5d-81ec857d3e42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 208277cf-9b2d-4609-adb1-6db031f55823
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c1fcf20-a429-425b-b1cb-82ee1c0199d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c02a89d-4ec8-48ec-8e42-ffac9b0b9e8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c73916fa-cc87-4942-a16a-3b008705ae18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f6d92b5-3154-43dd-a7fd-46e8e4270011
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26afd3e7-3716-45ca-9811-4edfbe478fb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d01bd392-9a9f-4a44-a681-50de219bebb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2374b3cc-cd75-46f6-9acb-3e5ab4f905b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bd03322-4158-46bc-96ad-e01e859e63dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff8fd721-3486-4070-8693-3fdf21beae8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2e92a7d-a4b8-4acb-9b9a-01db6f500032
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac74691f-a672-48f6-beef-6f8a679172b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5842abb-ecd9-4fbc-a96d-cbeabb8a4ed1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a0066e5-74b4-49fa-996b-5b4f6e03dd09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71191e1d-ff17-4346-861e-0a3e0088f5ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4390803f-04ff-4e7b-b89d-1d34acd0fdab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbc7d826-0f69-41c1-bc7b-0becfd4cab11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41c50b43-88b5-487f-827c-79b1da3aa83f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e3a2383-4e7e-4bea-9591-67f4193e520b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d497b6bd-f8fc-442b-b140-125443c47e12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 262436d7-d48c-4650-84ae-9b8a88ebe6c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c7c1074-61fc-44a4-ad5b-6d456aa9419e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a9c01a3-9f46-49d1-9da7-26e589762d80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb42b5c7-9a2d-4823-b66e-259a42def7e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 442d4081-f994-4ccb-b867-165367e1ee62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9494d38-c306-496a-8011-e179c20c59c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af8dfb36-c078-4e4d-aa41-8af3c9012143
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ff188d5-8bc5-4cad-b8bd-974fcec6206f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d429b1b-ca85-46e7-891a-b2c5c074b458
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f48cd1f-30ab-44b5-a1b8-665a520f937b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6a9b53c-f654-479a-a8b7-9747398ea09f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 969af232-d296-450f-bfb1-f156031ea5c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91715fee-ebb2-4c23-b4bb-2c3a561d1c62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb296d1c-94e6-4ccf-aab1-3c09d2820e16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3dc73c1-c9b4-4826-91a1-b4d97576acc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aaf73aa8-45ae-43c0-ba06-a4b55106f875
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a1221a3-cfe3-4116-a17f-92ebfa368669
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79cd2f54-08bb-482d-9441-57544113cc74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a3be1bb-6a64-4611-b1be-2d42ef5e6213
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cee2c7cb-409a-4d7c-8c17-f44956aca0f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13703e16-670e-40cb-b9cf-ea752fa3eead
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26d66b31-3448-4a0d-9ff9-ae4e8424e5a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd1c02a3-0363-43e4-a187-2ea730a21fe9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f500a2e-52c9-483e-bf33-e5e001b87b0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3bc3711-cec0-42c4-9d81-20101b263a80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2081f7e7-2946-4d18-8ee8-27a090751f27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 984d89d9-ca76-4f56-b2bb-2f93428daf1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9e3d6ee-61bf-4509-bdae-dfee994ae0ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 414e0562-01c1-4abd-9bb5-199aeee885e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcc64323-55aa-4890-a24d-f18e8f51ceeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5864f671-0744-4489-9d92-a935aede5c5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3668bc1e-b64a-4a13-8b44-4835ea5b9beb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b139665-3ff6-46ec-9dcf-79e30b54c562
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c290f491-5af6-417b-b90d-884f1390be32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b10c7d72-7d4d-4c9c-8ff9-c82d54cc696c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48e99843-3e12-48cd-94ae-1b1aa055f4cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3782e91b-83cf-4089-ae35-380485d2ed25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b497f9a-7907-4fe7-bdd7-f33225fd21b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9502cc34-649b-47ab-821c-788b079cb8cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b905eb66-d1d0-46b7-a829-566feaa7e1af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69ba1b8c-9d49-4997-9acf-1ecd0d13181b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0738a91f-a616-438c-9199-29a3e5f0cabf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de706c67-3fa8-4cc4-b712-b9d63a1dc6dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3fde826-9650-4960-aa47-36fa742d34be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32e841f8-987b-4528-92cf-c1faf8525d1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b41a476b-cda5-4c22-bf17-aa4aa365e70b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca9e52ff-d5ee-4aaf-b184-3024103e060f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52973d42-aefd-43a4-aee4-e2cfb87c5d7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9053554d-782a-46f5-95d8-236e5be8297c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 440cb327-efd4-4c63-b6ca-5c17cbd38141
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f921e60-2457-4351-b2fa-37eb54d79b61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 077e7097-a9fa-4522-8938-a2b51f423334
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ada51bd-d9e7-46e1-ac37-85ac81341759
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3489b116-3578-4bc9-997a-a7be4e9a1e95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a74be2fa-e87b-4e03-bf11-eede8629565d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acdccadf-7bc8-48b6-81be-059dc081dad3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbb1531b-697f-451c-819c-3e71b3325c4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bff0a4d3-2b12-4d45-904d-d43003823f25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec6419c3-3544-44d5-a458-f0ef909f2a9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56c84e64-691b-434c-bed4-0e29e51c8de7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63fa2c6f-fc86-49bf-8444-2b3f5be94bd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5d1f5ac-0915-46a8-b2e3-8897fb373465
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64a89f27-62eb-4bc7-ad1b-ce5c11d0b17b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee0f7182-5a2d-487e-a20e-e1689e06e9ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a720b99b-c0d8-4190-89fc-e9b25cf599bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2142efa6-82a1-4f60-86ce-a3e1c58dbbeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33536734-3abe-4fed-a93c-372dd10825d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b68cb87-5799-460d-989a-6913e52d2feb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4f3ab09-f7f5-45bb-b667-8a9c03d7b16b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd62d198-0c73-4cdf-8cfb-f3285d23b79f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c612333-575d-4dcf-a4ac-1056e0d59569
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e442e2c-3e98-4a05-84db-8245e95c9732
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3abb9b87-60d9-4589-8811-4c204ed60a73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad2d331e-ce30-4f62-a821-d8a8f5fa94a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4706a8c-3f1c-439b-9a54-41ebc91ec893
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f578e77c-3ab8-4075-8a70-8569dd6c807b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ee7de8e-b421-40bf-b6e6-32c5c7ba36c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c50679fe-54dc-412b-ba05-1182c8806584
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d77b4de-1482-4477-b069-3e6dc6ce5e5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7977ce0d-7749-4928-b22a-e09ec6f54f00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ee7db68-d583-46a9-bc59-89d8da4130b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2ae049b-9518-467a-b196-b1a2b383286e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcec4787-86c5-4108-bdff-51721d1eb4a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a93f9a06-0093-4cf6-8987-8bfd662131fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ed584a6-5e90-4c1f-bf1f-b58ecbf8b0d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 860b0fa1-1202-416c-8bc3-1a388a22ebdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca58120e-88fa-456d-94c3-fce0b50646c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 389d2dac-4430-40fc-a6fa-abd378e23df1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73f2aa97-0991-46d9-8b5a-96d01d8b283d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0060240-0d59-47c1-8005-64f000430a2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be10e7bd-f5d6-4967-b9c2-7c9e618d8af1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4199e7ca-8eca-4383-af9d-4154b2685aba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb33c3bb-e90f-472d-860e-e24e3744ca92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d13fe96-ce85-4578-8e2e-321146360b6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 686fe3fd-3667-4a1c-a897-8546aab1a36d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c208248b-23bc-4c10-a085-8393f45d6a04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c984047b-44ec-4ce0-b835-b05397c6bd04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3542dd7-a888-4aeb-a04c-f27cf083f11f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e195afa8-4b41-4d11-bbaf-30213ef66767
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdfe87a0-23d7-4f86-8917-aeca28b461ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a11b9e28-aed1-4d3f-aba1-ed9c2c66b570
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 783d5e63-c45c-4bc0-a7a5-23ab1053eae9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbbf77a1-1664-4c21-a1d9-57c5668a847d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e54c6296-1845-4732-bb94-8d9f8e20605f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba5f477c-a7a7-43ad-a325-133e225d5973
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49927847-68f4-4fe6-b4ef-e3a67ce55a68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8bc79cf-7c04-41d6-9844-848cd26e5c80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5196ac1c-ca4e-4f73-b421-a44a7b7e1d4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3b51648-167a-492c-a869-7bd5ec5b3c33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 986591b5-2620-44c2-8a69-e5827f294d57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a79e8350-a98a-4a1e-ad95-29c7ca42f97a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f37ab23-4ba8-4a8d-9c2f-4c777c3e1c5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12559b63-7cd9-4acd-81a8-82218b35278e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e7e4700-0293-4383-9129-23f0f89fa4d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22f36291-dc90-43ac-8f3f-463106b771eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 484b5917-466b-4c8e-a755-db02c18b2c9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61b566c0-2651-4c2b-8bfc-4a19c0912604
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4fb2dd7-62b7-4b56-a107-1f6c80284f05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6eabee5-606d-4a9b-96f4-48809929dce6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6aaeb91d-26fc-4fd1-97c9-65333a40f06e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29782f7f-d533-4892-a304-b1bfb56ec478
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8dc823e-3574-434e-a27c-9c0af0dd269a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a08a13a8-4c85-4805-9dd2-44e302fb2e3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ffddba9-a787-47b6-933e-c41d8b61c299
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12cc1440-10ed-4130-a0d5-9d75e80ed01d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a191216-5abc-4793-a628-e3063b54f5c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 473f1d34-71e3-4419-bc55-815b6dbc5b43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89f82f23-29fd-426f-9101-3cf5db9d92b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab7e59be-19a8-452f-be8f-aead3ba1c8e3
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_7
Server: localhost:8686
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_7
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_7/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_7/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_7/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_7/test_labels.txt

📊 Raw data loaded:
   Train: X=(6192, 24), y=(6192,)
   Test:  X=(1549, 24), y=(1549,)

⚠️  Limiting training data: 6192 → 800 samples
⚠️  Limiting test data: 1549 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_7 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: -0.0024

============================================================
🔄 Round 3 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0826 (↓), lr=0.001000
   • Epoch   2/100: train=0.0813, val=0.0838, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0807, val=0.0858, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0797, val=0.0851, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0791, val=0.0845, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0757, val=0.0839, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 3 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0201
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0034
============================================================


📊 Round 3 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2484, R²: -0.0015

📊 Round 3 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2484, R²: 0.0006

============================================================
🔄 Round 7 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0727 (↓), lr=0.000250
   • Epoch   2/100: train=0.0825, val=0.0727, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0823, val=0.0728, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0821, val=0.0728, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0819, val=0.0729, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0811, val=0.0730, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 7 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0120
   Val:   Loss=0.0727, RMSE=0.2696, R²=0.0057
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

============================================================
🔄 Round 10 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0815 (↓), lr=0.000063
   • Epoch   2/100: train=0.0797, val=0.0815, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0796, val=0.0815, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0795, val=0.0815, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0795, val=0.0815, patience=4/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0793, val=0.0815, patience=10/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 10 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0116
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0090
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2481, R²: 0.0031

============================================================
🔄 Round 11 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0789 (↓), lr=0.000016
   • Epoch   2/100: train=0.0804, val=0.0789, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0804, val=0.0789, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0803, val=0.0789, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0803, val=0.0789, patience=4/15, lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0803, val=0.0789, patience=10/15, lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 11 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0093
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0170
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

============================================================
🔄 Round 13 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0865 (↓), lr=0.000004
   • Epoch   2/100: train=0.0790, val=0.0866, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0790, val=0.0866, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0790, val=0.0866, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0790, val=0.0867, patience=4/15, lr=0.000004
   📉 Epoch 7: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0789, val=0.0868, patience=10/15, lr=0.000002
   📉 Epoch 15: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 13 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0108
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0097
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2480, R²: 0.0041

============================================================
🔄 Round 14 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 14 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0108
   Val:   Loss=0.0840, RMSE=0.2899, R²=0.0013
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

============================================================
🔄 Round 17 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 17 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0080
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0182
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2480, R²: 0.0041

============================================================
🔄 Round 18 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 18 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0116
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0012
============================================================


============================================================
🔄 Round 19 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 19 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0106
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0110
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2480, R²: 0.0040

📊 Round 19 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0040

============================================================
🔄 Round 22 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 22 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0080
   Val:   Loss=0.0737, RMSE=0.2714, R²=0.0119
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0040

============================================================
🔄 Round 24 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 24 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0106
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0105
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0040

📊 Round 24 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

============================================================
🔄 Round 27 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0698 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0698, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0698, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0698, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0698, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0698, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0698)

============================================================
📊 Round 27 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0098
   Val:   Loss=0.0698, RMSE=0.2641, R²=0.0148
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

📊 Round 27 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

📊 Round 27 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

📊 Round 27 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

📊 Round 27 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

============================================================
🔄 Round 34 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 34 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0106
   Val:   Loss=0.0749, RMSE=0.2736, R²=0.0111
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

============================================================
🔄 Round 36 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 36 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0121
   Val:   Loss=0.0797, RMSE=0.2822, R²=0.0050
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

📊 Round 36 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

📊 Round 36 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

============================================================
🔄 Round 41 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 41 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0099
   Val:   Loss=0.0847, RMSE=0.2911, R²=0.0081
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

📊 Round 41 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

📊 Round 41 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

📊 Round 41 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 48 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 48 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0111
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0077
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 51 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 51 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0093
   Val:   Loss=0.0850, RMSE=0.2916, R²=0.0123
============================================================


============================================================
🔄 Round 52 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 52 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0114
   Val:   Loss=0.0753, RMSE=0.2745, R²=0.0026
============================================================


============================================================
🔄 Round 53 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 53 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0096
   Val:   Loss=0.0818, RMSE=0.2859, R²=0.0059
============================================================


============================================================
🔄 Round 55 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 55 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0109
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0084
============================================================


============================================================
🔄 Round 56 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0688 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0688, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0688, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0688, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0688, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0688, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0688)

============================================================
📊 Round 56 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0088
   Val:   Loss=0.0688, RMSE=0.2623, R²=0.0190
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 57 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 57 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0112
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0043
============================================================


============================================================
🔄 Round 59 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 59 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0079
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0151
============================================================


============================================================
🔄 Round 61 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 61 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0108
   Val:   Loss=0.0759, RMSE=0.2756, R²=0.0105
============================================================


============================================================
🔄 Round 64 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 64 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0115
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0050
============================================================


============================================================
🔄 Round 65 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 65 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0111
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0014
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 66 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 66 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0078
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0077
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 67 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 67 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0083
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0077
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 68 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 68 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0109
   Val:   Loss=0.0758, RMSE=0.2754, R²=-0.0114
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 70 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 70 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0097
   Val:   Loss=0.0758, RMSE=0.2754, R²=0.0076
============================================================


============================================================
🔄 Round 71 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 71 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0123
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0012
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 73 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 73 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0111
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0097
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

============================================================
🔄 Round 74 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 74 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0082
   Val:   Loss=0.0883, RMSE=0.2972, R²=0.0168
============================================================


============================================================
🔄 Round 76 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 76 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0104
   Val:   Loss=0.0746, RMSE=0.2732, R²=0.0100
============================================================


============================================================
🔄 Round 80 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 80 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0113
   Val:   Loss=0.0780, RMSE=0.2792, R²=0.0088
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 81 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 81 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0119
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0076
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

📊 Round 81 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

============================================================
🔄 Round 84 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 84 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0132
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0000
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

📊 Round 84 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

============================================================
🔄 Round 87 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 87 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0098
   Val:   Loss=0.0709, RMSE=0.2663, R²=-0.0002
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

📊 Round 87 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

📊 Round 87 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

============================================================
🔄 Round 93 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 93 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0092
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0009
============================================================


============================================================
🔄 Round 94 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 94 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0119
   Val:   Loss=0.0742, RMSE=0.2725, R²=0.0031
============================================================


============================================================
🔄 Round 95 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 95 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0094
   Val:   Loss=0.0902, RMSE=0.3003, R²=0.0043
============================================================


============================================================
🔄 Round 96 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 96 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0106
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0120
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0036

📊 Round 96 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0036

📊 Round 96 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0036

============================================================
🔄 Round 101 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0662 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0662, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0662, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0662, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0662, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0663, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0662)

============================================================
📊 Round 101 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0087
   Val:   Loss=0.0662, RMSE=0.2573, R²=0.0126
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0036

============================================================
🔄 Round 103 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 103 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0098
   Val:   Loss=0.0792, RMSE=0.2815, R²=0.0109
============================================================


============================================================
🔄 Round 106 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 106 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0112
   Val:   Loss=0.0830, RMSE=0.2880, R²=0.0067
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

📊 Round 106 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

📊 Round 106 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

============================================================
🔄 Round 113 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 113 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0110
   Val:   Loss=0.0845, RMSE=0.2906, R²=0.0101
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0036

📊 Round 113 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0036

📊 Round 113 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0036

============================================================
🔄 Round 117 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 117 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0101
   Val:   Loss=0.0711, RMSE=0.2667, R²=-0.0012
============================================================


============================================================
🔄 Round 119 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 119 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0105
   Val:   Loss=0.0758, RMSE=0.2753, R²=-0.0157
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0035

============================================================
🔄 Round 121 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 121 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0078
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0213
============================================================


============================================================
🔄 Round 124 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 124 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0113
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0090
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0036

============================================================
🔄 Round 125 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 125 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0116
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0077
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0035

============================================================
🔄 Round 129 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 129 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0114
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0085
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0035

============================================================
🔄 Round 131 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 131 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0096
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0154
============================================================


============================================================
🔄 Round 132 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 132 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0113
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0091
============================================================


============================================================
🔄 Round 133 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 133 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0102
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0134
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0035

============================================================
🔄 Round 135 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 135 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0100
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0050
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0035

📊 Round 135 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0035

============================================================
🔄 Round 138 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 138 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0117
   Val:   Loss=0.0912, RMSE=0.3019, R²=0.0066
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0035

📊 Round 138 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0035

============================================================
🔄 Round 142 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 142 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2806, R²=0.0114
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0055
============================================================


============================================================
🔄 Round 143 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 143 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0081
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0187
============================================================


============================================================
🔄 Round 145 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 145 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0117
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0047
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0036

📊 Round 145 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0036

============================================================
🔄 Round 151 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 151 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0113
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0039
============================================================


============================================================
🔄 Round 154 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 154 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0111
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0065
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0036

📊 Round 154 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0036

============================================================
🔄 Round 159 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 159 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0124
   Val:   Loss=0.0730, RMSE=0.2701, R²=0.0043
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

📊 Round 159 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

============================================================
🔄 Round 161 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 161 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0112
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0088
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0036

============================================================
🔄 Round 163 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 163 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0096
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0160
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0036

📊 Round 163 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0036

============================================================
🔄 Round 165 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 165 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0095
   Val:   Loss=0.0723, RMSE=0.2690, R²=0.0150
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0036

📊 Round 165 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

============================================================
🔄 Round 174 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 174 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=0.0102
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0111
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0036

============================================================
🔄 Round 176 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 176 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2819, R²=0.0105
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0109
============================================================


============================================================
🔄 Round 177 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 177 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0097
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0051
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0036

============================================================
🔄 Round 178 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 178 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0107
   Val:   Loss=0.0740, RMSE=0.2720, R²=0.0065
============================================================


============================================================
🔄 Round 179 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0700 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0700, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0700, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0700, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0700)

============================================================
📊 Round 179 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0130
   Val:   Loss=0.0700, RMSE=0.2646, R²=-0.0002
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0036

============================================================
🔄 Round 183 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 183 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0112
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0064
============================================================


============================================================
🔄 Round 184 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 184 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0122
   Val:   Loss=0.0776, RMSE=0.2785, R²=0.0056
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0036

📊 Round 184 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0036

============================================================
🔄 Round 191 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 191 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0130
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0019
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0036

============================================================
🔄 Round 193 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 193 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0119
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0070
============================================================


============================================================
🔄 Round 194 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 194 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0088
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0160
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

📊 Round 194 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0036

📊 Round 194 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

📊 Round 194 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0036

============================================================
🔄 Round 201 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 201 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0109
   Val:   Loss=0.0830, RMSE=0.2882, R²=0.0001
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0036

============================================================
🔄 Round 205 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 205 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0103
   Val:   Loss=0.0880, RMSE=0.2967, R²=0.0121
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

📊 Round 205 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

============================================================
🔄 Round 207 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 207 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0125
   Val:   Loss=0.0841, RMSE=0.2899, R²=0.0043
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

📊 Round 207 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

📊 Round 207 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

📊 Round 207 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 213 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 213 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0106
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0114
============================================================


📊 Round 213 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 214 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 214 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0105
   Val:   Loss=0.0727, RMSE=0.2696, R²=0.0126
============================================================


============================================================
🔄 Round 218 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 218 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0120
   Val:   Loss=0.0873, RMSE=0.2955, R²=0.0055
============================================================


📊 Round 218 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 219 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 219 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0115
   Val:   Loss=0.0736, RMSE=0.2713, R²=0.0018
============================================================


📊 Round 219 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

📊 Round 219 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 221 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 221 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0113
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0095
============================================================


📊 Round 221 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 223 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 223 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0117
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0083
============================================================


📊 Round 223 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

📊 Round 223 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 227 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 227 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0109
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0110
============================================================


📊 Round 227 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 230 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 230 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0104
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0051
============================================================


📊 Round 230 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

============================================================
🔄 Round 233 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 233 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0100
   Val:   Loss=0.0755, RMSE=0.2749, R²=0.0106
============================================================


📊 Round 233 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

============================================================
🔄 Round 234 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 234 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0091
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0177
============================================================


📊 Round 234 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

============================================================
🔄 Round 236 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 236 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0093
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0175
============================================================


📊 Round 236 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

============================================================
🔄 Round 240 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 240 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0095
   Val:   Loss=0.0727, RMSE=0.2696, R²=0.0119
============================================================


📊 Round 240 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

============================================================
🔄 Round 242 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 242 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0101
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0104
============================================================


📊 Round 242 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

============================================================
🔄 Round 243 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 243 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0105
   Val:   Loss=0.0837, RMSE=0.2894, R²=0.0016
============================================================


📊 Round 243 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

============================================================
🔄 Round 245 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 245 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0122
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0009
============================================================


📊 Round 245 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

============================================================
🔄 Round 247 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 247 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0094
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0048
============================================================


📊 Round 247 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

============================================================
🔄 Round 248 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 248 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2829, R²=0.0100
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0061
============================================================


============================================================
🔄 Round 250 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 250 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0106
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0076
============================================================


============================================================
🔄 Round 251 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 251 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0135
   Val:   Loss=0.0811, RMSE=0.2847, R²=0.0009
============================================================


============================================================
🔄 Round 255 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0699 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0699, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0699, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0699, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 255 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0106
   Val:   Loss=0.0699, RMSE=0.2644, R²=0.0071
============================================================


📊 Round 255 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

📊 Round 255 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

📊 Round 255 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

📊 Round 255 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

📊 Round 255 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 266 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 266 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0105
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0089
============================================================


============================================================
🔄 Round 267 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 267 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0103
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0140
============================================================


============================================================
🔄 Round 268 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 268 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0129
   Val:   Loss=0.0837, RMSE=0.2894, R²=0.0020
============================================================


============================================================
🔄 Round 269 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 269 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0104
   Val:   Loss=0.0852, RMSE=0.2920, R²=0.0040
============================================================


📊 Round 269 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

============================================================
🔄 Round 273 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 273 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0117
   Val:   Loss=0.0714, RMSE=0.2672, R²=0.0070
============================================================


============================================================
🔄 Round 274 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 274 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2788, R²=0.0125
   Val:   Loss=0.0903, RMSE=0.3005, R²=0.0060
============================================================


📊 Round 274 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

============================================================
🔄 Round 276 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 276 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0102
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0124
============================================================


📊 Round 276 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

📊 Round 276 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 282 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 282 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0098
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0157
============================================================


📊 Round 282 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

📊 Round 282 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

📊 Round 282 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

📊 Round 282 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 287 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 287 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2829, R²=0.0097
   Val:   Loss=0.0811, RMSE=0.2847, R²=0.0099
============================================================


📊 Round 287 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

📊 Round 287 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

📊 Round 287 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 291 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 291 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0113
   Val:   Loss=0.0805, RMSE=0.2838, R²=0.0079
============================================================


============================================================
🔄 Round 294 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0683 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0683, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0683, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0684, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0684, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0684, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0683)

============================================================
📊 Round 294 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0119
   Val:   Loss=0.0683, RMSE=0.2614, R²=0.0066
============================================================


📊 Round 294 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

📊 Round 294 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

📊 Round 294 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

📊 Round 294 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

📊 Round 294 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 301 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 301 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0134
   Val:   Loss=0.0810, RMSE=0.2847, R²=-0.0007
============================================================


============================================================
🔄 Round 304 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0696 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0696, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0696, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0696, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0696, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0696, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0696)

============================================================
📊 Round 304 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0117
   Val:   Loss=0.0696, RMSE=0.2639, R²=0.0074
============================================================


📊 Round 304 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

📊 Round 304 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

============================================================
🔄 Round 308 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 308 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2790, R²=0.0077
   Val:   Loss=0.0899, RMSE=0.2998, R²=0.0179
============================================================


📊 Round 308 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

============================================================
🔄 Round 310 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 310 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0100
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0154
============================================================


📊 Round 310 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

============================================================
🔄 Round 313 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 313 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0060
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0268
============================================================


============================================================
🔄 Round 314 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 314 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0094
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0127
============================================================


============================================================
🔄 Round 315 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 315 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0115
   Val:   Loss=0.0743, RMSE=0.2725, R²=-0.0009
============================================================


============================================================
🔄 Round 316 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 316 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0101
   Val:   Loss=0.0822, RMSE=0.2868, R²=0.0120
============================================================


📊 Round 316 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

============================================================
🔄 Round 318 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 318 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0118
   Val:   Loss=0.0736, RMSE=0.2714, R²=0.0082
============================================================


📊 Round 318 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

============================================================
🔄 Round 320 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 320 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0110
   Val:   Loss=0.0736, RMSE=0.2713, R²=0.0116
============================================================


📊 Round 320 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

============================================================
🔄 Round 321 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 321 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0121
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0006
============================================================


📊 Round 321 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

============================================================
🔄 Round 324 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 324 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0091
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0068
============================================================


📊 Round 324 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

============================================================
🔄 Round 325 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 325 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0080
   Val:   Loss=0.0838, RMSE=0.2896, R²=0.0211
============================================================


📊 Round 325 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 327 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 327 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0149
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0026
============================================================


📊 Round 327 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

📊 Round 327 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

============================================================
🔄 Round 331 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 331 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2797, R²=0.0097
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0066
============================================================


============================================================
🔄 Round 332 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 332 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0104
   Val:   Loss=0.0894, RMSE=0.2989, R²=0.0136
============================================================


📊 Round 332 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

📊 Round 332 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

============================================================
🔄 Round 335 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 335 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0097
   Val:   Loss=0.0827, RMSE=0.2877, R²=-0.0192
============================================================


============================================================
🔄 Round 336 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 336 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0095
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0163
============================================================


📊 Round 336 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

📊 Round 336 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

============================================================
🔄 Round 342 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 342 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=0.0128
   Val:   Loss=0.0742, RMSE=0.2724, R²=0.0009
============================================================


📊 Round 342 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

📊 Round 342 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0040

============================================================
🔄 Round 346 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 346 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0093
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0008
============================================================


============================================================
🔄 Round 348 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 348 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0115
   Val:   Loss=0.0859, RMSE=0.2932, R²=0.0009
============================================================


============================================================
🔄 Round 350 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 350 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0113
   Val:   Loss=0.0797, RMSE=0.2822, R²=0.0106
============================================================


============================================================
🔄 Round 351 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 351 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0109
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0099
============================================================


============================================================
🔄 Round 352 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 352 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0091
   Val:   Loss=0.0893, RMSE=0.2988, R²=0.0122
============================================================


📊 Round 352 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

============================================================
🔄 Round 353 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 353 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0121
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0101
============================================================


============================================================
🔄 Round 355 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 355 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0123
   Val:   Loss=0.0733, RMSE=0.2708, R²=0.0057
============================================================


============================================================
🔄 Round 357 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 357 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0100
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0114
============================================================


📊 Round 357 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

📊 Round 357 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 359 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 359 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0104
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0145
============================================================


📊 Round 359 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 360 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 360 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0097
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0170
============================================================


============================================================
🔄 Round 362 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 362 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0105
   Val:   Loss=0.0715, RMSE=0.2674, R²=0.0130
============================================================


============================================================
🔄 Round 363 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 363 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0103
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0125
============================================================


📊 Round 363 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

============================================================
🔄 Round 364 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 364 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0114
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0084
============================================================


============================================================
🔄 Round 365 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 365 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0122
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0042
============================================================


📊 Round 365 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

📊 Round 365 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

📊 Round 365 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

📊 Round 365 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 379 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 379 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0110
   Val:   Loss=0.0862, RMSE=0.2935, R²=0.0065
============================================================


📊 Round 379 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

📊 Round 379 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 383 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 383 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0118
   Val:   Loss=0.0792, RMSE=0.2813, R²=0.0078
============================================================


============================================================
🔄 Round 384 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 384 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0116
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0070
============================================================


============================================================
🔄 Round 385 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 385 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0110
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0121
============================================================


📊 Round 385 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

============================================================
🔄 Round 389 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 389 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2810, R²=0.0068
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0101
============================================================


📊 Round 389 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

📊 Round 389 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

============================================================
🔄 Round 391 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 391 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0111
   Val:   Loss=0.0758, RMSE=0.2753, R²=-0.0434
============================================================


📊 Round 391 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

📊 Round 391 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

============================================================
🔄 Round 393 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0677 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0677, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0677, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0677, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0677, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0678, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0677)

============================================================
📊 Round 393 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0104
   Val:   Loss=0.0677, RMSE=0.2602, R²=0.0097
============================================================


============================================================
🔄 Round 395 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 395 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0113
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0096
============================================================


============================================================
🔄 Round 396 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 396 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0124
   Val:   Loss=0.0834, RMSE=0.2889, R²=0.0069
============================================================


📊 Round 396 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

📊 Round 396 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

============================================================
🔄 Round 401 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 401 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0110
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0072
============================================================


📊 Round 401 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

📊 Round 401 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

============================================================
🔄 Round 403 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 403 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0102
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0124
============================================================


============================================================
🔄 Round 405 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 405 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0096
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0021
============================================================


📊 Round 405 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

📊 Round 405 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

📊 Round 405 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

📊 Round 405 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

============================================================
🔄 Round 409 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 409 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0102
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0130
============================================================


📊 Round 409 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

📊 Round 409 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

📊 Round 409 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

📊 Round 409 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

============================================================
🔄 Round 417 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 417 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0128
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0026
============================================================


📊 Round 417 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

============================================================
🔄 Round 419 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 419 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0106
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0131
============================================================


============================================================
🔄 Round 420 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 420 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0067
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0278
============================================================


============================================================
🔄 Round 422 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 422 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0108
   Val:   Loss=0.0759, RMSE=0.2754, R²=0.0106
============================================================


📊 Round 422 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

============================================================
🔄 Round 423 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 423 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0104
   Val:   Loss=0.0735, RMSE=0.2712, R²=0.0077
============================================================


============================================================
🔄 Round 424 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 424 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=0.0113
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0107
============================================================


============================================================
🔄 Round 425 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 425 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0100
   Val:   Loss=0.0775, RMSE=0.2783, R²=0.0111
============================================================


============================================================
🔄 Round 426 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 426 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0092
   Val:   Loss=0.0840, RMSE=0.2899, R²=0.0182
============================================================


📊 Round 426 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

📊 Round 426 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

📊 Round 426 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 433 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 433 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0113
   Val:   Loss=0.0939, RMSE=0.3065, R²=0.0104
============================================================


📊 Round 433 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

📊 Round 433 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

============================================================
🔄 Round 436 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 436 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0109
   Val:   Loss=0.0744, RMSE=0.2727, R²=0.0130
============================================================


📊 Round 436 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

📊 Round 436 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

📊 Round 436 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

📊 Round 436 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

============================================================
🔄 Round 442 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 442 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0126
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0045
============================================================


📊 Round 442 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

📊 Round 442 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

============================================================
🔄 Round 444 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 444 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0107
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0078
============================================================


📊 Round 444 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

📊 Round 444 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0036

============================================================
🔄 Round 448 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 448 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0096
   Val:   Loss=0.0756, RMSE=0.2749, R²=0.0187
============================================================


📊 Round 448 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0036

============================================================
🔄 Round 451 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 451 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0098
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0039
============================================================


============================================================
🔄 Round 452 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 452 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2781, R²=0.0110
   Val:   Loss=0.0918, RMSE=0.3030, R²=0.0122
============================================================


============================================================
🔄 Round 453 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 453 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0109
   Val:   Loss=0.0876, RMSE=0.2960, R²=0.0026
============================================================


============================================================
🔄 Round 457 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 457 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0113
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0056
============================================================


📊 Round 457 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0036

📊 Round 457 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0036

📊 Round 457 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0036

📊 Round 457 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0036

============================================================
🔄 Round 464 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 464 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0108
   Val:   Loss=0.0752, RMSE=0.2743, R²=-0.0012
============================================================


📊 Round 464 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0036

============================================================
🔄 Round 465 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 465 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0105
   Val:   Loss=0.0749, RMSE=0.2736, R²=0.0149
============================================================


============================================================
🔄 Round 466 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 466 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0131
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0015
============================================================


============================================================
🔄 Round 467 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 467 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0116
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0043
============================================================


📊 Round 467 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0035

📊 Round 467 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0035

============================================================
🔄 Round 469 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 469 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0128
   Val:   Loss=0.0852, RMSE=0.2920, R²=0.0059
============================================================


📊 Round 469 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0035

============================================================
🔄 Round 470 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 470 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0119
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0084
============================================================


============================================================
🔄 Round 471 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 471 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0071
   Val:   Loss=0.0737, RMSE=0.2715, R²=-0.0002
============================================================


📊 Round 471 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0035

============================================================
🔄 Round 472 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 472 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0112
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0108
============================================================


📊 Round 472 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0036

📊 Round 472 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0036

============================================================
🔄 Round 476 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 476 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0099
   Val:   Loss=0.0907, RMSE=0.3012, R²=0.0018
============================================================


📊 Round 476 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0035

📊 Round 476 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0035

============================================================
🔄 Round 478 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 478 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2829, R²=0.0128
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0051
============================================================


============================================================
🔄 Round 479 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 479 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0102
   Val:   Loss=0.0793, RMSE=0.2815, R²=0.0156
============================================================


📊 Round 479 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0036

============================================================
🔄 Round 480 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 480 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0117
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0082
============================================================


📊 Round 480 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0036

📊 Round 480 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0036

============================================================
🔄 Round 484 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0697 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0697, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0697, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0697, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0698, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0697)

============================================================
📊 Round 484 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0113
   Val:   Loss=0.0697, RMSE=0.2640, R²=0.0011
============================================================


📊 Round 484 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

============================================================
🔄 Round 486 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 486 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0112
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0067
============================================================


============================================================
🔄 Round 489 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 489 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0103
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0132
============================================================


============================================================
🔄 Round 491 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 491 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0104
   Val:   Loss=0.0774, RMSE=0.2781, R²=0.0130
============================================================


============================================================
🔄 Round 492 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 492 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0118
   Val:   Loss=0.0807, RMSE=0.2842, R²=0.0085
============================================================


📊 Round 492 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

📊 Round 492 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 496 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 496 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0112
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0420
============================================================


============================================================
🔄 Round 497 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 497 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0109
   Val:   Loss=0.0792, RMSE=0.2815, R²=0.0005
============================================================


📊 Round 497 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

📊 Round 497 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

============================================================
🔄 Round 500 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 500 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0087
   Val:   Loss=0.0751, RMSE=0.2741, R²=0.0032
============================================================


📊 Round 500 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

📊 Round 500 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

📊 Round 500 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

📊 Round 500 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 509 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 509 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0125
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0070
============================================================


============================================================
🔄 Round 510 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 510 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0126
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0057
============================================================


📊 Round 510 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 511 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 511 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=0.0135
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0035
============================================================


============================================================
🔄 Round 512 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 512 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0104
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0062
============================================================


============================================================
🔄 Round 513 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0699 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0699, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0699, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0699, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 513 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0098
   Val:   Loss=0.0699, RMSE=0.2644, R²=0.0178
============================================================


📊 Round 513 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

📊 Round 513 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 516 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 516 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0123
   Val:   Loss=0.0842, RMSE=0.2901, R²=0.0071
============================================================


============================================================
🔄 Round 517 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 517 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0093
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0092
============================================================


📊 Round 517 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

📊 Round 517 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 520 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 520 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0112
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0085
============================================================


📊 Round 520 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 521 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 521 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0096
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0152
============================================================


============================================================
🔄 Round 524 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 524 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0118
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0039
============================================================


============================================================
🔄 Round 525 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 525 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0132
   Val:   Loss=0.0785, RMSE=0.2801, R²=-0.0091
============================================================


📊 Round 525 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

📊 Round 525 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

📊 Round 525 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 529 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 529 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0124
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0046
============================================================


📊 Round 529 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

============================================================
🔄 Round 532 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 532 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0133
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0017
============================================================


📊 Round 532 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

============================================================
🔄 Round 536 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 536 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0106
   Val:   Loss=0.0736, RMSE=0.2712, R²=0.0141
============================================================


============================================================
🔄 Round 537 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 537 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0089
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0123
============================================================


📊 Round 537 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

============================================================
🔄 Round 539 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 539 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0138
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0139
============================================================


============================================================
🔄 Round 540 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 540 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0099
   Val:   Loss=0.0736, RMSE=0.2714, R²=0.0176
============================================================


📊 Round 540 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

============================================================
🔄 Round 542 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 542 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0105
   Val:   Loss=0.0881, RMSE=0.2968, R²=0.0136
============================================================


============================================================
🔄 Round 545 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 545 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0100
   Val:   Loss=0.0759, RMSE=0.2756, R²=0.0164
============================================================


============================================================
🔄 Round 548 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 548 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0087
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0196
============================================================


📊 Round 548 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

============================================================
🔄 Round 549 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 549 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0103
   Val:   Loss=0.0906, RMSE=0.3009, R²=0.0151
============================================================


============================================================
🔄 Round 550 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 550 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0095
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0076
============================================================


📊 Round 550 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

============================================================
🔄 Round 554 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 554 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0105
   Val:   Loss=0.0710, RMSE=0.2665, R²=0.0049
============================================================


📊 Round 554 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

============================================================
🔄 Round 556 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 556 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0096
   Val:   Loss=0.0767, RMSE=0.2770, R²=0.0180
============================================================


📊 Round 556 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

============================================================
🔄 Round 565 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 565 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0121
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0037
============================================================


============================================================
🔄 Round 566 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 566 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0102
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0160
============================================================


📊 Round 566 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0040

============================================================
🔄 Round 567 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 567 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0116
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0096
============================================================


============================================================
🔄 Round 568 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 568 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0128
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0060
============================================================


📊 Round 568 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

📊 Round 568 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0040

============================================================
🔄 Round 574 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 574 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0139
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0020
============================================================


📊 Round 574 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

============================================================
🔄 Round 575 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 575 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0126
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0045
============================================================


📊 Round 575 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0040

============================================================
🔄 Round 577 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 577 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0116
   Val:   Loss=0.0732, RMSE=0.2706, R²=0.0102
============================================================


============================================================
🔄 Round 578 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 578 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0102
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0114
============================================================


============================================================
🔄 Round 580 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 580 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0125
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0020
============================================================


📊 Round 580 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0040

============================================================
🔄 Round 583 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 583 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0117
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0103
============================================================


📊 Round 583 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2479, R²: 0.0040

📊 Round 583 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2479, R²: 0.0040

📊 Round 583 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2479, R²: 0.0040

============================================================
🔄 Round 588 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 588 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=0.0106
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0012
============================================================


📊 Round 588 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2479, R²: 0.0040

============================================================
🔄 Round 589 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 589 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0104
   Val:   Loss=0.0815, RMSE=0.2854, R²=0.0103
============================================================


📊 Round 589 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2479, R²: 0.0040

📊 Round 589 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2479, R²: 0.0041

============================================================
🔄 Round 592 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 592 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0110
   Val:   Loss=0.0775, RMSE=0.2783, R²=0.0012
============================================================


============================================================
🔄 Round 593 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 593 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0116
   Val:   Loss=0.0748, RMSE=0.2734, R²=0.0082
============================================================


📊 Round 593 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2479, R²: 0.0040

📊 Round 593 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2479, R²: 0.0040

📊 Round 593 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2479, R²: 0.0041

📊 Round 593 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2479, R²: 0.0040

============================================================
🔄 Round 599 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 599 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0106
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0129
============================================================


============================================================
🔄 Round 600 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 600 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0120
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0033
============================================================


📊 Round 600 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2479, R²: 0.0041

============================================================
🔄 Round 601 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 601 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0086
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0198
============================================================


📊 Round 601 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2479, R²: 0.0041

📊 Round 601 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2479, R²: 0.0041

📊 Round 601 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2479, R²: 0.0040

📊 Round 601 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2479, R²: 0.0041

============================================================
🔄 Round 606 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 606 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0115
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0097
============================================================


📊 Round 606 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2479, R²: 0.0041

📊 Round 606 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2479, R²: 0.0040

============================================================
🔄 Round 609 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 609 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0114
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0114
============================================================


============================================================
🔄 Round 612 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 612 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0149
   Val:   Loss=0.0747, RMSE=0.2733, R²=-0.0059
============================================================


============================================================
🔄 Round 613 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 613 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0110
   Val:   Loss=0.0751, RMSE=0.2741, R²=-0.0017
============================================================


============================================================
🔄 Round 615 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 615 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0133
   Val:   Loss=0.0784, RMSE=0.2799, R²=0.0006
============================================================


📊 Round 615 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2479, R²: 0.0040

📊 Round 615 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2479, R²: 0.0040

============================================================
🔄 Round 617 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 617 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0117
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0073
============================================================


📊 Round 617 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2479, R²: 0.0040

📊 Round 617 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0040

============================================================
🔄 Round 622 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 622 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0098
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0174
============================================================


============================================================
🔄 Round 623 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 623 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2794, R²=0.0126
   Val:   Loss=0.0890, RMSE=0.2983, R²=0.0021
============================================================


📊 Round 623 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0040

============================================================
🔄 Round 626 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 626 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0104
   Val:   Loss=0.0722, RMSE=0.2688, R²=0.0019
============================================================


============================================================
🔄 Round 627 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 627 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0099
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0153
============================================================


📊 Round 627 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2479, R²: 0.0040

============================================================
🔄 Round 630 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 630 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0101
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0122
============================================================


============================================================
🔄 Round 631 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 631 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0106
   Val:   Loss=0.0763, RMSE=0.2761, R²=0.0096
============================================================


📊 Round 631 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2479, R²: 0.0040

📊 Round 631 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2479, R²: 0.0040

📊 Round 631 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0040

============================================================
🔄 Round 637 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 637 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0115
   Val:   Loss=0.0880, RMSE=0.2966, R²=0.0103
============================================================


📊 Round 637 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

============================================================
🔄 Round 638 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 638 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0113
   Val:   Loss=0.0731, RMSE=0.2704, R²=0.0101
============================================================


============================================================
🔄 Round 639 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 639 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0126
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0032
============================================================


============================================================
🔄 Round 640 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 640 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0125
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0059
============================================================


📊 Round 640 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

============================================================
🔄 Round 644 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 644 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0125
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0078
============================================================


📊 Round 644 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

============================================================
🔄 Round 646 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 646 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=0.0118
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0075
============================================================


📊 Round 646 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

============================================================
🔄 Round 647 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 647 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0115
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0090
============================================================


📊 Round 647 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0036

📊 Round 647 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0036

============================================================
🔄 Round 650 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 650 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0119
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0090
============================================================


📊 Round 650 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

📊 Round 650 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

📊 Round 650 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

============================================================
🔄 Round 660 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 660 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0106
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0154
============================================================


📊 Round 660 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 663 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 663 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0117
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0103
============================================================


📊 Round 663 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 664 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 664 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0148
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0029
============================================================


📊 Round 664 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 665 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 665 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0116
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0098
============================================================


============================================================
🔄 Round 666 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 666 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0147
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0321
============================================================


📊 Round 666 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

📊 Round 666 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

📊 Round 666 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 672 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 672 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0105
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0090
============================================================


📊 Round 672 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 676 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 676 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0114
   Val:   Loss=0.0779, RMSE=0.2792, R²=0.0099
============================================================


📊 Round 676 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 679 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 679 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0102
   Val:   Loss=0.0778, RMSE=0.2790, R²=0.0094
============================================================


📊 Round 679 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 680 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 680 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0098
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0186
============================================================


📊 Round 680 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

📊 Round 680 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

📊 Round 680 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 683 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 683 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0120
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0083
============================================================


📊 Round 683 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 685 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 685 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0102
   Val:   Loss=0.0756, RMSE=0.2749, R²=0.0145
============================================================


============================================================
🔄 Round 688 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 688 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0126
   Val:   Loss=0.0822, RMSE=0.2866, R²=0.0015
============================================================


📊 Round 688 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

📊 Round 688 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 690 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 690 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0124
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0071
============================================================


📊 Round 690 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 692 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 692 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0103
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0054
============================================================


📊 Round 692 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

📊 Round 692 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 694 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 694 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0120
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0047
============================================================


📊 Round 694 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 695 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 695 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0118
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0069
============================================================


============================================================
🔄 Round 698 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 698 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0103
   Val:   Loss=0.0880, RMSE=0.2966, R²=0.0032
============================================================


📊 Round 698 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

📊 Round 698 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 702 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 702 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0108
   Val:   Loss=0.0732, RMSE=0.2706, R²=0.0149
============================================================


📊 Round 702 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 704 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 704 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0129
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0057
============================================================


📊 Round 704 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 707 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 707 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0107
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0127
============================================================


============================================================
🔄 Round 708 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 708 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0147
   Val:   Loss=0.0895, RMSE=0.2991, R²=-0.0028
============================================================


📊 Round 708 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

📊 Round 708 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 710 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 710 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0109
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0049
============================================================


📊 Round 710 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

============================================================
🔄 Round 712 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 712 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0117
   Val:   Loss=0.0906, RMSE=0.3010, R²=0.0108
============================================================


📊 Round 712 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

📊 Round 712 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 719 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 719 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0125
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0067
============================================================


📊 Round 719 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 720 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 720 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0108
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0075
============================================================


📊 Round 720 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

============================================================
🔄 Round 724 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 724 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0101
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0164
============================================================


📊 Round 724 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

📊 Round 724 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

============================================================
🔄 Round 729 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 729 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0104
   Val:   Loss=0.0920, RMSE=0.3034, R²=0.0149
============================================================


============================================================
🔄 Round 731 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 731 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0110
   Val:   Loss=0.0902, RMSE=0.3003, R²=0.0128
============================================================


📊 Round 731 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 732 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 732 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0122
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0092
============================================================


============================================================
🔄 Round 733 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 733 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0122
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0084
============================================================


============================================================
🔄 Round 735 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 735 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0110
   Val:   Loss=0.0737, RMSE=0.2714, R²=0.0125
============================================================


📊 Round 735 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0039

============================================================
🔄 Round 737 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 737 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0119
   Val:   Loss=0.0789, RMSE=0.2808, R²=0.0104
============================================================


============================================================
🔄 Round 739 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 739 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0096
   Val:   Loss=0.0780, RMSE=0.2794, R²=0.0131
============================================================


============================================================
🔄 Round 741 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 741 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0090
   Val:   Loss=0.0921, RMSE=0.3034, R²=0.0204
============================================================


============================================================
🔄 Round 742 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 742 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0124
   Val:   Loss=0.0907, RMSE=0.3012, R²=0.0085
============================================================


============================================================
🔄 Round 743 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 743 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0127
   Val:   Loss=0.0869, RMSE=0.2947, R²=0.0075
============================================================


============================================================
🔄 Round 744 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 744 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=0.0122
   Val:   Loss=0.0876, RMSE=0.2960, R²=0.0090
============================================================


📊 Round 744 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 745 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 745 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=0.0120
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0023
============================================================


📊 Round 745 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 746 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 746 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0105
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0102
============================================================


📊 Round 746 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 748 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 748 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0091
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0045
============================================================


============================================================
🔄 Round 749 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 749 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0119
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0016
============================================================


📊 Round 749 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

============================================================
🔄 Round 750 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 750 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0133
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0196
============================================================


📊 Round 750 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 752 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 752 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0081
   Val:   Loss=0.0757, RMSE=0.2752, R²=0.0071
============================================================


📊 Round 752 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

📊 Round 752 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 755 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 755 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0116
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0116
============================================================


📊 Round 755 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 757 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 757 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0114
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0100
============================================================


============================================================
🔄 Round 758 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 758 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0128
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0059
============================================================


============================================================
🔄 Round 760 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 760 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0095
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0167
============================================================


📊 Round 760 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 761 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 761 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0115
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0065
============================================================


📊 Round 761 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0038

============================================================
🔄 Round 763 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 763 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0114
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0116
============================================================


============================================================
🔄 Round 764 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0694 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0694, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0694, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0694, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0694, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0694, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0694)

============================================================
📊 Round 764 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0110
   Val:   Loss=0.0694, RMSE=0.2635, R²=0.0135
============================================================


============================================================
🔄 Round 765 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 765 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0125
   Val:   Loss=0.0919, RMSE=0.3031, R²=-0.0027
============================================================


============================================================
🔄 Round 766 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 766 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0103
   Val:   Loss=0.0887, RMSE=0.2979, R²=0.0140
============================================================


============================================================
🔄 Round 769 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 769 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0129
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0063
============================================================


📊 Round 769 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

============================================================
🔄 Round 771 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 771 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0106
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0113
============================================================


📊 Round 771 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

📊 Round 771 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

============================================================
🔄 Round 773 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 773 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0123
   Val:   Loss=0.0768, RMSE=0.2772, R²=0.0066
============================================================


📊 Round 773 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

============================================================
🔄 Round 774 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 774 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0115
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0073
============================================================


📊 Round 774 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

📊 Round 774 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0037

============================================================
🔄 Round 780 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 780 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0076
   Val:   Loss=0.0744, RMSE=0.2727, R²=0.0101
============================================================


📊 Round 780 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0036

📊 Round 780 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0036

============================================================
🔄 Round 783 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 783 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0087
   Val:   Loss=0.0872, RMSE=0.2953, R²=0.0223
============================================================


============================================================
🔄 Round 785 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 785 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0123
   Val:   Loss=0.0874, RMSE=0.2957, R²=0.0093
============================================================


📊 Round 785 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0036

============================================================
🔄 Round 789 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 789 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0101
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0054
============================================================


📊 Round 789 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0036

============================================================
🔄 Round 791 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 791 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0097
   Val:   Loss=0.0810, RMSE=0.2847, R²=0.0119
============================================================


============================================================
🔄 Round 792 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 792 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=0.0117
   Val:   Loss=0.0749, RMSE=0.2736, R²=0.0106
============================================================


📊 Round 792 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0035

============================================================
🔄 Round 799 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 799 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0105
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0060
============================================================


📊 Round 799 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0035

============================================================
🔄 Round 800 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0946 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0946, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0946, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0946, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0946, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0946)

============================================================
📊 Round 800 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0138
   Val:   Loss=0.0946, RMSE=0.3075, R²=0.0032
============================================================


📊 Round 800 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0035

============================================================
🔄 Round 803 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 803 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0128
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0052
============================================================


📊 Round 803 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0035

============================================================
🔄 Round 804 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 804 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0128
   Val:   Loss=0.0774, RMSE=0.2781, R²=0.0069
============================================================


============================================================
🔄 Round 805 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 805 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0132
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0059
============================================================


📊 Round 805 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0035

📊 Round 805 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2480, R²: 0.0035

❌ Client client_7 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_status:14, grpc_message:"Socket closed"}"
>
