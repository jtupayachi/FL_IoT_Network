[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d510df8-93c1-4ba1-ae6b-920e97f04cae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c22889cb-5a92-494d-8da3-64138372aae6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad81c936-a345-4ef1-8741-bf0488e277a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74ff17a7-7c8a-434f-9eb0-a09d164d65cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a87a2bf4-20ee-45cb-b71f-bd9ad2447d7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a347dcb-8dfe-43b3-80b7-9c109ca240e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91a56ca8-0df7-48d9-9e4e-932763ecdac0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0746aa14-00a8-4249-8cd6-5564d477de66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee9e9bac-6247-441f-bd28-91bf45141f98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 263c7ae9-e1a1-4805-a15b-766957909c6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4313eead-befb-49d3-8fc7-f9e76f0f7da8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d57e8f30-e14f-4b35-969e-45b0ce248634
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89fb7e79-5243-45df-b2cb-7feed36fad45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbff03d2-563f-45cb-85b6-4635b81478d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a228c264-6365-4880-9bd0-08ea0c349ffe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 681bc366-548b-4ed1-83c8-569a9c24f971
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63d707b4-5f08-4157-ac37-c6661b070e72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9708b24-f013-4b63-957f-388631eaee86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cca3c7ac-5ddc-496a-a749-9e5a907275f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef552ec9-c652-483f-a9d4-15b9530ea719
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a6ba208-773a-4124-a8cf-33973afad94d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f8af76c-a065-42bc-a1e0-654a8543c52b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d23deb5c-1f14-4fab-8309-948cd0b3934d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8fcafaf-45ed-4df4-9bc8-82e9543fa82c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b55330f8-3ea2-4b5f-987f-bafab4924392
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e70cc76f-cfba-4e76-8bdb-9a1741e90ee2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1986b86d-18a9-4ebc-9a51-336f6618d261
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcf44ea9-28d2-4790-a573-0fed30df8d19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb4f9949-556d-4740-83d4-db2f925be512
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1888ea80-7179-44fd-a639-5af945b497a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cd774d7-7c20-438a-895b-2ed8070510da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64b3f4ae-ad4f-402e-97ba-ee54bcba5403
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b18498b-51c9-4796-b390-d404525a9537
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8c82b9c-e803-4597-b757-7939f1b7a0ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c0a58f6-fb52-4cdb-b2e8-e50ea669a197
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8478d9cd-e959-4c58-971f-5f6f1a8dde1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c914444-ecc0-4bbb-8171-ef29cae810b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a28f66f-c430-4a16-b3d5-f49ea03bcb82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13476ae8-5f2c-4475-8d87-33a047b02c3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80fe6ec9-51fc-4109-98b2-4e019740caeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 336f08a1-ee5e-4331-a442-be15e8b79127
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0965356-b5de-4825-ad20-a536ad469510
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a56c056-f7b9-4b07-b6bc-2dfb1a08036d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec67cd48-a534-4d96-b814-7a929503271c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7685169a-791f-4723-adba-98e3e7a3b6a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 610b93bb-a01d-41a4-81da-a5cd829270ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01efb41f-30ac-4051-8b7d-7d4e873d3197
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fe23cdc-1c9b-42c2-a675-99e3fa593f20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a18b4243-a645-4cc6-a30e-54cc20610f79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 761d68ab-1542-4021-ad33-e4ddb8a7d309
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13a32a55-650b-4ecf-b372-a316ece516ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2b45281-4521-4771-8b42-8b05a42c0d9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ae345dd-a830-4703-a566-ba82203cca07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 383bc4b7-b3a3-4357-a057-366fc11e2fe5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2b2e877-579d-4948-93d8-aecb336e2363
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62a6e1fb-e32a-42fb-bbf5-1c3ee505abb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f18f8339-2a88-4c4c-a0b7-f15215895c5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message faf6bcd5-c939-4f01-8c1d-1f5f51f5da3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03ae1682-0ac1-455c-8d96-9df25d02c5e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c25040f-93bd-411b-a86c-6230f926a0b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6b6f14d-fa9c-4299-99dc-63509a314666
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d55e9372-0bd3-4d87-ae06-05aacf4b7ffb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b630095-a847-4094-b97f-7eeb569e9266
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80dc2ea4-3313-4711-b016-79f2458c867e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d92cf97d-879c-4b69-b482-5ac22995b7f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01d74667-ef9c-4c45-b008-1be4342880e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e7e8010-0a9c-495b-80a4-1a0e91493d50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f16a2a46-1f45-4238-9c9a-871434e72641
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fd43c72-8d23-49e2-9894-96d2a361fb63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d417c09-bf62-4b24-a1e2-16f338c40b62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfdb39da-212a-4342-a54a-7aabc30b2441
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f75a68e-095d-4ae9-bd79-0a5c15b559b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4811314-aa20-4f25-a17f-9812f12d540a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e566dce6-79fd-40a5-b44d-243b65d3474c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8cfd15e-918f-48b8-bb46-98ea41a4c373
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f36378c1-0d4b-4618-bb8f-bac4ca3ecbe2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5132b6f0-cb5c-45a0-b0e0-fdc2fe1c1836
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 794ca950-0f1e-4c25-9ebf-1f9090d8e6b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3c9099b-8c37-4f3c-85d3-e43e607e40e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db92a98b-1187-47cf-9dc4-1b963f2f847e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8788f2e4-ca42-4468-af00-d29988189f8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d47b3765-7479-45bf-b274-a13b82833bda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b14898f1-63e8-43dc-a355-dabf46c2b835
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e86838c-a0a3-4efc-a1d8-7b0e392b6b21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4704288-02cd-4037-b1f6-498119a8c4e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98667775-f18b-44e8-90c5-8b4411356b17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11587037-cd65-49eb-baf6-8c5a52dea0d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d2f010e-df4a-4638-a853-e39bf2c06713
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5a29a03-501c-4748-83b1-ce35dda5718b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcb996d4-0116-4e40-9bea-cef2a0a0dc6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bbd5849-b8a9-4cdf-ac66-b52d0a59ff60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f83e6c58-228e-4df5-809a-5bf01425ed07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84d91c2e-0fe8-44f5-8beb-8e30fffcd8be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36c01ebb-4971-47bf-8aa8-2bdd151caa54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6d70a62-8c78-4de6-bf43-673b43333d77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67d6eb7b-39dd-4bd6-b746-c6354979d324
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77141751-4d10-4d85-8b6d-ebef33d40d4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1020c02-3486-4747-89cc-0cb5eb277d7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 374047e7-af86-41c2-bdd0-bc922f70492e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed9ac572-c94d-4e56-b74e-83782dcccce9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 653ea9bd-e121-40f2-8d09-b24575cd49a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f64bf17f-cd41-454f-a200-014b92cb17a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4eda5b08-2db7-4c39-9d52-c083e73260c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27a85cfb-fbea-4f7b-b9e9-ed92caebec3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a70130a-a04f-45b3-bc66-4da607771274
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0429775b-effb-4c0b-9ee6-5d9b4f6575d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d824af7-2c21-46a0-907a-6c12fa976f36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df741164-8eb2-46f5-b75c-b2485fc5ad1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53c3fe9c-d4fc-4ed8-90f8-45ba90e6a9ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a00edbc-a299-47ef-8294-36d7dde1901f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20778512-ab54-47e3-9d19-273b81d5c0f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 743a84f7-cc3a-4124-9651-acc072d3687b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8dd775a3-72e6-4a6d-bbb7-d9608963fde7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35b82ecf-e86d-4e93-b9fb-63728de79e72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e1d0225-7896-48ed-b6fc-26615b1744fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e054a0ef-ee98-4d51-b82a-fbf421271ef3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b23798b9-554e-45a8-a7c3-284b2dad838e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 473f35fb-6191-4a57-a602-e9bdd09c2a1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5f2e266-1025-43ab-9c4d-f0ee71533c0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85306bd6-a06f-4738-91db-40556831fd44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3b3bd2d-e151-4c11-ac88-a48af2f37d2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e698357f-ca19-4ea6-893a-3703f2ec5a4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f0846f3-6f87-4553-97fc-567e0ae66011
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b012171e-67cc-4e4c-a01e-c076b17bce19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecaab896-11a8-4f21-b385-d2d3d80ffe46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbc42e2a-6304-4cfc-83a7-761c646bfb6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b838ab4c-3ce1-479e-928a-6ca75fcf4506
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63ebe7e4-b1d9-438a-bf54-d061dd2e26b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2d71ce2-a40f-497f-83a1-6cdb8fadaf0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99e92f65-0b9b-40b6-822c-ae3d1e2e8ee3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e27e3a5-86dc-4de0-9390-6266c2783b60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a65a25f-0843-4783-b409-bd4b3f995cb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2461de8e-f2f9-485c-92b3-06fcd2eeba5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e226acb-067e-486f-a859-86b352e3866a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ecdeca7-e133-439c-ad25-c9d5b40b5b4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dce20629-a6c1-4da6-9378-cc3d931465d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e53074f9-1e8b-42ed-8266-3f9d6ac05d62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e51e192-7f9d-4101-8686-288aaf97f6d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1fcba8c-01e2-4e41-b13a-38d23aea5178
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e611a952-d678-4936-a54d-9c9f263fcf0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 326f80db-2162-4fe0-af8f-f7902c7f57d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00d44fe4-3ad8-4e69-b78a-5638c542f80d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7846af1-9c67-4ed6-8ce4-41bb541b2ccd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a0a841f-e294-4f7b-b624-0f3dd8a645a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b762191a-cd90-4318-98c6-c1c25df1b7b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0a847ff-86b7-4128-8d50-5c292ddd49a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6b13882-6da9-4674-8e98-ebb191c4f396
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62036ecd-e03b-465f-a741-a7040874b65c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbdf6e70-2445-4961-ac74-246774672160
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3821071-9386-4c03-84f7-008cac2840bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52070074-44b6-4766-8388-134cda22ff43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65415e1b-0d8d-46e2-8591-c1f504e8278b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 439d1b68-52aa-4645-aa1b-16f2cae442d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 082e9a19-dae5-4a38-b37b-e110cf1a3bf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b626a481-4b55-4914-8cb3-5620cd4d5912
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8ede9ab-b2cb-4e3f-82ed-d76f6987475e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32ecf13b-ddd9-49f8-af2b-4fbe3e5ad37e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 761ab451-05df-4a12-b6e7-8686e691a1cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fc5a127-b356-4a4e-9cc7-c2d115727489
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44872755-9ac8-4675-9458-b801e49a9f69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96a606ff-9a52-4403-9621-fe0d9e75ac35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09e56657-c5aa-43ab-b209-328689ea589f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2603862b-12bf-4b81-9616-fd66405c7733
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26229e64-4952-43f1-9df3-023f876304d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 570d95d5-2201-4b83-9a9b-95d943366ffa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d028544d-296d-4464-b27f-d2f3156e4ab3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 710fa554-4cb2-40b5-8fd3-02be13c1a152
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d626c7d-c2d2-49c3-a59f-94064a58b0fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c360aed0-3368-4e39-b94f-340477ba8d1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d2179a4-1ee4-40bc-86c8-3e87d29b9057
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bddd461-4ea5-4c44-98b8-483ba6203f8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 649a3fd1-f1f2-4d51-add4-1aca93982d46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c91e1e3-4c41-4e90-9eca-95530e463ef7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebbd6512-86fc-42d3-a191-6a44c4eb2e2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e14523d7-ae6c-4b9a-bbc7-e447910c3c8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61c51ae1-ff86-4f53-a1e1-87b1f471068e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 529722ba-c3b6-421a-a625-0fe601b9e9c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8667ee69-c7a9-428c-900c-7e2540a193c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f47bef9-7ed5-49a2-8335-a402ada60877
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b29002f1-b30a-45a7-bf10-0291b155a288
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b850506-0e0c-4b5c-806a-1a02d2fe7a97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61f2d195-4f85-4533-9536-bc8a70e93788
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b46ca7ce-a87e-4aa5-a3ea-9e78dedd1fbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dae9285a-6272-47bb-b091-56106122d220
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f347768-2407-4505-8310-6c1efb010d14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f96a94d6-388b-4cc0-b0de-ea8085c94f5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d07b22d-af5c-4914-b3b8-e4033d94fb1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83398128-12bc-47c7-99f6-048e235dc16a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5dfd0adf-8c96-4439-9a79-cfb9ba5c69a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bb416dd-e4f2-4595-a515-89f6df312a73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88e02468-04c0-4502-b417-cea3d3b4b709
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6e97a6e-9bf6-4159-b9f8-2fc81db60158
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f71649cd-4578-4812-8158-318bf2ff36d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f0383ed-7733-4e66-babb-adc6b77155a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cbc3910-7699-4d4a-ba22-a72ce6961a6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a047bbca-9f11-452c-a184-542401208734
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92b093e2-702f-417b-b492-afb875723349
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b00e36b-f931-4d41-8d96-6ef7df00d639
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a866bd7a-3047-41b0-8039-07cce9f84a2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 318e7faa-925a-455e-a6b9-f399883b0b1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c7379ff-6428-440b-874d-102aa03c5524
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0bfe5a6-09e9-446c-9d67-106031245052
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e99120f6-c06a-43ce-8ce3-ab40140fa5c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4c894e8-fb74-4857-a988-5de837ac220a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7638749f-fed1-406e-8c9f-9058f13ff123
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a14699dc-bc3d-4117-a00c-1613ea3447cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04a40ae0-24b6-46e9-9e9e-8fe2d41aa85c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7349b6a5-e5f5-4201-9b34-df0577b9769f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 304ee907-ab10-414d-87d9-df5c985a8af5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6607dde-0f16-4d24-a19e-da9b509080b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fed0b49-5d72-4261-81e8-452528a5db9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9206ae29-73da-4736-bb43-87c2549bc9fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 413a8419-097a-4a0c-b4d9-4c2bb5ec088a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ed5ca87-6e2d-4fd2-badc-78e6da11bd01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ee8a680-bafe-4c5e-8324-388917904186
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34dfa892-224b-4703-87d5-766378b99db8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bdc615a-ed1e-4905-8551-97b03aa966ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fe898f2-de9b-4c33-9c75-b974289886fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30b12a54-441c-4432-97a4-4167d521bbf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a3753a4-1862-47d7-8192-097126220f52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d77d755-3756-4d12-930a-b0ad54d1381a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80a80a85-65f2-464b-bcbc-f3c690d5b20c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd4c11f7-2baa-405a-925a-ce397564a738
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d859c29a-08c7-4e5d-8d11-3fddbafacd2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5c84c09-0c33-4530-945a-e50b708dffc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a20085b-aae0-4757-9f20-73849f0496ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fa95729-5dd1-4935-a3b4-0fb30151b51e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09420928-21b5-4bf3-ba99-3789d224b107
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fe2727d-8d1f-4cba-b0e3-bd197e25b9d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89d6869d-631f-44fc-96b7-7702947894b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc851942-ad14-49b4-9c8f-999f4d338c05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2b0b441-a18d-4eca-a225-756629f511d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c3b4fe1-b5d2-499a-ba6a-f5044b802316
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d4d2cc4-dc55-4e1d-8494-88e7f7adc6ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0a11c47-dfbf-443c-839b-7c64a570d3ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea03dc0a-cad6-49e7-a508-21abf485e78a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e83ad202-4973-463a-bd79-2e0c79f027d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdb1818d-28d2-4761-ad56-c34b6e25e8e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b69f8c49-7668-4e55-bdad-271e6bbed94a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 459244d6-4aea-4027-97a6-e482ccfb90f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2affaa1d-bb40-4801-a619-69f4426b3fe3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c33db2ae-0814-413a-b2c4-326c99548813
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0119c5e7-6aa5-4c61-b0a6-441f0683f8ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f042d478-a84c-402d-b3e3-f74fb926eb4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa2260f7-dd60-4b29-970a-fa8929627877
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd92e4d6-aa76-4ee6-88fa-ced8e5ce421e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10a9bdce-0c1c-4291-a95e-fee64016805f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11bbdcdd-9ce3-4200-bb39-98b711fafd26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29108f70-6232-420e-8fda-259d7e933595
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17fe9469-a544-469b-83ae-ffc298d800a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01ab5ca0-e7e1-49a2-b73e-e1b1676fddce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4df2a420-f903-4942-b6d2-5b039c3b7534
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f418604f-b92f-4dbb-a6c0-1aeb90346d7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bff63427-a245-4d87-b81d-1ecea13dbf92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2832312-74ea-42e8-b928-e62dc64fa7c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f8d4666-dc90-4a21-8d20-fb3f09f88606
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02ec8339-c94b-41cf-80e1-b1957eb34197
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f91f0a3e-6db3-4a3e-a97c-11561231864d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64b10516-dd64-4928-98a9-9e28535fcbec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c2fc7f3-eb13-482b-9336-8a45848d1388
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff37d18a-3556-499a-9cce-3e84e76d175c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cd3ad09-2c1d-4fef-8ce6-37a741ac1001
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2db94f8f-2a3e-4e07-8eeb-6adbe2b728b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b73dbd7e-7058-4ef8-b5d9-2fa8262cc16e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2062b735-a040-4c88-bf57-fe91ad6b999d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 907fce9f-b9e7-4323-8de5-f7be16b865bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dec3cba0-8239-45d2-9c0f-1d1c1aa888e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a61c36c-1d39-480b-8680-0d2f583c8c82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ab29665-b59f-4936-a97f-46cda17a958b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 663313d4-fb48-4be2-93dc-c7f9ba55a1d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc5628f0-9658-4269-adf5-0e9f55518e17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 014c89cf-e051-42e2-b807-3ca645c2569d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdadc49d-6816-4e83-8e9c-ecfa0b63eec2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 798e4568-0098-4f60-8a7d-5396e87bcf77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed41abd4-3543-4cff-8c3e-051dba022794
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bea9b342-ecf4-4ac6-a153-e77566ae072c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7303980-2b8c-4119-a890-48877def110b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06c15e70-de25-4ffb-9b09-42a812a37b58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 487231dc-c288-45b6-b942-19f8224a22d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ddbca733-810b-4353-873a-444973bf1e37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84ec065f-2a5b-4dfd-aa0c-d942c88a6675
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b10c154-2b43-4bd0-8dbf-8f9e98cfa62e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb5d37c1-8a69-4a88-bdb5-c70db613f2dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 596666d8-c8eb-4295-a947-f355e456a576
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d368e88-9ba9-408c-adb0-2159c01b3720
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 368891de-44a8-42f0-80c0-369a81e065ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5430410-2226-4947-a6e0-e427eedacbf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fc6b7b4-c142-445b-8532-b5ce8dc56680
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e70ea41c-8df0-46ae-b62a-bd3df61fdc74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8154c79d-2629-4eba-af2b-7f8d8602aa47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64ec25f2-5aa9-418a-bea4-0d77d74107ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8361f636-49a2-4bec-93a3-3faa2852619a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 927b83c7-de2a-4bb9-a896-b829aa16bc89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 619e979d-1da3-4e4b-a5fc-f062b0100e08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22d92818-cf34-4c77-9114-89c9739e46d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ea4efa1-87c1-4057-99a2-c570e1eb2d5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8b09a22-870f-4856-ad6c-03a5a5b502ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f6ae4bc-5d95-4dd6-83f6-03798171d161
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1227642e-9beb-4a81-bf4b-b0d4c3799ec5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec371d73-9a94-4c65-82c9-340b350cf603
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f9ce93f-6465-49de-bc84-a43fcf19b79a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cdf7b4eb-ec5a-4d7f-939e-0fd44baf0246
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a3390a2-9213-4dec-941e-40f5b72e3bed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0176b10a-b0d1-4fe3-adf8-a643b1108dcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6e146b5-2b43-492d-8e73-307b1b43257f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6336bc78-faab-48ca-a109-10401ab3e3ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20d9268c-6567-4227-997d-f21134d14009
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7b22d96-dc2b-48e9-b4dd-70278312404d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b575fccf-7698-406c-84ba-0d441f0d7e41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8cfac623-334e-4760-ab16-ab99d4b78c9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f75e23c-9c62-4ab4-b11c-711151e4112a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 400d0541-411d-48a0-a551-c7eae1a06f40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ece34de-d8c8-41d6-bc01-ebebd0297552
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7643cf77-866b-429d-8fe6-d35fa61e92fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61330f3e-5368-446c-a658-48068ea7f08a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96720a7c-702f-416d-b0a1-6215623a1696
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05d9526f-40cc-44c6-aba2-74f918fec68d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32c49f3e-9ab6-4423-acce-79746db13625
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d97c06b-810e-489d-88b7-0b2c3b41a211
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07eae6a4-9a43-4bcd-b428-6ea7490f4c5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21a803bc-ac1a-4bd1-8604-39fb435aa5f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cca24049-2afc-4e1c-bbc6-6c54deee6c07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9742a59e-127f-45f9-854d-2e5682cfc2ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75902a4e-6fbd-4eac-bd9c-08689cb9b3ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac59b833-d26a-446f-a7a5-d93caf2054e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d19c142-9590-4006-b572-ff68a14b4777
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35375666-8ac6-4592-982b-a2fb2647a919
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fea941ec-4316-4f2e-8e36-dc3981f83ac8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f840335-4402-4e84-a218-89e2ebc48505
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54ef4bc0-fecc-4d87-be65-11ada798081c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9dd39556-c0a7-4308-93e8-f428b6954b30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d9245a1-7438-4316-99d2-0a350414f143
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab59309b-258b-4119-a1ca-833a7dd4661c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51d97987-2095-4aea-9fb5-35b79d427d5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8dc8fc9-ca4a-4c60-a387-53d4778bd4bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85f99de4-2800-45a8-84ec-c89fa428fcc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c409015-25bd-420c-a253-2f4bf469321f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5f31fda-452b-4828-a311-e21243bcbdd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 664e0c6e-0b50-499c-80ee-a118844903ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3467fab-4111-4827-ad4d-212c453e5a08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebbccff4-9ece-4052-a574-f501cc637843
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fb7e7bb-6928-485a-8b95-cda40ce1915b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b5be59e-fa71-4f07-a7fc-98a592c8dc85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message caca7c30-a121-4139-869a-5b763ffb5892
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 238d7fe8-9be8-4db9-b375-e38b88b5dab6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e36cb2a9-6372-4659-9ff3-9a0e3b7ef848
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1ee9538-bbae-4b87-bb89-1a4e5ef59810
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89c92b05-42c4-43b6-80ea-d761744a5185
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0fbe3be-7bda-492f-93a0-c2e80c2546ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 598ed2b1-193b-4e9d-9848-f9b456082b1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5464691a-4488-4f91-9b5b-2f8551b13078
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c0995ba-21d4-4b0f-89c4-462b990e4a9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be581db8-41cc-48cc-ac88-39679cd4bf1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6980a0c8-4bca-4622-adf4-9e964aa785c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65aa36cc-9934-49a3-b7b6-6f3195c05485
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b06fe71f-c72c-41fa-8cf8-2f50c3ae0b55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70b3b71a-be29-4462-9f21-dfe8affab667
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d7292a6-e793-43c4-9426-21039b48eaf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1768102-fd56-4b56-b098-30a8852fc082
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ba9f11d-8ebb-4ae0-aed0-1655eb862448
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3817950-b662-40fe-b3cb-a88560ad21ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76015279-f51d-4149-94b7-ed7a512f6b0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd7226eb-8ffa-4d0d-926d-ca49716eaec9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c34b3b6-3026-4bea-aaf5-d4b2161e3e87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20e3ded4-167e-49d0-b8dd-b4eebeb65803
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ed3d6d2-538a-442d-8da3-291ef65cde04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb807b0e-feae-41cf-9a00-00e3cc210b2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c805e5b6-8f33-451c-b601-f121c59e80b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6b3a86e-b40d-4604-a0a7-6c65625b921c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00799d45-8b52-42b7-a9bb-5f6ac72892d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2b95ca0-d624-4821-abbf-6aba38aca98e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b3555a1-7a3b-4944-990a-be1ed41011c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30ab953e-6765-4ab7-8ae9-5c84516cbb27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6647dd0-7f8b-436a-a253-a26c6276424d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 248220a9-4509-468d-b5fd-1a486bfc55c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b707296-1f2c-4d47-a64d-6a856107c2ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b001b02a-b2cf-4cf1-afc7-69fa5dfa863d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ce7a343-8735-4c2f-b90b-8409aaf4bce1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d00e06ff-06c2-4820-80b2-6bc762e73f59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a33fc639-82de-44fc-9c2d-4ec0c863d49a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d250fac4-55bc-44fd-aaad-ee9352811d4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8bf27202-9265-46f4-9997-3cbf82bf6bbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69b5762b-c48f-4c2c-aac2-2f206291ba8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84d6ae93-2400-45e9-bd47-eb232d0e2775
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d362e0a-38c9-4aa8-b634-e70867e4fb8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b5f7cad-f134-4730-8e8c-81f3f08777a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1268a9f8-f531-406e-8632-f077c5b1366e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd40837b-178e-4bb9-bead-9136e16cc600
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 615a220d-c89e-46a2-813a-86d51cc4ff52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3323380-c0cb-4176-9dd3-e5cbcbf871c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 248a1baa-6cc6-4e46-b4e3-8a9373b91014
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d99d2df2-048e-4b54-adfa-403c0884cbdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 415fd7e3-5245-4971-92a4-d92d19bb5c75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f78440cd-a5ee-4b2b-9579-b1b5c0ccb6d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99dbd9e9-8eb9-4fff-9ce5-e1f97f70d928
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5080cc3-44b5-42bc-b585-86a4970a0219
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6e30500-869c-40cf-8d14-870d01f94d96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ca9d8a1-d152-4045-ab00-ab2a6a0756ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfd14ee0-c460-4498-936e-32c95983102f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3758976f-a814-443e-94f7-c1f8edf0b2c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a246c8f5-c21a-4a2e-a14c-5072eb6a0f2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eedf545c-15f6-4812-b445-775a528dee6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 265a243e-bcfc-4616-b5e7-e5860dcbe0cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe7969bb-c65d-44cb-b86c-57f7c742b2d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfdff0e4-d3ce-45ac-b028-083041bfa4d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31543e22-0c21-49a1-bafd-675a97b43a2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cf50268-2ba9-492f-a79e-6b5779f3f328
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e56d6aa3-7a7f-485d-bff4-e986200c8e8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24d5416f-6068-4072-a18b-e3ec41e6b934
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9da977fb-a083-4682-87d6-5425a490abbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52f19a56-283e-42ee-9fe4-0026ad40c6c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d59bc80-96c2-49b4-995e-d4bfcc2ab2db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a66e81a-fd9a-415f-8264-876010b3995b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59ccc24e-157f-490d-bc6f-01ffee50e8b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22d6838b-d6a4-43ba-bb31-9b3e5a9934d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffdde5a4-5574-4982-b425-286e31083d84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 860f783d-5066-4aad-8e35-68599c557f5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d2af698-83b5-4735-8757-04988524d50d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a101ca16-81e5-4ee1-8fbe-76490872bb3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3761426-f89e-4af8-9bd4-dd84d0cb747a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34a0bfb4-9930-4fc3-9758-81593ac0178c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db2aef79-ad15-4530-bbbc-9687828fc80f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ceb4774c-bfb6-48f7-a06e-abd54e45a36b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 104b2081-5f05-44cd-91d2-509fe6535527
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e34bc75d-6a44-45d0-814d-ff195514b5cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9669ecc3-6faa-44f3-a7d2-806e4ce4892f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 543dd4f9-f6cc-4a52-b43f-67a2f5e27088
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7da1648d-3221-4966-87d6-70231e2355c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdd266ec-e201-4d23-8cee-3e43b9c1bebc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2a44735-1f5e-4d63-b77e-16d8c184899c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 529186b7-e03f-4caa-8d5c-a6f3bfdcc5f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d13c0ce0-8d1d-4d22-a9ae-e7075d09962e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b01ec93d-020a-433a-a445-ae315cefc01c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 283aab32-9b15-47fa-9ece-79942a275e6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c59f203c-5c95-4bc2-9870-59a0bf525c5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 594174fb-5675-409c-8769-7b2b9021f5db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4777dd15-71ac-405f-9c92-c903eecdc1e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f75414a4-04ab-4ed0-96fe-f9602d7747ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1be40a66-e291-4b5a-82f9-5f83abfe394d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee89dc92-d7c1-45cc-803e-a9e371eadbd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 809518ac-3e93-4fd8-8fb0-0bf6723680dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22fd006d-fab7-4a28-a3e0-c6b1af84492a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0abb234f-25c0-4208-ab96-75ae52ca39e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2eb7be3b-5bfc-448d-a370-d144a2f0d402
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbaf368b-8859-4579-aa1d-317bec28bf03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 624ee04c-65d1-4e22-aca1-0b92ee274e61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ea4a770-e386-4b37-a7cd-a2e284844305
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9aee626-df22-4513-ba54-9c397ab0adf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d2041b5-e105-4bc3-ab47-a663752f3e59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66a260ff-7b7d-42af-a77b-472add368760
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8bc55576-463b-43e3-a02c-e4395725ea44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11244f01-bc3b-4621-82b4-c50d15a58039
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50ae4ebf-63c3-44bb-a3eb-e5c9ae416781
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79ddcc5f-7c69-4cfd-948c-6f76f9f4ff70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99b3b8cd-93cc-4912-836a-96aa008010f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b937d25-9ad2-48f1-81e5-a583fbd10f25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c500e3f-0f3c-44ec-be72-c3af6c22579b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 547ae710-d5cb-4702-af46-d906e825316d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39870978-a4d9-40a9-859a-5f06fbbc0896
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c012048f-807e-4d45-87e5-efc07843fcbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51283f76-189f-4828-9c35-c74b8cc187e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9331192b-23d6-4ec2-898d-c288e591c609
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e62f25a-894f-4d98-abda-ec2668b9a12f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bba9f89b-63f5-4555-bf00-260bb8df3971
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 896c11fb-c4e3-4898-b4f4-84ee2b934ce3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16dd8a96-d7de-48b6-be67-9615307877a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d446d40-bdf9-42ef-a41d-0558f7239a55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b5f2875-dda2-4557-ab67-008248a7ba35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25ae3929-0ee6-4e94-a809-5a3b9a21ea41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc165360-d6a9-418a-8a7d-d8096e3ab152
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1d5f378-9763-4361-b182-bc52e36975e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c5f4856-49af-482e-9b64-4d24960946f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67d44e99-1b68-47a5-bb16-1526dcc23d51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3f40e25-d112-4bd5-8419-085f740797ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac920bc0-a817-4d49-8f14-329e978bb8db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e42cde2-f43e-4876-ab4a-98df12474fc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49a04a01-856a-4b17-9eba-dfee8e8ff24a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfed7b68-0195-4807-ad34-794b2ceab43e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b37e88eb-bcd8-4739-aebf-ff1751557435
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 879f388f-5bbf-47e5-9252-f2a248ee6de3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f273704-ab53-48c1-8c84-561c266e06e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a7f47c9-e3fa-4a03-ae2a-b25076fc9611
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de96d7d2-f2ff-40cc-bc6e-b81da890801d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed4ce077-dd0e-4d49-9fe8-c2a01232f1b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dee9ef05-0e27-4322-8701-482a0da9578c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffcbe789-42cb-480a-b63b-475460c5975d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c6996f3-7d13-46a9-8cf9-d5ca68dd92e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afe442e1-67dd-4697-a219-bf184214ec49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8bd809a-c37b-4451-9ca1-c1c1263664db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de4836a2-95e7-4829-b7d8-f71316f0addb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e905a8d-3304-4b54-ab0f-a1f578ce07a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 524361f0-d171-4005-90f2-01eb5c340347
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5de80339-082a-4f98-af19-13ff3fc3c6eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9f09d38-0c2a-483b-98de-6264abf25a91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 436a5f70-6dfd-400a-b543-8b61ea9266cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0d3d2e0-25ba-4f2c-ab43-68020d8f94f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5183565-ec9c-4f3d-b081-391ff22f52f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6468903d-4ed8-405a-95d6-5d044ac712f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5b4c1a8-14bb-4cd4-b989-75b89f3ddff7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 996c693d-9484-4f16-9f57-3f0221865588
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01fdb1a6-dfc2-435c-9067-e2d505885fe6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3d391fa-4110-4205-b17c-de3deca404e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3fc5552-bdd8-4296-9168-ae0e32a99e3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81d16759-b49f-4bd2-925e-e3dd92cf7abc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6225a1e8-2430-40f3-b00e-2bed72117089
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66a1c7b3-0409-45cb-ba14-bb5c8c41c8c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea366e60-47db-418f-b92a-2738881c7d29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b5ae92f-5170-44ee-ae68-0a9c3d8819b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53674409-1da8-4f49-b3c2-78e50bc1efa0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51c4591f-762c-4e0e-8503-ebd53536bc5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf3d2606-3d53-400e-97e7-1af590aa3236
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1eeb9361-5567-4a9d-8a49-2b76d343c75b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 302155a4-f9c9-4333-8e71-7951f21ae4d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40fa5d51-bcf8-453a-98e4-c259a6424a84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17680591-9017-46f8-870d-ffe8338c3787
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7029bfe5-32e9-41ca-8393-310c941fecbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfb3a466-fb46-4d00-b5db-25c3db5512e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44c332d3-52f0-4c4c-ae0b-581ff48d8e0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42188e51-ef4b-44f8-bbaa-8c94197edee9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 801ca674-a64f-40a9-8953-94276276d1c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5a67676-a96f-4daf-b6b6-200099d2d21e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b72c7953-b6fc-47b5-93fa-b421ac8676a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d18eb394-2a7d-4989-a1e6-fae56fb2e74a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f930cef1-28d6-4017-bd0d-267fcfe4e099
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1b73c2d-1a86-4a85-b2ab-bf7820a8e6b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c21b458f-3388-4a03-80e7-667fdb665ef1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99971b3e-f624-45c8-a5f3-475ad37f914b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 170c6ab4-d20d-4abf-9fc9-82a7c56355fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4208d91d-9ebb-450b-8fac-ab3ac4dcb313
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5dcbb23c-371f-414c-b000-e1fc3708c1f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a0af7d5-65d3-48f7-82ec-6e4f02a221ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e2b5e4d-cdc7-4a27-b58b-ade05e615317
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6177259e-780c-46db-80eb-d1445c85aa22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c60a78b9-d1fe-4524-931b-183e91f3139f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e6a556a-7f4d-48df-9ccb-b3d8c6a1a22d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10ec15d2-9026-4a2d-a2c2-fdec6ca29b3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2752b7a4-3529-4d95-8ec1-08239c5fe51f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77f557cb-52fb-4039-84c2-d19c84deeaf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 695a03bf-cc65-439e-9129-2807805108dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 430ab722-c9c8-4f4d-b4f9-dbaa60ebea89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99d099a2-3551-4385-bc3d-7a39ca51070c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5c35307-bf56-4e84-adbe-9e8fb3b589c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1f4ed80-483a-48f7-b025-ce3ea9250b85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75673389-be73-4813-8370-f5cc44d59f2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7d0919b-b037-47ae-bb2b-c51bee404aa7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 403e222c-ca9f-4a1f-8e11-dd77a9babfef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76a36bb4-d36c-4912-bd1d-1bc288bac978
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbbdf7b2-a446-43d3-a3f6-e0f97cbd633d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba87b62b-f933-438c-9bdb-8950e09f4513
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff36c76e-6860-43bc-a176-39e06796e01f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f660b8a-6c49-437f-81f0-f8072a8d2107
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ad98cf5-7b75-4839-9e48-4abb97a0ca6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d13ddbb-5e59-4a16-8b92-0c35a3b7bc58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 096083c3-368e-4ae3-8a73-f4059b0534ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8278c5f-53be-4ea6-9703-d1ee1e36d7c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 205f95f7-9f11-4d60-bbf1-aaffdce02fcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 743871ed-6c65-49e7-b25a-eb1c7280821e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eff051e5-f204-4f40-ace6-ffeb86318c6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68eb28d4-05e5-49d6-ba6b-55cc4fd32435
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39b46272-bf08-46e2-86a9-619eba103f14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94471b5f-dccc-458c-8963-b69bda6cfaac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd423070-c5e5-430e-93dd-3a5b0b6e38e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afbd24a2-6daf-440e-8bf8-02dbb278bc80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a85d06a7-07be-460f-8730-5e6c716ad03b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea584485-1e7c-42b4-9fd8-223004fa4d52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3b9187a-679b-48cc-b028-8f10009b96b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f212a59c-4d02-41af-8fcb-83607418a7d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32c12bd3-b55d-4e19-820a-5f1e5075ca41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7959dabe-37ae-4c8d-97a6-2161faba8ed1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a1dd542-01b6-44df-a41e-04fd73fb013a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 453b30dc-b5c8-4199-844f-7c270f663cc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfe4c42c-5082-4486-8c7b-ac9a0bf5e46e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8bb6f0e7-7544-478f-86fc-ab4dac425f20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb8bce2e-4bce-47e6-a0a7-e922f7cc4ff3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2044777b-4ea5-468e-8ece-65c30dea37e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ecfbb195-cd31-45d3-a9d2-830059476d1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0e5a883-f632-43a8-ada6-45948ecd7af3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b37ed2c5-0383-4d81-814d-135f8fa2b411
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d141b250-1d0b-4268-a0ce-6735dd117247
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2c0418e-687b-4692-b4b2-7bf584f2a3f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fcba09f-b5b8-4101-bb6d-4d13fc49544a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00806e12-3170-48e1-9f48-ed70ed0a0322
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e666c451-98bb-4b6e-abab-0529329a15c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab1b080b-ac90-407e-b9be-33d356ff0cd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d14568aa-00a1-4491-a093-3f826195be79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be6b65eb-825e-4ef7-8885-3d40363b4193
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eff605d7-549a-4919-9c2d-2f75f6718479
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e4bc1a5-0c92-4b23-962d-4d747236fcc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec36b07b-d604-42d1-aff8-84df56682778
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b53736ee-62d5-4082-87c5-14227f4a5330
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c16cdcb-7714-4011-a065-7277a483835c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abc3c44d-d123-4c0c-b5cb-53c8d29ab0c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb135b96-c5b5-4b8d-83e8-dab5bdab43dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea3e4c06-d925-4268-a48d-59af72b36eb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 306a877b-122a-4888-8e1f-6cec6aeef5db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf91011f-1dfc-44e2-8745-7031df9e78e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d94c09af-8315-40af-9fcd-a667fafb733c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e0b86d9-00f3-4c7b-acb6-214d4a1277b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a8548b6-c182-4ddc-9818-52a0ad385043
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b37f5ce-063b-4729-89e5-cd5deb22c5a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60129448-c4a3-470c-af45-03a7d77bf308
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 789b10b7-3e90-47c8-bf0b-417b9676ccb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e3207b0-d83a-4b3a-b004-86c9a8942c9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b6634d6-eceb-41bb-9f75-6af1013bb9f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48228a0f-7e9c-4e0f-99ee-d6e091e5538f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90c7e078-b9e1-42ff-b3da-73c29c677ba0
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_8
Server: localhost:8686
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_8
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_8/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_8/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_8/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_8/test_labels.txt

📊 Raw data loaded:
   Train: X=(5265, 24), y=(5265,)
   Test:  X=(1317, 24), y=(1317,)

⚠️  Limiting training data: 5265 → 800 samples
⚠️  Limiting test data: 1317 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_8 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 1 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.2320, val=0.0920 (↓), lr=0.001000
   • Epoch   2/100: train=0.0914, val=0.0928, patience=1/15, lr=0.001000
   ✓ Epoch   3/100: train=0.0836, val=0.0913 (↓), lr=0.001000
   ✓ Epoch   4/100: train=0.0829, val=0.0896 (↓), lr=0.001000
   • Epoch   5/100: train=0.0820, val=0.0900, patience=1/15, lr=0.001000
   📉 Epoch 10: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0818, val=0.0902, patience=7/15, lr=0.000500
   📉 Epoch 18: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 1 Summary - Client client_8
   Epochs: 19/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0112
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0463
============================================================


============================================================
🔄 Round 2 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0784 (↓), lr=0.000250
   • Epoch   2/100: train=0.0841, val=0.0786, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0840, val=0.0787, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0839, val=0.0788, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0838, val=0.0789, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0836, val=0.0791, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 2 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0019
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0055
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2512, R²: -0.0029

============================================================
🔄 Round 3 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0774 (↓), lr=0.000063
   • Epoch   2/100: train=0.0847, val=0.0773, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0847, val=0.0774, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0847, val=0.0774, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0846, val=0.0775, patience=4/15, lr=0.000063
   📉 Epoch 8: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0845, val=0.0777, patience=10/15, lr=0.000031
   📉 Epoch 16: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 3 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0002
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0226
============================================================


============================================================
🔄 Round 4 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0835 (↓), lr=0.000016
   • Epoch   2/100: train=0.0830, val=0.0835, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0830, val=0.0835, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0830, val=0.0835, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0830, val=0.0835, patience=4/15, lr=0.000016
   📉 Epoch 8: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0829, val=0.0836, patience=10/15, lr=0.000008
   📉 Epoch 16: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 4 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0016
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0075
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0020

📊 Round 4 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0022

============================================================
🔄 Round 11 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0847 (↓), lr=0.000004
   • Epoch   2/100: train=0.0829, val=0.0847, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0829, val=0.0847, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0829, val=0.0847, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0829, val=0.0847, patience=4/15, lr=0.000004
   📉 Epoch 8: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0829, val=0.0847, patience=10/15, lr=0.000002
   📉 Epoch 16: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 11 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0038
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0043
============================================================


============================================================
🔄 Round 13 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0972 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0972, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0972, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0972, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0972, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0972, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0972)

============================================================
📊 Round 13 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0024
   Val:   Loss=0.0972, RMSE=0.3118, R²=-0.0080
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0022

============================================================
🔄 Round 14 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 14 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0057
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0008
============================================================


============================================================
🔄 Round 15 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 15 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0082
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0448
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0021

============================================================
🔄 Round 16 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 16 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0075
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0096
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0022

📊 Round 16 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0022

============================================================
🔄 Round 20 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 20 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0050
   Val:   Loss=0.0909, RMSE=0.3016, R²=-0.0066
============================================================


============================================================
🔄 Round 22 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 22 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0030
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0068
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 25 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 25 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0026
   Val:   Loss=0.0774, RMSE=0.2781, R²=-0.0090
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0021

============================================================
🔄 Round 29 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 29 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0045
   Val:   Loss=0.0848, RMSE=0.2913, R²=-0.0051
============================================================


============================================================
🔄 Round 30 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 30 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0035
   Val:   Loss=0.0741, RMSE=0.2721, R²=-0.0090
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 31 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 31 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0037
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0031
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 41 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 41 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0032
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0331
============================================================


============================================================
🔄 Round 42 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 42 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0029
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0115
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

📊 Round 42 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

📊 Round 42 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

📊 Round 42 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

📊 Round 42 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

📊 Round 42 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 55 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 55 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0027
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0065
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

📊 Round 55 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 58 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 58 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=-0.0037
   Val:   Loss=0.0753, RMSE=0.2745, R²=-0.0141
============================================================


============================================================
🔄 Round 59 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 59 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0056
   Val:   Loss=0.0818, RMSE=0.2861, R²=-0.0075
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

📊 Round 59 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 62 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 62 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0027
   Val:   Loss=0.0780, RMSE=0.2794, R²=-0.0089
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 64 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 64 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0025
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0072
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 66 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 66 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0022
   Val:   Loss=0.0897, RMSE=0.2994, R²=-0.0158
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 67 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 67 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0030
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0057
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0021

============================================================
🔄 Round 71 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 71 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0031
   Val:   Loss=0.0754, RMSE=0.2745, R²=-0.0080
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0021

📊 Round 71 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0021

============================================================
🔄 Round 77 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 77 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0029
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0063
============================================================


============================================================
🔄 Round 78 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 78 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0013
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0146
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0021

📊 Round 78 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0021

📊 Round 78 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0021

============================================================
🔄 Round 83 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 83 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0036
   Val:   Loss=0.0763, RMSE=0.2763, R²=-0.0126
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0021

📊 Round 83 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0021

============================================================
🔄 Round 85 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 85 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0030
   Val:   Loss=0.0926, RMSE=0.3044, R²=-0.0072
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0021

============================================================
🔄 Round 88 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 88 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=-0.0041
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0087
============================================================


============================================================
🔄 Round 89 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 89 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0042
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0352
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0021

============================================================
🔄 Round 91 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 91 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0032
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0044
============================================================


============================================================
🔄 Round 92 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 92 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0020
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0096
============================================================


============================================================
🔄 Round 95 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 95 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=-0.0027
   Val:   Loss=0.0744, RMSE=0.2728, R²=-0.0208
============================================================


============================================================
🔄 Round 97 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 97 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0060
   Val:   Loss=0.0742, RMSE=0.2723, R²=0.0041
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0021

============================================================
🔄 Round 100 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 100 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0039
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0012
============================================================


============================================================
🔄 Round 101 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 101 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0031
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0051
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0021

============================================================
🔄 Round 102 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 102 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0052
   Val:   Loss=0.0770, RMSE=0.2776, R²=-0.0024
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0021

📊 Round 102 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0021

============================================================
🔄 Round 105 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 105 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0048
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0082
============================================================


============================================================
🔄 Round 106 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 106 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0028
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0082
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0021

📊 Round 106 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0021

📊 Round 106 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0021

📊 Round 106 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

📊 Round 106 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

📊 Round 106 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0021

============================================================
🔄 Round 114 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 114 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0026
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0161
============================================================


============================================================
🔄 Round 115 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 115 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0055
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0039
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0021

============================================================
🔄 Round 117 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 117 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0019
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0120
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0021

============================================================
🔄 Round 118 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 118 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0029
   Val:   Loss=0.0756, RMSE=0.2750, R²=-0.0056
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0021

============================================================
🔄 Round 120 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 120 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0030
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0109
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0021

📊 Round 120 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0021

============================================================
🔄 Round 124 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 124 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0030
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0106
============================================================


============================================================
🔄 Round 127 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 127 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0032
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0095
============================================================


============================================================
🔄 Round 128 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 128 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0035
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0062
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0021

============================================================
🔄 Round 129 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 129 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0036
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0026
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0021

============================================================
🔄 Round 132 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 132 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0042
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0045
============================================================


============================================================
🔄 Round 133 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 133 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0039
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0015
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0021

📊 Round 133 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0021

============================================================
🔄 Round 135 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 135 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0014
   Val:   Loss=0.0778, RMSE=0.2790, R²=-0.0261
============================================================


============================================================
🔄 Round 136 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 136 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0036
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0025
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0021

============================================================
🔄 Round 137 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 137 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0052
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0045
============================================================


============================================================
🔄 Round 138 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 138 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0026
   Val:   Loss=0.0766, RMSE=0.2767, R²=-0.0071
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0021

📊 Round 138 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0021

============================================================
🔄 Round 140 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 140 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0044
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0014
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0021

============================================================
🔄 Round 142 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 142 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0071
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0073
============================================================


============================================================
🔄 Round 144 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 144 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0046
   Val:   Loss=0.0919, RMSE=0.3031, R²=-0.0228
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0021

============================================================
🔄 Round 145 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 145 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0047
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0071
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0021

============================================================
🔄 Round 147 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 147 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0035
   Val:   Loss=0.0775, RMSE=0.2783, R²=-0.0032
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0021

============================================================
🔄 Round 153 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 153 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0043
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0033
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0021

============================================================
🔄 Round 157 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0963 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0963, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0963, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0963, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0963, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0963, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0963)

============================================================
📊 Round 157 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0015
   Val:   Loss=0.0963, RMSE=0.3103, R²=-0.0110
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0021

============================================================
🔄 Round 158 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 158 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0042
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0024
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0021

============================================================
🔄 Round 160 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 160 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0063
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0210
============================================================


============================================================
🔄 Round 161 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 161 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0071
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0040
============================================================


============================================================
🔄 Round 162 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 162 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0019
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0097
============================================================


============================================================
🔄 Round 163 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 163 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0054
   Val:   Loss=0.0909, RMSE=0.3014, R²=-0.0052
============================================================


============================================================
🔄 Round 164 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 164 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0031
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0074
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0021

📊 Round 164 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0021

📊 Round 164 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0021

📊 Round 164 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0021

📊 Round 164 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0021

📊 Round 164 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0021

📊 Round 164 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0021

📊 Round 164 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0021

📊 Round 164 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0021

📊 Round 164 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0021

📊 Round 164 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0021

============================================================
🔄 Round 181 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 181 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0027
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0061
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0021

📊 Round 181 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0021

============================================================
🔄 Round 185 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 185 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0037
   Val:   Loss=0.0749, RMSE=0.2736, R²=-0.0017
============================================================


============================================================
🔄 Round 187 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 187 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0042
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0008
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0021

📊 Round 187 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0021

============================================================
🔄 Round 189 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 189 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0061
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0136
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0021

============================================================
🔄 Round 190 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 190 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0063
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0004
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0021

📊 Round 190 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0021

📊 Round 190 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0021

📊 Round 190 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0021

============================================================
🔄 Round 200 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 200 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0035
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0069
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0021

📊 Round 200 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 205 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 205 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=-0.0111
   Val:   Loss=0.0892, RMSE=0.2986, R²=-0.0189
============================================================


============================================================
🔄 Round 206 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 206 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0045
   Val:   Loss=0.0740, RMSE=0.2721, R²=-0.0013
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 208 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 208 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0033
   Val:   Loss=0.0776, RMSE=0.2785, R²=-0.0080
============================================================


============================================================
🔄 Round 212 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 212 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0031
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0047
============================================================


📊 Round 212 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 215 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0672 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0672, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0672, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0672, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0672, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0672, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0672)

============================================================
📊 Round 215 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=-0.0025
   Val:   Loss=0.0672, RMSE=0.2593, R²=-0.0186
============================================================


============================================================
🔄 Round 216 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 216 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0043
   Val:   Loss=0.0752, RMSE=0.2742, R²=-0.0053
============================================================


📊 Round 216 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 218 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 218 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0039
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0039
============================================================


📊 Round 218 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 219 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 219 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0028
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0075
============================================================


📊 Round 219 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 220 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 220 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0053
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0027
============================================================


============================================================
🔄 Round 221 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 221 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0029
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0071
============================================================


📊 Round 221 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

📊 Round 221 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

📊 Round 221 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

📊 Round 221 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 226 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 226 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0035
   Val:   Loss=0.0918, RMSE=0.3030, R²=-0.0062
============================================================


============================================================
🔄 Round 227 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 227 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0011
   Val:   Loss=0.0897, RMSE=0.2996, R²=-0.0119
============================================================


📊 Round 227 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 229 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 229 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0056
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0040
============================================================


============================================================
🔄 Round 231 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 231 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0024
   Val:   Loss=0.0885, RMSE=0.2974, R²=-0.0108
============================================================


📊 Round 231 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 233 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 233 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0038
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0035
============================================================


============================================================
🔄 Round 236 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 236 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0027
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0062
============================================================


📊 Round 236 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0022

📊 Round 236 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0022

============================================================
🔄 Round 238 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 238 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0030
   Val:   Loss=0.0806, RMSE=0.2838, R²=-0.0199
============================================================


📊 Round 238 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0022

📊 Round 238 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0022

============================================================
🔄 Round 240 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 240 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0022
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0084
============================================================


📊 Round 240 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0022

============================================================
🔄 Round 242 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 242 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0038
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0140
============================================================


📊 Round 242 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 244 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 244 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0036
   Val:   Loss=0.0911, RMSE=0.3018, R²=-0.0042
============================================================


📊 Round 244 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

📊 Round 244 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 250 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 250 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0051
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0052
============================================================


============================================================
🔄 Round 251 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 251 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0039
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0106
============================================================


📊 Round 251 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

📊 Round 251 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

📊 Round 251 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 258 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 258 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0043
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0100
============================================================


📊 Round 258 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 260 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 260 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0037
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0029
============================================================


📊 Round 260 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 265 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 265 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0026
   Val:   Loss=0.0919, RMSE=0.3032, R²=-0.0209
============================================================


📊 Round 265 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 267 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 267 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0064
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0008
============================================================


============================================================
🔄 Round 269 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 269 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0055
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0031
============================================================


📊 Round 269 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 270 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 270 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0030
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0052
============================================================


============================================================
🔄 Round 271 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 271 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0038
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0092
============================================================


📊 Round 271 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

📊 Round 271 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

📊 Round 271 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 276 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 276 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0039
   Val:   Loss=0.0918, RMSE=0.3031, R²=-0.0080
============================================================


📊 Round 276 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

📊 Round 276 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 278 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 278 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2928, R²=-0.0051
   Val:   Loss=0.0732, RMSE=0.2705, R²=0.0006
============================================================


📊 Round 278 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

📊 Round 278 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 280 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 280 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0024
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0155
============================================================


📊 Round 280 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

📊 Round 280 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 284 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 284 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0018
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0124
============================================================


📊 Round 284 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

📊 Round 284 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

📊 Round 284 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 289 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 289 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0035
   Val:   Loss=0.0728, RMSE=0.2698, R²=-0.0124
============================================================


📊 Round 289 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0022

📊 Round 289 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

📊 Round 289 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 299 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 299 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0028
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0058
============================================================


📊 Round 299 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 300 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 300 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0044
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0002
============================================================


📊 Round 300 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 301 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 301 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0043
   Val:   Loss=0.0750, RMSE=0.2738, R²=-0.0076
============================================================


============================================================
🔄 Round 303 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 303 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0028
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0193
============================================================


============================================================
🔄 Round 304 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 304 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0040
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0066
============================================================


📊 Round 304 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0022

📊 Round 304 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

📊 Round 304 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 314 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 314 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2885, R²=-0.0023
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0093
============================================================


============================================================
🔄 Round 318 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 318 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0028
   Val:   Loss=0.0780, RMSE=0.2792, R²=-0.0064
============================================================


📊 Round 318 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

📊 Round 318 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

📊 Round 318 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 323 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 323 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0065
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0329
============================================================


📊 Round 323 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 330 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 330 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0021
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0120
============================================================


============================================================
🔄 Round 331 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 331 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0045
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0143
============================================================


📊 Round 331 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0022

📊 Round 331 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0022

============================================================
🔄 Round 333 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 333 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0030
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0071
============================================================


============================================================
🔄 Round 336 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 336 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0027
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0067
============================================================


============================================================
🔄 Round 337 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 337 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0021
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0239
============================================================


============================================================
🔄 Round 338 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 338 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0034
   Val:   Loss=0.0785, RMSE=0.2801, R²=-0.0036
============================================================


📊 Round 338 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0022

📊 Round 338 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0022

📊 Round 338 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0022

📊 Round 338 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0022

📊 Round 338 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0022

📊 Round 338 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0022

============================================================
🔄 Round 348 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 348 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0034
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0053
============================================================


============================================================
🔄 Round 349 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 349 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0026
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0074
============================================================


📊 Round 349 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0022

============================================================
🔄 Round 353 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 353 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0041
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0050
============================================================


============================================================
🔄 Round 354 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 354 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0032
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0225
============================================================


📊 Round 354 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0022

============================================================
🔄 Round 355 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 355 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0044
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0044
============================================================


============================================================
🔄 Round 357 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 357 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0027
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0075
============================================================


📊 Round 357 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 358 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 358 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0037
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0089
============================================================


============================================================
🔄 Round 363 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 363 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0027
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0080
============================================================


============================================================
🔄 Round 364 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 364 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0030
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0049
============================================================


============================================================
🔄 Round 368 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 368 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0059
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0101
============================================================


📊 Round 368 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0022

📊 Round 368 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0022

============================================================
🔄 Round 372 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 372 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0010
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0127
============================================================


📊 Round 372 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

📊 Round 372 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 376 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 376 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0046
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0013
============================================================


📊 Round 376 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 377 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 377 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0031
   Val:   Loss=0.0844, RMSE=0.2904, R²=-0.0208
============================================================


📊 Round 377 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 379 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 379 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0047
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0026
============================================================


📊 Round 379 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

📊 Round 379 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 383 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 383 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0014
   Val:   Loss=0.0871, RMSE=0.2952, R²=-0.0141
============================================================


📊 Round 383 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0022

📊 Round 383 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0022

📊 Round 383 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0022

============================================================
🔄 Round 388 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 388 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0028
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0121
============================================================


📊 Round 388 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0022

============================================================
🔄 Round 391 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 391 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0034
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0316
============================================================


============================================================
🔄 Round 392 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0945 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0945, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0945, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0945, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0945)

============================================================
📊 Round 392 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0005
   Val:   Loss=0.0945, RMSE=0.3074, R²=-0.0162
============================================================


============================================================
🔄 Round 395 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 395 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0041
   Val:   Loss=0.0814, RMSE=0.2852, R²=-0.0007
============================================================


📊 Round 395 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0022

============================================================
🔄 Round 397 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0933, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 397 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0025
   Val:   Loss=0.0933, RMSE=0.3054, R²=-0.0090
============================================================


📊 Round 397 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0022

============================================================
🔄 Round 400 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 400 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0029
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0055
============================================================


📊 Round 400 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0022

============================================================
🔄 Round 401 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 401 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0036
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0118
============================================================


============================================================
🔄 Round 403 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 403 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0036
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0142
============================================================


📊 Round 403 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0022

============================================================
🔄 Round 404 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 404 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=-0.0028
   Val:   Loss=0.0848, RMSE=0.2913, R²=-0.0093
============================================================


📊 Round 404 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0022

============================================================
🔄 Round 405 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 405 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0029
   Val:   Loss=0.0751, RMSE=0.2740, R²=-0.0069
============================================================


📊 Round 405 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0022

📊 Round 405 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0022

============================================================
🔄 Round 408 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 408 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0029
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0084
============================================================


📊 Round 408 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 412 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 412 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0031
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0082
============================================================


📊 Round 412 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

📊 Round 412 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

📊 Round 412 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 417 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 417 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0015
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0114
============================================================


============================================================
🔄 Round 418 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 418 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0031
   Val:   Loss=0.0741, RMSE=0.2721, R²=-0.0052
============================================================


📊 Round 418 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 419 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 419 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0018
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0099
============================================================


============================================================
🔄 Round 420 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 420 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0043
   Val:   Loss=0.0907, RMSE=0.3012, R²=-0.0011
============================================================


============================================================
🔄 Round 421 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 421 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0013
   Val:   Loss=0.0717, RMSE=0.2678, R²=-0.0201
============================================================


============================================================
🔄 Round 422 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 422 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0040
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0007
============================================================


📊 Round 422 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 427 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 427 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2871, R²=-0.0037
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0070
============================================================


📊 Round 427 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

📊 Round 427 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 429 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 429 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0029
   Val:   Loss=0.0907, RMSE=0.3011, R²=-0.0058
============================================================


📊 Round 429 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 432 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 432 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0042
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0111
============================================================


📊 Round 432 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

📊 Round 432 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

📊 Round 432 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 437 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 437 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0032
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0107
============================================================


============================================================
🔄 Round 438 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 438 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0048
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0009
============================================================


📊 Round 438 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 439 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 439 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0029
   Val:   Loss=0.0730, RMSE=0.2702, R²=-0.0083
============================================================


============================================================
🔄 Round 441 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 441 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0045
   Val:   Loss=0.0875, RMSE=0.2959, R²=-0.0020
============================================================


============================================================
🔄 Round 442 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 442 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=-0.0022
   Val:   Loss=0.0743, RMSE=0.2726, R²=-0.0136
============================================================


============================================================
🔄 Round 447 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 447 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0055
   Val:   Loss=0.0914, RMSE=0.3023, R²=-0.0001
============================================================


============================================================
🔄 Round 449 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0953 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0953, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0953, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0953, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0953, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0953, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0953)

============================================================
📊 Round 449 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=-0.0017
   Val:   Loss=0.0953, RMSE=0.3086, R²=-0.0131
============================================================


📊 Round 449 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

📊 Round 449 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 458 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 458 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0034
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0064
============================================================


============================================================
🔄 Round 461 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 461 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0039
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0010
============================================================


📊 Round 461 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

📊 Round 461 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

📊 Round 461 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 464 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 464 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0036
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0020
============================================================


============================================================
🔄 Round 466 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 466 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0043
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0098
============================================================


============================================================
🔄 Round 467 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 467 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0039
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0007
============================================================


============================================================
🔄 Round 468 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 468 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0022
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0073
============================================================


📊 Round 468 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 469 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 469 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0034
   Val:   Loss=0.0931, RMSE=0.3052, R²=-0.0055
============================================================


📊 Round 469 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

📊 Round 469 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

📊 Round 469 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 473 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 473 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0019
   Val:   Loss=0.0911, RMSE=0.3018, R²=-0.0106
============================================================


📊 Round 473 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 475 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 475 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0044
   Val:   Loss=0.0807, RMSE=0.2842, R²=0.0013
============================================================


📊 Round 475 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 476 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 476 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0027
   Val:   Loss=0.0717, RMSE=0.2678, R²=-0.0256
============================================================


============================================================
🔄 Round 477 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 477 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0052
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0053
============================================================


📊 Round 477 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

📊 Round 477 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 484 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 484 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0040
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0061
============================================================


📊 Round 484 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

📊 Round 484 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

📊 Round 484 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 489 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 489 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=-0.0027
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0073
============================================================


📊 Round 489 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 490 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.1005 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.1005, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.1005, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.1005, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.1005, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.1005, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1005)

============================================================
📊 Round 490 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=-0.0046
   Val:   Loss=0.1005, RMSE=0.3170, R²=0.0002
============================================================


============================================================
🔄 Round 491 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 491 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0027
   Val:   Loss=0.0720, RMSE=0.2682, R²=-0.0212
============================================================


📊 Round 491 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 494 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 494 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0086
   Val:   Loss=0.0913, RMSE=0.3022, R²=-0.0145
============================================================


📊 Round 494 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 496 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 496 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0042
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0008
============================================================


📊 Round 496 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

📊 Round 496 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 501 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 501 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0038
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0030
============================================================


============================================================
🔄 Round 502 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 502 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0033
   Val:   Loss=0.0783, RMSE=0.2799, R²=-0.0118
============================================================


📊 Round 502 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

📊 Round 502 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

📊 Round 502 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 508 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 508 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0013
   Val:   Loss=0.0759, RMSE=0.2754, R²=-0.0128
============================================================


============================================================
🔄 Round 509 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 509 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0029
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0103
============================================================


📊 Round 509 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 514 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 514 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0030
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0047
============================================================


📊 Round 514 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 516 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 516 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0032
   Val:   Loss=0.0763, RMSE=0.2761, R²=-0.0285
============================================================


============================================================
🔄 Round 517 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 517 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0052
   Val:   Loss=0.0890, RMSE=0.2984, R²=0.0003
============================================================


📊 Round 517 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 522 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 522 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0034
   Val:   Loss=0.0838, RMSE=0.2896, R²=-0.0080
============================================================


============================================================
🔄 Round 523 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 523 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0024
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0069
============================================================


📊 Round 523 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 524 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 524 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0025
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0120
============================================================


============================================================
🔄 Round 525 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 525 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0036
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0050
============================================================


📊 Round 525 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0022

============================================================
🔄 Round 528 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 528 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0015
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0104
============================================================


============================================================
🔄 Round 529 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 529 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0018
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0155
============================================================


📊 Round 529 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0022

============================================================
🔄 Round 534 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 534 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0049
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0009
============================================================


📊 Round 534 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0022

============================================================
🔄 Round 537 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 537 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0021
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0096
============================================================


============================================================
🔄 Round 541 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 541 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0047
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0126
============================================================


📊 Round 541 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0022

============================================================
🔄 Round 542 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 542 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0031
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0063
============================================================


📊 Round 542 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0023

📊 Round 542 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0023

============================================================
🔄 Round 545 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 545 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0035
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0057
============================================================


============================================================
🔄 Round 546 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 546 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0042
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0075
============================================================


============================================================
🔄 Round 547 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 547 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0067
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0138
============================================================


📊 Round 547 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0023

📊 Round 547 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0023

📊 Round 547 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0023

============================================================
🔄 Round 554 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 554 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0023
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0148
============================================================


============================================================
🔄 Round 555 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 555 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0019
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0110
============================================================


============================================================
🔄 Round 556 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 556 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0040
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0243
============================================================


📊 Round 556 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0023

📊 Round 556 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0023

📊 Round 556 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0023

============================================================
🔄 Round 559 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 559 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0041
   Val:   Loss=0.0926, RMSE=0.3043, R²=-0.0008
============================================================


📊 Round 559 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0023

📊 Round 559 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0023

============================================================
🔄 Round 567 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 567 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0030
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0108
============================================================


============================================================
🔄 Round 568 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 568 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0044
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0106
============================================================


📊 Round 568 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0023

============================================================
🔄 Round 569 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 569 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=-0.0037
   Val:   Loss=0.0892, RMSE=0.2986, R²=-0.0027
============================================================


📊 Round 569 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0023

============================================================
🔄 Round 571 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 571 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=-0.0036
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0045
============================================================


============================================================
🔄 Round 572 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 572 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0034
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0059
============================================================


📊 Round 572 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0023

============================================================
🔄 Round 573 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 573 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0055
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0016
============================================================


============================================================
🔄 Round 575 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 575 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=-0.0037
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0023
============================================================


📊 Round 575 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0023

📊 Round 575 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0023

📊 Round 575 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0023

📊 Round 575 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0023

📊 Round 575 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0023

============================================================
🔄 Round 587 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 587 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0041
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0082
============================================================


============================================================
🔄 Round 591 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 591 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0019
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0121
============================================================


============================================================
🔄 Round 592 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 592 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0026
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0068
============================================================


============================================================
🔄 Round 595 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 595 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0019
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0097
============================================================


📊 Round 595 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0023

============================================================
🔄 Round 599 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 599 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0017
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0135
============================================================


📊 Round 599 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0023

============================================================
🔄 Round 604 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 604 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0033
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0038
============================================================


📊 Round 604 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0023

============================================================
🔄 Round 605 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 605 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0048
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0392
============================================================


📊 Round 605 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0023

============================================================
🔄 Round 607 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 607 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0025
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0073
============================================================


============================================================
🔄 Round 608 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 608 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0051
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0116
============================================================


============================================================
🔄 Round 609 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 609 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0036
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0166
============================================================


============================================================
🔄 Round 610 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 610 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=-0.0032
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0106
============================================================


============================================================
🔄 Round 614 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0988 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0988, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0988, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0988, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0988, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0989, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0988)

============================================================
📊 Round 614 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=-0.0041
   Val:   Loss=0.0988, RMSE=0.3143, R²=-0.0194
============================================================


============================================================
🔄 Round 616 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 616 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0031
   Val:   Loss=0.0863, RMSE=0.2939, R²=-0.0147
============================================================


📊 Round 616 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0023

📊 Round 616 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0023

📊 Round 616 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0023

============================================================
🔄 Round 620 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 620 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0027
   Val:   Loss=0.0919, RMSE=0.3031, R²=-0.0062
============================================================


============================================================
🔄 Round 622 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 622 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0035
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0051
============================================================


📊 Round 622 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0023

📊 Round 622 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0023

============================================================
🔄 Round 625 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 625 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0028
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0119
============================================================


📊 Round 625 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0023

============================================================
🔄 Round 628 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 628 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0021
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0090
============================================================


📊 Round 628 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0023

============================================================
🔄 Round 632 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 632 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0033
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0096
============================================================


📊 Round 632 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0023

============================================================
🔄 Round 633 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 633 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0040
   Val:   Loss=0.0778, RMSE=0.2790, R²=-0.0042
============================================================


📊 Round 633 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0023

📊 Round 633 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0023

📊 Round 633 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0023

📊 Round 633 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0023

📊 Round 633 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0023

============================================================
🔄 Round 641 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 641 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0048
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0017
============================================================


📊 Round 641 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0023

============================================================
🔄 Round 644 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 644 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0031
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0051
============================================================


============================================================
🔄 Round 645 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 645 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0020
   Val:   Loss=0.0792, RMSE=0.2815, R²=-0.0134
============================================================


📊 Round 645 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 648 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 648 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0035
   Val:   Loss=0.0862, RMSE=0.2937, R²=-0.0053
============================================================


📊 Round 648 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 654 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 654 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0029
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0083
============================================================


============================================================
🔄 Round 655 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 655 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0010
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0117
============================================================


📊 Round 655 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0023

📊 Round 655 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 659 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 659 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0015
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0104
============================================================


📊 Round 659 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0023

📊 Round 659 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0023

============================================================
🔄 Round 662 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 662 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0015
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0104
============================================================


📊 Round 662 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0023

============================================================
🔄 Round 669 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 669 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0018
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0131
============================================================


============================================================
🔄 Round 670 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 670 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0045
   Val:   Loss=0.0768, RMSE=0.2772, R²=0.0022
============================================================


📊 Round 670 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0023

============================================================
🔄 Round 672 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 672 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0026
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0082
============================================================


📊 Round 672 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0023

============================================================
🔄 Round 674 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 674 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0025
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0124
============================================================


📊 Round 674 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0023

============================================================
🔄 Round 677 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 677 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0029
   Val:   Loss=0.0830, RMSE=0.2880, R²=-0.0097
============================================================


📊 Round 677 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0023

============================================================
🔄 Round 679 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 679 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0039
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0119
============================================================


📊 Round 679 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0023

📊 Round 679 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0023

============================================================
🔄 Round 682 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 682 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0030
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0093
============================================================


📊 Round 682 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0023

============================================================
🔄 Round 684 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 684 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0029
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0056
============================================================


📊 Round 684 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0023

📊 Round 684 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0023

============================================================
🔄 Round 686 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 686 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0021
   Val:   Loss=0.0830, RMSE=0.2880, R²=-0.0093
============================================================


============================================================
🔄 Round 687 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 687 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0029
   Val:   Loss=0.0871, RMSE=0.2952, R²=-0.0069
============================================================


============================================================
🔄 Round 688 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 688 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0027
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0098
============================================================


📊 Round 688 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0023

============================================================
🔄 Round 689 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 689 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0038
   Val:   Loss=0.0745, RMSE=0.2730, R²=-0.0215
============================================================


============================================================
🔄 Round 690 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 690 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0044
   Val:   Loss=0.0834, RMSE=0.2887, R²=-0.0097
============================================================


📊 Round 690 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0023

============================================================
🔄 Round 695 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 695 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0022
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0198
============================================================


📊 Round 695 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0023

📊 Round 695 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0023

============================================================
🔄 Round 697 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 697 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0030
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0042
============================================================


📊 Round 697 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0023

📊 Round 697 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0023

============================================================
🔄 Round 702 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 702 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0060
   Val:   Loss=0.0858, RMSE=0.2930, R²=0.0050
============================================================


============================================================
🔄 Round 703 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 703 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0022
   Val:   Loss=0.0735, RMSE=0.2712, R²=-0.0103
============================================================


📊 Round 703 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0023

============================================================
🔄 Round 705 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 705 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0054
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0152
============================================================


📊 Round 705 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0023

📊 Round 705 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0023

============================================================
🔄 Round 712 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 712 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0012
   Val:   Loss=0.0890, RMSE=0.2984, R²=-0.0170
============================================================


📊 Round 712 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0023

============================================================
🔄 Round 713 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 713 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0022
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0069
============================================================


============================================================
🔄 Round 715 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0674 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0674, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0674, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0674, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0674, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0674, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0674)

============================================================
📊 Round 715 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0041
   Val:   Loss=0.0674, RMSE=0.2596, R²=-0.0002
============================================================


============================================================
🔄 Round 716 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 716 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0035
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0033
============================================================


📊 Round 716 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0023

============================================================
🔄 Round 717 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 717 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0029
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0046
============================================================


📊 Round 717 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0023

============================================================
🔄 Round 721 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 721 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0050
   Val:   Loss=0.0901, RMSE=0.3001, R²=-0.0059
============================================================


============================================================
🔄 Round 722 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 722 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0065
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0307
============================================================


📊 Round 722 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0023

============================================================
🔄 Round 725 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 725 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0013
   Val:   Loss=0.0896, RMSE=0.2994, R²=-0.0102
============================================================


📊 Round 725 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0023

📊 Round 725 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0023

============================================================
🔄 Round 728 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 728 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0031
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0275
============================================================


📊 Round 728 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0023

📊 Round 728 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0023

============================================================
🔄 Round 734 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 734 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=-0.0055
   Val:   Loss=0.0771, RMSE=0.2778, R²=0.0046
============================================================


📊 Round 734 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0023

📊 Round 734 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0023

============================================================
🔄 Round 736 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 736 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0033
   Val:   Loss=0.0926, RMSE=0.3042, R²=-0.0046
============================================================


📊 Round 736 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0023

📊 Round 736 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0023

============================================================
🔄 Round 739 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 739 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0088
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0082
============================================================


============================================================
🔄 Round 740 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 740 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=-0.0032
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0036
============================================================


📊 Round 740 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0023

============================================================
🔄 Round 742 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 742 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0012
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0112
============================================================


============================================================
🔄 Round 744 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 744 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0035
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0086
============================================================


============================================================
🔄 Round 745 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 745 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0046
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0040
============================================================


============================================================
🔄 Round 746 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 746 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0030
   Val:   Loss=0.0915, RMSE=0.3024, R²=-0.0079
============================================================


============================================================
🔄 Round 747 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 747 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0045
   Val:   Loss=0.0745, RMSE=0.2729, R²=-0.0025
============================================================


============================================================
🔄 Round 748 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 748 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0026
   Val:   Loss=0.0918, RMSE=0.3030, R²=-0.0065
============================================================


============================================================
🔄 Round 749 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 749 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0053
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0005
============================================================


📊 Round 749 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0023

============================================================
🔄 Round 753 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 753 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0015
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0137
============================================================


============================================================
🔄 Round 756 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 756 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0015
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0212
============================================================


📊 Round 756 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2513, R²: -0.0023

============================================================
🔄 Round 759 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 759 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0018
   Val:   Loss=0.0911, RMSE=0.3018, R²=-0.0084
============================================================


============================================================
🔄 Round 760 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 760 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0031
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0035
============================================================


📊 Round 760 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0023

📊 Round 760 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0023

============================================================
🔄 Round 766 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 766 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0025
   Val:   Loss=0.0856, RMSE=0.2927, R²=-0.0058
============================================================


📊 Round 766 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0023

📊 Round 766 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0023

============================================================
🔄 Round 768 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 768 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0033
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0049
============================================================


============================================================
🔄 Round 771 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 771 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0056
   Val:   Loss=0.0889, RMSE=0.2981, R²=-0.0101
============================================================


📊 Round 771 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0023

============================================================
🔄 Round 772 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 772 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0051
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0053
============================================================


📊 Round 772 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0023

============================================================
🔄 Round 775 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 775 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0019
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0096
============================================================


============================================================
🔄 Round 776 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0692 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0692, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0692, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0692, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0692, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0692, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0692)

============================================================
📊 Round 776 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0036
   Val:   Loss=0.0692, RMSE=0.2631, R²=-0.0013
============================================================


📊 Round 776 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0023

📊 Round 776 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0023

📊 Round 776 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 780 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 780 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0046
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0005
============================================================


📊 Round 780 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

📊 Round 780 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 785 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0941, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 785 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0025
   Val:   Loss=0.0940, RMSE=0.3067, R²=-0.0079
============================================================


============================================================
🔄 Round 786 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 786 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0018
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0100
============================================================


📊 Round 786 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

📊 Round 786 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

📊 Round 786 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

📊 Round 786 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 792 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 792 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0047
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0141
============================================================


============================================================
🔄 Round 793 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 793 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0023
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0112
============================================================


============================================================
🔄 Round 795 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 795 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0038
   Val:   Loss=0.0765, RMSE=0.2765, R²=-0.0283
============================================================


📊 Round 795 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 796 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 796 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0031
   Val:   Loss=0.0818, RMSE=0.2859, R²=-0.0031
============================================================


📊 Round 796 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 799 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 799 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0039
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0160
============================================================


📊 Round 799 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

📊 Round 799 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0022

============================================================
🔄 Round 802 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 802 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0033
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0053
============================================================


============================================================
🔄 Round 803 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 803 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0032
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0140
============================================================


============================================================
🔄 Round 804 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 804 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0032
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0134
============================================================


============================================================
🔄 Round 807 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 807 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0030
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0038
============================================================


📊 Round 807 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2512, R²: -0.0023

❌ Client client_8 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_message:"Socket closed", grpc_status:14}"
>
