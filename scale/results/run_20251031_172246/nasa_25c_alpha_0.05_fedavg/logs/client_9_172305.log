[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5781529-6989-4de8-a6ff-e041c5b68e5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59484235-540c-49cd-93ba-5938a298c08f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16011487-f75d-4a9c-bc0f-4aaaae813691
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6e5eb7a-3c99-4246-808d-afe9ff3b21c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64bb3183-fba2-41a9-8b4f-9546f29e1caf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9c64925-1e1b-4af4-9b20-e59ea92aaae4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a862e45-4ddc-41aa-bb20-66bdbb218ede
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 520fab12-37c1-4190-902b-81146a99ae0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f3a4928-e817-4fb7-a29a-0a59666b905f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3b5f244-be51-48cb-9088-ab93ee0c559c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ad44393-240f-4e3c-86f9-db8886361fdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1f58cc7-ac39-413c-b343-b2653284aeca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a0730d8-9b98-406b-96b6-4dde6282de68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74e324d7-b154-499c-a0b4-f3062c6b2d6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 665a32b6-bac8-4b20-8586-4c34abaf786a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e14a5db-5051-4a2e-82e7-ac35a1e86f45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0bfd361-9b8e-4681-8d2e-df09318785f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a41f4218-1cf4-47dd-9c35-c47f63fd219a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8acf545-bcd1-4f59-a2aa-1c60beb6a70b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 039f2e61-268d-4ea6-94d6-2a922f641d11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 084e36bb-95c2-48b7-95f5-bfe12fb9d0cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7ec254f-1488-4e6f-8c41-ea22e871f673
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c408172-4a3e-43a6-8a0c-dcb500b4ba91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7228e585-526a-468a-9702-1aaf46626cf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be6d8b87-a8d9-4134-be2f-a0351998d6a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc61d3af-59d8-4ab8-82c6-a2442b7873a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec601016-73f6-47e4-9e4b-788d10d17905
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26bdc74f-8c40-485f-84c4-d4d25f07488e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74d5bec1-12ab-4204-9cc8-d7bdba53ce3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ee87fef-6295-49bc-bec3-80d22b5f7cfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e845f0c-2dc4-4e77-9c47-c119f4bcd922
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e7b73e2-da85-4533-a2b9-f90feed8ab8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 157b29f4-7e13-4686-8101-a449d52d4fc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8abb7a15-65c2-4f08-824d-f248a227ec33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 933c5fdd-5e21-40ae-bce8-28030e07fd16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f04f50b5-1b5c-455c-9c04-d6b52c1b7dc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12ea755f-ddc1-436e-89a0-cfd15f4f84dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2df3ed85-d079-42b2-b927-24496300373d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e22966ac-bb88-448a-a8e1-0f4bb75bd26c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c39efd55-d942-41cd-812f-6a0eb9124d57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc2c02bb-87ec-464a-b8b2-253146ed5eb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 144f0feb-8929-46f9-acc6-b078d969773a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8581a805-1084-4cfd-b2f6-b730e008871e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0526c194-8427-4637-98da-4566167eeca1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c840eef5-6c07-48c0-abe0-ae2c97dc59cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e9e64ac-221e-4c70-9370-325f7e3d4fa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecfbac98-97f8-44f8-adaa-4d75186ff39d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8adc196d-ef6c-4905-9b94-bd81b29d0428
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bdf5b5a9-9e0f-40d3-a62c-9ef96351bf3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ea6939f-d8da-4fa0-9294-123398fd579c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2fbe068-65b4-4fd4-93d6-720700b38f98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d82500f4-5cb7-4bf1-92c4-de0c42de1314
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc4517ea-1f27-4d18-be50-6b162fdff041
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37f4ebb6-2dee-4ce1-a2b2-e462ebc8c906
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 743a1579-0b33-40eb-b2f1-27d2d57e550a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bc4dc46-0aaa-45be-afaa-150f615e7892
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 002ffa78-08f6-444d-a70b-d70d4634e1d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ccd7512-0c90-44f8-98cb-8c10c7786b93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 112bfced-7209-405d-b087-1659eb549e75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ffed336-307b-4399-a704-495aac130ce4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ae82b07-8b32-40e6-bd4c-bfe13f247dc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdc0a2cf-20c2-4f19-addb-84b627639ab8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 157281d6-6fbc-4033-895a-d396f31a06cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message addca39d-b1aa-4747-8f16-bea746cc20f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 061140fd-3849-4b5b-b9b3-c4a45adb1135
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c145b0bb-8103-45e6-8f12-873203ac8d8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb9033f1-9a31-4eff-a50b-cc29013aa36d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a29a4567-7ac0-4a2b-98d8-341ea6749ada
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79df7445-0a03-4842-a6fc-9c8a3833d20a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9f0bf6a-d6d9-45fd-b4e4-d019c8ff9801
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77c1f6a4-7fd5-4f62-a7d2-8cb02e85d1d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4efc1e10-b3a0-44b7-916d-cb9593071cbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fad54f8f-bf6a-444a-9be0-85297f730eaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff04718b-5c6e-4bec-af64-7524e2bcaa06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7f8e4cd-52a4-407f-a179-b3647979096a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ed99691-b8e7-4b14-b059-0df17d53b992
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f223f3fd-ad0e-4332-aff7-3b7825a8767b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35135336-7cb2-4ae7-af60-f50387c6d158
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e66b162-f950-4921-8641-529683d72128
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6add3a7-99ae-4b07-bf80-16ac1ac65c52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8103b44-564a-4255-951a-e72f84f509e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 850493db-42d2-4961-a9a2-d5f47b5b6987
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e0a5e49-deb6-45a7-ac0c-f4271f6d1a48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a64a487-ee81-46ae-a4a3-e51f879ed310
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message affdab40-a459-4e7d-bd58-7861c05eed59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2eff75e-2fd5-4c11-8711-1fa2a4e6f1de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0a591dd-2f19-4e8c-b68c-7b6543806565
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6dbdae4-9b77-459c-bb8c-605d8d8bd1ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 424ccf7e-8b77-4312-93c8-c2fa10822563
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f0acaa0-55af-4e9b-a8ac-4c631c1067c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d083ead-1caf-4254-9722-b0d966b1aafa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4fe4025-4b1d-42fc-8d3a-b4a6617eab4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32ac3762-0cab-403b-926f-d2560d036c5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9aaf4f2-6b4b-4935-884d-b1ac9adee5ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d68c6f3e-8698-4ad1-8f41-4106b098c273
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28049e40-c76a-4e09-8051-5617f8526e4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f80479c7-7951-46c5-b162-e64f31e3e15d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca969287-feb7-418c-b9a0-6feed7ed2821
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5275a0bf-4921-4437-99f5-d89856c44fdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43f65235-e999-4ca7-8e94-e6856e5aa7ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 709dbe77-2ff8-4f49-a16e-cd5080f7c6c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd2057d5-7480-4f71-85f6-71ca1d7f9ace
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf350f80-b14b-4813-a4b5-4fc556a568f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff2ce53c-1533-4b02-abca-de987e4bf3d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fbed7ba-2ef7-4673-878d-0aafdf731e4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 855f5b9d-9c0b-47a1-b4f3-deb01defebaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da432b51-f463-49a6-8672-1b5436b199db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67a702e4-485f-4ed1-a8e1-4ddc4705f531
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d92e5666-356b-445b-89aa-fdbc483ed856
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7174bf1c-7274-4ae8-854e-a954f825cc1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8439428-6345-4276-9246-494862181e9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd5fb1d8-0f38-4c90-87fc-3204afaed3d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35cb8bf0-6d4e-4188-8d3a-0b962898dd8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a3b99f6-5d7d-4557-9da2-93f61104713e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d40b0b5c-f735-41de-acb3-9da267851ac3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26f44046-0336-4c68-9876-7b6a8c240ce4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45c02c21-b65f-402f-9fbb-bef08c968df0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7413e0b3-8f41-429c-b366-92c0cc34eea9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 831427ba-c452-4ab9-b1e8-f8559ace7392
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 877e34ed-9e6e-4b26-998b-e0e0204e313a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3342403-4cc0-49eb-973c-4999b4d4878a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a6963d0-f4f3-4014-bc63-365c92f68aa0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86be564d-589d-4976-9369-9f6e5d3bb450
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 758ce49e-b3bc-41cb-93e3-0eb280ef2001
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1405063e-bd5e-46e4-a3e3-7b6e91697ac7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 043c7fb2-45a9-413a-9e2a-add5f97eecda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a5da47b-84f3-4db4-a946-40c6f7dc9044
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22db5515-21f5-44e0-b355-3c5010da378b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae7740b3-f9c9-485b-b19e-c1580eb26a66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6bccfb1-c194-4b05-ae08-63eb9cc4bcf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd81fc71-9739-45e9-a5a5-13ecad2f49ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3653fde0-60f4-43e8-9e23-c8ab2c6e4587
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c7db841-e741-4dc5-9545-03d058a4b038
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3a27750-c76f-478e-95fd-e91412b66093
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c25c7d44-146e-41be-9d6a-2f004fa082c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbf58d75-8a34-4fa2-93a8-d22b08a99d23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58465c2b-c5fd-41d2-84b4-00b04c0bd7ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9389c6cc-3d43-43dd-b7d0-d0a1b9528fa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67beee87-7c41-4ebe-aed8-f05c806b444e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f5b28b6-3755-42a5-b8a7-5df272193065
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52ae2e5c-7109-4c25-ba99-ef27fffdde6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88a8c225-a527-415e-98d0-fb5de5f6bdb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45921af4-84fe-4e72-ada1-c765b7f1bf35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51cd1b23-0e82-44b4-a462-d65ab0457807
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a4f31d3-35dc-4567-ac07-8b4c37d75f98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41cea16a-8bc0-4dab-b9ed-4ebbdf7a3eb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49ffcf05-3811-4881-be65-e8b18169953e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 960f6220-f201-49b3-82c3-8a57409767a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6618694f-ada3-4084-b2f8-903a9236d4b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8af61b8a-83c5-4dab-af99-77b42604a71e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcd9e6ca-a42e-4e05-b711-c02a5f78db85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59461d66-642a-4859-9a15-8acd4bc95b62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55f6bc59-7e5b-4efe-b541-2e3bbe828f75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92a11798-2d84-4072-b9df-3f43a719292f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19662a21-e4e3-47c4-9553-62a0f4f7ef5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 227d02bf-1b73-4eb5-9680-5bd021a52d70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43f4d489-8be5-4223-893a-b7c2c5d73ea1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac3e852f-acdf-4ba9-b74b-267f445c7d27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0b826c8-7bfb-4c99-b6cd-e2ad3a1cdb16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b7c134f-e318-4ddf-b7e3-e4ab0a8ab82c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a7f59a7-a87c-4134-9400-bce200d0bb5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e92acbb9-d435-4776-a98d-71a91d106b4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16010a05-e854-4287-85c2-a5de52a9d962
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a48f6ce-3142-469e-a935-f546ddef8d01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe1b11e2-165b-4234-ba63-10a5f55725ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 220a3ea7-8026-42f9-ba7f-4d561c3a19de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cad1de75-71be-42f4-9102-35a1643632ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f4be6cf-37bb-43f2-81e3-337093d88bfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75b0e780-230f-4059-8d94-e3c087215ca2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a20129c-0cfd-42bf-b674-51566a15cc53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f42e16ca-29b7-4f0b-bb13-52a87ad44552
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb4a1b50-27dc-4abd-8df2-c54b615b332c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10320b6f-ac5f-4f97-9584-dbf12b22fd35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c7e7741-7684-4bc5-90b9-6643a3b84021
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e33e5cc8-2d19-4c48-975c-9e4ac77ece4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8997a311-255c-46ec-b339-f36c1a462722
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b85f0a05-4af5-4833-810d-1e7cae918da0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2deaf10c-86ce-4160-98af-ee5683974d4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 650b01f4-4294-434f-a35f-85d9462fbbb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b5c7cff-eff9-4e1a-a429-c9dcf44e24a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d301e76-2f52-4baf-86ab-6b10e14c4359
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa4d4034-3b02-4b29-b9e1-09ba94e09d1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8ffee0b-e22f-4849-878c-2412bd6361b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5166ca0b-fd54-42a2-ba87-9cc067bfa214
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0bebbae-24d2-4fec-b4fb-dfab384fecd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ff0e232-cefc-47da-a2d2-494d6ef2ff17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 096300b5-a15a-4c9b-a7fb-8f941dcc2651
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edad1895-85c3-436f-b8f1-0e05cda12986
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c525c870-d921-4a49-84f5-560c21eb9c4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4c3474f-87b9-4a4b-9df0-6e622462faa3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fb10079-caf8-4ac3-a247-f953def3fc97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a348ac6c-ec98-4789-afe2-86739b051b08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bba356b9-556d-4619-ab11-6777efeab705
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13e3d888-e7c0-4155-b239-24c4f23b8cbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 462a4fc5-4f4b-467e-b016-454b5caebdae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a1c3cd2-dd9a-48d3-8fe9-a7ebe09b5076
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffc170b4-44a5-4dd9-bde7-1c750a4dc675
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 349c88ce-c4a5-4152-baa3-9b1e6dcb3b31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 582ed0bd-28eb-482f-929a-e10db958cd52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0be02a9c-d915-42c8-a8e7-c15f11afcf9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44558068-e35d-451e-9bee-7edb1b8c7da1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3eb32dad-e398-43a5-90ba-c949bfdd4648
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7f5fe23-7243-4387-bf2b-d5feef89c495
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be941b99-4bec-46fb-8950-9dc59f7e6869
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 226a9691-e1af-43d6-b1e6-fbbc5d28f259
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edee948c-3f56-4b01-8c6c-101187953e66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70543a29-e9d3-4827-a40c-210547801a9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c09bb07d-367b-4403-afe4-c1c89b990b9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3040088-1aa5-433e-ad99-c51dc362439f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f860981-ff69-4792-8c23-93a03bf117a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3cb3b3e-7dd2-4af4-b9df-c1529da112b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89fedf85-89ca-4309-853d-9d88ed4d3374
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3c2c092-f832-459b-9ddf-af0f70aade5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91ab97bc-1105-401c-bb4e-e4d7af6a0b5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcc47992-04ce-467c-a831-f1333320db3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e06123ac-916a-4279-bcc9-ae4fee0f8f3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce06b702-c878-42db-be2a-c4d07c1464ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2a017d1-85aa-4d53-ad89-3a71d3a2d51a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b3a5076-865d-4ef4-9d8d-e5701edf9afb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa095af3-62fb-479a-b8ba-fd8d9cbee527
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4388938e-d78e-42aa-a21e-fc00c3573693
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bcfd685d-add1-4609-ab46-5e8585ccf1b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e90419c-7fa8-4832-8fae-c865c8cd1511
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fc432c4-56f0-48b6-8fd7-194ffa46afce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b6aec52-e17c-4d89-8a3a-f00c77072767
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcf40898-c167-431c-898a-c1fe22901a82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3aa68638-4194-4447-b485-c3aca8fde217
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7744428-70a3-49d4-b53c-bb6b4268147f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8f6b765-3549-414c-a6c6-bd5211f2cde0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7f9f326-d57e-460c-823a-52e16a339cd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message deaef47c-e751-4142-a895-dce9260fdc19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6a92b01-7423-47fa-a5f9-baae6ec380ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ab4e4e6-cd3b-417a-a148-f593221c5d98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09cfb6c5-a5ac-4710-9a14-c042132a7508
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52e704ee-fbce-4487-b1e9-f6e40e593fe9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42e7d0f7-3c82-473b-a9dc-aa5a47e43d36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92972ff6-a085-4f13-8545-0964718c4474
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b054b3e5-37ff-4a24-a6ff-d216c38c5736
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42724259-04a9-4919-9817-3b2b30b331ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf7ade20-ba14-4db9-bd94-47adef9c4c32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2694baf-a63d-414f-a5cb-db033f2f7312
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb6472fd-c4fd-4c0e-961d-4c4ed75bbb4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0e1be92-5df0-4497-8c68-6813371257cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d26f4ebf-2f81-404c-97df-615e3cdaea37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35c8777e-5be8-426b-846c-7520020d639e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02a62f00-8496-4558-bd29-0a7a107dc7b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aedc114a-99d5-48bc-9485-8791f0ab5137
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa643ad9-e2d5-4d1f-b621-f1b80ce873b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb80ba2a-e4e5-4593-9d1c-039939866a2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f57f8371-2644-45eb-8be3-cbd5c67e4b28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa652393-4d7d-4b00-a179-94e8e0872a97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e46cd05-956e-43c0-9212-54ba81681472
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04ef9c85-6676-49ef-babd-9a460ea16653
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fb856a6-90a3-4b29-a7d0-b76fb139ad3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc3537a4-f47c-46ac-8f48-935977936d3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd48245d-c65d-4efc-8fb2-bc0ad677a5f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0199d12b-a91c-4a46-b09a-830c18e04f8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a2afc62-85ab-4dc5-bb07-138ae1157c3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a95e2abb-3617-4563-b3f7-43e08b3d977e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ab25982-29d1-4e62-bdd7-43d94fbf1772
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b8ed4cd-de21-46c2-8b38-440be9a3737d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83299f17-f64b-44fa-8f36-c819bc069de3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6d2c3fc-b02b-49ba-8256-7e5b200d1f90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c005e08-4e1e-4286-984f-2bcbb0b08810
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae6d49cb-e499-4317-8ca8-9b9c2a19d99d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2671109e-0471-4088-a9b2-cf16dd058475
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 928b0e13-6349-4e96-8170-bf2b3d8d3a5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3aedfddb-c047-45f5-953f-26be2502448e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9e01ed0-9023-4605-b8f1-b6237b341c65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49ccf331-7e00-4920-bdd0-cf456f40d434
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e16fa87-c407-4ea4-9c4d-7b411f36a0fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c33d82f-af42-4b3f-b136-b37c2613a3f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5ef9065-d664-4db5-b63d-22272fd319d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 194cc14f-909b-48a2-a0bd-67acd70fd9a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cfd44a4-2dbc-4dde-8132-1765a4134f32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21166eca-0514-4f60-8a67-346e9d1ec087
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1afdd437-b841-4b1e-a879-891a28a20479
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8ccc223-66c8-4da4-b7f5-74217ba95edf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43dc577a-fd1a-49f0-b9e9-8251e30d6226
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 716ef385-9ced-418d-a548-48a527841a67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e77eaeb-07e3-4065-909a-33fdc3393e61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a118b097-66db-472b-a3c7-8e7a8918ec60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3af5459d-8a44-4db8-8926-3b3e9dccf75d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ed2f43d-c9b5-47b6-b1b9-874c796b3f77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3282e4f0-893c-4993-a6d7-b9505049562d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba75f8b6-f28f-4754-9e96-15c60d08fa38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8079f6f8-2852-40c4-be0a-06a750f618d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 406496b7-4a8f-43a1-a128-ac6b7b1532fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e403585-2948-43ad-9482-6b794842c5e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4ae71e7-47a2-4d27-95e2-a7a81555bf16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7220a47d-1cf8-4b19-8284-f0c803d02697
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a956d41-0539-43b4-85b1-2c5e1aa3d649
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee0c2739-a995-45a0-bb60-9f9439c94141
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95fa0def-e78f-468f-9b95-e9c7c4510392
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6350b3c8-9c13-469b-9057-776bd00c1180
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3aa1e4e1-8493-4e89-84ac-f8341d3c292d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58bac844-95f4-4bb3-ae0b-a077d34c6892
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49191cb2-48ec-4501-b245-f0312c330ec9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98876eaf-8822-41fb-8ac6-c8b50d0932f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c524b2da-0571-448e-8457-fdbdc7222438
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7114bd9-b862-4399-840d-0f673b96a67c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03c910de-9c3e-4302-9f92-dfdcd58a2bb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48628dec-9df5-44fd-b040-b4c3fa69ea6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc34ec6b-1c5e-4ca5-adde-84b67ba98bda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea772e12-58f9-4d59-a903-799a847f113e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 463cb565-bef1-4e6b-bf0e-017c6f0594b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8419e10-6f3c-439d-92dc-beca5cc35b44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9dc8e24-3828-40c8-b526-74f0e3ae5512
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45d85ffb-b588-415c-a113-ca90dee077a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fdd5fa5-7dc7-482b-b353-92177f7eaedb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd8e557c-7713-416e-a621-ed4a8a3bfddc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8beb6215-0109-4a1f-aa27-82241062241b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84b305ce-9ea3-4220-9ef1-67a7613461a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cdce22c2-b0fd-4b88-bf8f-bf15b7e816fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10ac197c-6232-4c81-9326-c10915066a27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0a01ff5-6d1a-4425-95b3-73c6bf537d10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80da305b-7a46-4dac-ac32-1850ce0caac2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b0b4abd-c2f5-4ccf-aca0-8597300b9849
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98354636-e4bb-4c33-b329-6713b7373e40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee957b0f-44bd-4cc1-8a16-362eb3e57ff5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f8c929f-ee92-47e0-80ef-1ecc365bf669
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a4145b4-04b4-4e96-883a-b1126f85f68b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e67390f-b5db-4892-a79c-af992fdbdc8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c47530ac-9ebe-4222-ad98-d9b2f8940a4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82702682-fd17-44dc-8f6c-ae3203c01663
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6456458-36ac-494a-a116-ca29801ae9da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7bf35883-a26d-46ba-89ad-5af7e7392806
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e94ffe1-abae-4c51-b61c-dd0039e3b14e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3298fd96-a245-427f-89de-9e066325091d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5555e48-55ee-457e-af84-4b0cee8215ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19610f91-5e80-4b5f-8d85-d117b5b401b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b70d944-7343-445a-ad9e-d0fa2da746a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24167cf7-8bcd-4972-9dec-e5083ca4e840
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23db3f0f-e36c-49bc-a1ab-8c68e83d8f42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79e3d4fb-c391-48f7-a4fb-7d6c7240f9fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bac034e7-a284-4ce4-bdf8-76d8fb549378
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bdd31e4-5f3e-4d48-95b0-1a1e2923096b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20904c52-2fe7-4ecd-a967-62a851f92d76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6b3b525-8f44-4d6a-b706-c14e531e7d60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fb874aa-4e2c-44ee-82cc-a804f24088d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24e14345-9857-4ef4-ad92-35e5f6226008
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9a427de-bcbc-4b74-bf7c-6916c5123754
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59653f36-b533-45fc-a449-c65d77a30bed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ae24cde-b054-4cc7-80de-151a541f0603
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d0f24ae-f1e8-4446-a35b-0067a7ac44bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ff2246e-2b85-4156-a4ea-0488833766d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad91156a-46ef-4a03-9532-2275f7fa1f62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69ca5114-7f45-4382-986b-c075666db050
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 638c447f-7114-45cf-81df-e8662963c235
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7ea846b-9fa0-499f-8d28-23d044ebe825
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a0f9871-1109-4cc4-a9f0-2682de52414b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7a5e7d3-a12c-426a-a904-72541cc34e2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ed206e9-a248-4b55-bc3a-cc13ee905bd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4d3c7fb-728b-4681-8e18-125d0c948e09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1985eb10-4d65-48b5-bbc4-a2d24dd73f03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4df71880-a9f6-47ea-b7eb-ae0be612f04a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 070dfeee-1705-4ef3-ba15-7d43820bb24c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 264995df-48f6-48a9-a8cb-a3b21cc7c27e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4665e7b1-8c5e-4199-9d89-ee7832402275
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 567d009f-834d-494f-a81d-a4e66c300fa6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b504add-3a3c-4516-a854-d6dbe15e31ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a1e9e54-4258-4d78-8834-828d03f57367
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2e3b0c2-4e8b-4e17-be9d-15bbe3d672b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ec4be94-6921-4729-aef2-d1515a7e3906
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9c574ea-7852-4613-9c50-6657b8890434
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48db376e-452d-430a-9b1e-7cd9c72650a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d75fa94-443f-47ed-818d-edae717cf4bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c7b6bc1-c94b-4d08-87e8-2b48b61602a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea902f59-79e0-49a7-b243-98f19f7c307e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e6314e7-6a54-4cff-8c0d-6e0c63f87a2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56d48638-b04c-46b9-b221-0e94161910b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d735cb8e-23c6-49f1-bbd3-9f49f649c8ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b20ab664-e891-441d-9f59-44e180867512
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 979b906c-7bfd-4d8b-8fd3-259ed9ac20e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93f0c8b8-e7f2-47b9-bc09-1a60a26d6669
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27dbfaa3-eaa4-47a8-84d6-8c1f7879da7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3dfff048-d606-4fbe-b1ef-9712384e45cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78e692eb-98e1-4992-a8cd-7236c432a0e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 613c3dc6-12aa-41d3-ae86-fea86215e87a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dae14108-593d-427d-85c6-51a4cb72f9e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a0f729a-f338-4a6a-b030-fc03c6aad169
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b21885be-dc0d-41b2-a4a1-be1b85c48f55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eabb9442-efcd-4d0e-a90e-3310d61b7de0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30c86cd7-50ef-4a19-963d-efe732d577bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0507e681-abe2-4b5f-bf74-db0c7fe32532
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d8cc3ca-d6f0-4e71-b138-69f174d1e57e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09f5847d-645e-4e33-b89d-49b6da808bf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07d1afaa-c006-46bc-9a1d-bde4c7aa9bf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a93e1bb6-25af-4c4c-9dda-3e8c9c5d2f76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f56a644-493e-4575-9710-225c3a938fd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c8ebf39-5d8b-4e37-b0fa-9648d93e8988
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 450afe1d-deea-4a20-a21b-2287b864b2b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 481f6bc1-2586-41fb-b002-2538f4aee79b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0cc0ad66-2f9f-4fa8-85cf-7ca1a9d45663
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5b6b570-870e-49d4-9ef0-4354dc34b66d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fde3a177-07d1-4176-8170-a6f1d5d471f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ece973f-b4a3-4ac1-bcb3-9beb069c832f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18147ba9-b59f-4084-85bf-ad98ab65e760
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6432c12-caff-4f8c-9f61-e1e83b8ec65f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec7bac4a-6638-4db4-873c-b140a39ae3bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6c6a94b-ceff-463d-8b8a-1363dd214e7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9260fbed-9ee4-4a22-8405-14ea935b36b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5806aee-55eb-4854-87b0-9d2c53512f43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92b129f0-abe6-45db-8a0b-218aef52ad69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 196be1cf-38fc-4d61-9459-ec424cf0863c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63c4ef3e-deb6-449f-92d5-e7f4c51e4f5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42d2a5f0-5951-44e6-8d8b-9e335693f833
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d27212a7-2363-4adc-b5df-554e8bf524e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 065029e1-252d-4db4-852e-0d101c4930f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e72ca52a-f812-4096-8593-31a9c21facf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 693271a6-09d7-4694-a86d-c66f33d21eaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b2d2872-81f6-41ca-ad1c-84610296f5ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 115d13bb-2f10-4da0-93fd-89cc265cc049
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8191297-7d04-4cb0-8490-039213544832
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cebbc9a2-7a94-4a3f-b2af-399911c8ad34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a16e59e3-e338-461c-8a9f-6c112ce1f31d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42cb2c43-9357-47a0-8557-2fb7d0e5741a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8aacdc9e-3bcf-49f3-9275-eb359c951ead
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c718542-266d-46c7-ad0c-d93930b61a30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 803bc6a1-7dc5-4f25-8744-61477dae0dad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e4b9b47-76e9-4efe-bc9e-2e3d8485b527
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9afd7d61-8fdf-4ea7-b728-96bed2413f99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5c0de12-51e3-436c-b463-1b3581201cca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42c0ea9f-c54c-4af6-8fbc-078377853403
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce1cab39-6714-45ba-881b-f64b5b287caa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4122c930-ff35-4c9a-8743-bc5eba0fe72d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 999ac121-2560-4b98-bcba-3635d6ec9e17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa544f1c-c0f6-4830-90d6-6ad7a8cc9b6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7eedeb3b-0cce-4a44-998f-8d4330042423
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7948a09e-9b6c-42f5-98c9-4a80d996f3e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba111dea-5ee5-47a9-8233-c6ec4afa797f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7e5fb4d-6af4-423e-af3c-f2e71e367492
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b23607e-07e3-44a4-a35f-e32759eb8aa4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89c7dfd7-2478-4aa9-9a9b-0810a19f0539
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06f8dfca-45fa-47b9-af27-4cf1bb065b58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67f4b17e-5683-43b2-a696-f12a09363d21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77827201-d964-4c6f-9fa5-9b486586f20b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2a419e4-e6f4-46ad-b257-1be61c873941
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00d13d70-3d49-4af4-9358-ac6bc85d64fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 411a4cca-ce0b-4a1b-8a3a-29dc24ff2d60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f1833f3-c07d-4df6-9b4c-fce83790f096
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ae907be-5090-4906-9285-7ae2b1543a3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f952195b-f73d-4641-a978-acf7fca4d6bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6807c2e-806d-4f58-ab77-926b44e1ef43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2989fa5-caaa-4b25-8213-0f1e9d21b93b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee581dcd-fb19-454e-ace9-2b2f20a34fc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c1b5b8b-921c-409f-af1e-ee48a6d0f329
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c0ba5ce-73c3-4fa0-ab8c-2d3dca5818fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4792decb-6389-4ee6-a065-c419354402c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 267058ce-c893-4a27-a0b0-d047db77be5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69eb0254-37ef-445a-9d2c-fdd77cabc093
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 366ac2ad-60d3-4415-a0db-aad28f1759bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 010ab3dd-2ff5-428f-9b91-1384b8e7779f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d26000c2-3ae7-462b-9cc2-4718315ed271
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cff63a8-d8ff-4135-aba7-1e0e78060da2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 476c410e-d5f4-41f7-a4a3-1c4b4130d335
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00ff9f89-dd48-4e58-a6ea-d53d1823295f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a8b37aa-b7a9-4777-8f34-95fdcf9854ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14493a43-c333-41ed-989d-b6e072b606c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9703dd13-9c59-4a9f-a145-39fbac8ec160
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a79da600-7ea2-48dd-9f9f-04bc45320fee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a958d085-7485-4d93-9d06-63f4053fbf8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 265612c1-38d4-4d33-8e7c-0c3c03c35f4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90bed420-5e74-40ee-9625-2cfa1ec5c77d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12657459-ced4-4251-9779-16507c3069b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ecc18bf-aae7-4cdb-ad20-ffb0a0b90f7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e56d06b0-9af5-4c9c-b36a-4a5baa244318
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e5d22fe-754f-4117-ba12-5993bd1096bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a921f350-afa2-492d-a0f2-4747b69b70b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4221d49a-bfef-49c7-bd05-1bc341cb5f00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4218d0f6-7afe-4f05-bcc9-a15e6100a11b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2d92614-ee98-4c04-a500-6c15038aa7e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b748056f-3687-4958-88a5-d70398b2556d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f33470c-7994-4285-b6db-113f75944f9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d867a5e4-eb29-44f4-b982-571d39e8c0a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 591eb68f-f514-444a-a6cd-0cd132c42b99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7a405b1-2f89-474f-be56-c55268dadcb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6cf6393e-4740-495a-b1a7-386141ec601c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc43fb97-dc7f-4698-8098-6141526b525d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1071bcd-c341-49ff-baaa-79352b8e3a86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bee6a20d-2a40-4709-b478-96d3a6028ee7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c0505d3-4d9b-4880-a4fb-ab755199dcf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7957a75d-73e0-45ce-a953-39c040618f92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bb8c0f0-e092-4ac5-aaed-4bd0b6e123b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d909cbd3-1353-4971-b3de-5dfc2a7c78e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db279b06-a949-4fd3-bd16-cfc31e93486d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09d7bd43-5960-46db-a588-798323aa7e50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26047ed8-8797-4f5b-9f70-bb7e40ab56fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d12fe6e-53db-411c-8db6-eeece057ecb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7195c9aa-61fd-4af6-9dcf-f47e5dec5ea2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb7028ca-da0b-46dc-8bd4-477a8a713f7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36d34d76-3b26-4d87-8276-7a157f0b0a5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a926923-c483-43e4-bf56-4ac999359114
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7e69fe5-2c27-4fd8-b481-98cac88770d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9003dc02-fede-4d09-90ff-b83f0f5d2428
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ed9c6e6-d122-47f9-8ee2-1e96e118c983
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 521e20ff-f78b-4ece-a93c-cfdf8a0c9d23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e3ba5ea-dfd8-4281-904f-01e0a0311cf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a04026b1-e9ad-43f6-9218-fe1d1937869a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffcb570d-df16-4289-987b-e38bd62e1783
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message feaf3062-7dcf-4524-9635-c9fd9abe0a1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97f5685e-907d-4b06-a769-c44ec5f30c31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4391b04-bbca-41f4-8327-d635ce508cae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c61b6d29-a764-4729-91af-5cd84a571461
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ccae15f-d467-430d-b05f-37df496e90e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81bcb23c-c399-4574-9afc-4472aec7a013
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2e2adfe-e4fe-4168-9787-cb85bc034ceb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1e34acc-6fcf-4657-8ee7-3b11d9cf1245
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72e615d8-f28b-459a-8c29-0075ae800e0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcce9196-20ae-46d6-9b73-788a49f244b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8a654f9-3f69-41d1-babd-0afcb43937d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc03b975-f19d-4888-b995-7c184dede1b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51a7d280-b144-409c-ad09-aac7a58fbfd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77b1068c-4656-489e-b2d3-80641c2d74a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfc456f4-c9c9-4475-be42-616f0d34f482
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0c63071-6201-4c69-9cab-90e6533ddfe5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f91ec91-bbfe-4d5b-bf4a-2a8a17471744
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f92e60d3-0e7b-4e24-bd81-4f29926c5dbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31ec27fd-0aca-4614-aecb-278aebce1595
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ec4a489-5777-4280-bd6b-943d867e570c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c28009b-d045-4b02-ae58-b91f0e02af65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 903505fb-dcbb-4b3c-adb0-41c573ba6147
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56f4fa4e-ee90-4355-b7b4-f21d6cdf4b0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 476a27c1-17f0-4453-bb86-eae6b1ac0102
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfb3d370-ea78-4ae2-8676-0ffafa7e5b02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b45b29f7-10e2-4505-9331-1312206db912
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9b65008-0ec3-4dd7-8dcf-13c75f14da51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9acd8a63-94fb-4f25-9891-2da60e9203f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33fe43f7-c7c2-46fb-a709-906385d3401e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee87ec43-0d05-4959-bc9a-42963a385a9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ead43f37-57d1-4f6c-bbb3-801ed73b2591
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ec35e5d-d8f7-4054-a046-4b09809ab6d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d18c52a-6305-467b-92d2-701012253193
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77b2ff39-0ffd-4693-81e1-a722533c9e24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f3b1ca3-713a-410f-926d-ddfe6cf02083
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a47eb27-8213-413e-a8c4-43de8126c4eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1c91537-c5ff-47df-84d6-b93a6db75884
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff2461b9-f0a6-4e74-bfe9-98c7b9768917
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3b9f421-b156-461f-9e49-9b01cb75f6dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef401ace-6b03-44ee-86e0-bb5252b8c640
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d5435d2-d6af-4061-8684-cf843095985e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71605c15-230a-468c-9dae-c61f178f5938
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4c6afb8-bf62-4f84-a512-1232ab5a62ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b024f495-72d2-4cd0-bd80-03c027acbbc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 930434f8-d59d-40e3-8d37-7f5a28c49281
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 873346f1-f559-45db-b35b-e741fe403c65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48a7af64-e35b-4d40-a856-f09a60ad3a88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d2eaa8f-b009-4ff3-877c-44ac3f10d2c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43f42146-9cfd-496a-a48d-01d3b3758177
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e23c7341-53fb-4492-b02a-ca790d634a3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc3c26e4-9672-4e7c-9c56-369b9eba22c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9730a215-c501-4530-91a0-7d49b4e96f19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 038061f5-4d88-4da2-8b7e-e3b693ac0943
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7e1c1c2-8f0d-41cb-894f-38d26348df64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81595e9e-80fb-495b-9d09-109204de6e38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a77f5cbf-92d5-4a99-ad99-a6351b86aa9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dca6f9d9-f16d-4921-bc1d-89d380ee35fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc287faf-371f-4b46-96f9-6f025e81f248
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad8a9c0d-fae3-498f-a8e6-ade7de4b31d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36eaf6c2-9c25-4173-925c-af3f9e52cf1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0beca304-0b1d-4232-a0b2-067fde82f9c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0fa8919-926e-44a7-9174-692408735e24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88c953b1-b156-49e5-a08c-9a597b0c6211
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb8e33cd-415f-42a8-8e52-597133ce2295
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09cba909-73f3-405f-b885-99a423ac9aae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d1dcae5-b7b8-48b2-8e7e-57280e100969
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1db90229-2f27-4302-8826-84d78cd4dfce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e09f7e7-f6f3-484d-96ec-6b48742b66af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e57b6a1b-c569-4ad1-ab33-d941fe235b13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 282694bc-93ca-4689-8842-6e2bad1d0656
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1a2f024-f054-4ecd-bd0c-4b97bb12f76d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64af5134-0d78-433b-99da-20e8240edeab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bcb8a31c-28df-498a-8870-4dc700090841
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74a64c27-4b57-4acd-b960-74244af86c96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09457def-0ef1-4687-93d1-170751cda476
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce254332-1a34-4730-b3de-167d22741248
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51c81622-c473-40a5-a735-febebe683bcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98ddbbb0-759f-4b99-984e-5ed08cb698c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99c5c6d2-7289-49d0-a3bc-ac13e6b089b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b35e7b7-f327-47e1-b58d-0988ac666f33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 689c4e41-c742-44e4-8042-d9724a6ee278
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d30459e-729a-4c9f-85b1-94ae07529c29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce53931a-6164-4077-9eb5-148d8c93d44e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d5221cb-789e-44b0-b722-6fff846d3373
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1d57d0f-e926-44b1-8c71-a64801a98f26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2e631c4-abbc-455c-aacf-43be8b7621fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3deae8a-6960-4451-bb1b-5b7f5fe7b135
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ea0125e-a395-498a-b3bf-5b5d97a805fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a455f80-a7c1-4b3c-95f5-be75cc71d343
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e59fa9ef-7a28-4827-8743-25548c7c5852
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23d009fb-7638-418a-9d4b-e8379f2ddea3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3a7ff30-6831-4f4a-b32e-bbd8071f00af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31f884d1-c564-49bc-bed8-95205129c881
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 439285ad-2a24-4fff-a113-aedb0e10b1d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 354feb9b-e03c-4ea8-ac4f-416840dd74a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 234cbb62-553b-4fb2-9a27-a8283c95f7c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b137941e-f10f-4e38-8d67-b9478824f6fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36207bde-7aff-470c-8e1d-cdb6a075e1e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7833563d-e46d-4911-bb34-032461f81744
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9a63b77-b37e-4e40-91dd-eca73d7c9639
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b529f63-b8dd-464c-a276-4cf23e336169
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bdd6d1d-2a4d-4257-ace8-a62caccc4a4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4007f03-6093-4607-b24f-e9fcf19247c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42f4da61-895f-4eae-a544-130ab9141d18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50685951-13d5-4088-9e86-a600779c1346
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89579800-b736-4815-aa8d-026f728ad4e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79cb9fed-e88b-4663-beb9-bf42f228ef5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e17a6ce-6d6d-4953-a00d-c67cc1a2ad37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29dfab4c-ae12-40aa-9b39-300a24e3ac64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72311ba9-9cd3-480c-a246-26dd5b6a354b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21da05b0-3ff2-4c78-a93e-014293723c18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 469601b7-07d0-4836-85bc-ec4b8f73a9b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e817d5a7-b20e-4c5b-985f-1822cb5ae877
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6f463e9-4722-423f-9fb6-a9dd631b3886
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc68c96d-c2ea-48fe-959a-9b1918717024
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 333fc386-4d99-4e2f-b144-f233d311719a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 992b9b51-4c1a-4582-9a8d-9a4ef23630a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c30e4ee1-61b8-4e4a-b8ee-3c43a02cee3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c616dc8-236e-4379-b848-ebb353958f58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65fdb756-760e-41ed-a4f4-01004dc34c66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16d073f4-9517-4c36-976d-a3aab6bd009b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d0254e3-8ef7-4323-99b1-3aebfca86f08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e728cab3-be23-4411-923a-4b1c046a0dab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3dbc934c-d160-4799-abc1-0b2ea0ca61a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2a1a757-c4c6-4280-a5ae-139854c41b14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f7779b2-6d6d-4e65-9d90-99fd4fee60f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4129bb24-5337-470a-9728-bfb2c821fcc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f673308-a7d5-40dc-b209-d2a146f93ac4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c04464a-f95d-432e-9640-25e6faa9d441
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f8d3dff-7000-4f32-9b59-302534781f95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50d993d9-4eb9-4e25-8b1d-e9e26f20a585
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ceb7d52f-8bbc-4ac7-887d-8f61792f8168
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be3f15fc-32fe-4363-a57e-588d2e62ea68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ad75264-0c3e-42a6-92b1-0787a1c30589
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6738dbd-67a1-4033-802d-a2a61bed4a4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f6d91da-4ad3-4f39-be2f-e0bf552e2c2d
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_9
Server: localhost:8686
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_9
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_9/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_9/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_9/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_9/test_labels.txt

📊 Raw data loaded:
   Train: X=(5643, 24), y=(5643,)
   Test:  X=(1411, 24), y=(1411,)

⚠️  Limiting training data: 5643 → 800 samples
⚠️  Limiting test data: 1411 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_9 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 2 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0829 (↓), lr=0.001000
   • Epoch   2/100: train=0.0832, val=0.0893, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0848, val=0.0964, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0848, val=0.0926, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0833, val=0.0876, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0797, val=0.0839, patience=3/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250
   • Epoch  21/100: train=0.0778, val=0.0837, patience=13/15, lr=0.000250
   📉 Epoch 23: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 2 Summary - Client client_9
   Epochs: 23/100 (early stopped)
   LR: 0.001000 → 0.000125 (3 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0269
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0875
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2471, R²: 0.0030

📊 Round 2 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0046

📊 Round 2 Test Metrics:
   Loss: 0.0810, RMSE: 0.2845, MAE: 0.2471, R²: 0.0050

============================================================
🔄 Round 6 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0927 (↓), lr=0.000125
   • Epoch   2/100: train=0.0773, val=0.0928, patience=1/15, lr=0.000125
   • Epoch   3/100: train=0.0772, val=0.0928, patience=2/15, lr=0.000125
   • Epoch   4/100: train=0.0772, val=0.0927, patience=3/15, lr=0.000125
   • Epoch   5/100: train=0.0771, val=0.0927, patience=4/15, lr=0.000125
   📉 Epoch 8: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0768, val=0.0927, patience=10/15, lr=0.000063
   📉 Epoch 16: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 6 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0067
   Val:   Loss=0.0927, RMSE=0.3045, R²=0.0016
============================================================


============================================================
🔄 Round 7 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0815 (↓), lr=0.000031
   • Epoch   2/100: train=0.0802, val=0.0814, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0802, val=0.0814, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0802, val=0.0814, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0802, val=0.0813, patience=4/15, lr=0.000031
   • Epoch  11/100: train=0.0801, val=0.0813, patience=10/15, lr=0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 7 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000031 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0042
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0036
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2471, R²: 0.0032

============================================================
🔄 Round 11 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0751 (↓), lr=0.000031
   • Epoch   2/100: train=0.0817, val=0.0751, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0817, val=0.0752, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0816, val=0.0752, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0816, val=0.0752, patience=4/15, lr=0.000031
   📉 Epoch 7: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0815, val=0.0752, patience=10/15, lr=0.000016
   📉 Epoch 15: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 11 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0038
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0099
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2470, R²: 0.0055

📊 Round 11 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0056

============================================================
🔄 Round 17 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0788 (↓), lr=0.000008
   • Epoch   2/100: train=0.0810, val=0.0788, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0810, val=0.0787, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0809, val=0.0787, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0809, val=0.0786, patience=4/15, lr=0.000008
   📉 Epoch 7: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0809, val=0.0785, patience=10/15, lr=0.000004
   📉 Epoch 15: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 17 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0023
   Val:   Loss=0.0788, RMSE=0.2808, R²=0.0056
============================================================


============================================================
🔄 Round 18 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0857 (↓), lr=0.000002
   • Epoch   2/100: train=0.0794, val=0.0857, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0794, val=0.0856, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0793, val=0.0856, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0793, val=0.0856, patience=4/15, lr=0.000002
   📉 Epoch 7: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0793, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 18 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0026
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0051
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0056

📊 Round 18 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0056

============================================================
🔄 Round 25 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 25 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0017
   Val:   Loss=0.0764, RMSE=0.2765, R²=0.0102
============================================================


============================================================
🔄 Round 26 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 26 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0051
   Val:   Loss=0.0760, RMSE=0.2757, R²=-0.0322
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0056

============================================================
🔄 Round 29 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 29 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0008
   Val:   Loss=0.0811, RMSE=0.2849, R²=0.0043
============================================================


============================================================
🔄 Round 30 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 30 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0020
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0091
============================================================


============================================================
🔄 Round 31 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 31 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0026
   Val:   Loss=0.0841, RMSE=0.2899, R²=-0.0008
============================================================


============================================================
🔄 Round 32 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 32 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0017
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0051
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0056

📊 Round 32 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0056

============================================================
🔄 Round 38 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 38 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0008
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0108
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0056

📊 Round 38 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0056

============================================================
🔄 Round 45 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 45 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0012
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0093
============================================================


============================================================
🔄 Round 46 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 46 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0047
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0196
============================================================


============================================================
🔄 Round 47 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 47 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0010
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0047
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0055

============================================================
🔄 Round 49 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 49 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2828, R²=0.0012
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0045
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0056

📊 Round 49 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0056

============================================================
🔄 Round 52 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 52 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0015
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0109
============================================================


============================================================
🔄 Round 53 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 53 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0031
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0042
============================================================


============================================================
🔄 Round 54 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 54 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0031
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0027
============================================================


============================================================
🔄 Round 55 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 55 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0035
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0005
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0056

============================================================
🔄 Round 57 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 57 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0042
   Val:   Loss=0.0745, RMSE=0.2730, R²=-0.0008
============================================================


============================================================
🔄 Round 59 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 59 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0037
   Val:   Loss=0.0749, RMSE=0.2737, R²=0.0002
============================================================


============================================================
🔄 Round 60 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 60 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0007
   Val:   Loss=0.0711, RMSE=0.2667, R²=0.0155
============================================================


============================================================
🔄 Round 63 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 63 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0052
   Val:   Loss=0.0763, RMSE=0.2763, R²=-0.0041
============================================================


============================================================
🔄 Round 64 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 64 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0043
   Val:   Loss=0.0819, RMSE=0.2863, R²=0.0002
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0056

📊 Round 64 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0055

📊 Round 64 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0055

============================================================
🔄 Round 70 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 70 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0033
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0024
============================================================


============================================================
🔄 Round 71 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 71 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0064
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0145
============================================================


============================================================
🔄 Round 72 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 72 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0033
   Val:   Loss=0.0756, RMSE=0.2749, R²=0.0031
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0055

📊 Round 72 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0055

📊 Round 72 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0055

============================================================
🔄 Round 80 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 80 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0013
   Val:   Loss=0.0873, RMSE=0.2954, R²=0.0083
============================================================


============================================================
🔄 Round 81 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 81 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0034
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0019
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0055

📊 Round 81 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0055

============================================================
🔄 Round 84 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 84 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0060
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0093
============================================================


============================================================
🔄 Round 87 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 87 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0039
   Val:   Loss=0.0751, RMSE=0.2740, R²=-0.0013
============================================================


============================================================
🔄 Round 88 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 88 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0041
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0162
============================================================


============================================================
🔄 Round 89 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 89 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=0.0050
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0067
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0055

============================================================
🔄 Round 93 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 93 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0057
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0096
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0055

📊 Round 93 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0055

📊 Round 93 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0055

📊 Round 93 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0055

============================================================
🔄 Round 97 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 97 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0030
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0054
============================================================


============================================================
🔄 Round 98 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 98 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=0.0019
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0028
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0055

============================================================
🔄 Round 99 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 99 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0019
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0105
============================================================


============================================================
🔄 Round 102 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 102 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0059
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0193
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0055

============================================================
🔄 Round 105 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 105 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0036
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0019
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0055

============================================================
🔄 Round 109 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 109 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0064
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0078
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0056

============================================================
🔄 Round 111 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 111 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0046
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0122
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0056

============================================================
🔄 Round 112 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 112 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0045
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0006
============================================================


============================================================
🔄 Round 114 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 114 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0031
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0058
============================================================


============================================================
🔄 Round 117 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 117 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0037
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0021
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0055

============================================================
🔄 Round 118 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 118 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0049
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0012
============================================================


============================================================
🔄 Round 120 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 120 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0040
   Val:   Loss=0.0869, RMSE=0.2947, R²=0.0014
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0055

============================================================
🔄 Round 121 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 121 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0028
   Val:   Loss=0.0831, RMSE=0.2884, R²=0.0064
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0055

📊 Round 121 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0055

============================================================
🔄 Round 125 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 125 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0007
   Val:   Loss=0.0726, RMSE=0.2695, R²=0.0020
============================================================


============================================================
🔄 Round 127 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0703 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0703, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0703, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0703, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0703)

============================================================
📊 Round 127 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0023
   Val:   Loss=0.0703, RMSE=0.2651, R²=0.0068
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0055

============================================================
🔄 Round 128 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 128 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0036
   Val:   Loss=0.0784, RMSE=0.2801, R²=-0.0154
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0055

============================================================
🔄 Round 129 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 129 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0038
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0030
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0055

============================================================
🔄 Round 130 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 130 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0042
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0011
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0055

============================================================
🔄 Round 131 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 131 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0038
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0038
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0055

📊 Round 131 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0055

📊 Round 131 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0055

📊 Round 131 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0055

============================================================
🔄 Round 137 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 137 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0035
   Val:   Loss=0.0737, RMSE=0.2715, R²=-0.0020
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0055

============================================================
🔄 Round 139 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 139 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0033
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0029
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0055

📊 Round 139 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0055

📊 Round 139 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0055

============================================================
🔄 Round 143 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 143 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0061
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0265
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0055

📊 Round 143 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0055

============================================================
🔄 Round 145 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0682 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0682, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0682, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0682, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0682, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0681, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0682)

============================================================
📊 Round 145 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0048
   Val:   Loss=0.0682, RMSE=0.2611, R²=-0.0125
============================================================


============================================================
🔄 Round 146 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 146 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0045
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0043
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0056

📊 Round 146 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0056

============================================================
🔄 Round 153 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 153 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0004
   Val:   Loss=0.0764, RMSE=0.2763, R²=0.0064
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0056

📊 Round 153 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0056

============================================================
🔄 Round 155 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 155 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0039
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0027
============================================================


============================================================
🔄 Round 156 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 156 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0047
   Val:   Loss=0.0760, RMSE=0.2756, R²=-0.0007
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0056

============================================================
🔄 Round 158 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 158 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0047
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0007
============================================================


============================================================
🔄 Round 161 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 161 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0032
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0040
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0056

📊 Round 161 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0056

============================================================
🔄 Round 167 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0707, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0707, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0707, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0707, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 167 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0029
   Val:   Loss=0.0707, RMSE=0.2659, R²=0.0048
============================================================


============================================================
🔄 Round 168 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 168 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0035
   Val:   Loss=0.0802, RMSE=0.2833, R²=0.0041
============================================================


============================================================
🔄 Round 170 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 170 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0071
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0243
============================================================


============================================================
🔄 Round 172 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 172 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0014
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0114
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0056

📊 Round 172 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0056

============================================================
🔄 Round 174 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 174 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0014
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0049
============================================================


============================================================
🔄 Round 178 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 178 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0014
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0086
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0056

============================================================
🔄 Round 179 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 179 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2877, R²=0.0048
   Val:   Loss=0.0717, RMSE=0.2677, R²=-0.0049
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0056

📊 Round 179 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0056

============================================================
🔄 Round 183 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 183 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2835, R²=0.0030
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0068
============================================================


============================================================
🔄 Round 185 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 185 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0063
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0067
============================================================


============================================================
🔄 Round 186 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 186 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0046
   Val:   Loss=0.0720, RMSE=0.2683, R²=-0.0132
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0056

📊 Round 186 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0056

============================================================
🔄 Round 188 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 188 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0059
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0093
============================================================


============================================================
🔄 Round 189 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 189 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0040
   Val:   Loss=0.0721, RMSE=0.2685, R²=0.0025
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0056

📊 Round 189 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0056

============================================================
🔄 Round 193 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 193 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0001
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0129
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0056

📊 Round 193 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0056

============================================================
🔄 Round 195 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 195 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0044
   Val:   Loss=0.0864, RMSE=0.2940, R²=0.0012
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0056

============================================================
🔄 Round 196 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 196 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0040
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0020
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0056

============================================================
🔄 Round 197 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 197 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0049
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0018
============================================================


============================================================
🔄 Round 198 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 198 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0030
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0061
============================================================


============================================================
🔄 Round 199 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 199 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0070
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0154
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0056

📊 Round 199 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0056

============================================================
🔄 Round 201 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0666 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0666, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0666, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0666, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0666, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0667, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0666)

============================================================
📊 Round 201 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0023
   Val:   Loss=0.0666, RMSE=0.2581, R²=0.0040
============================================================


============================================================
🔄 Round 203 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 203 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0044
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0113
============================================================


============================================================
🔄 Round 205 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 205 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0062
   Val:   Loss=0.0740, RMSE=0.2720, R²=-0.0166
============================================================


============================================================
🔄 Round 206 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 206 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0012
   Val:   Loss=0.0750, RMSE=0.2739, R²=-0.0029
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0056

============================================================
🔄 Round 207 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 207 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0042
   Val:   Loss=0.0756, RMSE=0.2749, R²=-0.0018
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0056

============================================================
🔄 Round 209 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 209 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0039
   Val:   Loss=0.0822, RMSE=0.2866, R²=0.0031
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0057

============================================================
🔄 Round 210 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 210 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0004
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0117
============================================================


============================================================
🔄 Round 213 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 213 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0026
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0076
============================================================


============================================================
🔄 Round 214 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 214 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0018
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0089
============================================================


📊 Round 214 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0057

📊 Round 214 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0057

============================================================
🔄 Round 220 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 220 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0052
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0038
============================================================


📊 Round 220 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0057

============================================================
🔄 Round 222 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0687 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0687, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0687, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0687, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0687, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0687, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0687)

============================================================
📊 Round 222 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0015
   Val:   Loss=0.0687, RMSE=0.2622, R²=0.0138
============================================================


📊 Round 222 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0057

============================================================
🔄 Round 228 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 228 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2819, R²=0.0034
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0041
============================================================


============================================================
🔄 Round 231 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 231 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0046
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0027
============================================================


📊 Round 231 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0057

📊 Round 231 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0057

📊 Round 231 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0057

============================================================
🔄 Round 237 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 237 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0037
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0008
============================================================


📊 Round 237 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0057

📊 Round 237 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0057

📊 Round 237 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0057

📊 Round 237 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0057

============================================================
🔄 Round 246 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 246 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=-0.0021
   Val:   Loss=0.0933, RMSE=0.3055, R²=0.0144
============================================================


📊 Round 246 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0057

============================================================
🔄 Round 247 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 247 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0012
   Val:   Loss=0.0906, RMSE=0.3011, R²=0.0072
============================================================


📊 Round 247 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0057

============================================================
🔄 Round 248 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 248 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0050
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0032
============================================================


============================================================
🔄 Round 251 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 251 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0037
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0020
============================================================


📊 Round 251 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0057

============================================================
🔄 Round 254 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 254 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0024
   Val:   Loss=0.0856, RMSE=0.2927, R²=0.0071
============================================================


📊 Round 254 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0057

============================================================
🔄 Round 256 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 256 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0028
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0068
============================================================


============================================================
🔄 Round 258 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 258 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0005
   Val:   Loss=0.0842, RMSE=0.2901, R²=0.0077
============================================================


============================================================
🔄 Round 262 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 262 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0060
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0174
============================================================


📊 Round 262 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0057

============================================================
🔄 Round 263 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 263 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0041
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0030
============================================================


============================================================
🔄 Round 264 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 264 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0055
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0195
============================================================


📊 Round 264 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0057

============================================================
🔄 Round 267 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 267 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0033
   Val:   Loss=0.0788, RMSE=0.2806, R²=-0.0225
============================================================


📊 Round 267 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0057

📊 Round 267 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0057

============================================================
🔄 Round 270 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 270 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0004
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0103
============================================================


📊 Round 270 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0057

============================================================
🔄 Round 271 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 271 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0030
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0046
============================================================


📊 Round 271 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0057

📊 Round 271 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0057

📊 Round 271 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0057

============================================================
🔄 Round 278 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 278 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0067
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0075
============================================================


📊 Round 278 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0057

============================================================
🔄 Round 281 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 281 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0040
   Val:   Loss=0.0725, RMSE=0.2692, R²=0.0026
============================================================


============================================================
🔄 Round 282 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 282 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0025
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0067
============================================================


📊 Round 282 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0057

📊 Round 282 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0057

============================================================
🔄 Round 286 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 286 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0051
   Val:   Loss=0.0741, RMSE=0.2722, R²=-0.0200
============================================================


============================================================
🔄 Round 287 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 287 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0033
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0042
============================================================


📊 Round 287 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0057

============================================================
🔄 Round 289 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 289 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0020
   Val:   Loss=0.0910, RMSE=0.3017, R²=0.0097
============================================================


============================================================
🔄 Round 290 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 290 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0049
   Val:   Loss=0.0750, RMSE=0.2739, R²=-0.0078
============================================================


============================================================
🔄 Round 291 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 291 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0025
   Val:   Loss=0.0939, RMSE=0.3064, R²=0.0062
============================================================


📊 Round 291 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0057

============================================================
🔄 Round 293 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 293 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0046
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0002
============================================================


============================================================
🔄 Round 295 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 295 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0008
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0126
============================================================


📊 Round 295 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0057

============================================================
🔄 Round 300 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 300 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0032
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0040
============================================================


📊 Round 300 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0057

📊 Round 300 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0057

📊 Round 300 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0057

============================================================
🔄 Round 303 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 303 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0036
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0011
============================================================


📊 Round 303 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

📊 Round 303 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

============================================================
🔄 Round 306 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 306 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0060
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0381
============================================================


📊 Round 306 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

============================================================
🔄 Round 307 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 307 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0028
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0084
============================================================


📊 Round 307 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0057

📊 Round 307 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0057

============================================================
🔄 Round 310 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 310 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0056
   Val:   Loss=0.0789, RMSE=0.2808, R²=-0.0043
============================================================


============================================================
🔄 Round 311 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 311 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0048
   Val:   Loss=0.0792, RMSE=0.2815, R²=-0.0107
============================================================


============================================================
🔄 Round 312 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 312 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2806, R²=0.0046
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0028
============================================================


============================================================
🔄 Round 313 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 313 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=0.0046
   Val:   Loss=0.0892, RMSE=0.2986, R²=0.0010
============================================================


📊 Round 313 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0057

📊 Round 313 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0057

============================================================
🔄 Round 316 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 316 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0003
   Val:   Loss=0.0763, RMSE=0.2763, R²=-0.0292
============================================================


📊 Round 316 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0057

============================================================
🔄 Round 319 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 319 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0014
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0019
============================================================


📊 Round 319 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0057

📊 Round 319 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0057

============================================================
🔄 Round 322 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 322 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0035
   Val:   Loss=0.0746, RMSE=0.2732, R²=0.0010
============================================================


============================================================
🔄 Round 324 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 324 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=-0.0013
   Val:   Loss=0.0889, RMSE=0.2981, R²=0.0067
============================================================


📊 Round 324 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0057

📊 Round 324 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

📊 Round 324 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

============================================================
🔄 Round 329 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 329 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0071
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0179
============================================================


📊 Round 329 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

============================================================
🔄 Round 331 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 331 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0058
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0217
============================================================


📊 Round 331 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

============================================================
🔄 Round 335 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 335 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0045
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0002
============================================================


============================================================
🔄 Round 336 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 336 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2813, R²=0.0041
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0007
============================================================


📊 Round 336 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

📊 Round 336 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

============================================================
🔄 Round 344 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 344 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0043
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0003
============================================================


📊 Round 344 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

============================================================
🔄 Round 346 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 346 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0075
   Val:   Loss=0.0818, RMSE=0.2859, R²=-0.0337
============================================================


============================================================
🔄 Round 352 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 352 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0067
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0197
============================================================


📊 Round 352 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

============================================================
🔄 Round 353 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 353 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0023
   Val:   Loss=0.0736, RMSE=0.2714, R²=0.0040
============================================================


📊 Round 353 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

📊 Round 353 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

📊 Round 353 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

============================================================
🔄 Round 358 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 358 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0029
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0042
============================================================


📊 Round 358 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

============================================================
🔄 Round 359 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 359 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2843, R²=0.0065
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0126
============================================================


📊 Round 359 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

📊 Round 359 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

📊 Round 359 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

============================================================
🔄 Round 364 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 364 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0063
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0152
============================================================


📊 Round 364 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

============================================================
🔄 Round 371 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 371 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0046
   Val:   Loss=0.0844, RMSE=0.2904, R²=-0.0151
============================================================


📊 Round 371 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

============================================================
🔄 Round 373 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 373 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0022
   Val:   Loss=0.0834, RMSE=0.2887, R²=-0.0012
============================================================


============================================================
🔄 Round 374 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 374 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0040
   Val:   Loss=0.0888, RMSE=0.2980, R²=0.0033
============================================================


📊 Round 374 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

============================================================
🔄 Round 376 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 376 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0045
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0063
============================================================


============================================================
🔄 Round 377 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 377 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0022
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0039
============================================================


============================================================
🔄 Round 378 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 378 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0038
   Val:   Loss=0.0729, RMSE=0.2700, R²=0.0016
============================================================


📊 Round 378 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

📊 Round 378 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

📊 Round 378 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

============================================================
🔄 Round 384 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 384 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0040
   Val:   Loss=0.0827, RMSE=0.2877, R²=0.0031
============================================================


============================================================
🔄 Round 385 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 385 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0017
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0100
============================================================


============================================================
🔄 Round 388 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 388 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0043
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0019
============================================================


📊 Round 388 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

============================================================
🔄 Round 391 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 391 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0052
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0229
============================================================


============================================================
🔄 Round 392 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 392 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0044
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0013
============================================================


📊 Round 392 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

============================================================
🔄 Round 394 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 394 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=-0.0020
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0023
============================================================


============================================================
🔄 Round 395 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 395 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0053
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0034
============================================================


📊 Round 395 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

============================================================
🔄 Round 400 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 400 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0032
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0050
============================================================


============================================================
🔄 Round 403 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 403 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0080
   Val:   Loss=0.0915, RMSE=0.3024, R²=-0.0405
============================================================


📊 Round 403 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

============================================================
🔄 Round 404 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 404 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0025
   Val:   Loss=0.0729, RMSE=0.2700, R²=0.0083
============================================================


📊 Round 404 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

📊 Round 404 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

============================================================
🔄 Round 408 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 408 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0020
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0177
============================================================


============================================================
🔄 Round 409 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 409 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0059
   Val:   Loss=0.0734, RMSE=0.2710, R²=-0.0233
============================================================


============================================================
🔄 Round 413 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 413 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0006
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0155
============================================================


📊 Round 413 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

📊 Round 413 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

============================================================
🔄 Round 415 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 415 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0075
   Val:   Loss=0.0764, RMSE=0.2763, R²=-0.0370
============================================================


📊 Round 415 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

============================================================
🔄 Round 416 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 416 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0030
   Val:   Loss=0.0819, RMSE=0.2863, R²=0.0060
============================================================


📊 Round 416 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0057

============================================================
🔄 Round 418 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 418 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0011
   Val:   Loss=0.0897, RMSE=0.2996, R²=0.0020
============================================================


📊 Round 418 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

============================================================
🔄 Round 420 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 420 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0058
   Val:   Loss=0.0906, RMSE=0.3011, R²=-0.0053
============================================================


============================================================
🔄 Round 421 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 421 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0008
   Val:   Loss=0.0809, RMSE=0.2843, R²=-0.0098
============================================================


📊 Round 421 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

============================================================
🔄 Round 422 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 422 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0046
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0010
============================================================


============================================================
🔄 Round 424 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 424 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0057
   Val:   Loss=0.0710, RMSE=0.2665, R²=-0.0061
============================================================


📊 Round 424 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

📊 Round 424 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

============================================================
🔄 Round 429 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 429 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0038
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0001
============================================================


============================================================
🔄 Round 430 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 430 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0041
   Val:   Loss=0.0755, RMSE=0.2747, R²=0.0033
============================================================


📊 Round 430 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

📊 Round 430 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

============================================================
🔄 Round 432 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 432 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0037
   Val:   Loss=0.0749, RMSE=0.2737, R²=0.0053
============================================================


📊 Round 432 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

============================================================
🔄 Round 433 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 433 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0041
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0034
============================================================


📊 Round 433 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

============================================================
🔄 Round 434 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0938, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 434 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0001
   Val:   Loss=0.0938, RMSE=0.3062, R²=0.0108
============================================================


📊 Round 434 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

📊 Round 434 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

📊 Round 434 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

📊 Round 434 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

📊 Round 434 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

============================================================
🔄 Round 444 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 444 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0029
   Val:   Loss=0.0840, RMSE=0.2899, R²=0.0081
============================================================


============================================================
🔄 Round 445 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 445 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0044
   Val:   Loss=0.0736, RMSE=0.2712, R²=-0.0083
============================================================


📊 Round 445 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

============================================================
🔄 Round 447 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 447 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0052
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0017
============================================================


============================================================
🔄 Round 448 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 448 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0030
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0086
============================================================


============================================================
🔄 Round 449 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 449 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0044
   Val:   Loss=0.0710, RMSE=0.2664, R²=-0.0010
============================================================


📊 Round 449 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0057

============================================================
🔄 Round 451 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 451 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0063
   Val:   Loss=0.0780, RMSE=0.2794, R²=-0.0096
============================================================


📊 Round 451 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0057

📊 Round 451 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0057

============================================================
🔄 Round 454 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0661 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0661, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0661, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0661, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0661, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0661, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0661)

============================================================
📊 Round 454 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0023
   Val:   Loss=0.0661, RMSE=0.2571, R²=0.0131
============================================================


📊 Round 454 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0057

============================================================
🔄 Round 456 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 456 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0048
   Val:   Loss=0.0925, RMSE=0.3042, R²=0.0010
============================================================


📊 Round 456 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0057

============================================================
🔄 Round 458 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 458 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0038
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0055
============================================================


📊 Round 458 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0057

============================================================
🔄 Round 462 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 462 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0019
   Val:   Loss=0.0790, RMSE=0.2810, R²=0.0092
============================================================


📊 Round 462 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0057

============================================================
🔄 Round 463 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 463 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0052
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0689
============================================================


📊 Round 463 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0057

📊 Round 463 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0057

============================================================
🔄 Round 467 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 467 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0023
   Val:   Loss=0.0718, RMSE=0.2680, R²=0.0114
============================================================


📊 Round 467 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0057

📊 Round 467 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0057

📊 Round 467 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0057

============================================================
🔄 Round 471 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 471 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0043
   Val:   Loss=0.0775, RMSE=0.2785, R²=0.0034
============================================================


📊 Round 471 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0057

============================================================
🔄 Round 472 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 472 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0035
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0035
============================================================


📊 Round 472 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0057

============================================================
🔄 Round 474 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 474 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0041
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0024
============================================================


============================================================
🔄 Round 475 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 475 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0058
   Val:   Loss=0.0807, RMSE=0.2842, R²=-0.0230
============================================================


============================================================
🔄 Round 477 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 477 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0024
   Val:   Loss=0.0722, RMSE=0.2687, R²=0.0109
============================================================


📊 Round 477 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

============================================================
🔄 Round 485 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 485 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0049
   Val:   Loss=0.0749, RMSE=0.2737, R²=-0.0069
============================================================


============================================================
🔄 Round 486 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 486 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0028
   Val:   Loss=0.0834, RMSE=0.2887, R²=0.0011
============================================================


📊 Round 486 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

============================================================
🔄 Round 488 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 488 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0018
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0072
============================================================


📊 Round 488 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

📊 Round 488 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

============================================================
🔄 Round 492 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 492 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0044
   Val:   Loss=0.0875, RMSE=0.2957, R²=0.0016
============================================================


============================================================
🔄 Round 493 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0663 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0663, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0663, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0663, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0663, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0663, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0663)

============================================================
📊 Round 493 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0029
   Val:   Loss=0.0663, RMSE=0.2576, R²=0.0082
============================================================


📊 Round 493 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

============================================================
🔄 Round 494 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 494 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0039
   Val:   Loss=0.0751, RMSE=0.2741, R²=0.0023
============================================================


📊 Round 494 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

============================================================
🔄 Round 497 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 497 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0024
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0032
============================================================


============================================================
🔄 Round 498 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 498 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0016
   Val:   Loss=0.0830, RMSE=0.2880, R²=0.0062
============================================================


📊 Round 498 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

📊 Round 498 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

📊 Round 498 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

📊 Round 498 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

============================================================
🔄 Round 504 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 504 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0034
   Val:   Loss=0.0802, RMSE=0.2831, R²=0.0018
============================================================


============================================================
🔄 Round 505 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 505 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0028
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0049
============================================================


📊 Round 505 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

📊 Round 505 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

📊 Round 505 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

============================================================
🔄 Round 508 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 508 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0008
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0147
============================================================


📊 Round 508 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

============================================================
🔄 Round 511 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0947 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0947, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0947, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0947, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0948, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0948, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0947)

============================================================
📊 Round 511 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2774, R²=0.0032
   Val:   Loss=0.0947, RMSE=0.3078, R²=-0.0010
============================================================


📊 Round 511 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

============================================================
🔄 Round 513 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 513 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0021
   Val:   Loss=0.0733, RMSE=0.2707, R²=0.0090
============================================================


📊 Round 513 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

📊 Round 513 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

============================================================
🔄 Round 516 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 516 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0060
   Val:   Loss=0.0763, RMSE=0.2762, R²=-0.0335
============================================================


📊 Round 516 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

============================================================
🔄 Round 518 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 518 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0019
   Val:   Loss=0.0907, RMSE=0.3012, R²=0.0109
============================================================


📊 Round 518 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

📊 Round 518 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

============================================================
🔄 Round 523 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 523 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0026
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0102
============================================================


============================================================
🔄 Round 524 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 524 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0026
   Val:   Loss=0.0780, RMSE=0.2792, R²=0.0014
============================================================


============================================================
🔄 Round 526 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 526 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0040
   Val:   Loss=0.0731, RMSE=0.2703, R²=0.0036
============================================================


📊 Round 526 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

📊 Round 526 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

📊 Round 526 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

============================================================
🔄 Round 532 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 532 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0019
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0122
============================================================


📊 Round 532 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

📊 Round 532 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

============================================================
🔄 Round 537 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 537 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0043
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0023
============================================================


📊 Round 537 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

📊 Round 537 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

📊 Round 537 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

============================================================
🔄 Round 540 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 540 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0043
   Val:   Loss=0.0748, RMSE=0.2736, R²=-0.0001
============================================================


📊 Round 540 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

📊 Round 540 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

============================================================
🔄 Round 544 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 544 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2836, R²=0.0021
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0112
============================================================


📊 Round 544 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

============================================================
🔄 Round 545 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 545 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0020
   Val:   Loss=0.0806, RMSE=0.2840, R²=0.0114
============================================================


============================================================
🔄 Round 546 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0699 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0699, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0699, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0699, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 546 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0029
   Val:   Loss=0.0699, RMSE=0.2644, R²=0.0085
============================================================


============================================================
🔄 Round 547 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 547 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0041
   Val:   Loss=0.0878, RMSE=0.2962, R²=0.0013
============================================================


📊 Round 547 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

============================================================
🔄 Round 548 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 548 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0069
   Val:   Loss=0.0741, RMSE=0.2721, R²=-0.0600
============================================================


============================================================
🔄 Round 550 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 550 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0043
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0008
============================================================


📊 Round 550 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

============================================================
🔄 Round 553 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 553 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0033
   Val:   Loss=0.0898, RMSE=0.2997, R²=0.0047
============================================================


============================================================
🔄 Round 555 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 555 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0048
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0001
============================================================


============================================================
🔄 Round 556 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 556 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0036
   Val:   Loss=0.0739, RMSE=0.2719, R²=0.0034
============================================================


============================================================
🔄 Round 558 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 558 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0013
   Val:   Loss=0.0806, RMSE=0.2838, R²=0.0133
============================================================


============================================================
🔄 Round 559 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 559 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0002
   Val:   Loss=0.0793, RMSE=0.2817, R²=0.0023
============================================================


📊 Round 559 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

============================================================
🔄 Round 560 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 560 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0055
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0213
============================================================


📊 Round 560 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

============================================================
🔄 Round 561 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 561 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0010
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0125
============================================================


============================================================
🔄 Round 563 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 563 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0030
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0052
============================================================


📊 Round 563 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

============================================================
🔄 Round 564 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 564 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0034
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0055
============================================================


📊 Round 564 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

============================================================
🔄 Round 567 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 567 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0038
   Val:   Loss=0.0710, RMSE=0.2664, R²=0.0038
============================================================


📊 Round 567 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

📊 Round 567 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

============================================================
🔄 Round 569 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 569 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0039
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0040
============================================================


📊 Round 569 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

📊 Round 569 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

============================================================
🔄 Round 574 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 574 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0060
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0039
============================================================


📊 Round 574 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

============================================================
🔄 Round 585 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 585 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0020
   Val:   Loss=0.0723, RMSE=0.2689, R²=0.0052
============================================================


============================================================
🔄 Round 590 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 590 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0030
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0047
============================================================


📊 Round 590 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

📊 Round 590 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0060

📊 Round 590 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

============================================================
🔄 Round 595 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 595 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0074
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0212
============================================================


📊 Round 595 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0060

📊 Round 595 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0060

============================================================
🔄 Round 603 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 603 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0020
   Val:   Loss=0.0770, RMSE=0.2776, R²=0.0098
============================================================


📊 Round 603 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0060

📊 Round 603 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0060

============================================================
🔄 Round 605 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 605 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=0.0036
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0047
============================================================


📊 Round 605 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0060

📊 Round 605 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0060

📊 Round 605 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0060

📊 Round 605 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0060

📊 Round 605 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0060

============================================================
🔄 Round 610 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 610 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=0.0049
   Val:   Loss=0.0765, RMSE=0.2765, R²=-0.0020
============================================================


============================================================
🔄 Round 611 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 611 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0056
   Val:   Loss=0.0819, RMSE=0.2863, R²=-0.0037
============================================================


============================================================
🔄 Round 613 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 613 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0043
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0016
============================================================


📊 Round 613 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0060

============================================================
🔄 Round 614 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 614 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0052
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0116
============================================================


📊 Round 614 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

============================================================
🔄 Round 620 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 620 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0074
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0149
============================================================


📊 Round 620 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0060

============================================================
🔄 Round 621 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 621 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0053
   Val:   Loss=0.0899, RMSE=0.2999, R²=-0.0027
============================================================


============================================================
🔄 Round 622 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 622 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0068
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0101
============================================================


============================================================
🔄 Round 625 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 625 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0034
   Val:   Loss=0.0811, RMSE=0.2849, R²=0.0045
============================================================


============================================================
🔄 Round 626 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 626 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0040
   Val:   Loss=0.0744, RMSE=0.2728, R²=-0.0219
============================================================


📊 Round 626 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0060

📊 Round 626 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0060

📊 Round 626 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0060

📊 Round 626 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0060

============================================================
🔄 Round 632 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0680 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0680, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0680, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0680, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0681, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0681, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0680)

============================================================
📊 Round 632 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0023
   Val:   Loss=0.0680, RMSE=0.2608, R²=0.0019
============================================================


============================================================
🔄 Round 633 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 633 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0027
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0083
============================================================


============================================================
🔄 Round 634 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 634 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0026
   Val:   Loss=0.0752, RMSE=0.2743, R²=0.0101
============================================================


============================================================
🔄 Round 635 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 635 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0023
   Val:   Loss=0.0826, RMSE=0.2873, R²=0.0086
============================================================


============================================================
🔄 Round 636 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 636 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0069
   Val:   Loss=0.0767, RMSE=0.2769, R²=-0.0086
============================================================


📊 Round 636 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0060

============================================================
🔄 Round 638 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 638 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0035
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0061
============================================================


📊 Round 638 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

============================================================
🔄 Round 640 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 640 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0044
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0028
============================================================


📊 Round 640 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

📊 Round 640 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

============================================================
🔄 Round 642 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 642 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0019
   Val:   Loss=0.0802, RMSE=0.2831, R²=0.0043
============================================================


📊 Round 642 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

============================================================
🔄 Round 646 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 646 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0033
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0078
============================================================


============================================================
🔄 Round 647 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 647 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0063
   Val:   Loss=0.0741, RMSE=0.2723, R²=-0.0151
============================================================


📊 Round 647 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

============================================================
🔄 Round 648 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 648 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2787, R²=0.0047
   Val:   Loss=0.0919, RMSE=0.3032, R²=-0.0029
============================================================


📊 Round 648 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

============================================================
🔄 Round 652 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 652 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0072
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0126
============================================================


📊 Round 652 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

📊 Round 652 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

============================================================
🔄 Round 656 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 656 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0042
   Val:   Loss=0.0792, RMSE=0.2815, R²=0.0029
============================================================


============================================================
🔄 Round 657 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 657 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=0.0047
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0025
============================================================


============================================================
🔄 Round 660 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 660 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0043
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0028
============================================================


============================================================
🔄 Round 661 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 661 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0003
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0130
============================================================


📊 Round 661 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

============================================================
🔄 Round 663 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0696 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0696, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0696, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0696, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0696, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0695, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0696)

============================================================
📊 Round 663 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0035
   Val:   Loss=0.0696, RMSE=0.2638, R²=0.0072
============================================================


============================================================
🔄 Round 664 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 664 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0042
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0043
============================================================


📊 Round 664 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

============================================================
🔄 Round 666 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 666 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0014
   Val:   Loss=0.0760, RMSE=0.2756, R²=0.0144
============================================================


📊 Round 666 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

============================================================
🔄 Round 669 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 669 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0040
   Val:   Loss=0.0749, RMSE=0.2737, R²=0.0054
============================================================


📊 Round 669 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

============================================================
🔄 Round 673 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 673 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0019
   Val:   Loss=0.0774, RMSE=0.2783, R²=-0.0055
============================================================


📊 Round 673 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

📊 Round 673 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

============================================================
🔄 Round 675 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0670 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0670, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0670, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0671, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0671, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0673, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0670)

============================================================
📊 Round 675 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0000
   Val:   Loss=0.0670, RMSE=0.2588, R²=-0.0152
============================================================


📊 Round 675 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

============================================================
🔄 Round 676 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 676 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0009
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0057
============================================================


============================================================
🔄 Round 677 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 677 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0051
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0003
============================================================


============================================================
🔄 Round 678 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 678 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0055
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0169
============================================================


============================================================
🔄 Round 680 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 680 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0030
   Val:   Loss=0.0849, RMSE=0.2915, R²=0.0082
============================================================


📊 Round 680 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

📊 Round 680 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

============================================================
🔄 Round 682 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0695 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0695, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0695, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0695, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0695, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0695, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0695)

============================================================
📊 Round 682 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0034
   Val:   Loss=0.0695, RMSE=0.2637, R²=0.0074
============================================================


📊 Round 682 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

📊 Round 682 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

============================================================
🔄 Round 689 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 689 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0048
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0014
============================================================


============================================================
🔄 Round 690 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 690 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0077
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0090
============================================================


============================================================
🔄 Round 691 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 691 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0042
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0030
============================================================


============================================================
🔄 Round 693 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 693 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0021
   Val:   Loss=0.0728, RMSE=0.2697, R²=0.0061
============================================================


============================================================
🔄 Round 694 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 694 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0037
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0063
============================================================


============================================================
🔄 Round 695 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 695 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0060
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0034
============================================================


📊 Round 695 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

📊 Round 695 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

============================================================
🔄 Round 698 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0705, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 698 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0062
   Val:   Loss=0.0705, RMSE=0.2656, R²=-0.0114
============================================================


📊 Round 698 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

============================================================
🔄 Round 701 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 701 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0029
   Val:   Loss=0.0731, RMSE=0.2704, R²=0.0103
============================================================


📊 Round 701 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

============================================================
🔄 Round 703 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 703 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0032
   Val:   Loss=0.0722, RMSE=0.2686, R²=0.0085
============================================================


📊 Round 703 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

============================================================
🔄 Round 705 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 705 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0075
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0166
============================================================


📊 Round 705 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

📊 Round 705 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

============================================================
🔄 Round 708 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 708 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0049
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0012
============================================================


📊 Round 708 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

============================================================
🔄 Round 714 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 714 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0053
   Val:   Loss=0.0721, RMSE=0.2685, R²=-0.0039
============================================================


📊 Round 714 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

============================================================
🔄 Round 716 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 716 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=0.0027
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0106
============================================================


📊 Round 716 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

============================================================
🔄 Round 719 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 719 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0048
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0039
============================================================


============================================================
🔄 Round 722 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 722 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0050
   Val:   Loss=0.0751, RMSE=0.2740, R²=-0.0088
============================================================


📊 Round 722 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0060

============================================================
🔄 Round 726 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 726 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0030
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0085
============================================================


============================================================
🔄 Round 727 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 727 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0019
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0051
============================================================


📊 Round 727 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0060

============================================================
🔄 Round 728 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 728 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0056
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0037
============================================================


============================================================
🔄 Round 729 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 729 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0011
   Val:   Loss=0.0730, RMSE=0.2701, R²=0.0161
============================================================


============================================================
🔄 Round 730 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 730 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0056
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0028
============================================================


📊 Round 730 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0060

📊 Round 730 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0060

============================================================
🔄 Round 734 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 734 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0066
   Val:   Loss=0.0736, RMSE=0.2713, R²=-0.0075
============================================================


📊 Round 734 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0060

============================================================
🔄 Round 735 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 735 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0025
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0092
============================================================


📊 Round 735 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0060

============================================================
🔄 Round 737 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 737 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0029
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0094
============================================================


📊 Round 737 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0060

============================================================
🔄 Round 738 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 738 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0019
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0018
============================================================


📊 Round 738 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

============================================================
🔄 Round 740 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 740 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0058
   Val:   Loss=0.0742, RMSE=0.2723, R²=-0.0023
============================================================


📊 Round 740 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

============================================================
🔄 Round 743 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 743 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0029
   Val:   Loss=0.0900, RMSE=0.2999, R²=0.0072
============================================================


📊 Round 743 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

============================================================
🔄 Round 744 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 744 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0048
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0019
============================================================


📊 Round 744 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

============================================================
🔄 Round 746 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 746 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=0.0007
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0175
============================================================


📊 Round 746 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

📊 Round 746 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

============================================================
🔄 Round 749 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 749 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2803, R²=0.0055
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0027
============================================================


📊 Round 749 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

============================================================
🔄 Round 751 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 751 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0063
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0082
============================================================


📊 Round 751 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

============================================================
🔄 Round 754 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 754 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0032
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0016
============================================================


📊 Round 754 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

============================================================
🔄 Round 755 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 755 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0003
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0084
============================================================


📊 Round 755 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0060

============================================================
🔄 Round 758 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 758 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0053
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0000
============================================================


📊 Round 758 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0060

============================================================
🔄 Round 759 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 759 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0023
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0075
============================================================


📊 Round 759 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

============================================================
🔄 Round 761 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 761 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0056
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0035
============================================================


📊 Round 761 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

📊 Round 761 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

📊 Round 761 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

============================================================
🔄 Round 765 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 765 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0061
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0088
============================================================


📊 Round 765 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

📊 Round 765 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

============================================================
🔄 Round 768 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 768 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0058
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0097
============================================================


============================================================
🔄 Round 769 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 769 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0062
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0080
============================================================


============================================================
🔄 Round 773 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 773 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0019
   Val:   Loss=0.0753, RMSE=0.2744, R²=-0.0075
============================================================


📊 Round 773 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

============================================================
🔄 Round 774 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 774 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0034
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0453
============================================================


📊 Round 774 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

📊 Round 774 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

📊 Round 774 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

📊 Round 774 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

============================================================
🔄 Round 780 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 780 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0036
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0007
============================================================


📊 Round 780 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

============================================================
🔄 Round 782 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 782 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0046
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0141
============================================================


============================================================
🔄 Round 786 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 786 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0008
   Val:   Loss=0.0856, RMSE=0.2925, R²=0.0144
============================================================


============================================================
🔄 Round 787 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 787 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0018
   Val:   Loss=0.0770, RMSE=0.2776, R²=0.0140
============================================================


📊 Round 787 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

📊 Round 787 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

============================================================
🔄 Round 789 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 789 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0042
   Val:   Loss=0.0764, RMSE=0.2763, R²=0.0040
============================================================


📊 Round 789 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

============================================================
🔄 Round 791 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 791 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0039
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0052
============================================================


📊 Round 791 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

============================================================
🔄 Round 793 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 793 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0052
   Val:   Loss=0.0721, RMSE=0.2685, R²=0.0003
============================================================


📊 Round 793 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

📊 Round 793 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

============================================================
🔄 Round 800 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 800 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0008
   Val:   Loss=0.0834, RMSE=0.2889, R²=0.0061
============================================================


📊 Round 800 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

📊 Round 800 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

📊 Round 800 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

============================================================
🔄 Round 803 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 803 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0014
   Val:   Loss=0.0725, RMSE=0.2693, R²=0.0027
============================================================


📊 Round 803 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

============================================================
🔄 Round 804 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 804 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0031
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0099
============================================================


============================================================
🔄 Round 806 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 806 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0041
   Val:   Loss=0.0785, RMSE=0.2803, R²=0.0066
============================================================


📊 Round 806 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0059

============================================================
🔄 Round 807 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 807 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0005
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0051
============================================================


📊 Round 807 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2470, R²: 0.0058

❌ Client client_9 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_status:14, grpc_message:"Socket closed"}"
>
