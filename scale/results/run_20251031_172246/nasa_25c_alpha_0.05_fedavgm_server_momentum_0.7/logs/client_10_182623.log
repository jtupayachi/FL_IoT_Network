[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad11aa7c-dd29-49d3-931c-db0074241bf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d141c3e-0b56-411c-b074-13f69b30e097
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40013a0d-5fed-4b00-bca3-be989b4f74fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 462038e1-3acd-4992-9448-8beca903f7a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c552a659-914e-4f0f-b847-4dcf7a3151ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12108892-33fc-4e32-9528-9e9bafc1301b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00f170ab-4ff8-470e-a0ae-097bbc6343d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0286d777-d1d8-4e78-88b1-891682598042
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fede1b0f-5528-4fe9-8780-aa5664b249bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6daf9a3-f17c-40c2-9880-5d18d8153b48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e2b241b-db85-4383-b419-d4c2b03a1147
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bba5f003-a870-4c4e-9913-6b0554a675cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e8350c2-5d95-4495-906d-8bd5be8c0a6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2abd3241-a2cc-4959-a5a6-c4c7effdba24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ab3f462-701c-4b7d-8d87-b7e1c12c8975
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46a05659-c50a-4fff-aa59-8e6a7aa44baa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 428c4ede-4ef9-490c-822c-7aa465b86f7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46de3517-bacf-4e04-9885-719675219b69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1dd01cff-57b3-4b18-8391-79ea228a3e38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cfcc0e2-607e-4b7f-a7ca-96f9fc14357b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa28aaef-922f-402e-8ece-b530dbfe1745
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1e0f664-8cea-47bf-a265-673f49b631a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83fd1740-bd11-40d9-b817-0bdd4424d6d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 182e1ec4-eb13-4c53-87c8-878ea85aba60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70ae11c7-5522-4b20-b534-0691590746d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1707a3e0-7155-40c5-b3e4-cc71d3149a1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4645d4b4-aca2-44f0-b3a7-314f66fdee28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82986be8-db9e-4332-8e89-f48375a99add
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d099cf5f-5d7f-4cbe-8762-34d79e66ae09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7951be81-91e1-4012-82d7-980c87fca065
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97761a56-3da3-4f99-ba49-348d742840c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4ab9422-096b-4b25-9b1d-621c3ad2d095
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d5eb29b-477c-481e-936c-08ba50f7cdd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 896a0bf4-ad51-4fa0-83de-15b1e69c9167
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bcf7f70-ad5b-4395-81c7-e73b8ac926ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90556972-11c7-45ae-b4b6-ab3f25e7d6a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65afce39-59b6-4b93-95d7-ec77ef3bf71d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0ed809b-b339-4155-9822-620533c99c91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42ab7df2-204e-4ce7-b943-245cbce72a37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3dc151d-edbf-4686-b9a3-08fb7cb623a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a678bd2-f0f8-4870-9a58-e21b5131a95d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29e6e497-eefa-413e-9a3c-edf601b683a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26df49d0-f92b-4364-907e-def9304ef570
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message becb9b93-5c92-41bc-bf51-a1bbbf457f57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9379fc7-67ea-45f0-af0c-7288372eb2d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c81659f2-d97d-4943-a4e4-bf6bac61567e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7452d19c-c784-4efc-9c81-025be9268300
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db44057b-b2a2-45c0-a94c-2f66c3f3158c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6de78a9a-d61b-47c7-98f5-df7716a3524a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 011166f6-e123-47da-9416-9f0cf82eecc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0866f2a-ffbc-4fbc-8c96-e550491a099b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 046036e0-4723-4bec-99d9-2d245dda3236
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bffe917d-f6bb-45dc-9aef-292c6d97d4d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdd6cfcd-62e9-4af4-8dc1-740b71d07823
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd85b518-d237-49fb-8197-59d9284c69f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be6990b7-b5f5-4abe-9d18-bc4a6f4e380f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97943d7d-66d0-4976-b73a-07300e39eb6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 854ae2f7-666d-4e89-a699-fe4baee7ead6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2e7d447-4840-45b9-b8f4-97bbecf1dfcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3da7b601-eedd-49d0-9d94-b22472a3ceb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd9e037c-dc39-4c02-a576-09fdb1676ec2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c8a9541-8ccf-40ea-af34-e8fd22015773
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36f71521-b308-456e-b70f-6b1086943fe5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c0255ae-022e-4c1e-b61e-c505d478291f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8942749-dba7-43d7-a90e-28a51e48a913
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4222bf7-1d76-47ec-89d8-362fcf36a95f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12a2120e-0081-4a8d-b246-fdb3a5e13085
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47422967-3120-495a-9815-ce6191cb44f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e29645c2-10f3-42dd-8d13-ca636a804450
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b88bad7f-a733-4e9b-ba9a-781f592a2fd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e04e566-d276-4a87-9962-7df2c1c6546f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 858175de-f1c2-4292-a7ab-c486ef7c5d5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d85deffe-399f-485d-b0f8-6b6561868ebb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1841371b-caf3-4f13-8a1e-17bf9b49877a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6515a82b-4804-4722-a404-92121f204f48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33eb7fbe-6084-434d-8266-eeb40aabbfc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15d7e065-b800-4ed0-b076-0805920929b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b2fcfbc-7904-4676-a99c-5233b5d25cf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8817d39e-2154-4deb-b6db-0163c47a40d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2803c03a-4b3f-4786-8377-7fe0ce942e9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca5401b4-6bf6-469a-9934-e3bb86453aa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05b6cb04-548d-44b5-a862-c16b07e15512
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message baf013c0-6615-4c4b-bfe5-446e3a25d7a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4e18899-2605-4e86-b1d4-88ae142ebe99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f40743f4-e00b-48ec-b4ea-a99b8f17ab81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af9379a9-d7a2-4124-b5ef-de8e65c7d0d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ad97d89-2fc2-4c52-85f5-cba40181a9c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9cb2a201-dc9a-4dc4-8bcf-4c89a4a47605
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f870f37d-8f3f-42df-a649-d8bfe257ae1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4104cc2-8029-4e21-b773-c23bcaddd3ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e812284b-7f42-4cce-9d17-b70bf79af84a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1825470-fc75-4542-a58c-38cf132682fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dce60ac7-eb93-4d11-9e68-fa77b705b64c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b59a41da-23f9-45b4-a70f-2499d320f0d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac2e4e31-c449-4ead-8e46-8666cc366336
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5abe6929-cf4d-4141-978e-67f378541cb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac375683-95bf-4d26-b6b8-b367948bcfc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd18caa0-7edf-48fb-962c-1040f60e4827
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b745b1af-ae7a-4d66-b6a9-1fabf14bf5b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ffac5a1-ed9b-418d-99c0-46ebf979448f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d98b59a8-c564-4f40-a21d-aec87e7b8ae7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1e0ffe6-b34b-461c-be83-758c08309a49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1697c95-3b34-4367-a3c6-c23e1e810f2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f96c4d6-65a8-4d9f-8333-97a1073e4c52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0d121b6-4bad-4190-bc16-9e06ddc3e1e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7698f1dd-e61c-4ac3-a541-a03926b0427e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa5f25e6-ea83-41fc-9b18-a20011a25804
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a542a47-284e-409a-aeb8-99cd6c1d1a7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5eb07d6d-1811-4877-a7a5-0b6e06ba30dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b309ab3-9efa-453d-9ac9-8cf7d8cd8e0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30dba27c-cd3d-44d1-8293-7e929ea6136c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f47a2eb7-828e-4f74-af77-8c0c6bff9546
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 380afbb5-5b04-4576-ab3b-f66e1a3c895b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a7ef58e-2ceb-4882-a6c3-ed737f51f73a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00dc76c9-936a-4c6f-b5f8-5dc29aa39376
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb594418-8a04-434d-beca-3c280ef89f93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55403038-903c-492d-9a6a-09dad289dc32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4769679-71d6-49ae-88e0-68b53a334a2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7281fa0f-3f18-420c-977d-7774db975a8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abf1fee5-0d37-44fc-86b8-3cdeb4124ccb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0aeb3d4-dabd-41b6-87db-66d08c7b45fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fe97577-1ad8-4bd7-b0d6-13de33cc5d9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9389c6de-bd58-42a8-bd1a-f3cf4a274d98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13f6169a-cc25-4f28-8054-7bdaa44af0db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ddc1618-245b-4074-9fd5-22a4c97a35ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd213593-2703-4e81-b742-14822fe3381b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70c5c203-043a-4e9d-a1fb-282af51b4654
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e320f26c-6913-492e-a8ef-0a0fdacfce98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 818bdfed-0f7f-453e-afd7-2b47a97fa87a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a627a02-7dd8-4b07-b4e9-5eb2790ddf83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad2308c0-17c5-42fc-9a6e-affd7acd2484
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 997a90ac-2966-481b-9a7a-92a106d6b344
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f37d051-b4b1-4af6-a6b8-e5de84d58b6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8a2c733-0562-4612-af08-87e9c0f9f801
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17e5977e-cd4a-437b-a2fc-0827d258257d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29021770-9c48-47ff-afe5-081d297c912f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8ee0274-0041-4b8d-85c3-01b74f8e40ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79dbe25c-5d2c-455a-ba09-4fb94b093110
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 239193bf-ad23-4569-be44-cb9e926a3d00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8bc81668-18e2-40a4-ab48-4002e48e55ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6a7e436-f7b8-4ef1-840b-e7abaa9a139e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74e94d2a-f69f-4a8f-b62b-8f69b99f11a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 573c7a97-fb56-455f-85dd-7de4f4b5e789
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 581a699f-3f97-44de-90b3-67e391287f62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29cea457-e719-42fa-92bf-06c90fa4a371
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51af3dcd-709e-4d8c-b6fd-c6f562ef00e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c000dfb-dea6-4a42-a3b0-750ba30104d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bccc6bc-ee8a-4016-a19d-cdbc591c25b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d090e724-925d-4fc1-a466-590a817fa861
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5c550d2-4848-4f05-b35a-4a8a7fa70689
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 653d78bc-a63e-4e3e-aba5-765896f4d1f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8142ff4-62f9-44ab-aa57-e923b27d3153
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b65bd1d6-b9ea-4269-8ff5-a27ea34229e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1a4e419-d7c7-49cb-975e-003afec58f5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94c5cae2-906c-4da0-8bc7-cb550364a691
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 482a79f5-a78c-46fc-a5b0-a43efe6a2523
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc21da21-606c-4739-87c4-3c1b634cddfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cac98ce6-be5a-4e83-b0af-d9dd558b17ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19384e47-7176-4ab3-b537-26fb90e31a1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01d0734b-aa71-4e82-9d3c-9b69779031b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c2c0eb5-ecb3-4d2a-a466-be6e69145dae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9484973-765d-467a-acac-6ec0beb74e67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 107a7c25-b579-4b2c-b154-cd50c80fec69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73a5c8ae-9a00-4699-99a2-eb287751ad15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1828b75-203d-41d9-9b68-9f9e7caa8a05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9d58fbc-5d7b-4b28-9cfd-57dd9b72dc9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36f34bff-7fb9-413a-aaa0-b4992b15c0a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1fc5737-8058-4c63-a55d-c7ae0b72821f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4de47ee-f225-4495-aa2b-03fa0c2e554d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a94a7db-7eca-4ca1-97c7-eac11d4afa6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcfd7aca-7cee-4f92-a4af-40a3af3866f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message addc8641-b3c0-4c2d-a949-c6ee35bf475e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40e2e04f-b667-4a43-b294-4f9c54e94b5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f80e562-c49b-4517-99d9-b19816a9bee4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1ccb8c2-3ef5-4e3b-a366-5c8119e9b52e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc9d90ce-a831-476d-b5af-aba953f8d5d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bea061fc-f488-41e5-9bc7-e85b6935920b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f03aea78-6ce1-4b77-8d12-1b35109a5727
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5a5ad58-eb4c-4fcc-a650-6d26df5db28f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f15c0334-17fb-4859-aec2-df594de56420
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b719101a-87d8-44a4-aba7-d5703af0902d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10b314a1-775d-4e8b-aea0-95d8f7207e73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fe6dd73-1e4a-4015-8cde-8b0be7e8bf38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8efb07c-f61d-4486-bc4e-a208f975625b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 484e150b-92e7-4c48-a465-bdcc0882db25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b8a049a-b9b9-48bd-8b52-9fb363cd69ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48915e40-623b-4148-9c89-c650c5a67250
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 733abaf8-6e6c-4309-ba57-9d8d19789d68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37f0814a-b64f-4d51-8dce-b6a0cc0c825d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76447be9-0bc3-496a-b172-e49c99cfbfe2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fdc1e9d-a62d-4208-83fb-7f216b43d173
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12c14c6f-6621-4858-9041-07a3ca468fe8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7011471-cbe8-4dce-8d04-f18a11d6ed6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e42c6a62-ab8f-421b-9c75-aa953b4c2b34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b000aa90-a1a0-4abf-b590-4a6fdb85489d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2c1061e-0434-4222-9dae-1f40011d7d3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d80fe0e-83ef-4145-bf57-b3ba9941dac9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ef0297d-5987-47df-acfb-318df0a8d548
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bd00725-d311-465a-86ff-6f046b2642eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9916e45c-7462-4f09-b39d-dc5cff4e2091
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 703ce555-2424-4e38-a803-e7da99e900d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80383c0e-c5cc-40a0-8d22-62a7598a114f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c48fe31b-f0a2-4fcc-b11e-92ec9d453cad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e329a762-ee32-4131-9a84-98b8c9b1ee0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a92bb936-214b-4a6d-bda1-6102f2d5b803
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be6d4163-77bd-48c7-b6c8-8237b5e094df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddd92243-368c-4cee-b031-8d400f7b4163
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c74f855-8c00-4a5d-9037-cbb689bfdbde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24a29bae-dd8a-4f50-a548-6620f5e78e42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ce1553f-aba4-4efa-adad-ceca2cd905ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1b6d959-d7be-4ef9-832d-0cd946a0578c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eef424a5-0202-4b40-90b4-dfa98669b296
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01024c02-4128-49f3-a2ff-f2132012e446
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27fadecf-d1f1-439b-9e73-5fbbc8e5e2ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9004d2c7-3c0a-434c-abe3-f8cff25c3571
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e298c77-1313-4490-bf40-16cc89946860
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8288125-aa26-417e-925d-f93dd6b80b23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4be77f7-cc42-4670-97fa-3959a153c773
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b15a7d6d-195e-42ca-8da7-a130005a172c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f97171f7-f1b9-49d0-b5bb-9922d583986d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62ac0ad7-3041-47ca-a73b-ed59c045b427
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d77f758-fd2a-4029-a487-e8c1298f4aab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27cfb366-360c-43b3-b342-519f159aaa02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fdd8869-3621-48bb-b4e6-8fd751007253
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec8dba54-9875-4524-ae46-fa5fb70abd43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28804820-f8d2-427d-b4f0-31f981df6633
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3e25e25-73a0-43f1-b309-e90ab728b55e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0aec6c41-9bcc-49ba-b0c5-7b1d590aec83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d03ee957-f44c-47d2-b475-82f75b770a8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00108b00-4b0c-4898-a4b1-7dbeacb3faa6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5ba2bcd-d1e4-4651-b1f9-48b64e15d884
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5826c160-4f2a-42ee-8385-c1e67a1fd404
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5c8b9f9-c3fd-4d2c-a09c-6bcb8cda5fb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce3d2c6d-0c03-48ed-b0fe-28ecceff051a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c971c9e9-a2d2-46d3-901d-c67451872d32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8cc5283f-d76f-435d-87e3-637e186bd2ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc10fc4b-1da6-4dd8-8897-68c59349548d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8651ddb2-5af3-4847-a500-bb5d21cf1f2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 098fc4c5-442e-4bdc-bcb9-deefdb35ca43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba64f5e9-5618-4d39-bbbf-1543e622f0c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12d00e9b-e2ce-44ca-aeca-05938c594aa3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 300f2b80-303d-40c6-a829-dcca93dcad4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 099eaa04-3c82-4fb7-a0d0-4238e6d0e34d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a648a48a-803e-4458-a557-91e195dbe71f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1f850de-66ed-4661-9c7f-3911c5b86ed2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 115c65ed-1b83-4b2c-9485-345a9ae4d04d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8038fdf-96a6-4eff-9948-64f3cb048897
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 085747cd-e121-40a2-9ff2-47488dc74280
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba98b7a2-4f5f-4d9e-8bc8-40fc94f974b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d04dbe2e-f1c3-4983-87a2-083cc782dc91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 919abc6e-4935-4d48-8e4b-95849a6b88a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea47a031-009a-491e-a3e3-1c5b3ee6b4db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f655d397-5738-40d3-93b6-02f3da3c3bc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa1db5d6-c10d-4bf5-8504-a18883abc964
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7342baa-ae88-45a4-93f7-ec2500118e21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c981f85f-dcb2-4234-a329-57548e822e5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f5d0b03-13ab-4b93-a971-51d465321bd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43ba6ff3-ef2d-4089-96fd-218178b01aa6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77df29d6-40de-45c8-ab74-ba800f060e18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7dd2e8db-2a1d-4adf-915f-7c61239ca2e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e74abff-03d1-4cdc-b628-f263dadd07d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32046592-47e4-4910-85d0-3030124c3776
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02e1ac0a-d7bb-44e4-8a57-b0a36c964bd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d8da876-768e-4be9-b3de-7b3deae87f17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba81943b-1312-41dc-bea7-5f5fa729126a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91882fc7-d3bf-4eb9-a4fc-5894bfeb76b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d85077d-9eab-4360-b6f6-cfc09e64fcea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81e458f7-cd80-4b25-b433-158380baa9c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd26dba1-8941-4a11-af03-f3dd6d2fa87c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c124ad65-23d6-4671-8446-e40b303b5ce5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4934beee-4c54-473e-b4c7-5b3021277e00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efcc8fd6-1064-4d25-b2b5-be16498a9515
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8078262-bc73-4254-8c11-e744defa6d16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e216025b-f7d1-4333-9284-59a8d7700202
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cc1529a-b0b3-4bba-b58d-51b2e273a9a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eddee81e-2c1a-4d03-9f11-d0ef2f860a0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15526ec1-4d0a-44de-ba4f-0225a9b12b41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 690369ac-e929-4547-bbb9-184dc5d4a81a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74cddd52-de16-427b-94da-44c73ec59baa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99572286-2255-449d-80c4-3a72acc7f906
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 544da622-3da7-4047-908e-443dca798fe3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0504f7bb-e200-4fe5-950d-3b6b3ce239b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bf3fc49-cddf-41bc-a9b1-95a25d07bfae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fb3b93d-15f1-4787-a5e3-5714bce39e1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 376b9888-b7fa-477d-a40a-fa96feb44147
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac726367-5fba-42e6-bb17-85a9495620c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2b6c5dc-f6b4-4b53-ab17-57ba1b50e17d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69f447c1-dc7e-4ae8-875d-5068a0c0b8ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b591102e-1f9d-4818-b0e6-5238c109b6f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0c0ad47-c4b4-451d-9d22-b89ce88f313b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1847ca17-fe2a-43d8-aed7-4a486fa0a8db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f897839a-820a-4216-9c89-5e7d7f292ca4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af075709-97ac-4b2f-8614-7387fd00e673
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1b74294-5857-4b89-8c97-b3758c818137
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8d79a93-2d48-4f14-a248-233b8f7b83d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 457b6866-84ac-4be8-9561-9895ac947801
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e572cfd3-87c9-43f1-a7a5-f357fb93d693
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82328d80-0cca-4ebd-957b-8e29293975de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf7b14ff-1df0-4989-b6d9-0d527be89bfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f736d98-d3fb-485b-bd13-105da9d57a37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0da41436-11e5-43dc-8299-5bc076277ff8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25449f82-a010-4939-8ecf-ecf0f9aea34f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b88747a-8c84-4cf0-998e-3ac2fd64533d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 808af906-03a4-4bc5-84e9-a84ae20cdd43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a43397b5-44fd-4023-a6c9-782553f6cb93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9449f53b-8c74-4607-8531-f17a89d1a1d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d495ef3-4f99-4992-8c65-940221b0557c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e864d7f-311c-4144-929a-4c7d725b86f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 860de3e6-1a7a-497e-988e-469903f506f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a817ab81-908c-4406-b8b6-fd9b216373ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef4bd563-c9cb-4655-a7d0-e6dbd09de4ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 176e9981-8506-4eef-ab40-54a5674eb84c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75d136a8-1926-4db5-9e60-a18fef47932f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19252f8e-7cf2-42ef-8535-68f092bda300
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bab6894a-5280-42df-a3fc-972a4346c526
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40a7f7e0-7596-4eab-8a02-631850e37393
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e89ba01a-2f56-4c12-aff2-b662226d1d46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9a310dc-ab03-494a-8793-3a11cfbf8cb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c11207c1-eedb-4f89-9800-b62cb6cc49b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60953bc6-1fd8-47b6-9983-2d06eb630668
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1cfbc61-9177-472e-86b0-874ce6aa975c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message adb66f22-4f4b-4093-b9f2-ccc8e416e91f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98227888-bd60-4c73-83c3-137d59663e88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b558dae5-9242-4ab4-a2ab-c7ea0f55509e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4b2e0c3-d21c-4717-91ac-be9e3ad9aebd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1dee6cc5-e339-4f31-9eda-1f59d44bb97c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f7b00fe-6142-4920-b8b7-90d600636113
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d500fed-ce68-4357-9ef7-9a1db2999889
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e404faf0-0d72-45dc-8221-54a031b2521b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d43f4114-43d6-4d90-8053-35831b7c6815
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48d8bdff-2726-45ac-a949-ab07d82f789f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e9bd676-da49-49ff-a2fa-487f860b8309
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3145eb8f-a72c-4811-a30f-f7e91708cc0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f99dc755-5500-48d4-a518-c421044ca32f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57b22bd3-67cf-4477-be9b-a915cc8800c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 415c45ec-e3c3-483d-a922-d6af35faa4fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8cf0577b-6419-41fd-8f7c-aca3e8e267e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f128566a-6db2-4477-9fb6-041f8ea80568
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef09ab11-2e11-4ceb-a118-3fe89475fd10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e59febd-1b8b-4aa9-a870-79d6a3bd2b57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acfa4c94-adb5-4fd6-b289-7743685aed85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dde66235-af18-4772-88fd-13ea99aeec13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 620cd0d2-f09f-47ed-84af-43cfadd1222b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44bf73f6-17de-4374-8bf1-134b596bc911
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f1d498a-55cd-4e3b-876c-a9ae4448f4f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef3c399f-b427-49ef-9805-a8784843db46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11deb26a-d409-4c7b-80e5-121f214da2d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5dcb25af-c80c-4770-adbf-de829fbef879
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51f33146-1ab1-44e2-9cf1-93566f250e94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d492581-6680-4283-a389-02e1e9aec617
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df2134f6-becc-4162-9082-fcbfe933713e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3de13f77-a1de-4a9e-afa0-691682392837
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0ba6eb6-8cc1-4267-b4ba-60f71ba0858a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd8cf0f4-5c03-407a-ad5f-be34d2af8776
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ac1070a-5504-46f5-b986-43464e134246
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04fc0349-2ce2-443f-bf5e-86e67061c1e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11c28bf8-ed8b-4b26-a75e-d417f3c795cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 377eafa1-0e34-4c37-b2ea-f9f6b771c87b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db6edc72-e7cf-4eea-8d59-bb1ab13d96fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fef856d-09cd-42c2-80a8-934245b38d5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c7a286b-9712-419c-a4d9-8d6e18f342d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87dcee74-02f3-4328-88e7-5f17510addf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a044415-1f23-4b97-8a29-06151f9ad020
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88325f1d-5364-486d-b9af-9ff88cb864fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bf5cf76-7f10-4742-9756-260ead15f531
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41a95ca1-8a84-40c2-878e-d217ac82bb78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e9eaf29-8b23-4f7f-b68d-ba3740bd570e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9dcdef4b-0f0e-4ef6-8ea0-6835e34f2639
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a19cedc8-d068-45d9-9c2d-2277aa1c89a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8368009-c9b2-4030-8990-28dad90fbd2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 579eb2a1-161d-4087-a3c3-ef40a91d4040
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6de8b6df-cd53-4fec-86b2-590337f23535
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23d19a91-b35a-4d18-9b4c-63e702414bbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68237247-add3-4d40-be52-aec1c49b78d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7ee3dfb-7981-4155-9076-619a69687623
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 011dbe95-e095-4fb0-88e8-ae56a9e45e0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d33d9ad-4fc9-41d0-ad91-81b696bdf447
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24c71b65-04d2-4821-9c77-953f91d6cf51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6057db5-539c-4a20-88d7-a47ec843c862
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44dec99e-fc80-4967-b323-bd75facee0e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db42f432-3998-4ee3-bb30-d7eef8043aaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1eb6523c-ab53-46c4-a93b-68b6344ea04d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 964fc917-2cb6-447f-ad4f-2d0018b3e114
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5095a41c-c861-4e40-b1d6-f121eee36412
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36a0e018-9380-4ead-a1b8-4ae03295b400
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60b9e4ac-273a-48b3-b45d-1170ad782a53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8559f014-6d6b-4291-b9bb-332aada15f44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfaeaa19-1373-4099-a715-e9e710fad2b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76c48497-f7b6-4384-9409-529632d5ed37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4924791-2d16-47eb-a272-66ba4f6c6b59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 882704b9-9702-4acb-bf93-9d01e0f175c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7858c110-ec19-42c7-a72e-0c692cecebda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9af5583c-bc57-424c-8db3-87d679139586
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba464842-79ac-4817-8e8a-9609aba68f5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23317170-0951-415d-92d5-7b8e7fa9b835
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5fbdcca-5047-4773-b870-3e63f2865813
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2acded60-47a5-4744-a0cf-aa98c264466e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b859dc0f-588a-4d40-a081-238c079557fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e428f77-732d-43b4-87b4-70ff8d0faebd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c261246-b51b-4e41-b4b6-08d8517c14b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4253969e-4558-4527-8603-9d8b8c906fac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d447bff-0126-46f1-919a-ccb0ac147cfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9dca7cd1-01de-491f-8a9b-99255dc4be66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce880d45-3ce6-4a44-962a-24e1ab809d02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11ae7581-a995-4b3c-bd62-d11bf791b468
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f8c08e4-b28c-4aa3-a873-fff6c11d4700
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a81a2647-7bea-47c5-bc49-5aefe59352fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d3e17ec-99bd-4721-96e3-5bcc05f78e7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3c0ab69-1249-4f9b-a12d-4c10d4bcbe13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06f858a7-a2be-4794-995e-b6f186f55be1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 423417e9-c8df-4b80-9b77-8d5635a7409a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad7d6051-f8a0-4553-b75a-557740f30259
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4ba8170-9879-41d9-a75c-7e20b4f849bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f15350f-cdea-4406-88ee-c457916c08c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a4b1956-cea8-45d5-abb3-c3e3121ec996
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb17e6cf-63dc-4487-9487-5fc174687616
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2b21650-409f-46ae-aac8-a1b4c2c357d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5878ec4-ff25-4a7a-a7df-efe2e9a77411
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4fda867-aab5-4c5e-951a-9d368d2faab9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e82ed2e-097b-4b67-bd34-7a24a938369e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfc741a3-70b6-447a-9aa0-33a539b735d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6196ee80-4f20-4903-b8a2-fb9155869d35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4d32917-ff7c-48d9-9a4e-358f0a981224
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 317830c8-240e-4408-bf3a-6d7d833c5c04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b91f3be-f13d-463b-963b-1b978c2ea746
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 393bc891-45f0-4257-b765-fd58d5b0be67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 422559fb-c10f-4f87-93ae-87010ce175af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1eabe85-40e1-4766-92a6-626a1b9c8b30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f00572ef-5613-4e47-9c4b-1bb5f77814be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c91b3350-480a-46ae-9ccf-cd2fa25dbaae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9d0df95-54e3-4f97-bbc5-81003ac397e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a341a57-3ce1-44bf-9511-41d39be0d929
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 605b393e-e4a8-450f-ac8d-b3207667a407
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 662f26e6-a672-41c2-b68d-f393a490cafe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40d05b1a-879c-4beb-815a-79685cebadfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fae102b8-dbbb-4b83-b6f5-429fb322a815
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47971750-fc86-4ed9-93c2-39c1f01782b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee9fe674-b007-40a4-a04f-c2babaef8769
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dcc17eb6-794a-417f-8293-531244fa6ea9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d136434-92eb-4c07-8e45-28319ceab640
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 595de353-7b43-4fb4-8637-3a438d5ed201
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 080bc1f2-eb3e-4f7b-8f29-c50f57b2cfa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b51e291-08eb-424a-9add-acceeab3af39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0d30eda-82ae-48f2-8c5c-9680061575ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1b74dad-da85-4017-a263-c65b061c0c60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c497921-67db-4f7c-8399-aaf29505c8f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b502b92a-7e10-473b-876a-6f761ea4ab0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46856402-6a77-4a40-ab1f-3c315abe8cb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61e0d554-b0e8-493c-b519-8c87b9b1ca54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 200d8f27-3526-48eb-a728-6d44954c6a46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ef826c9-6912-4308-9e30-668cd7162c82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9f2b33a-f3d5-40f6-bca0-d45960f03be3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 693558f0-c625-4486-8e02-dca3d118edcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c5c6ccf-ba17-4b2f-8577-3b598d3af0a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f220210-c09d-4148-b1dc-a76379a61eec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7cf92f1d-1b77-43f9-9243-adce2442f7fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba956d5a-b938-4482-85fc-ab36d93e341d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22c0feca-14a1-4ce2-b2a3-fb1f6bb6623b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ea725f6-4f5c-4829-8754-dbf87bfb0004
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_10
Server: localhost:8688
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_10
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_10/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_10/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_10/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_10/test_labels.txt

📊 Raw data loaded:
   Train: X=(4872, 24), y=(4872,)
   Test:  X=(1218, 24), y=(1218,)

⚠️  Limiting training data: 4872 → 800 samples
⚠️  Limiting test data: 1218 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_10 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 1 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1990, val=0.0858 (↓), lr=0.001000
   • Epoch   2/100: train=0.0909, val=0.1042, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0885, val=0.0868, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0801, val=0.0889, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0815, val=0.0887, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0795, val=0.0886, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 1 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0186
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0021
============================================================


📊 Round 1 Test Metrics:
   Loss: 0.4035, RMSE: 0.6352, MAE: 0.5654, R²: -3.8142

📊 Round 1 Test Metrics:
   Loss: 0.0958, RMSE: 0.3095, MAE: 0.2589, R²: -0.1430

📊 Round 1 Test Metrics:
   Loss: 0.1021, RMSE: 0.3196, MAE: 0.2651, R²: -0.2183

============================================================
🔄 Round 6 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0853 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0801, val=0.0838 (↓), lr=0.000250
   • Epoch   3/100: train=0.0798, val=0.0839, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0796, val=0.0841, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0795, val=0.0840, patience=3/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0793, val=0.0839, patience=9/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 6 Summary - Client client_10
   Epochs: 17/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0019
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0126
============================================================


============================================================
🔄 Round 7 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0839 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.0803, val=0.0832 (↓), lr=0.000063
   • Epoch   3/100: train=0.0800, val=0.0830, patience=1/15, lr=0.000063
   • Epoch   4/100: train=0.0799, val=0.0828, patience=2/15, lr=0.000063
   • Epoch   5/100: train=0.0798, val=0.0828, patience=3/15, lr=0.000063
   • Epoch  11/100: train=0.0797, val=0.0827, patience=4/15, lr=0.000063
   • Epoch  21/100: train=0.0795, val=0.0825, patience=14/15, lr=0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 7 Summary - Client client_10
   Epochs: 22/100 (early stopped)
   LR: 0.000063 → 0.000063 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0083
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0055
============================================================


============================================================
🔄 Round 8 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0807 (↓), lr=0.000063
   • Epoch   2/100: train=0.0814, val=0.0808, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0805, val=0.0813, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0801, val=0.0816, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0800, val=0.0819, patience=4/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0797, val=0.0822, patience=10/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 8 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0141
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0017
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0927, RMSE: 0.3045, MAE: 0.2608, R²: -0.1058

📊 Round 8 Test Metrics:
   Loss: 0.0861, RMSE: 0.2933, MAE: 0.2527, R²: -0.0266

============================================================
🔄 Round 10 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0858 (↓), lr=0.000016
   ✓ Epoch   2/100: train=0.0811, val=0.0852 (↓), lr=0.000016
   • Epoch   3/100: train=0.0806, val=0.0848, patience=1/15, lr=0.000016
   ✓ Epoch   4/100: train=0.0803, val=0.0845 (↓), lr=0.000016
   • Epoch   5/100: train=0.0801, val=0.0843, patience=1/15, lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0795, val=0.0839, patience=4/15, lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004
   • Epoch  21/100: train=0.0793, val=0.0837, patience=14/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 10 Summary - Client client_10
   Epochs: 22/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0107
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0129
============================================================


============================================================
🔄 Round 11 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000004 → 0.000002
   ✓ Epoch   1/100: train=0.0785, val=0.0863 (↓), lr=0.000002
   • Epoch   2/100: train=0.0785, val=0.0863, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0785, val=0.0863, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0785, val=0.0862, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0785, val=0.0862, patience=4/15, lr=0.000002
   📉 Epoch 9: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0785, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 11 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0051
   Val:   Loss=0.0863, RMSE=0.2937, R²=0.0103
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2470, R²: 0.0106

============================================================
🔄 Round 12 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0875, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0800, val=0.0872, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0798, val=0.0870, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 12 Summary - Client client_10
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0004
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0365
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2476, R²: 0.0014

============================================================
🔄 Round 15 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 15 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0001
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0349
============================================================


============================================================
🔄 Round 16 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 16 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0015
   Val:   Loss=0.0806, RMSE=0.2840, R²=0.0516
============================================================


============================================================
🔄 Round 17 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 17 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0085
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0197
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2478, R²: 0.0118

📊 Round 17 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2483, R²: 0.0089

📊 Round 17 Test Metrics:
   Loss: 0.0834, RMSE: 0.2887, MAE: 0.2487, R²: 0.0053

============================================================
🔄 Round 21 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 21 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0141
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0228
============================================================


============================================================
🔄 Round 22 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 22 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0086
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0114
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2486, R²: 0.0064

📊 Round 22 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2485, R²: 0.0069

============================================================
🔄 Round 24 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 24 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2836, R²=0.0120
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0094
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2484, R²: 0.0075

============================================================
🔄 Round 26 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 26 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0027
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0254
============================================================


============================================================
🔄 Round 28 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 28 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0194
   Val:   Loss=0.0848, RMSE=0.2913, R²=-0.0329
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2480, R²: 0.0106

============================================================
🔄 Round 30 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 30 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0118
   Val:   Loss=0.0894, RMSE=0.2990, R²=0.0037
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2478, R²: 0.0120

📊 Round 30 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2477, R²: 0.0130

📊 Round 30 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2476, R²: 0.0134

============================================================
🔄 Round 37 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 37 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0105
   Val:   Loss=0.0936, RMSE=0.3059, R²=0.0090
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2475, R²: 0.0146

============================================================
🔄 Round 38 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 38 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0127
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0017
============================================================


============================================================
🔄 Round 40 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 40 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0202
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0293
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2473, R²: 0.0156

============================================================
🔄 Round 41 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 41 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0158
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0206
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2473, R²: 0.0159

============================================================
🔄 Round 43 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0686 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0686, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0686, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0686, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0686, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0686, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0686)

============================================================
📊 Round 43 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0061
   Val:   Loss=0.0686, RMSE=0.2619, R²=0.0385
============================================================


============================================================
🔄 Round 44 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 44 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0099
   Val:   Loss=0.0720, RMSE=0.2683, R²=0.0269
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2472, R²: 0.0168

============================================================
🔄 Round 46 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 46 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0096
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0269
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2471, R²: 0.0173

============================================================
🔄 Round 47 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 47 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0152
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0055
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2471, R²: 0.0175

============================================================
🔄 Round 48 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 48 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0184
   Val:   Loss=0.0898, RMSE=0.2996, R²=-0.0150
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2470, R²: 0.0177

============================================================
🔄 Round 49 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 49 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0149
   Val:   Loss=0.0862, RMSE=0.2935, R²=0.0032
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2470, R²: 0.0181

📊 Round 49 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2469, R²: 0.0189

============================================================
🔄 Round 56 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 56 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0099
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0281
============================================================


============================================================
🔄 Round 58 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 58 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0178
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0005
============================================================


============================================================
🔄 Round 59 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 59 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0098
   Val:   Loss=0.0716, RMSE=0.2675, R²=0.0221
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2468, R²: 0.0196

============================================================
🔄 Round 62 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 62 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0209
   Val:   Loss=0.0819, RMSE=0.2863, R²=-0.0200
============================================================


============================================================
🔄 Round 64 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 64 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0082
   Val:   Loss=0.0752, RMSE=0.2743, R²=0.0379
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2467, R²: 0.0200

📊 Round 64 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2466, R²: 0.0209

============================================================
🔄 Round 76 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 76 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0118
   Val:   Loss=0.0779, RMSE=0.2792, R²=0.0056
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2466, R²: 0.0210

📊 Round 76 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2466, R²: 0.0210

📊 Round 76 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2466, R²: 0.0210

============================================================
🔄 Round 81 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 81 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0165
   Val:   Loss=0.0866, RMSE=0.2944, R²=-0.0209
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2466, R²: 0.0211

============================================================
🔄 Round 83 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 83 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0137
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0187
============================================================


============================================================
🔄 Round 84 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 84 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0147
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0101
============================================================


============================================================
🔄 Round 88 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 88 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0142
   Val:   Loss=0.0710, RMSE=0.2664, R²=0.0132
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2465, R²: 0.0213

📊 Round 88 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2465, R²: 0.0215

📊 Round 88 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2465, R²: 0.0216

============================================================
🔄 Round 94 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 94 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0120
   Val:   Loss=0.0770, RMSE=0.2776, R²=0.0196
============================================================


============================================================
🔄 Round 95 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 95 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2850, R²=0.0165
   Val:   Loss=0.0741, RMSE=0.2722, R²=-0.0041
============================================================


============================================================
🔄 Round 96 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 96 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0217
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0105
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2464, R²: 0.0219

============================================================
🔄 Round 97 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 97 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0134
   Val:   Loss=0.0739, RMSE=0.2718, R²=0.0215
============================================================


============================================================
🔄 Round 98 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 98 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0123
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0207
============================================================


============================================================
🔄 Round 99 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 99 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0033
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0579
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2464, R²: 0.0221

📊 Round 99 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2464, R²: 0.0221

============================================================
🔄 Round 104 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 104 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0101
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0328
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2464, R²: 0.0223

============================================================
🔄 Round 108 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 108 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0137
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0050
============================================================


============================================================
🔄 Round 109 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 109 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0104
   Val:   Loss=0.0740, RMSE=0.2721, R²=0.0197
============================================================


============================================================
🔄 Round 110 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 110 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0140
   Val:   Loss=0.0731, RMSE=0.2704, R²=0.0190
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2463, R²: 0.0224

📊 Round 110 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2463, R²: 0.0225

============================================================
🔄 Round 114 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 114 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0083
   Val:   Loss=0.0734, RMSE=0.2709, R²=0.0390
============================================================


============================================================
🔄 Round 115 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 115 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0142
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0169
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2463, R²: 0.0225

============================================================
🔄 Round 116 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 116 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0160
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.0110
============================================================


============================================================
🔄 Round 117 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0702, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0702, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 117 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0141
   Val:   Loss=0.0702, RMSE=0.2649, R²=0.0161
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2463, R²: 0.0225

📊 Round 117 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2463, R²: 0.0225

============================================================
🔄 Round 120 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 120 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0130
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0224
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2463, R²: 0.0226

============================================================
🔄 Round 124 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 124 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0088
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0411
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2463, R²: 0.0227

📊 Round 124 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2463, R²: 0.0227

============================================================
🔄 Round 126 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 126 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0097
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0117
============================================================


============================================================
🔄 Round 127 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 127 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0146
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0104
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2463, R²: 0.0227

📊 Round 127 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2463, R²: 0.0227

📊 Round 127 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2463, R²: 0.0227

============================================================
🔄 Round 134 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 134 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0066
   Val:   Loss=0.0717, RMSE=0.2677, R²=0.0527
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2463, R²: 0.0228

📊 Round 134 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2463, R²: 0.0228

📊 Round 134 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2463, R²: 0.0228

📊 Round 134 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2463, R²: 0.0228

============================================================
🔄 Round 148 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 148 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0120
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0276
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2463, R²: 0.0228

============================================================
🔄 Round 149 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 149 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0168
   Val:   Loss=0.0734, RMSE=0.2708, R²=0.0086
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2463, R²: 0.0228

============================================================
🔄 Round 152 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 152 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0169
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0056
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2463, R²: 0.0227

============================================================
🔄 Round 155 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 155 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0176
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0009
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2463, R²: 0.0227

📊 Round 155 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2463, R²: 0.0227

============================================================
🔄 Round 157 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 157 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0194
   Val:   Loss=0.0861, RMSE=0.2933, R²=-0.0006
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2463, R²: 0.0227

📊 Round 157 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2463, R²: 0.0227

============================================================
🔄 Round 167 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 167 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0120
   Val:   Loss=0.0753, RMSE=0.2745, R²=0.0187
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2463, R²: 0.0228

============================================================
🔄 Round 168 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 168 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0167
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0007
============================================================


============================================================
🔄 Round 169 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 169 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0171
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0077
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2463, R²: 0.0228

============================================================
🔄 Round 172 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 172 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0165
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0107
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2463, R²: 0.0229

============================================================
🔄 Round 174 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 174 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0209
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0145
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2463, R²: 0.0230

============================================================
🔄 Round 175 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0682 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0682, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0682, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0682, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0682, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0682, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0682)

============================================================
📊 Round 175 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0111
   Val:   Loss=0.0682, RMSE=0.2611, R²=0.0304
============================================================


============================================================
🔄 Round 177 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 177 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0195
   Val:   Loss=0.0740, RMSE=0.2721, R²=-0.0065
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2463, R²: 0.0230

📊 Round 177 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2463, R²: 0.0230

============================================================
🔄 Round 182 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 182 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0184
   Val:   Loss=0.0768, RMSE=0.2772, R²=-0.0043
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2462, R²: 0.0231

============================================================
🔄 Round 187 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 187 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0121
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0287
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2462, R²: 0.0231

============================================================
🔄 Round 190 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 190 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0103
   Val:   Loss=0.0724, RMSE=0.2691, R²=0.0381
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2462, R²: 0.0231

============================================================
🔄 Round 191 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 191 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0101
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0347
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2462, R²: 0.0232

📊 Round 191 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2462, R²: 0.0232

============================================================
🔄 Round 194 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 194 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0238
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0401
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2462, R²: 0.0232

📊 Round 194 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2462, R²: 0.0232

============================================================
🔄 Round 197 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 197 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0193
   Val:   Loss=0.0881, RMSE=0.2969, R²=-0.0014
============================================================


============================================================
🔄 Round 198 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 198 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0075
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0439
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2462, R²: 0.0233

============================================================
🔄 Round 200 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 200 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0186
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0000
============================================================


============================================================
🔄 Round 203 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 203 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0214
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0099
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2462, R²: 0.0233

📊 Round 203 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2462, R²: 0.0233

============================================================
🔄 Round 207 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 207 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0169
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0070
============================================================


============================================================
🔄 Round 209 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 209 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0069
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0449
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2462, R²: 0.0232

============================================================
🔄 Round 210 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 210 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0134
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0165
============================================================


============================================================
🔄 Round 211 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 211 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0162
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0054
============================================================


📊 Round 211 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2462, R²: 0.0232

📊 Round 211 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2462, R²: 0.0231

============================================================
🔄 Round 215 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 215 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2819, R²=0.0140
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0020
============================================================


📊 Round 215 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2462, R²: 0.0231

============================================================
🔄 Round 216 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 216 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0198
   Val:   Loss=0.0728, RMSE=0.2699, R²=-0.0050
============================================================


📊 Round 216 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2462, R²: 0.0231

📊 Round 216 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2462, R²: 0.0231

📊 Round 216 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2462, R²: 0.0231

============================================================
🔄 Round 221 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 221 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0161
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0116
============================================================


📊 Round 221 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2462, R²: 0.0232

📊 Round 221 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2462, R²: 0.0232

============================================================
🔄 Round 225 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 225 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0147
   Val:   Loss=0.0720, RMSE=0.2683, R²=0.0012
============================================================


============================================================
🔄 Round 226 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 226 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0129
   Val:   Loss=0.0721, RMSE=0.2684, R²=0.0225
============================================================


📊 Round 226 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2462, R²: 0.0232

📊 Round 226 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2462, R²: 0.0232

============================================================
🔄 Round 229 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 229 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0090
   Val:   Loss=0.0751, RMSE=0.2741, R²=0.0432
============================================================


============================================================
🔄 Round 230 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 230 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0118
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0009
============================================================


📊 Round 230 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2462, R²: 0.0232

============================================================
🔄 Round 231 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 231 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0095
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0359
============================================================


============================================================
🔄 Round 232 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 232 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0038
   Val:   Loss=0.0711, RMSE=0.2666, R²=0.0660
============================================================


============================================================
🔄 Round 233 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 233 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0098
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0377
============================================================


📊 Round 233 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2462, R²: 0.0233

📊 Round 233 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2462, R²: 0.0234

📊 Round 233 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2462, R²: 0.0234

============================================================
🔄 Round 238 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 238 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0186
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0040
============================================================


📊 Round 238 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2462, R²: 0.0234

📊 Round 238 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2462, R²: 0.0235

📊 Round 238 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2462, R²: 0.0235

============================================================
🔄 Round 246 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 246 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0118
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0262
============================================================


============================================================
🔄 Round 247 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 247 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0176
   Val:   Loss=0.0877, RMSE=0.2962, R²=0.0011
============================================================


📊 Round 247 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2461, R²: 0.0236

📊 Round 247 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2461, R²: 0.0237

============================================================
🔄 Round 251 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 251 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0156
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0062
============================================================


📊 Round 251 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2462, R²: 0.0236

============================================================
🔄 Round 255 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0706 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0706, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0706, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0706, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0706)

============================================================
📊 Round 255 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0110
   Val:   Loss=0.0706, RMSE=0.2657, R²=0.0286
============================================================


📊 Round 255 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2461, R²: 0.0236

📊 Round 255 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2461, R²: 0.0236

📊 Round 255 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2461, R²: 0.0236

============================================================
🔄 Round 258 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0613 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0613, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0613, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0613, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0613, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0613, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0613)

============================================================
📊 Round 258 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0161
   Val:   Loss=0.0613, RMSE=0.2476, R²=0.0026
============================================================


📊 Round 258 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2461, R²: 0.0236

============================================================
🔄 Round 259 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 259 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0160
   Val:   Loss=0.0733, RMSE=0.2707, R²=0.0094
============================================================


📊 Round 259 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2461, R²: 0.0236

============================================================
🔄 Round 262 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 262 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0106
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0325
============================================================


📊 Round 262 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2462, R²: 0.0236

📊 Round 262 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2462, R²: 0.0236

📊 Round 262 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2461, R²: 0.0236

📊 Round 262 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2461, R²: 0.0237

============================================================
🔄 Round 269 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 269 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0109
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0320
============================================================


============================================================
🔄 Round 271 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 271 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0194
   Val:   Loss=0.0765, RMSE=0.2765, R²=-0.0002
============================================================


📊 Round 271 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2461, R²: 0.0237

============================================================
🔄 Round 273 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 273 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0168
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0110
============================================================


============================================================
🔄 Round 274 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 274 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0118
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0296
============================================================


============================================================
🔄 Round 275 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 275 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0182
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0054
============================================================


📊 Round 275 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2461, R²: 0.0237

============================================================
🔄 Round 277 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 277 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0219
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0098
============================================================


============================================================
🔄 Round 281 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 281 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0205
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0195
============================================================


============================================================
🔄 Round 282 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 282 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0208
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0162
============================================================


============================================================
🔄 Round 284 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 284 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2776, R²=0.0289
   Val:   Loss=0.0906, RMSE=0.3010, R²=-0.0354
============================================================


📊 Round 284 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2461, R²: 0.0238

============================================================
🔄 Round 285 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 285 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0082
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0435
============================================================


============================================================
🔄 Round 286 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 286 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2776, R²=0.0137
   Val:   Loss=0.0906, RMSE=0.3010, R²=0.0184
============================================================


📊 Round 286 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2461, R²: 0.0239

📊 Round 286 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2461, R²: 0.0239

📊 Round 286 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2461, R²: 0.0239

============================================================
🔄 Round 291 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 291 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0220
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0335
============================================================


============================================================
🔄 Round 292 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0635 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0635, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0635, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0635, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0635, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0636, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0635)

============================================================
📊 Round 292 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0094
   Val:   Loss=0.0635, RMSE=0.2521, R²=0.0374
============================================================


============================================================
🔄 Round 293 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 293 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0162
   Val:   Loss=0.0766, RMSE=0.2767, R²=0.0023
============================================================


============================================================
🔄 Round 294 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 294 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0197
   Val:   Loss=0.0919, RMSE=0.3032, R²=0.0026
============================================================


📊 Round 294 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2461, R²: 0.0238

============================================================
🔄 Round 295 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 295 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0086
   Val:   Loss=0.0818, RMSE=0.2861, R²=0.0415
============================================================


📊 Round 295 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2461, R²: 0.0238

📊 Round 295 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2461, R²: 0.0237

============================================================
🔄 Round 299 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 299 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0203
   Val:   Loss=0.0721, RMSE=0.2685, R²=-0.0057
============================================================


============================================================
🔄 Round 300 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 300 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0200
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0033
============================================================


============================================================
🔄 Round 303 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 303 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0281
   Val:   Loss=0.0872, RMSE=0.2952, R²=-0.0475
============================================================


📊 Round 303 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2461, R²: 0.0236

============================================================
🔄 Round 304 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 304 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0245
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0239
============================================================


📊 Round 304 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2461, R²: 0.0236

📊 Round 304 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2461, R²: 0.0236

============================================================
🔄 Round 306 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 306 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0185
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0049
============================================================


📊 Round 306 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2462, R²: 0.0236

============================================================
🔄 Round 308 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 308 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0111
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0313
============================================================


============================================================
🔄 Round 310 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 310 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0144
   Val:   Loss=0.0718, RMSE=0.2680, R²=0.0229
============================================================


============================================================
🔄 Round 311 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 311 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0222
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0098
============================================================


📊 Round 311 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2461, R²: 0.0236

============================================================
🔄 Round 312 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 312 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0167
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0039
============================================================


📊 Round 312 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2461, R²: 0.0236

============================================================
🔄 Round 316 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 316 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0135
   Val:   Loss=0.0880, RMSE=0.2967, R²=0.0157
============================================================


📊 Round 316 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2461, R²: 0.0236

📊 Round 316 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2461, R²: 0.0236

📊 Round 316 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2462, R²: 0.0236

============================================================
🔄 Round 319 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 319 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0114
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0314
============================================================


============================================================
🔄 Round 321 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 321 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0161
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0148
============================================================


============================================================
🔄 Round 322 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 322 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0068
   Val:   Loss=0.0749, RMSE=0.2737, R²=0.0522
============================================================


============================================================
🔄 Round 323 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 323 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0169
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0082
============================================================


📊 Round 323 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2461, R²: 0.0236

============================================================
🔄 Round 325 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0703 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0703, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0703, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0703, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0703)

============================================================
📊 Round 325 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0120
   Val:   Loss=0.0703, RMSE=0.2651, R²=0.0342
============================================================


📊 Round 325 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2461, R²: 0.0236

📊 Round 325 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2462, R²: 0.0236

============================================================
🔄 Round 327 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 327 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0052
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0573
============================================================


============================================================
🔄 Round 329 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 329 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0169
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0124
============================================================


📊 Round 329 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2462, R²: 0.0235

============================================================
🔄 Round 331 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 331 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0108
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0337
============================================================


📊 Round 331 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2462, R²: 0.0235

============================================================
🔄 Round 333 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 333 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0110
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0350
============================================================


📊 Round 333 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2462, R²: 0.0235

============================================================
🔄 Round 334 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 334 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0218
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0142
============================================================


📊 Round 334 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2462, R²: 0.0236

============================================================
🔄 Round 336 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 336 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0228
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0095
============================================================


============================================================
🔄 Round 339 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 339 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0185
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0041
============================================================


============================================================
🔄 Round 341 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 341 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0131
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0237
============================================================


📊 Round 341 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2461, R²: 0.0239

============================================================
🔄 Round 344 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 344 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0095
   Val:   Loss=0.0728, RMSE=0.2698, R²=0.0369
============================================================


📊 Round 344 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2461, R²: 0.0240

============================================================
🔄 Round 346 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0685 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0685, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0685, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0685, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0685, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0686, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0685)

============================================================
📊 Round 346 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0158
   Val:   Loss=0.0685, RMSE=0.2618, R²=0.0169
============================================================


📊 Round 346 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2461, R²: 0.0241

============================================================
🔄 Round 350 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 350 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0068
   Val:   Loss=0.0731, RMSE=0.2703, R²=0.0556
============================================================


📊 Round 350 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2461, R²: 0.0241

📊 Round 350 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2461, R²: 0.0241

============================================================
🔄 Round 353 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 353 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0158
   Val:   Loss=0.0814, RMSE=0.2854, R²=0.0092
============================================================


📊 Round 353 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2461, R²: 0.0242

📊 Round 353 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2461, R²: 0.0242

============================================================
🔄 Round 355 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 355 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0188
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0062
============================================================


📊 Round 355 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2460, R²: 0.0243

📊 Round 355 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2460, R²: 0.0243

📊 Round 355 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2460, R²: 0.0243

📊 Round 355 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2460, R²: 0.0244

============================================================
🔄 Round 361 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 361 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0203
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0063
============================================================


📊 Round 361 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2460, R²: 0.0244

============================================================
🔄 Round 363 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 363 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0063
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0471
============================================================


📊 Round 363 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2460, R²: 0.0244

📊 Round 363 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2460, R²: 0.0244

============================================================
🔄 Round 365 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 365 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0138
   Val:   Loss=0.0850, RMSE=0.2916, R²=0.0240
============================================================


📊 Round 365 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2460, R²: 0.0244

============================================================
🔄 Round 366 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 366 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2806, R²=0.0085
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0425
============================================================


============================================================
🔄 Round 367 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 367 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0182
   Val:   Loss=0.0755, RMSE=0.2747, R²=-0.0382
============================================================


📊 Round 367 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2460, R²: 0.0244

============================================================
🔄 Round 369 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 369 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0071
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0508
============================================================


============================================================
🔄 Round 370 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 370 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0243
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0209
============================================================


📊 Round 370 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2460, R²: 0.0243

============================================================
🔄 Round 374 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 374 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0104
   Val:   Loss=0.0775, RMSE=0.2783, R²=0.0343
============================================================


📊 Round 374 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2460, R²: 0.0243

📊 Round 374 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2460, R²: 0.0243

📊 Round 374 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2460, R²: 0.0243

============================================================
🔄 Round 381 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 381 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2765, R²=0.0216
   Val:   Loss=0.0929, RMSE=0.3047, R²=-0.0028
============================================================


📊 Round 381 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2460, R²: 0.0244

============================================================
🔄 Round 383 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 383 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0088
   Val:   Loss=0.0721, RMSE=0.2685, R²=0.0483
============================================================


📊 Round 383 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2460, R²: 0.0244

============================================================
🔄 Round 385 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 385 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0172
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0027
============================================================


📊 Round 385 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2460, R²: 0.0244

============================================================
🔄 Round 387 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 387 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0133
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0183
============================================================


📊 Round 387 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2460, R²: 0.0244

============================================================
🔄 Round 392 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 392 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0175
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0113
============================================================


📊 Round 392 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2460, R²: 0.0243

📊 Round 392 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2460, R²: 0.0243

============================================================
🔄 Round 395 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 395 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0188
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0040
============================================================


📊 Round 395 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2460, R²: 0.0243

============================================================
🔄 Round 398 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 398 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0131
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0194
============================================================


📊 Round 398 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2460, R²: 0.0244

============================================================
🔄 Round 401 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 401 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0156
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0109
============================================================


============================================================
🔄 Round 404 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 404 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0077
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0754
============================================================


============================================================
🔄 Round 405 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 405 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2835, R²=0.0102
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0365
============================================================


📊 Round 405 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2460, R²: 0.0244

📊 Round 405 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2460, R²: 0.0243

============================================================
🔄 Round 410 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 410 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0202
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0015
============================================================


============================================================
🔄 Round 412 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 412 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2810, R²=0.0201
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0410
============================================================


📊 Round 412 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2460, R²: 0.0242

============================================================
🔄 Round 414 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 414 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0156
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0168
============================================================


📊 Round 414 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2461, R²: 0.0242

============================================================
🔄 Round 415 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 415 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2829, R²=0.0120
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0305
============================================================


📊 Round 415 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2461, R²: 0.0241

============================================================
🔄 Round 417 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 417 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0111
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0368
============================================================


📊 Round 417 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2461, R²: 0.0241

============================================================
🔄 Round 418 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 418 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0093
   Val:   Loss=0.0889, RMSE=0.2982, R²=0.0335
============================================================


📊 Round 418 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2461, R²: 0.0241

📊 Round 418 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2461, R²: 0.0241

============================================================
🔄 Round 424 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 424 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0167
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0134
============================================================


============================================================
🔄 Round 425 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 425 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0173
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0053
============================================================


============================================================
🔄 Round 426 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 426 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0178
   Val:   Loss=0.0720, RMSE=0.2684, R²=0.0095
============================================================


📊 Round 426 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2461, R²: 0.0242

============================================================
🔄 Round 430 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 430 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0139
   Val:   Loss=0.0744, RMSE=0.2727, R²=0.0268
============================================================


============================================================
🔄 Round 431 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 431 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0137
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0273
============================================================


📊 Round 431 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2461, R²: 0.0242

============================================================
🔄 Round 434 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 434 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0166
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0143
============================================================


📊 Round 434 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2460, R²: 0.0243

📊 Round 434 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2460, R²: 0.0243

============================================================
🔄 Round 437 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 437 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0217
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0061
============================================================


============================================================
🔄 Round 439 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 439 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0156
   Val:   Loss=0.0756, RMSE=0.2749, R²=0.0132
============================================================


📊 Round 439 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2460, R²: 0.0243

============================================================
🔄 Round 443 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0712 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 443 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0119
   Val:   Loss=0.0712, RMSE=0.2668, R²=0.0360
============================================================


📊 Round 443 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2461, R²: 0.0243

============================================================
🔄 Round 444 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 444 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0235
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0110
============================================================


============================================================
🔄 Round 447 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 447 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0204
   Val:   Loss=0.0806, RMSE=0.2838, R²=-0.0022
============================================================


📊 Round 447 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2461, R²: 0.0242

📊 Round 447 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2461, R²: 0.0241

============================================================
🔄 Round 451 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 451 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0253
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0229
============================================================


📊 Round 451 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2461, R²: 0.0241

📊 Round 451 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2461, R²: 0.0240

============================================================
🔄 Round 453 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 453 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0142
   Val:   Loss=0.0930, RMSE=0.3049, R²=-0.0014
============================================================


📊 Round 453 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2461, R²: 0.0240

============================================================
🔄 Round 456 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 456 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0271
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0289
============================================================


📊 Round 456 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2461, R²: 0.0240

📊 Round 456 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2461, R²: 0.0241

============================================================
🔄 Round 461 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 461 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0106
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0316
============================================================


📊 Round 461 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2461, R²: 0.0241

📊 Round 461 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2461, R²: 0.0241

============================================================
🔄 Round 464 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 464 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0072
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0502
============================================================


📊 Round 464 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2461, R²: 0.0242

📊 Round 464 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2461, R²: 0.0242

📊 Round 464 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2460, R²: 0.0243

============================================================
🔄 Round 471 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 471 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0225
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0066
============================================================


============================================================
🔄 Round 472 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 472 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0187
   Val:   Loss=0.0890, RMSE=0.2983, R²=0.0066
============================================================


============================================================
🔄 Round 473 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 473 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0147
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0230
============================================================


📊 Round 473 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2460, R²: 0.0243

============================================================
🔄 Round 475 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 475 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0153
   Val:   Loss=0.0730, RMSE=0.2702, R²=0.0201
============================================================


============================================================
🔄 Round 477 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 477 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0179
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0100
============================================================


📊 Round 477 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2460, R²: 0.0243

============================================================
🔄 Round 479 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 479 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0141
   Val:   Loss=0.0716, RMSE=0.2676, R²=0.0225
============================================================


📊 Round 479 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2461, R²: 0.0243

📊 Round 479 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2461, R²: 0.0242

============================================================
🔄 Round 484 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 484 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0215
   Val:   Loss=0.0830, RMSE=0.2880, R²=-0.0040
============================================================


📊 Round 484 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2461, R²: 0.0242

============================================================
🔄 Round 485 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0684 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0684, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0684, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0684, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0684, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0684, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0684)

============================================================
📊 Round 485 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0081
   Val:   Loss=0.0684, RMSE=0.2615, R²=0.0473
============================================================


📊 Round 485 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2461, R²: 0.0242

📊 Round 485 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2460, R²: 0.0243

📊 Round 485 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2460, R²: 0.0243

============================================================
🔄 Round 492 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 492 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0174
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0123
============================================================


📊 Round 492 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2460, R²: 0.0244

📊 Round 492 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2460, R²: 0.0244

============================================================
🔄 Round 495 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 495 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0086
   Val:   Loss=0.0774, RMSE=0.2781, R²=0.0423
============================================================


============================================================
🔄 Round 496 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 496 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0140
   Val:   Loss=0.0751, RMSE=0.2741, R²=0.0259
============================================================


📊 Round 496 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2460, R²: 0.0244

============================================================
🔄 Round 497 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 497 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0160
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0004
============================================================


============================================================
🔄 Round 498 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 498 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0143
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0226
============================================================


📊 Round 498 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2460, R²: 0.0245

============================================================
🔄 Round 500 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 500 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0115
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0357
============================================================


📊 Round 500 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2460, R²: 0.0245

============================================================
🔄 Round 502 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 502 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0227
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0087
============================================================


📊 Round 502 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2460, R²: 0.0245

📊 Round 502 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2460, R²: 0.0245

============================================================
🔄 Round 508 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 508 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0211
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0140
============================================================


📊 Round 508 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2460, R²: 0.0245

============================================================
🔄 Round 512 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 512 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=0.0248
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0143
============================================================


📊 Round 512 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2460, R²: 0.0244

============================================================
🔄 Round 513 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 513 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0166
   Val:   Loss=0.0759, RMSE=0.2754, R²=0.0150
============================================================


============================================================
🔄 Round 514 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 514 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0155
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0205
============================================================


📊 Round 514 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2460, R²: 0.0244

============================================================
🔄 Round 516 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 516 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0171
   Val:   Loss=0.0779, RMSE=0.2792, R²=0.0098
============================================================


📊 Round 516 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2460, R²: 0.0244

📊 Round 516 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2460, R²: 0.0245

============================================================
🔄 Round 519 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 519 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2835, R²=0.0164
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0170
============================================================


📊 Round 519 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2460, R²: 0.0245

============================================================
🔄 Round 523 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 523 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0183
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0079
============================================================


📊 Round 523 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2460, R²: 0.0246

📊 Round 523 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2460, R²: 0.0246

============================================================
🔄 Round 525 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 525 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0243
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0196
============================================================


============================================================
🔄 Round 526 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 526 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0218
   Val:   Loss=0.0709, RMSE=0.2662, R²=-0.0083
============================================================


📊 Round 526 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2460, R²: 0.0246

============================================================
🔄 Round 527 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0645 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0645, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0645, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0645, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0645, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0645, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0645)

============================================================
📊 Round 527 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0158
   Val:   Loss=0.0645, RMSE=0.2540, R²=0.0195
============================================================


============================================================
🔄 Round 529 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 529 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0172
   Val:   Loss=0.0787, RMSE=0.2806, R²=0.0140
============================================================


============================================================
🔄 Round 531 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 531 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0111
   Val:   Loss=0.0898, RMSE=0.2997, R²=0.0324
============================================================


📊 Round 531 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2460, R²: 0.0247

============================================================
🔄 Round 534 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 534 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0197
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0033
============================================================


============================================================
🔄 Round 536 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 536 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0160
   Val:   Loss=0.0875, RMSE=0.2957, R²=0.0168
============================================================


📊 Round 536 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2460, R²: 0.0248

📊 Round 536 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2460, R²: 0.0248

📊 Round 536 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2460, R²: 0.0248

============================================================
🔄 Round 540 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 540 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0123
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0309
============================================================


📊 Round 540 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2460, R²: 0.0249

📊 Round 540 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2459, R²: 0.0249

📊 Round 540 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2459, R²: 0.0249

============================================================
🔄 Round 544 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 544 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0161
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0188
============================================================


📊 Round 544 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2459, R²: 0.0250

============================================================
🔄 Round 545 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 545 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0261
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0307
============================================================


📊 Round 545 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2459, R²: 0.0250

============================================================
🔄 Round 546 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 546 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0099
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0415
============================================================


📊 Round 546 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2459, R²: 0.0251

📊 Round 546 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2459, R²: 0.0251

============================================================
🔄 Round 549 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 549 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0198
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0047
============================================================


📊 Round 549 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2459, R²: 0.0251

📊 Round 549 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2459, R²: 0.0251

📊 Round 549 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2459, R²: 0.0251

============================================================
🔄 Round 553 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 553 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0161
   Val:   Loss=0.0709, RMSE=0.2662, R²=0.0126
============================================================


============================================================
🔄 Round 554 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 554 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0227
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0066
============================================================


============================================================
🔄 Round 556 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 556 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0144
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0077
============================================================


📊 Round 556 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2459, R²: 0.0251

============================================================
🔄 Round 558 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 558 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0128
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0112
============================================================


📊 Round 558 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2459, R²: 0.0250

📊 Round 558 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2459, R²: 0.0250

============================================================
🔄 Round 562 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 562 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0205
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0073
============================================================


📊 Round 562 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2459, R²: 0.0249

📊 Round 562 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2459, R²: 0.0249

📊 Round 562 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2459, R²: 0.0249

============================================================
🔄 Round 567 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 567 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0129
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0267
============================================================


📊 Round 567 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2459, R²: 0.0249

============================================================
🔄 Round 570 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 570 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0133
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0279
============================================================


📊 Round 570 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2459, R²: 0.0249

============================================================
🔄 Round 572 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 572 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0160
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0180
============================================================


============================================================
🔄 Round 573 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0692 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0692, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0692, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0692, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0692, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0693, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0692)

============================================================
📊 Round 573 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0001
   Val:   Loss=0.0692, RMSE=0.2631, R²=0.0804
============================================================


📊 Round 573 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2459, R²: 0.0249

❌ Client client_10 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_status:14, grpc_message:"Socket closed"}"
>
