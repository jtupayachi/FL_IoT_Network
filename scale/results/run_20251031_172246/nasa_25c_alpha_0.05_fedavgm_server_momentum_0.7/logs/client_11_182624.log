[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e0be8fc-0f49-4c16-b7ea-c6286cf7af8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67cb70e1-fcec-4154-8293-2713d3185e6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1fe05a8-2fed-4056-9cd9-041e3bad8a8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6c5f00f-2da5-44f8-aef2-e182f4b9f1b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91f2c7bd-e9bf-4a0e-b0c2-d12d39d5d1fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7edbcc93-50d8-456e-b4c2-2909393aad78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c844d7cd-aa04-44fd-b73f-361189466182
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4c545ad-8d39-4f78-82c7-45950cddb238
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c4c016e-7cf6-4eac-96cf-fa383b185efa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4eec373f-f517-4867-b6d8-06b310292d5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5f5b0b9-6702-4745-ad83-c76cf7db65cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ce47574-8561-49c3-88ea-7488d2056482
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4066808-884c-4e90-a4dd-95a853a3d239
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d97c6cf4-fe6b-4e0a-82d6-84add8e34246
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd92173e-4add-4346-8484-f0a3145531f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 146ca1dd-b392-47c7-b372-9a07d521621b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae3c2fee-e326-42c6-8af3-197cf1682f75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72ad7ae5-9e8a-4769-b0f9-1036574eba99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08a8b126-456e-4e3d-b172-eae793156f2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 408c6123-f535-4c16-bff3-df23754f4366
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af7187b0-e614-4b86-aff5-a90951d85659
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1e1708f-70e3-4d65-8f9f-127b8485d1e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e583d8e6-acbf-411e-a1f2-14de1eb86806
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0eb8bf23-ac95-4c5c-adb5-e335853f00e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df5f9a85-0121-438e-9f4c-bf326f9abff8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab434b29-4353-4186-bb58-05ad70bc3e51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 473dfb8e-c6bd-479d-8cdb-708a257168d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2dbcd1a6-a4ad-4a82-9572-ddb3b931440e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6c76301-33a5-44ac-96f5-5dc6f13fa370
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2add92a8-23f0-4272-82d2-280c651568b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8d723fe-6e9a-4a7c-aa42-bec988e428b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab61ac50-3750-466f-806c-4ede392203c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d215571f-fe82-4f5a-b89a-b9205108fcb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c55d14d-02fe-4995-95e3-ce4cb568a52c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7635c1a-d8b8-491a-b7ce-5a324add517e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab58b043-416c-4b21-93cf-c41b2846548d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 641a5219-33f6-4dad-a9ef-04452e2f4366
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 602e656e-a0a7-4818-ad39-baebb2eb1c5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4df4da22-a8fd-4220-b56d-bc90c9e5cfd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1bb5762-7008-4542-9845-0d3a7127c291
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22e19265-c0b8-4e26-a340-0e3a657d0464
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 516e17f9-4dfe-452c-9e9e-f8d106610257
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c181d865-adda-41e6-8756-b98ab1d53ad4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78194a30-4556-4c7e-a487-7a55be4f9af6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75a404e2-0c5a-4ff3-af4e-f12e65b09421
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f054619-25ba-418c-9c58-37dd327b2319
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fff0b24-fc3d-4541-855e-f25558ff03ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04b7a4fe-b037-4b9d-8a17-732bd6330578
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46c431e8-4264-41d5-a299-129217c53ec3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a3a6ea3-db00-4247-992e-5a22a48f1b50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 495bf460-052d-4794-91cd-8749fe2a8db3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb4cd7bf-d3a7-4d01-aa30-32e3bfd56d29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b8680f0-fbbe-432c-b124-b1f4ff7ad030
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 408cfc09-f29a-4147-b35a-7d03155c4406
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8ec1a94-c8e7-44d8-a82f-152889055215
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b539f616-7575-4a45-8d6c-7b654803a723
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 928a364b-cd8b-4dd1-af41-cbed4a29d1a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f866cd0-08f0-4466-8626-f11b66078acd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4680d8bd-e4d5-4451-9b4a-5df3ff7dc6f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8693652a-7cf9-441d-806d-a00036d0a5db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0709fe6d-27c3-45b4-adca-888406851e28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5f76623-5fa8-44e1-acf5-5215fcd1b30c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f8fc63b-854d-44d4-8d32-c24c683fe7f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bc5d3db-f03f-4597-ab68-2f0e1767210d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20a95818-0895-49dd-be90-d79d8c933702
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86c28537-c1b5-4a96-ab4e-a27ef826a39d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b07f9bc8-490e-4a97-97a4-331a6f73e1c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b2c85d2-6115-4044-b3eb-fa8abbace4d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a02fbc92-845a-4ae0-b449-4aa26c99e35b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c4e0ceb-9420-4c2d-b7b1-5c50d3900d0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4f5a340-afd8-4b9f-910b-c2a4b24e5389
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab9fa924-032e-4548-a706-df27ff5bea49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf194216-971e-4502-8c98-379084aa7969
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a097d97b-e805-453a-ba48-98beb5bda6c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c987fd3-70f5-40c4-9b02-5b50dd5e2d1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d13077a3-5705-4359-a9ae-17a88be624fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e84bff5d-515b-4524-9dcc-383d591da753
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d3302ff-c3e9-4840-9d34-d0fe0a803b34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7ff3f2f-16ad-4314-ac5c-a24d57ca7df6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e3a2484-e893-4c87-b2ef-9128b651b78e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 624f67b3-6481-4d19-abe8-fa5f638c3815
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a8a226e-8f5d-4e04-a0f6-1f3c84218be1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 351b231c-d866-45e0-8a5b-22b6f06c746c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1d94076-a567-43ae-b2d7-b0b9d985fbcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f7f292b-e047-428d-9066-83f245e24e3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd750aa4-d9e4-4214-99e6-077b090cc495
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 228ae1a8-1b7f-408e-bf50-128feccb63b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d291e9c-9931-4247-b648-326439e231d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9545b8e-198d-498e-b67b-b1008211813c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbb9c47b-0a33-45d8-83ad-ab0222228353
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4009b5f6-4115-40bb-b0eb-a3a0819dc99b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48c37597-fd52-47b0-8fd6-995a1c44bd25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1b000cc-932c-41c8-b5f1-bb2f8653048a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message daea0225-efc4-4a66-afb8-a302efca1884
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea44f462-11b0-4fa6-8010-9d816e4dd998
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c9e4786-8aed-49f7-ac43-4c00c7cc17af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa1b76b8-05b6-4b05-9871-38b039618bd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca23d098-1f7a-4c07-8666-45a19a1d2bb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4176806b-8fe5-419a-9d07-75d10209dd21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ede302a-5a46-4485-994b-897da56ec477
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b02912d1-5426-4cf7-8f52-d3b28d38bd36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7b672c0-7597-4129-a48f-14197784f555
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ff8cb79-e3df-4173-8177-8cc78bb11c44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d1344c3-9523-4a08-a15d-0fe4d05625ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 176579e4-afc2-478b-879f-835d9cebd39f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 040f64c8-46b5-4304-8088-435cf8d57dc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a82f2848-af65-460f-9ab6-1688e541ac0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08a8aee1-f574-4cf3-9ec9-039e5dc59ea2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91b0cfe4-8954-4070-8a35-a3f60e7e3d4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9cd98f2-bc86-4eef-97f1-42d08e224f21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 420c1cef-8a93-488e-bbaa-cef5d1e26279
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 303d0b4c-f607-41be-89f3-95799aa5db5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4dc175cb-8d14-45a4-9621-bcae54bd847d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb1309f9-a15a-4b1d-8419-69c86c9ec1dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13ec4398-b2f4-46c2-9723-2a55121b6030
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15220f43-6401-464b-a55d-a043d92e69a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96b6a50e-9699-4fb6-9342-8c40ebb15efb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 328a849f-3ff3-43c4-8ae1-7ad9a1ab8435
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6f65e81-c333-47f3-830b-86407dde8664
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba27872a-b7ea-4bfa-9d4f-9778f13e0839
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58da51ae-d708-436c-9243-d82c2838a543
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28f0dd1f-6fc9-4f87-8474-2c3ce2850666
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70fb059c-6921-489b-86d6-96f2842f4238
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e480f39-51e0-4826-a275-08f48f4895f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09620696-6c4b-4df5-ba8c-d05e4ad58944
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3132881e-7546-4b26-985d-599726f12d3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f589f86b-8533-48ee-99ab-7c5406c58420
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 229c08fa-1fcc-42cb-a98c-7c500625266f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3408bcf-67a8-44af-b43d-5b90f80273dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1eb40d53-baaa-4dcb-9be6-ffd0ee4de990
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75807451-61df-4912-a5dd-21422705dcb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc68262d-d587-45d1-8003-034be5c9ca7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da925568-c724-48e4-806f-3df2d6402c7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d172b572-6088-4e72-ac7d-0fb3b38e5a57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b5d2fa7-ebd1-4578-982e-82c03037f4b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 854835c1-a418-4773-abd9-b05651c2a1f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8788fde6-7f43-46f3-ad21-f2d454962731
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15a3d851-1078-4aab-aecc-e1f4794abe27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09aa0fde-719f-4ee0-8775-6393abb7b409
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0d4cfbf-4320-4774-b9d9-f08df0a37abf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5890afe-4411-43da-90ca-53abc9bf2e39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95ce2c67-8d7e-460c-abf1-b0efa60d7cfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a157be7-ff27-4281-9ac2-2b20ea8bf70b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d758313f-8ffd-4e43-9df1-c783f93eb109
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af23f497-e268-4c9d-a8b9-32006647fb74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c76c8dce-af65-4649-bc4f-ddde440aa806
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a194907-5284-44a8-a5eb-9d9d351fcc4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66d0a7d1-dc58-4445-afdc-2e8782a1dcda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20f816e4-c45d-4d6b-a61a-ef0f850d4016
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a8cb469-3a93-4fcd-97b9-0c2746a0185d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35ff50a5-a67f-4f36-9ef7-003c0d60d89d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ddff88d-b483-450c-b228-b2447daac641
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f898dfe-a548-460e-b6dc-b42369bcbb00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80db1f5a-7113-4c47-9dea-050f9b264e3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04adc044-ff50-4b9d-b8ba-d0a67eb933c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c64f9e10-5161-458b-afb3-5d47ba5b50e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3347f2e5-90d6-469f-97c5-56e001606d84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0328c926-d2d1-4b9b-a3a1-0d7fc565c5ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 350b9567-d081-4fc2-a746-e449d7a20727
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message daeba6fa-6214-41b8-ae69-62e7a2f9a774
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a606e41-2c6a-41c1-9b37-04e2f4867726
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7728baba-eac2-433a-9e80-8536347fe436
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8bd0bd7f-b332-4deb-9293-3eff22323da7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90fbed5b-5d89-4090-9503-7f6d9faa5e45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4c544e0-2d9c-4846-a323-b5df1b3b824b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a49cd8f-a0ee-4c76-b678-f06c31e170c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8ce3d86-10e2-4cba-89bb-4cc9e6b030b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 926a518b-d48d-4166-bfc1-188de777a143
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abdd01d1-344d-4dba-b984-b809b0053d48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d5e75e3-95c1-4628-892d-7bc30f5bda2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92a31962-8346-4239-b8a2-f6a611232ada
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4656b4f8-521d-4763-98da-84c9b8b792d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14c4c53a-be78-46c5-a75f-ec484ead3792
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f563d26b-6e02-4214-917a-be84cf55ef4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8521f97b-3322-4c8b-a613-87fa01466d32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf33fbcd-3112-4273-bcec-1ea87eea1896
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 346c075e-8678-4336-86c5-ab73d9dc8880
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d72cf124-f2cf-47cc-816d-5fa9c82ec7bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba24dcd8-c62d-4c2e-8a77-279dd646b941
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b81c9e3-3dd9-4c25-b383-c5e257a7d2c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14542f0d-b8b7-4caa-aa6a-7634dbd86d11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8057d3d-e256-4296-97a3-0bf87fbae5ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51f553d6-3f50-4b9a-bf27-69b7c241cfb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19d05583-6581-4d79-af56-585043b3291c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bc4f276-d6af-402a-a7a0-aa38a70b5367
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 693bab5b-64a3-4e07-a8c9-a22977f801f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 482f17e9-e0cd-4b4c-b9fc-5bb7b071f8ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e8fc09d-c40a-44d6-a2e1-5cce28313ce4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe032e0d-1d4c-4490-b6e5-52503af7b5c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1cffae8f-31d1-474a-8cf4-a780f40d36da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37d6d69a-cd0a-4a16-9d96-58212562833d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 236af9fe-b0ee-4aa3-a9af-9009b80252fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 751674e4-5236-42f4-b290-026708db6477
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c0cff26-c322-4d93-82b5-3f543f99745e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9ec23a3-615f-43b2-afa9-9fdd0eed4a4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 566f20a4-d262-4908-9332-878dcaff7e21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f1522a3-c3ce-452d-a6bc-29036c18229e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65767c90-d598-44af-aa2d-17af9d973011
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b74c5f1-0630-491b-ab03-4021804875e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55946b60-9a5c-4b08-824b-f269fa822b13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 219a7294-c883-47e1-9d68-b0a2b22141a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4cfd523-8657-4771-8cdf-8c8fa68c436f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 428fafdc-71d2-4048-a2e9-4eb4608178e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96fa3f18-8779-40c1-89f8-fdcb615e9e36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8ba8546-b58e-4564-bf0c-2e4db50ad1b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5d1d86c-71bd-4afc-9249-2bf94dc2028e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7da14064-bb41-40ab-8728-8add65a55e92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5cae01e-5bd0-4ce9-8299-3dc63fe1f96c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b6eb7e3-79d3-42c4-b559-0235d3de69a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f8dc2cd-e1e4-4e70-8907-de7eced2a578
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb0f8bcf-2cec-40c1-aa22-19e636803127
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9599acbd-60ba-498e-93ea-66b51fb2b3fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db76ac0c-7a6f-4364-8737-1d57aa504a70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a611178-8e32-40f4-bbd5-8b67149c98b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b2a8f96-a7df-4b91-bf6a-149e5b672659
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0cabc0c1-384d-430b-b30e-6332d274cf6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4b0c794-8f02-44fe-8d36-32ef68b387d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1493017b-1801-4352-90f0-d2959839dbd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 878a6eb8-dd31-42f7-92fb-3787927d8c7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6dd21d5-6a57-4bc1-af49-fdb0bdba2a5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53ef6ee5-bb34-4bd0-8224-084533106fbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58eef2c2-93a2-4e19-80ec-833e5780e750
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d705094-be8b-4538-b638-bdb74e84a239
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b07378d5-1668-42b3-882a-954f79e6de54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bdae5f55-66b0-4300-9372-ae63df109c16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e79f7d10-1dd9-4929-984a-92d6931c7a8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f0e17eb-fdca-4ead-88fa-cf2cd70b1359
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8543b8d-864b-42e4-bac1-3dde080a1acd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff9a6357-2697-4f12-a802-343bc0912073
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a683d3c-104d-4eb3-af4f-2ba6931ddcdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15869819-7588-4020-8259-e0be638df567
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b11c2830-f0a5-4658-a5c8-83cdbd980a62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1208ce2f-f68a-40b3-8dde-a3f79c66cb34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4491a6e8-5dfe-4308-a7a7-93960e453d54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b39908d1-4700-42d4-9072-2b7ddf94ad74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 746cce46-0e7d-4090-89e7-710c1bc04fe3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5980b08d-9896-4ea8-afee-f7efb25c961f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64810168-34cc-41fb-bd14-4915ec712a2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1594908-2558-4b4d-abef-656ee53e2f47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cced7a08-f79b-456b-a270-8715009fe542
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c9f2495-8a49-4c52-b3ef-9b31a459d258
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da0140aa-4f57-45b5-b7b1-0ee830d9e923
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39ff8ccf-5f2c-4210-97ae-c117ebe2508b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9ff695c-3ea4-4084-90e0-d52020138025
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9e66db8-b2b0-44f1-99de-d3ea374396ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da706dba-dbf3-4b1b-83f9-ab59ba359849
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab551f12-dace-4ad4-9fe1-27cfd4d3be93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e62ee636-48ce-4f15-8c65-7d1de5a4fa50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f240a6a-8204-40c5-8090-fb4af7b9f14e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7d4c31d-c1b8-4d91-8a07-c55d302ec1a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a512e6ca-a63a-4c49-a480-06dd88919064
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bd0057f-2010-4645-af0c-587c30e05998
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e6b052d-0757-4322-afdb-8b5a1789acaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d85ac01c-c1a4-4b3d-a4de-f32bfe8f304b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eae18888-76b7-4974-a361-bb935142d7d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a67696c-a7c7-49d2-a918-1989e5dabc88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0262c109-62a8-4e97-85d6-3ce7843ab7e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3e1979e-6432-493c-a13c-49f45a7b12d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68eb1cbd-e174-450a-864a-1fbdf87ca084
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e634b3b-a540-45fc-9d30-47ed61db89aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b45c11a-1866-45df-8631-3af6da2df027
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf570e59-b9b0-44ca-aa97-25348a6917c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb07eeb3-b2ea-49f2-bdeb-57d44d7baf75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5699d224-c7c3-4976-8ba2-e7f21955b651
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3113200a-595f-43eb-886e-71679ecb54d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7382c81c-3433-441b-828c-f7f2cf5c5a7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a34ff3d-a4e3-4bb8-af34-d7370a8f4058
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4bcd031-4b2a-4e9e-92c0-5dbfc1936f79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5503b58e-4d95-40f8-b496-f4d8e1d111f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93a9ecb9-3b44-49d4-bae0-685996da2b2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f92754f3-fec4-4e33-a144-03350a1cf861
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7e38fcf-0113-4b04-92a5-612f18667f66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 310e4e34-31f9-464b-a1ba-4b7858618541
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc0b207f-74fe-433d-8173-58401fdb5f8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8515ac39-5fb9-41c3-b338-9c29fcac6e1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 046eeb34-737b-4de9-ac8a-e5c3a7c4bd06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28c00fea-9e6c-46a1-b891-8c7f224d29e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c438fc1b-4878-484b-97c3-f9aa09eb97d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57236080-c0c2-4014-9e12-9d413a098e1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2f9d39b-b030-4b87-83fa-95afbb23c224
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60ffd8f9-d8bf-4f09-a31c-13c2e3075d90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a589cd1-ee65-400c-904a-94be364e7a45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed69c4dc-84fe-4a39-bf89-82281625cb90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b637e6ac-13ca-4670-891a-4fd5db5ca21f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6027c9e8-2c8d-4409-9c07-bfbe16d368c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fb6cea3-7749-467f-bb87-43e0e7d87be7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9961b99e-205a-4356-a67f-df57f62e711e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a6531a3-8672-45f2-853e-328ff349d479
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35ba880a-ae7c-4309-a5aa-f54577c74c97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0547391-95fb-4203-93a9-ba72ac400e8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message caddd398-e2f9-42e6-81dc-cae6046f334d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cecbe67f-75c3-48b7-9eb8-773a7865d19e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd4559dd-9b1b-47ca-a079-77cfbf3fd50e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fa26ced-d13a-45fd-9096-9ee77996f1e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4f83d77-30d5-4047-8cf6-2859aeb6dd2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9686ce86-fe10-4b10-b2e8-e8e9fb34f4a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6133add3-c9b5-49f7-9ead-7a0ef14108c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18763662-4d3a-44de-8124-f6cbf4d955f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b2f502b-b313-41f3-8f7f-6ad6fbe86f92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9dcd1f29-e498-40b9-bbc0-9fdc5596b32e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17997019-e738-46d4-9289-e6a512ed9bfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afa25005-e7d0-41c7-ba9f-e1c8ea5121a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32a6aff6-bb61-4b6e-97b3-d50fa308c341
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 455668c3-20ee-44fa-b36f-eace6b22a0fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfc85141-b4f8-4ba8-a0f6-9289d561aa41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 069b33ed-ec66-473c-aac1-877bf6d41c88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9431dad-cea9-4616-8edd-c056f447dc4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff7db6ed-c2a3-433e-a5f3-870e14eb8885
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a846e650-a3a0-423e-b02c-fca2fe1fbadf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94613772-dceb-4ce7-9d3f-229720193a6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc550856-2123-4a84-a039-013dd024f5ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7bd8a851-31b0-49dc-bf44-1d525f8ce61a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80afaa56-f2cb-460c-8c5f-6751f780dda5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4586cbd-b5d3-4753-bd90-c480d9920561
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4e8cfd9-97b2-4ac1-bfea-0d75ffdc0227
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd7896ec-3553-4623-aeda-621f3ec76d02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c068346-b5d1-4fbb-b6a5-a927388a7a82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 045843ab-c3e7-455c-81bd-1b6cec0507fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdefe1fb-661b-4e68-ad66-c576558151e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 649a79cb-44b4-4715-bb1a-52c968e69f0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b6ba034-6c43-41a0-9c40-218eaa15a30c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ff5489a-2544-450e-a6f0-d7d3924893d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d048023-6163-4aa6-9a6c-8cfe8461a6f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75b49a74-46ad-4be4-96f6-881880ed1dca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2e88164-42f0-47f3-9368-97f90c650079
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 698164f3-256e-4bea-8a75-6c232dd822b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb36e96d-dddc-494e-ace8-3fc48d3a2222
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5bc3b42-76e8-4787-a9ba-e04e1244888c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eab743e8-fd44-4c7a-9ba3-4dc9e8eccba6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7fba81c-9f29-4a1e-aa9b-73a60c761f9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88a3fadb-f9fa-445a-ae7f-a6f41d97c2ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4009b42a-1a4e-4db2-bfea-0074dac3e8b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6061b55-ffa3-4eec-b0dd-2761c2d3cf4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23c617ef-40bb-49bf-b12e-b939062007c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b102215-8668-4241-9b0d-cbff90b390af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23b967da-e3fb-464a-aa4d-5f7c72824767
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a519540-8a94-405e-912b-8564444c0a5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffe46c35-3e2d-44db-8975-70e25b4d0cc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2c2f7e1-b5be-4b46-b059-88958f2b4423
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d88f2808-0e79-41e8-a969-2c3244ba94d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ff39d97-76c7-4f41-9a2a-afbc25de2382
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d41e1f95-2c5f-4fcf-9869-93c6a984ce83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b38b68f-3e0e-4246-87dd-952902846315
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f725b6c9-2b52-472d-a8fc-e52c967d18ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2331612b-e340-4e1e-9469-04c5d5001d52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd8ed3b9-2e8c-4a28-a8d2-48c511a71b61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 895fd896-59f7-45b6-9204-87859a99283e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4edc56c5-d18a-4495-8d44-df4f8534dfb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d358cf99-8fdd-4027-91ab-a5df9142e77d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31311475-36ae-43da-a21c-fb5b68cd82c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c010529-90ec-40c3-a260-92ac12606ff8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0708171-71d8-4760-bfcd-4de67a5c2c1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df3eaebd-818e-4969-9cb5-938414cc25f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 036d2ce5-a774-48a0-ba85-b80e8164e2d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1eef7836-ac89-4d86-80a5-e78531e5974b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a7f595a-2b2e-4e26-be31-d37a4419e5a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fd62428-5a36-457c-a3b3-4cf4eb26748c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75ae189f-6f9b-4339-95cf-26ca17411501
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30db74b5-7af6-4873-8cd6-97d466cea418
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ccf20c29-c700-4a01-8cdf-c97268577807
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7204615-7472-42ec-836c-5e3c600903d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9dab7af-e4fe-4110-bc77-d6a6afe79d1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ff872be-ca7c-429a-8689-ac5fe67b65a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f71ec4a3-2ea9-41ac-9b2e-c2870d7f0980
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8dfa803d-70a2-41e2-bb2d-575a2274cccd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de3c835c-db7e-4b3e-9520-2a1fbc5433dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d340778-2496-4b36-8813-ab5dde2df879
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1c69813-1425-458f-89d5-d1d80c234655
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d90ca9d-f4ff-4d89-95ee-0e7a0178b8af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e345d627-db8b-4cd6-ae5c-3d897753f91b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59342c4f-b3b4-489c-9f0d-ad6082f06f24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e800866-59e6-431c-83b6-964e602609cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 711b9a28-d2a0-49fd-a662-014fd21aaacc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1e7f4e8-551c-474b-b40e-3efbfc7c2225
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1044be8f-f409-4c25-8d71-fd01f139c611
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36ad3bf5-bcd1-4361-af04-749c410f2341
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c5a63af-2c36-41a8-a311-e12ccc42b78e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 692d56eb-0d17-4509-bf1e-a28067b5b71c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16f7554f-d9d9-4d39-ac3e-da99ee54ac2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bce0567-b202-4100-b696-8c058363be83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75b4b850-9820-4a38-8c9e-d8a3f973b6f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce2229cf-8ac1-4562-92d9-a41f7c340c0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57203d40-551c-46c9-a50f-e07437d022c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07db5f47-c247-46e7-9923-4d5dc1510072
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5114a632-a07e-401c-a057-6e6ef7ab81e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ee2e05d-629a-43fa-86d9-e182c9c5b391
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a499a816-14b3-40a1-b267-aef82eb6fd79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d3bc61a-392a-4133-85d0-fdb3c0421b64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fb747e3-ba25-4a1a-a1fe-d1a6eb4a2d68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e27ddd19-4432-4e84-9235-5e8912747f8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57c87551-6535-41d4-a0a0-366d62541175
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ff96d12-e088-482b-b804-6db6588469e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea642500-baa8-4c79-bfcb-775c7da22d2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a03b1688-dd04-407e-8907-d7f3bff1d3b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3dcaa0fb-c3bc-4487-afb8-3da6790e6c9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67d201ec-17f3-4427-8b76-e4eb5715d301
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 091ba1e5-a7bb-49af-865d-47237cd9c627
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d33c2b8-2be5-4de8-aeea-d7b925f115b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72117a6c-238d-46e1-a621-0132b0e532bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20bb784a-c41c-43b3-9307-167cbf4ff3d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04685c57-701b-416d-8877-455f9992832a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b93d0f2-3aff-4112-85aa-77af8c0ba40d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4487aa05-b3cd-4bf1-9372-917e8d2a0cc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e813ced-8fc0-4589-928f-3e978aeaa827
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbec1e0f-ff8d-468c-80cc-bec422e03e58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7fb2288-7b47-4668-b712-418e71ba97db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c2a1f41-893e-4156-b6a6-5d6f99cb6e53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b1e8b0b-8f57-4202-9528-2c72610eab2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e52e8cc-442f-4e89-b183-660e58b5224e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4fd84b4-63d2-48f3-b697-124483fdf814
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a44ca73-5258-43f9-a450-973a52241b7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21db38d0-0727-466b-8928-5a5fe01b0c44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7041761-f835-4cf4-b734-740471854018
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 579929b3-02f3-4410-8287-75fb9ffa696c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68971f0b-8ca1-45ce-b5d6-4019b672cd6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7df09315-d348-482d-b5c8-9c31d52e1b7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e07e6c4-6043-4ef3-ba52-17116695df82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 608588c8-1f76-45ae-abc4-4c62543f188e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5556e1c9-e84d-48d7-b8d1-db2e5c1df323
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3aa1c5a-4e08-4f2a-9ab3-3f07c8295853
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46b58247-2e95-4426-9d02-71dfeeb408db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cdddcc85-9d24-4d71-b166-1848683adff9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba91b2e6-face-4297-9fed-61bb27240de8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42b65c02-6d29-41e3-b685-137764f73187
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8dfe216e-0bfa-492d-90d2-29bffacf6f2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73c6e92b-7787-4d51-9361-f5601e723e4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d0d5098-948d-4cbf-acab-e3de61f9f9e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19dd75be-10ee-457b-85ac-b96ffbe6f033
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 393e6e1d-99ab-48f9-a798-2074caacff27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d77f7f10-b71f-4b9e-9c1a-f0a21a909ff8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b0f4721-587f-4e43-9362-62425c9cab07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96fe642d-1e10-4e7b-aadb-3d3985520ab5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d1af453-6649-433d-9c84-0ca1bbddd504
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfa1b93d-8fe4-4bd2-b38b-7fd6f853598d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bff8fab-5cc7-4c0f-8bf3-312bd5ad0706
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8cfe235-a684-44bf-92f7-7488e0204b82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80083384-ab26-4781-ae64-ff949c219d66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b34b757-33c1-4713-8946-564398dd9f65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17b9ded4-d7e0-4586-8615-bb06d2b9fc59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 214150c0-2b08-4578-900d-6032f4fa25aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97e3427b-aeb8-4046-bed1-0953a233f8d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b063c05-bec6-4c07-b552-48ee3eb8dd76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96623525-61d6-4a58-bec8-f2d8195b36fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79e238bd-683b-40af-862d-770cab4014fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 854abaf8-616f-4fca-ad14-6b970091138b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9bf2383-c21c-4879-aa36-8487c926cdd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 152ebc01-7c51-4302-ac39-3457b2670717
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9336e598-149a-43ac-b050-ea5e1c88695a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fc03e5d-6bc9-48d6-9110-3b1d5042e86f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3eb27bc-0a60-400b-b00f-23bab7545ca2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 299b0b32-a5b8-497b-8617-ee777e7d399a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e097ff5b-0aa6-4f1f-b29f-3fe7b39b69d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff6b90c6-c1b5-47cd-824d-e0777fb949dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8051e4bb-8626-428f-aaeb-c416781d8cd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05e34b04-f7cc-420b-a4ed-dcf81455bf49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32c5cca1-420c-4bd3-baf3-b6b66552b143
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9197ed0-2918-412c-ac72-87a2c04b8f91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a80e7173-be2b-4f72-af18-95b172c631b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6ae5e38-d23e-4124-8ebd-8f13035bc88c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59419b2c-e4f8-451f-8d8f-9992d79e1114
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fa89c2c-e65f-4db1-88fc-cccb6e06a2df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a8aa399-661a-4faa-a2d6-0de2c5a56708
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 997f2b8d-4a53-40e0-a87b-cdc018037686
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7aa46130-acb2-4825-9c9c-56ee67a71d7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0c82e9f-afe0-4651-8c09-82ce320f0913
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_11
Server: localhost:8688
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_11
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_11/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_11/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_11/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_11/test_labels.txt

📊 Raw data loaded:
   Train: X=(6688, 24), y=(6688,)
   Test:  X=(1673, 24), y=(1673,)

⚠️  Limiting training data: 6688 → 800 samples
⚠️  Limiting test data: 1673 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_11 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 1 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1815, val=0.0885 (↓), lr=0.001000
   • Epoch   2/100: train=0.0847, val=0.0952, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0794, val=0.0910, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0790, val=0.0901, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0790, val=0.0905, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0782, val=0.0916, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 1 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0129
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0044
============================================================


📊 Round 1 Test Metrics:
   Loss: 0.3809, RMSE: 0.6172, MAE: 0.5479, R²: -3.7528

============================================================
🔄 Round 6 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0908, val=0.0782 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0823, val=0.0775 (↓), lr=0.000250
   • Epoch   3/100: train=0.0814, val=0.0785, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0815, val=0.0785, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0814, val=0.0784, patience=3/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0809, val=0.0786, patience=9/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 6 Summary - Client client_11
   Epochs: 17/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0066
   Val:   Loss=0.0775, RMSE=0.2785, R²=-0.0016
============================================================


============================================================
🔄 Round 8 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0855 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.0808, val=0.0835 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.0803, val=0.0827 (↓), lr=0.000063
   • Epoch   4/100: train=0.0801, val=0.0823, patience=1/15, lr=0.000063
   ✓ Epoch   5/100: train=0.0800, val=0.0822 (↓), lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0797, val=0.0821, patience=6/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 8 Summary - Client client_11
   Epochs: 20/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0128
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0057
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2446, R²: -0.0091

============================================================
🔄 Round 10 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0842 (↓), lr=0.000016
   • Epoch   2/100: train=0.0808, val=0.0843, patience=1/15, lr=0.000016
   📉 Epoch 3: LR reduced 0.000016 → 0.000008
   • Epoch   3/100: train=0.0801, val=0.0845, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0796, val=0.0846, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0794, val=0.0847, patience=4/15, lr=0.000008
   📉 Epoch 11: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0787, val=0.0854, patience=10/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 10 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0184
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0264
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2442, R²: 0.0139

============================================================
🔄 Round 12 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0763 (↓), lr=0.000004
   • Epoch   2/100: train=0.0815, val=0.0762, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0814, val=0.0761, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0813, val=0.0760, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0812, val=0.0760, patience=4/15, lr=0.000004
   • Epoch  11/100: train=0.0808, val=0.0756, patience=3/15, lr=0.000004
   • Epoch  21/100: train=0.0804, val=0.0754, patience=13/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 12 Summary - Client client_11
   Epochs: 23/100 (early stopped)
   LR: 0.000004 → 0.000004 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0111
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0294
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2477, R²: -0.0238

============================================================
🔄 Round 14 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0754 (↓), lr=0.000004
   • Epoch   2/100: train=0.0814, val=0.0752, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0813, val=0.0751, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0813, val=0.0750, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0812, val=0.0749, patience=4/15, lr=0.000004
   • Epoch  11/100: train=0.0810, val=0.0745, patience=5/15, lr=0.000004
   • Epoch  21/100: train=0.0807, val=0.0739, patience=8/15, lr=0.000004
   • Epoch  31/100: train=0.0805, val=0.0736, patience=7/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 14 Summary - Client client_11
   Epochs: 39/100 (early stopped)
   LR: 0.000004 → 0.000004 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0242
   Val:   Loss=0.0738, RMSE=0.2717, R²=0.0108
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0170

📊 Round 14 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2425, R²: 0.0161

📊 Round 14 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2424, R²: 0.0159

============================================================
🔄 Round 24 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0825 (↓), lr=0.000004
   • Epoch   2/100: train=0.0789, val=0.0825, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0788, val=0.0825, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0788, val=0.0825, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0787, val=0.0825, patience=4/15, lr=0.000004
   📉 Epoch 6: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0785, val=0.0825, patience=10/15, lr=0.000002
   📉 Epoch 14: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 24 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0132
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0394
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2424, R²: 0.0164

📊 Round 24 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0169

============================================================
🔄 Round 27 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 27 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0294
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0161
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0172

📊 Round 27 Test Metrics:
   Loss: 0.0788, RMSE: 0.2806, MAE: 0.2425, R²: 0.0174

============================================================
🔄 Round 29 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 29 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0129
   Val:   Loss=0.0755, RMSE=0.2747, R²=0.0563
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2425, R²: 0.0177

📊 Round 29 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2425, R²: 0.0180

============================================================
🔄 Round 32 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 32 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0323
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0198
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2426, R²: 0.0190

============================================================
🔄 Round 39 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 39 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0269
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0174
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2426, R²: 0.0192

============================================================
🔄 Round 40 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 40 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0217
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0384
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2426, R²: 0.0194

============================================================
🔄 Round 43 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 43 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0282
   Val:   Loss=0.0834, RMSE=0.2889, R²=0.0148
============================================================


============================================================
🔄 Round 44 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 44 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0207
   Val:   Loss=0.0750, RMSE=0.2740, R²=0.0313
============================================================


============================================================
🔄 Round 45 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 45 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0296
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0069
============================================================


============================================================
🔄 Round 47 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 47 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0214
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0319
============================================================


============================================================
🔄 Round 50 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 50 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0283
   Val:   Loss=0.0806, RMSE=0.2838, R²=0.0197
============================================================


============================================================
🔄 Round 53 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 53 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0278
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0223
============================================================


============================================================
🔄 Round 55 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 55 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0354
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0087
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0785, RMSE: 0.2803, MAE: 0.2428, R²: 0.0200

============================================================
🔄 Round 56 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 56 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0275
   Val:   Loss=0.0751, RMSE=0.2741, R²=0.0072
============================================================


============================================================
🔄 Round 61 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 61 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0330
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0009
============================================================


============================================================
🔄 Round 62 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 62 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0317
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0086
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2428, R²: 0.0200

📊 Round 62 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2428, R²: 0.0201

============================================================
🔄 Round 65 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 65 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0201
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0551
============================================================


============================================================
🔄 Round 66 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 66 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0358
   Val:   Loss=0.0717, RMSE=0.2677, R²=-0.0170
============================================================


============================================================
🔄 Round 68 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 68 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0298
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0172
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2429, R²: 0.0201

============================================================
🔄 Round 69 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 69 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0233
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0441
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2429, R²: 0.0201

============================================================
🔄 Round 70 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 70 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0322
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0086
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2429, R²: 0.0201

📊 Round 70 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2429, R²: 0.0201

📊 Round 70 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2429, R²: 0.0201

============================================================
🔄 Round 74 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 74 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0277
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0278
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2429, R²: 0.0201

📊 Round 74 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2429, R²: 0.0201

📊 Round 74 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2429, R²: 0.0200

📊 Round 74 Test Metrics:
   Loss: 0.0785, RMSE: 0.2803, MAE: 0.2429, R²: 0.0200

============================================================
🔄 Round 82 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 82 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0328
   Val:   Loss=0.0776, RMSE=0.2787, R²=0.0030
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0785, RMSE: 0.2803, MAE: 0.2429, R²: 0.0200

📊 Round 82 Test Metrics:
   Loss: 0.0785, RMSE: 0.2803, MAE: 0.2429, R²: 0.0200

============================================================
🔄 Round 85 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 85 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0213
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0533
============================================================


============================================================
🔄 Round 86 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 86 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0222
   Val:   Loss=0.0752, RMSE=0.2742, R²=0.0512
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0785, RMSE: 0.2803, MAE: 0.2429, R²: 0.0200

📊 Round 86 Test Metrics:
   Loss: 0.0785, RMSE: 0.2803, MAE: 0.2429, R²: 0.0200

============================================================
🔄 Round 89 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 89 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0293
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0224
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0785, RMSE: 0.2803, MAE: 0.2429, R²: 0.0200

============================================================
🔄 Round 92 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 92 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0211
   Val:   Loss=0.0747, RMSE=0.2732, R²=0.0532
============================================================


============================================================
🔄 Round 93 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 93 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0312
   Val:   Loss=0.0769, RMSE=0.2774, R²=0.0141
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0785, RMSE: 0.2803, MAE: 0.2429, R²: 0.0200

📊 Round 93 Test Metrics:
   Loss: 0.0785, RMSE: 0.2803, MAE: 0.2430, R²: 0.0200

============================================================
🔄 Round 95 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0702, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0702, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 95 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=0.0210
   Val:   Loss=0.0702, RMSE=0.2650, R²=0.0522
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0785, RMSE: 0.2803, MAE: 0.2430, R²: 0.0200

📊 Round 95 Test Metrics:
   Loss: 0.0785, RMSE: 0.2803, MAE: 0.2430, R²: 0.0200

============================================================
🔄 Round 97 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 97 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0298
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0199
============================================================


============================================================
🔄 Round 98 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 98 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2774, R²=0.0317
   Val:   Loss=0.0871, RMSE=0.2951, R²=0.0143
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0785, RMSE: 0.2803, MAE: 0.2430, R²: 0.0200

📊 Round 98 Test Metrics:
   Loss: 0.0785, RMSE: 0.2803, MAE: 0.2430, R²: 0.0200

============================================================
🔄 Round 102 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 102 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0284
   Val:   Loss=0.0730, RMSE=0.2702, R²=0.0249
============================================================


============================================================
🔄 Round 103 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0707, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0707, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0707, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0707, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 103 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0209
   Val:   Loss=0.0707, RMSE=0.2659, R²=0.0610
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0785, RMSE: 0.2803, MAE: 0.2430, R²: 0.0199

📊 Round 103 Test Metrics:
   Loss: 0.0785, RMSE: 0.2803, MAE: 0.2430, R²: 0.0199

📊 Round 103 Test Metrics:
   Loss: 0.0785, RMSE: 0.2803, MAE: 0.2430, R²: 0.0199

============================================================
🔄 Round 108 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 108 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0289
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0253
============================================================


============================================================
🔄 Round 110 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 110 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.0306
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0204
============================================================


============================================================
🔄 Round 111 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 111 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0246
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0424
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0199

📊 Round 111 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0199

============================================================
🔄 Round 118 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 118 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0276
   Val:   Loss=0.0882, RMSE=0.2970, R²=0.0315
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0199

============================================================
🔄 Round 121 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 121 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0278
   Val:   Loss=0.0856, RMSE=0.2925, R²=0.0260
============================================================


============================================================
🔄 Round 122 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0695 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0695, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0695, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0695, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0695, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0695, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0695)

============================================================
📊 Round 122 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0299
   Val:   Loss=0.0695, RMSE=0.2637, R²=0.0113
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0199

📊 Round 122 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0199

============================================================
🔄 Round 124 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 124 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0310
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0185
============================================================


============================================================
🔄 Round 125 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 125 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=0.0322
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0081
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0199

============================================================
🔄 Round 128 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 128 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0260
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0383
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0199

📊 Round 128 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0199

============================================================
🔄 Round 132 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 132 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0267
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0204
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0198

📊 Round 132 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0198

============================================================
🔄 Round 135 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 135 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0338
   Val:   Loss=0.0775, RMSE=0.2783, R²=-0.0008
============================================================


============================================================
🔄 Round 136 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 136 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0277
   Val:   Loss=0.0823, RMSE=0.2870, R²=0.0316
============================================================


============================================================
🔄 Round 140 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 140 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0274
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0228
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0198

📊 Round 140 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0198

📊 Round 140 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0198

============================================================
🔄 Round 145 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 145 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2770, R²=0.0230
   Val:   Loss=0.0876, RMSE=0.2960, R²=0.0450
============================================================


============================================================
🔄 Round 146 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 146 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=0.0295
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0169
============================================================


============================================================
🔄 Round 147 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 147 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0347
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0024
============================================================


============================================================
🔄 Round 148 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 148 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0239
   Val:   Loss=0.0785, RMSE=0.2801, R²=0.0441
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0198

📊 Round 148 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0198

============================================================
🔄 Round 150 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 150 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0292
   Val:   Loss=0.0798, RMSE=0.2824, R²=0.0204
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0198

📊 Round 150 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0198

============================================================
🔄 Round 154 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 154 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0356
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0055
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0198

📊 Round 154 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0198

============================================================
🔄 Round 157 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 157 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0297
   Val:   Loss=0.0890, RMSE=0.2984, R²=0.0203
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0198

============================================================
🔄 Round 162 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 162 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0316
   Val:   Loss=0.0858, RMSE=0.2928, R²=0.0026
============================================================


============================================================
🔄 Round 164 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 164 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0238
   Val:   Loss=0.0731, RMSE=0.2704, R²=0.0466
============================================================


============================================================
🔄 Round 165 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 165 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0234
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0412
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0198

============================================================
🔄 Round 167 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 167 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0350
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0208
============================================================


============================================================
🔄 Round 169 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 169 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0333
   Val:   Loss=0.0822, RMSE=0.2868, R²=-0.0013
============================================================


============================================================
🔄 Round 172 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 172 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0260
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0378
============================================================


============================================================
🔄 Round 173 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 173 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0304
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0205
============================================================


============================================================
🔄 Round 175 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 175 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2748, R²=0.0348
   Val:   Loss=0.0925, RMSE=0.3042, R²=0.0011
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0198

============================================================
🔄 Round 178 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 178 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0239
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0394
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0198

============================================================
🔄 Round 179 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0697 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0697, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0697, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0697, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0697, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0697)

============================================================
📊 Round 179 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0331
   Val:   Loss=0.0697, RMSE=0.2641, R²=0.0057
============================================================


============================================================
🔄 Round 180 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 180 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0280
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0161
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0198

📊 Round 180 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0198

============================================================
🔄 Round 182 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 182 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0210
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0488
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0198

📊 Round 182 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0198

============================================================
🔄 Round 185 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0699 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0699, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0699, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0699, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 185 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0178
   Val:   Loss=0.0699, RMSE=0.2644, R²=0.0770
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

============================================================
🔄 Round 190 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 190 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0302
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0065
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

============================================================
🔄 Round 192 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 192 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0345
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0012
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

============================================================
🔄 Round 193 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 193 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0243
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0399
============================================================


============================================================
🔄 Round 196 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 196 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0252
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0413
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

============================================================
🔄 Round 198 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 198 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0312
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0192
============================================================


============================================================
🔄 Round 200 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 200 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0313
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0159
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

============================================================
🔄 Round 203 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 203 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0261
   Val:   Loss=0.0711, RMSE=0.2666, R²=0.0373
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2431, R²: 0.0197

📊 Round 203 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2431, R²: 0.0197

============================================================
🔄 Round 206 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 206 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0257
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0368
============================================================


============================================================
🔄 Round 207 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 207 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0208
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0540
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

============================================================
🔄 Round 208 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 208 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0246
   Val:   Loss=0.0724, RMSE=0.2692, R²=0.0296
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

📊 Round 208 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

============================================================
🔄 Round 210 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 210 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0300
   Val:   Loss=0.0725, RMSE=0.2692, R²=0.0236
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

📊 Round 210 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

📊 Round 210 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

============================================================
🔄 Round 214 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 214 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2783, R²=0.0265
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0110
============================================================


📊 Round 214 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

📊 Round 214 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

============================================================
🔄 Round 219 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 219 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0343
   Val:   Loss=0.0765, RMSE=0.2765, R²=0.0024
============================================================


📊 Round 219 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

============================================================
🔄 Round 221 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 221 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0369
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0045
============================================================


📊 Round 221 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

📊 Round 221 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

============================================================
🔄 Round 224 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 224 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0341
   Val:   Loss=0.0913, RMSE=0.3022, R²=0.0092
============================================================


============================================================
🔄 Round 226 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 226 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0254
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0273
============================================================


📊 Round 226 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

📊 Round 226 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

📊 Round 226 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

📊 Round 226 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

============================================================
🔄 Round 232 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 232 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0283
   Val:   Loss=0.0757, RMSE=0.2752, R²=0.0270
============================================================


📊 Round 232 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

============================================================
🔄 Round 234 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 234 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0352
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0036
============================================================


============================================================
🔄 Round 235 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 235 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=0.0242
   Val:   Loss=0.0752, RMSE=0.2742, R²=0.0245
============================================================


📊 Round 235 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

📊 Round 235 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

📊 Round 235 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

📊 Round 235 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

============================================================
🔄 Round 243 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 243 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0262
   Val:   Loss=0.0805, RMSE=0.2838, R²=0.0400
============================================================


============================================================
🔄 Round 244 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 244 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0275
   Val:   Loss=0.0718, RMSE=0.2679, R²=0.0324
============================================================


============================================================
🔄 Round 245 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 245 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0276
   Val:   Loss=0.0717, RMSE=0.2678, R²=0.0345
============================================================


============================================================
🔄 Round 246 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 246 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0235
   Val:   Loss=0.0729, RMSE=0.2699, R²=0.0526
============================================================


📊 Round 246 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2431, R²: 0.0197

============================================================
🔄 Round 250 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 250 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0206
   Val:   Loss=0.0731, RMSE=0.2704, R²=0.0638
============================================================


📊 Round 250 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2431, R²: 0.0196

📊 Round 250 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2431, R²: 0.0196

📊 Round 250 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2431, R²: 0.0196

============================================================
🔄 Round 253 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 253 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0264
   Val:   Loss=0.0802, RMSE=0.2831, R²=0.0370
============================================================


📊 Round 253 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2431, R²: 0.0196

📊 Round 253 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2431, R²: 0.0196

============================================================
🔄 Round 256 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 256 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0323
   Val:   Loss=0.0765, RMSE=0.2765, R²=0.0123
============================================================


============================================================
🔄 Round 257 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 257 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0328
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0090
============================================================


📊 Round 257 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2431, R²: 0.0196

============================================================
🔄 Round 259 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 259 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0288
   Val:   Loss=0.0877, RMSE=0.2962, R²=0.0283
============================================================


📊 Round 259 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2431, R²: 0.0197

============================================================
🔄 Round 261 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 261 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0278
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0316
============================================================


📊 Round 261 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

============================================================
🔄 Round 263 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 263 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0286
   Val:   Loss=0.0889, RMSE=0.2981, R²=-0.0026
============================================================


📊 Round 263 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

📊 Round 263 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0196

============================================================
🔄 Round 266 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 266 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0332
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0111
============================================================


📊 Round 266 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2431, R²: 0.0196

============================================================
🔄 Round 267 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0737, val=0.0995 (↓), lr=0.000001
   • Epoch   2/100: train=0.0737, val=0.0995, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0737, val=0.0995, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0737, val=0.0995, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0737, val=0.0995, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0737, val=0.0995, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0995)

============================================================
📊 Round 267 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0738, RMSE=0.2716, R²=0.0349
   Val:   Loss=0.0995, RMSE=0.3154, R²=0.0113
============================================================


============================================================
🔄 Round 268 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 268 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0326
   Val:   Loss=0.0728, RMSE=0.2699, R²=0.0133
============================================================


============================================================
🔄 Round 269 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 269 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0299
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0165
============================================================


============================================================
🔄 Round 271 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 271 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0257
   Val:   Loss=0.0736, RMSE=0.2713, R²=0.0432
============================================================


📊 Round 271 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2431, R²: 0.0196

============================================================
🔄 Round 273 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 273 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0289
   Val:   Loss=0.0767, RMSE=0.2770, R²=0.0303
============================================================


============================================================
🔄 Round 274 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 274 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0214
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0603
============================================================


📊 Round 274 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2431, R²: 0.0196

============================================================
🔄 Round 277 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 277 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0261
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0365
============================================================


📊 Round 277 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2431, R²: 0.0196

============================================================
🔄 Round 278 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 278 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0255
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0426
============================================================


📊 Round 278 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2431, R²: 0.0196

============================================================
🔄 Round 282 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 282 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0343
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0005
============================================================


============================================================
🔄 Round 283 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 283 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0290
   Val:   Loss=0.0778, RMSE=0.2788, R²=0.0273
============================================================


============================================================
🔄 Round 284 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 284 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0345
   Val:   Loss=0.0723, RMSE=0.2688, R²=-0.0087
============================================================


============================================================
🔄 Round 286 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 286 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=0.0333
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0098
============================================================


📊 Round 286 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2431, R²: 0.0196

============================================================
🔄 Round 288 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 288 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0299
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0204
============================================================


📊 Round 288 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2431, R²: 0.0196

📊 Round 288 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2431, R²: 0.0196

============================================================
🔄 Round 292 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 292 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0273
   Val:   Loss=0.0766, RMSE=0.2767, R²=0.0370
============================================================


📊 Round 292 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2431, R²: 0.0196

📊 Round 292 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2431, R²: 0.0196

============================================================
🔄 Round 295 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 295 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0216
   Val:   Loss=0.0775, RMSE=0.2783, R²=0.0532
============================================================


============================================================
🔄 Round 296 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 296 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0289
   Val:   Loss=0.0749, RMSE=0.2737, R²=0.0287
============================================================


📊 Round 296 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2431, R²: 0.0196

============================================================
🔄 Round 298 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 298 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0305
   Val:   Loss=0.0845, RMSE=0.2906, R²=0.0236
============================================================


📊 Round 298 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2431, R²: 0.0197

📊 Round 298 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

============================================================
🔄 Round 304 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 304 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0214
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0315
============================================================


📊 Round 304 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

============================================================
🔄 Round 306 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0655 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0655, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0655, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0655, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0655, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0655, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0655)

============================================================
📊 Round 306 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0330
   Val:   Loss=0.0655, RMSE=0.2559, R²=0.0076
============================================================


============================================================
🔄 Round 307 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 307 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0253
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0377
============================================================


📊 Round 307 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

============================================================
🔄 Round 308 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 308 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0266
   Val:   Loss=0.0721, RMSE=0.2685, R²=0.0385
============================================================


============================================================
🔄 Round 310 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 310 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0362
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0024
============================================================


============================================================
🔄 Round 311 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 311 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0220
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0372
============================================================


============================================================
🔄 Round 314 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 314 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0311
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0213
============================================================


============================================================
🔄 Round 315 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 315 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0323
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0028
============================================================


============================================================
🔄 Round 316 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 316 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0285
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0254
============================================================


📊 Round 316 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

============================================================
🔄 Round 318 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 318 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2745, R²=0.0274
   Val:   Loss=0.0929, RMSE=0.3048, R²=0.0127
============================================================


📊 Round 318 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

📊 Round 318 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

============================================================
🔄 Round 320 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 320 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0360
   Val:   Loss=0.0889, RMSE=0.2981, R²=0.0054
============================================================


📊 Round 320 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

📊 Round 320 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

============================================================
🔄 Round 324 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 324 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0298
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0251
============================================================


📊 Round 324 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

============================================================
🔄 Round 326 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 326 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0348
   Val:   Loss=0.0802, RMSE=0.2833, R²=0.0073
============================================================


📊 Round 326 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

📊 Round 326 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

============================================================
🔄 Round 331 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 331 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0324
   Val:   Loss=0.0745, RMSE=0.2729, R²=-0.0195
============================================================


📊 Round 331 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

📊 Round 331 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

📊 Round 331 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

📊 Round 331 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

📊 Round 331 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

============================================================
🔄 Round 336 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 336 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0293
   Val:   Loss=0.0774, RMSE=0.2783, R²=0.0161
============================================================


📊 Round 336 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

📊 Round 336 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

============================================================
🔄 Round 339 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 339 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0195
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0502
============================================================


📊 Round 339 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

📊 Round 339 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

📊 Round 339 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0196

============================================================
🔄 Round 345 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 345 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0235
   Val:   Loss=0.0734, RMSE=0.2710, R²=0.0541
============================================================


============================================================
🔄 Round 346 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 346 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0280
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0297
============================================================


📊 Round 346 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2431, R²: 0.0196

============================================================
🔄 Round 348 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 348 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0325
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0107
============================================================


📊 Round 348 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2431, R²: 0.0196

📊 Round 348 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2431, R²: 0.0196

============================================================
🔄 Round 350 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 350 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0210
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0603
============================================================


📊 Round 350 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2431, R²: 0.0196

📊 Round 350 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2431, R²: 0.0196

📊 Round 350 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2431, R²: 0.0196

============================================================
🔄 Round 353 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 353 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0341
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0083
============================================================


============================================================
🔄 Round 354 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 354 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=0.0254
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0460
============================================================


📊 Round 354 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2431, R²: 0.0196

============================================================
🔄 Round 356 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 356 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0270
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0372
============================================================


============================================================
🔄 Round 357 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 357 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2794, R²=0.0310
   Val:   Loss=0.0822, RMSE=0.2866, R²=0.0237
============================================================


============================================================
🔄 Round 358 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 358 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0222
   Val:   Loss=0.0778, RMSE=0.2788, R²=0.0559
============================================================


📊 Round 358 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2431, R²: 0.0196

============================================================
🔄 Round 360 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 360 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0306
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0157
============================================================


============================================================
🔄 Round 361 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 361 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0356
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0024
============================================================


📊 Round 361 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2431, R²: 0.0196

============================================================
🔄 Round 362 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 362 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0307
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0239
============================================================


============================================================
🔄 Round 363 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 363 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0277
   Val:   Loss=0.0739, RMSE=0.2719, R²=0.0374
============================================================


📊 Round 363 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2431, R²: 0.0196

============================================================
🔄 Round 364 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 364 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0311
   Val:   Loss=0.0737, RMSE=0.2715, R²=0.0226
============================================================


============================================================
🔄 Round 365 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 365 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0383
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0221
============================================================


📊 Round 365 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2431, R²: 0.0196

============================================================
🔄 Round 368 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 368 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0295
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0002
============================================================


📊 Round 368 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2431, R²: 0.0196

============================================================
🔄 Round 369 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 369 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0330
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0159
============================================================


📊 Round 369 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2431, R²: 0.0196

============================================================
🔄 Round 371 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0692 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0692, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0692, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0693, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0693, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0693, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0692)

============================================================
📊 Round 371 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2850, R²=0.0350
   Val:   Loss=0.0692, RMSE=0.2632, R²=-0.0056
============================================================


📊 Round 371 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2431, R²: 0.0196

📊 Round 371 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2431, R²: 0.0196

📊 Round 371 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2431, R²: 0.0196

============================================================
🔄 Round 380 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 380 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0314
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0214
============================================================


============================================================
🔄 Round 381 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 381 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=0.0278
   Val:   Loss=0.0898, RMSE=0.2996, R²=0.0250
============================================================


📊 Round 381 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2431, R²: 0.0196

============================================================
🔄 Round 382 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 382 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0266
   Val:   Loss=0.0739, RMSE=0.2719, R²=0.0366
============================================================


📊 Round 382 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2431, R²: 0.0196

============================================================
🔄 Round 383 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 383 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0312
   Val:   Loss=0.0743, RMSE=0.2725, R²=0.0204
============================================================


📊 Round 383 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2431, R²: 0.0196

============================================================
🔄 Round 386 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 386 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0300
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0083
============================================================


============================================================
🔄 Round 388 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 388 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0207
   Val:   Loss=0.0717, RMSE=0.2677, R²=0.0662
============================================================


📊 Round 388 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2431, R²: 0.0196

============================================================
🔄 Round 389 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 389 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0279
   Val:   Loss=0.0737, RMSE=0.2714, R²=0.0327
============================================================


📊 Round 389 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2431, R²: 0.0196

============================================================
🔄 Round 390 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 390 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2774, R²=0.0293
   Val:   Loss=0.0865, RMSE=0.2942, R²=0.0310
============================================================


📊 Round 390 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2431, R²: 0.0196

📊 Round 390 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2431, R²: 0.0196

============================================================
🔄 Round 393 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 393 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0300
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0242
============================================================


📊 Round 393 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2431, R²: 0.0196

============================================================
🔄 Round 396 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 396 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0367
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0029
============================================================


============================================================
🔄 Round 397 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 397 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0342
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0106
============================================================


📊 Round 397 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2431, R²: 0.0196

============================================================
🔄 Round 399 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 399 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0299
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0272
============================================================


📊 Round 399 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2431, R²: 0.0196

============================================================
🔄 Round 400 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 400 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0306
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0260
============================================================


============================================================
🔄 Round 401 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 401 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0338
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0076
============================================================


============================================================
🔄 Round 402 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 402 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2797, R²=0.0324
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0106
============================================================


📊 Round 402 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2431, R²: 0.0196

============================================================
🔄 Round 403 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 403 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0347
   Val:   Loss=0.0838, RMSE=0.2894, R²=0.0094
============================================================


============================================================
🔄 Round 405 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 405 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0242
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0518
============================================================


📊 Round 405 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2431, R²: 0.0196

============================================================
🔄 Round 409 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0708 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0708, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0708, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0708, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 409 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2843, R²=0.0325
   Val:   Loss=0.0708, RMSE=0.2661, R²=0.0109
============================================================


============================================================
🔄 Round 410 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 410 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0391
   Val:   Loss=0.0794, RMSE=0.2817, R²=-0.0109
============================================================


============================================================
🔄 Round 413 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 413 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0312
   Val:   Loss=0.0793, RMSE=0.2817, R²=0.0198
============================================================


📊 Round 413 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0196

============================================================
🔄 Round 415 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 415 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2792, R²=0.0303
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0218
============================================================


📊 Round 415 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

============================================================
🔄 Round 422 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 422 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=0.0285
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0343
============================================================


📊 Round 422 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0196

============================================================
🔄 Round 425 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 425 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0347
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0107
============================================================


============================================================
🔄 Round 430 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 430 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0281
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0354
============================================================


============================================================
🔄 Round 431 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 431 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0292
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0318
============================================================


============================================================
🔄 Round 432 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 432 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0349
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0086
============================================================


📊 Round 432 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0196

📊 Round 432 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0196

============================================================
🔄 Round 435 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 435 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0282
   Val:   Loss=0.0853, RMSE=0.2920, R²=0.0313
============================================================


============================================================
🔄 Round 436 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 436 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.0322
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0186
============================================================


📊 Round 436 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0196

============================================================
🔄 Round 440 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0680 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0680, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0680, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0680, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0680, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0680, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0680)

============================================================
📊 Round 440 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=0.0308
   Val:   Loss=0.0680, RMSE=0.2608, R²=0.0250
============================================================


📊 Round 440 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0196

📊 Round 440 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0196

============================================================
🔄 Round 444 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 444 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2774, R²=0.0294
   Val:   Loss=0.0865, RMSE=0.2940, R²=0.0262
============================================================


============================================================
🔄 Round 445 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 445 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0206
   Val:   Loss=0.0769, RMSE=0.2772, R²=0.0649
============================================================


📊 Round 445 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0196

============================================================
🔄 Round 449 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 449 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=0.0344
   Val:   Loss=0.0897, RMSE=0.2995, R²=0.0108
============================================================


📊 Round 449 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0196

============================================================
🔄 Round 451 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 451 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0302
   Val:   Loss=0.0710, RMSE=0.2665, R²=-0.0195
============================================================


📊 Round 451 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0196

============================================================
🔄 Round 452 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 452 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0248
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0476
============================================================


📊 Round 452 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0196

📊 Round 452 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0196

============================================================
🔄 Round 454 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 454 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0334
   Val:   Loss=0.0806, RMSE=0.2840, R²=0.0145
============================================================


📊 Round 454 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0196

============================================================
🔄 Round 457 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 457 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2797, R²=0.0331
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0159
============================================================


📊 Round 457 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

📊 Round 457 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

📊 Round 457 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

============================================================
🔄 Round 464 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 464 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2763, R²=0.0312
   Val:   Loss=0.0887, RMSE=0.2979, R²=0.0246
============================================================


============================================================
🔄 Round 467 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 467 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2774, R²=0.0272
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0386
============================================================


============================================================
🔄 Round 468 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0705, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 468 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0346
   Val:   Loss=0.0705, RMSE=0.2656, R²=0.0002
============================================================


📊 Round 468 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

============================================================
🔄 Round 469 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 469 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0232
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0466
============================================================


📊 Round 469 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

📊 Round 469 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

📊 Round 469 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

============================================================
🔄 Round 474 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 474 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0235
   Val:   Loss=0.0716, RMSE=0.2676, R²=0.0509
============================================================


============================================================
🔄 Round 475 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0699 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0699, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0699, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0699, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 475 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0295
   Val:   Loss=0.0699, RMSE=0.2644, R²=0.0312
============================================================


============================================================
🔄 Round 476 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 476 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0303
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0208
============================================================


============================================================
🔄 Round 479 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 479 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0235
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0454
============================================================


📊 Round 479 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

============================================================
🔄 Round 481 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 481 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0365
   Val:   Loss=0.0768, RMSE=0.2772, R²=0.0009
============================================================


📊 Round 481 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

📊 Round 481 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

============================================================
🔄 Round 484 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 484 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0335
   Val:   Loss=0.0752, RMSE=0.2743, R²=0.0124
============================================================


📊 Round 484 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

📊 Round 484 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

📊 Round 484 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

============================================================
🔄 Round 495 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 495 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0245
   Val:   Loss=0.0725, RMSE=0.2692, R²=0.0494
============================================================


📊 Round 495 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

📊 Round 495 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

📊 Round 495 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

📊 Round 495 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

============================================================
🔄 Round 501 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 501 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0295
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0305
============================================================


📊 Round 501 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

============================================================
🔄 Round 503 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 503 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0400
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0840
============================================================


📊 Round 503 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

📊 Round 503 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

============================================================
🔄 Round 509 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 509 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0325
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0193
============================================================


📊 Round 509 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

============================================================
🔄 Round 512 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 512 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0289
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0344
============================================================


============================================================
🔄 Round 513 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 513 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0309
   Val:   Loss=0.0759, RMSE=0.2754, R²=-0.0020
============================================================


📊 Round 513 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

============================================================
🔄 Round 514 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 514 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0274
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0299
============================================================


============================================================
🔄 Round 515 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0690 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0690, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0690, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0690, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0690, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0690, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0690)

============================================================
📊 Round 515 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0261
   Val:   Loss=0.0690, RMSE=0.2627, R²=0.0458
============================================================


============================================================
🔄 Round 516 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 516 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0262
   Val:   Loss=0.0737, RMSE=0.2715, R²=0.0317
============================================================


============================================================
🔄 Round 517 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 517 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0298
   Val:   Loss=0.0780, RMSE=0.2792, R²=0.0225
============================================================


📊 Round 517 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

============================================================
🔄 Round 520 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 520 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0246
   Val:   Loss=0.0721, RMSE=0.2685, R²=0.0528
============================================================


📊 Round 520 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

============================================================
🔄 Round 521 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 521 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2810, R²=0.0302
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0286
============================================================


============================================================
🔄 Round 523 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 523 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2819, R²=0.0312
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0188
============================================================


📊 Round 523 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

============================================================
🔄 Round 526 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 526 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0324
   Val:   Loss=0.0749, RMSE=0.2738, R²=0.0194
============================================================


📊 Round 526 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

============================================================
🔄 Round 529 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 529 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0267
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0396
============================================================


============================================================
🔄 Round 530 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 530 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=0.0302
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0297
============================================================


📊 Round 530 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

============================================================
🔄 Round 533 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 533 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0296
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0206
============================================================


📊 Round 533 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

📊 Round 533 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

📊 Round 533 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

============================================================
🔄 Round 536 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 536 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0292
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0320
============================================================


📊 Round 536 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0197

============================================================
🔄 Round 541 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 541 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0301
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0103
============================================================


============================================================
🔄 Round 542 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 542 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0265
   Val:   Loss=0.0733, RMSE=0.2707, R²=0.0462
============================================================


============================================================
🔄 Round 543 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 543 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0214
   Val:   Loss=0.0760, RMSE=0.2756, R²=0.0602
============================================================


📊 Round 543 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0198

📊 Round 543 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0198

============================================================
🔄 Round 545 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 545 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0321
   Val:   Loss=0.0735, RMSE=0.2711, R²=0.0215
============================================================


============================================================
🔄 Round 546 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 546 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0313
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0017
============================================================


============================================================
🔄 Round 547 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 547 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=0.0310
   Val:   Loss=0.0753, RMSE=0.2745, R²=0.0215
============================================================


============================================================
🔄 Round 548 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 548 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0305
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0262
============================================================


============================================================
🔄 Round 552 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 552 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0272
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0425
============================================================


📊 Round 552 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0198

============================================================
🔄 Round 553 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 553 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2803, R²=0.0216
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0509
============================================================


📊 Round 553 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0198

📊 Round 553 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0198

============================================================
🔄 Round 556 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 556 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0196
   Val:   Loss=0.0767, RMSE=0.2770, R²=0.0724
============================================================


📊 Round 556 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0198

============================================================
🔄 Round 559 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 559 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0363
   Val:   Loss=0.0763, RMSE=0.2763, R²=0.0011
============================================================


📊 Round 559 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0198

📊 Round 559 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0198

📊 Round 559 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0198

============================================================
🔄 Round 563 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 563 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0277
   Val:   Loss=0.0733, RMSE=0.2707, R²=0.0410
============================================================


============================================================
🔄 Round 566 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 566 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0400
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0153
============================================================


📊 Round 566 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0198

============================================================
🔄 Round 567 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 567 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0198
   Val:   Loss=0.0752, RMSE=0.2742, R²=0.0715
============================================================


📊 Round 567 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0198

============================================================
🔄 Round 568 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 568 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0313
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0254
============================================================


📊 Round 568 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0198

============================================================
🔄 Round 569 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 569 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0365
   Val:   Loss=0.0721, RMSE=0.2686, R²=0.0008
============================================================


📊 Round 569 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0198

📊 Round 569 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0198

============================================================
🔄 Round 571 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0704, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0704, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0704, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0704, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0704, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 571 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0300
   Val:   Loss=0.0704, RMSE=0.2654, R²=0.0316
============================================================


============================================================
🔄 Round 574 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0700 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0700, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0700, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0700, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0700)

============================================================
📊 Round 574 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0317
   Val:   Loss=0.0700, RMSE=0.2645, R²=0.0212
============================================================


📊 Round 574 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2430, R²: 0.0198

============================================================
🔄 Round 575 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 575 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0349
   Val:   Loss=0.0720, RMSE=0.2684, R²=-0.0040
============================================================


❌ Client client_11 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_status:14, grpc_message:"Socket closed"}"
>
