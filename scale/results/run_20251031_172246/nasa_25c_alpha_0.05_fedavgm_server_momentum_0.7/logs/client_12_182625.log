[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fecdac6d-b79b-4319-8b5f-938d24382f21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36dd9865-cafd-453a-9f37-b5fb65cc89f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acb307b2-7953-47eb-a899-d13a2034b41e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72134854-69c7-45ea-b518-cf5e040f8e1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f43d9478-94b5-4773-afa9-1e970a097971
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce2bce38-308a-4f25-b5e9-2ab8cacb0004
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd072845-f2ff-49a1-9b0e-ed010e04a70c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf234991-d73f-4fc1-a751-44503e4e78d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02bf4243-2fd9-499f-814b-bbf74d57bbe2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69301f26-e0a4-4e52-83ab-9b3d454a999f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a460b58d-f896-4714-94a2-4083250e0ecf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4627e699-16f9-4772-a05e-a8a995bdd7f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 857815ce-fc78-41dc-b1c4-72cffd3ddbe0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88a6497e-fe59-4352-a6a7-6032f5c685c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c80175dc-9d9b-489f-8caf-899e28c0bbe6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8b2aec7-2b9f-417a-8537-7f321a4a5d3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffb13a0b-31ed-498d-b82f-fc1ab443ab86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4abaec02-fa00-4487-af0d-28604a383207
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f0916ab-765f-49e8-9a0d-8af3a4dec094
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32bd8a36-2058-4071-a710-78c3acafd486
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dffdeb78-dca9-401e-9da6-220d5a996fd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78ee6078-45a6-4ca7-a60f-62c0ed29b5b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bd66179-ddd5-43d5-b04e-e09ceee2b9be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e947de8d-6a10-4c19-873b-4e12037e6024
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0b67fbf-2a10-4626-bc99-accab331c766
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acf45503-fa4a-4afa-ad2a-744c9c3c9a0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b86100bf-4891-4cf9-8c9e-3afa6c7e77c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2efc56cd-8339-4539-9cb4-0ebd8eef0198
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44fb4dcb-19ee-45e7-bc41-1989993eb222
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 416e0ff5-76fb-4317-8d46-78fddf479f02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 054000da-c135-48ee-a043-020b90e30846
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5336e5b5-3024-4735-a4d5-4f031aee7495
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6249d792-4aab-4a8b-b204-b11d07d24c44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa29936b-5c48-4291-8c91-26f68dfec19a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ea0ec01-193e-470d-9dda-9f5e64e476af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d336b01-3d6c-4fae-a70b-a8404a62b003
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38eeb664-4e5e-4162-adc8-7feb39bc16cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbaaaf2b-74df-4980-b438-fad46e744768
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 159e37b9-7a1c-4915-a015-54d5c6da1a71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c86af6e-c0ea-42d8-a38a-162c5f962c1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68956be5-1a32-4a29-a1ed-274e0f81f917
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f726067-4e61-4ce5-9deb-a5f734607b84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9131f75a-d3e1-4543-a28f-40e91a4557a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8730bed-c8ab-455e-8068-8846099da1bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93513fff-26b1-450b-a9c1-2f99c525ee32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11ba8fc3-3475-4804-adb2-aa997ff6e922
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6c78062-c7ff-4d17-afbf-eb88d06eca94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 770c8b5c-a36b-43de-87ee-3d1240d969bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fa5d1b6-e458-4c6a-96e8-68b33166a4a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 052e3121-4b91-4dc7-8854-523df4cc7b31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b4dd2e3-af35-455c-8d46-191e9b685176
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2f0413b-5202-4f11-a8fc-8c3e287fd1d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66926dbf-f26b-4358-805d-053576f433e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09492f66-f0f4-46ca-815d-3ac30f4ff334
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc64dc69-2dab-453b-8541-7f7e896f4923
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e72c02d2-2b5b-40bf-ba8e-4cb492ff2b44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfbdf09c-5aa7-4a8c-828d-6211d95c3ee0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfc84a86-8109-4f92-b77f-97591938d88a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8d4e6f9-af1b-4b0b-a65d-f41f5b737761
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fb7a165-28f7-4209-81b8-c928efd3d098
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9513cfb9-4681-44f4-977f-90b6a24282a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4df866f-9baf-4506-b37e-332e04c0ddec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 982572a6-5e5a-4df3-a663-1326cf53373f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 217bceec-5d01-46a8-8582-9c6be14c4aef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8cfe0465-3652-4781-ba1c-cc438f08e2b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 210270ab-1f06-4e71-b0f0-3a99b97f11b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf146a45-a961-4d08-824c-225d8c346e98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a786fa56-bea5-4745-a985-9d697dcbfbdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6378f95a-7377-4c52-8566-96f2126da284
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43f59076-6dc9-4925-beff-1859c5d95068
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee3e19e1-5d49-40e4-8aa7-6acc08578067
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e5f0027-bf27-4e0a-8169-c157cb09a742
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bb2b0f4-ccd0-4b7a-bf0b-141ef59e0c2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7cddb86-704b-40d7-a73e-98ebf3244922
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1591244-07f4-4052-bf02-bf1b87da0fe2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df52c175-19e2-4e5b-b94a-78952257007f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5388562-47a9-4b50-8015-75558f11ebd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07c1d621-cbe0-41b4-915c-6168d671b83d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 640fe402-b0aa-4535-8d1d-b8ab6d40d6fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dab41b34-eadf-46e3-87c2-3f9a4e368c17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f790089e-e7ec-4e54-8f6a-4e42e38f473f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77d75f5f-f9e7-49cf-a95c-19e72f562cdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e55d0846-16dc-4368-a4de-9149c092d092
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60f63985-3d76-478a-be22-9cdf19d83b8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e21e5e1b-0bac-4ce7-ab0e-6d03cc56f011
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09bcd3a5-ef97-4522-9b81-0d753854a4bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ac2887c-bbce-4ac5-8a37-9a26936c7f6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8aaa4ce3-f74e-4cc4-ad9c-d7323dff0200
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24051419-50da-47e8-be0c-b083c00bec91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd107b16-f359-412a-9a8b-fdad538b4391
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c448d6ac-8641-4adb-8692-9175a6605c90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e651a893-54ee-454f-b1fa-e43e877b4ede
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29d58760-f2f8-4f25-ae21-0ba3615750d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa082ecb-a95a-4d96-965e-212594d12d05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32f25457-1225-424b-bfb8-5924008a27f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 501b6b4d-c908-4133-8d0e-06523b8ffa6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82029e79-07d0-407f-9aeb-425e72aeba50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d61faaef-a0ec-428a-a227-17543d7d576c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f7a22ed-e2f1-4115-b5e2-325dc756a0ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b9f3c7b-7b1f-4302-8533-9093afb3024f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06628f20-ce7c-49b2-b63a-5ed9e8d89f96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0af9798e-8971-4082-87f5-16f5147e6a8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a3b0d5d-8708-4a69-b624-e99802859aa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f102c22c-3c84-4ebc-a47a-55dd086ef75c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c86b273-d55a-4a97-970d-dc77a65fce8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92975195-b3ab-4188-8ff2-988ebb6a3158
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 215af0f5-f016-4c51-a736-654336739655
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c8437cf-8a40-46d8-84da-724732021bb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1cfc142d-faf1-406b-8961-ec63a3dddbfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e785296-6d5d-410b-a156-4356e7043609
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message caf22661-d0d5-4e13-a6dd-740bbc39f43e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae96beaa-3066-4b93-8279-c0d20545954d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ab93997-3793-408c-a01c-2c0c7b834bb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a96a28b3-6bc8-487f-8a35-cb24ce82430b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb12ccb7-df12-4a07-bb83-28df1d48de86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1eecb896-e63a-468e-8fca-918e6bf23861
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1dbe4a0d-41d1-484f-ba28-871c4ca4c4af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f0c270f-7e63-452e-a79f-7bcd766018b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71ed40d6-51ce-4400-b927-d509e221ea4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 445c8e49-135e-405e-bd2e-3e34aaf55cbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 494eedad-8559-4caa-a90f-cd31c157422d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 981f2890-1d5a-48c6-bc72-161ca6989471
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1c9cc4b-1c21-480b-83d7-cfddf4b52525
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6e8996a-0ccf-45c3-a45b-efa60a54a1e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7826de19-e60f-406e-be25-dc83b61dff8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82dd557a-8515-4cef-ad4e-e536eac25503
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23e02d5d-4650-41f7-b80f-9ba4a9a8b740
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed16e5f5-f745-4b0a-9de6-6c551ea799a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b5c33ac-5402-4263-b074-54bfd02cef9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 068bcaee-2221-418a-b0cd-dfaf9cac5a8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6aafa89-9696-45d8-aea6-8ab44dd0ae27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34cf2619-a8ce-4c48-a0ce-1ef3a3836794
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a257b79f-8133-4419-b98f-cca566520127
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73a48fa9-abe1-4712-a4f7-956610282109
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f626f97-5735-4fbd-978b-cd678d6e91f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51fcdc48-627b-4544-b7c9-5713eb0633f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2cd9dafe-3394-44af-9f87-0a0f8503c55c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 237dade5-aa69-4b7f-9885-005aa2c4d77d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dad801f5-2ab1-4feb-86ba-e703283a441d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 547fb118-3e9c-48df-8f4c-3126d8e5b91b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a65cd00e-bd3f-4f72-a461-0d8a18b942f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8cd2ac5-f9cc-44d5-a43d-84c2189b061c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 332ec2a8-4676-4312-b648-9bf1ba0fc6bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6decb51d-8efd-4a92-9cea-336d82044f98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7a19a81-f669-4333-804f-ef6d706d66a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5c29e66-e401-42fd-ae2b-146b0db6b585
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe466018-128a-40a4-9f26-4e2efbd41391
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb13a0f5-e565-467c-91c9-e58bb5ade735
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbcf7742-d074-4c79-9247-2c545fb83144
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d945e26f-099b-4967-bf65-fd6a02a9644b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3b69dd5-3a99-47cc-8ee5-25255711db89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 449a4ac8-1e19-4972-bc84-c487db7afcb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce436063-937a-41a5-a8ed-b5a92eb2d2fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b90c7958-aa0c-4d54-b569-b9b3a0d284e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b28eb45b-1301-4952-8b3f-b4f3d6669665
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20734311-f0ea-4274-9c99-e34b6ebb2b8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28ed60dc-9e51-4612-a598-97ab7d7a1aba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 755254bd-1070-4a2a-a308-ec150e18e7ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39305053-89a8-4ee1-890f-705c5065414d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 496d0e41-a004-4705-a657-73c6d4cf9348
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5edeba26-872f-447e-bee9-464c516aa4ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3672615-63ff-4d09-a41d-baf61db054dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 096d625f-b487-4540-8e11-d57a607b01f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4080c97f-08ce-4164-971e-4bc0762a7c43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55c16102-2c96-4c1b-bfef-c6abe671bb86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfc62528-8fa1-4658-b6df-9a006dfc95a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d134af1-d65d-4b73-8546-20e27fb52264
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 756bb66f-c0a4-4a4a-8dd6-14d26fcb8fed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73cb7057-aa7a-4f1d-b3a9-e8763fe10539
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2169b932-5e21-483a-95db-3c4b7a239b1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd245501-b4bf-4f4a-8689-8e98c0a81609
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfa2b07f-4698-46c9-b1a1-aa26653a47e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f938df84-566d-405d-af36-d69f77e649c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbd522de-c5e0-45ac-a193-4fc31658d404
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24f4544e-028b-484d-ade7-de6ed6369470
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e76d5d0-b23b-476d-ac97-383e516052e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a6c8fc2-416e-46ad-8e0c-ac62fa99515d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b488e602-2eff-4586-bc4f-6838ea7c0dd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 470e4e77-ca38-4e39-9a8b-8e1cb46076e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ca10e65-7b43-4bf1-9136-0400d7cb0817
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92f1b7bf-3b42-4d17-bed5-a6f3125c2875
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2323fb4e-555a-4036-a280-7608c80fe2e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c43a6075-374b-4658-8bd6-c88b6281fedc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35dc3ab6-436d-4ea4-adfc-1d83cf806e5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0eee2600-7235-4711-bc05-5292981042ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c1f0de3-b904-4d3f-ab24-d2f5588461cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 403c248f-26d9-4083-baed-29e138b98d30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc89d081-a052-40f6-ba24-d4be95f6a075
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08e13112-7c3d-4bd3-af28-1f1a1dc41335
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26f64d23-743b-487c-8e5b-f3132f5aca67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9d3734f-7bfa-48e5-8506-52e12607c9d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eae0507e-efea-4efb-9b01-7dc49d52161b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 387c41d4-3d72-47cc-a557-7538c2e32eac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ffcc7b9-cfc3-4f60-b556-980caca4538f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29e79056-168b-4172-af00-061637d79140
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07add80f-55bf-434c-9b1c-b9b6b61b766d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62fdd7e9-654d-4bba-893a-15c2ca3b5308
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3440748d-a962-4de3-9af0-bd752175d1de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d404bc91-6118-4471-b574-d060b746ca89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c3f397a-4b91-4697-824b-ad4ba3f82daa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 972cd02d-c7ff-4887-8d38-913a1abef1d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4a22f9d-c84c-49bc-b387-b0281d9088e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aba6807b-c0dc-4047-93df-0fd0b40b8acd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b2221df-bc35-4743-9d2a-534e31fcee53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce39f891-bfd7-4831-9071-6dc67760b571
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1c47e27-aecf-4ce2-b511-9c1c7c8e5257
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f554143-056d-4803-87c9-1c1f83e9a43c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbcf37af-539d-4149-b1c2-1bb0ad65b08c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b9f8919-5f9e-497a-93e4-7898cf2a5d0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b82b5a88-256a-4c6f-9af4-d2adf3f08687
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8197bce2-59af-4911-a0f2-497dcfab0a8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb2e175c-a208-493e-88e0-97669d2e5cda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36cb2695-8502-4992-9ed8-3724024c203f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed567a1f-bed0-4c05-aa6a-9adf675ff491
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e76a7f10-d881-40bd-8a30-b856f414d7a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1412ba82-1f58-465d-b170-8fe67da5565d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 053260c1-5094-4f04-b0eb-1abe8d7865a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07492040-19f7-49b4-9b93-dce52b0c46df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 897fd01b-e26e-48c5-8e32-70bfcb0a1134
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afd036a4-1254-4740-8f32-ff40e10d568c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 979a99a4-e123-4534-8245-eeccf581cb39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a1413c3-87b4-4fb7-978b-00ca368da108
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5207e98b-63b6-45b8-bfd9-de17db1c89f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e50fa40e-6421-44a0-a6e1-ed3024c8597e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a194b443-e46d-48e8-a329-edd33b1016c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 898d177b-9011-4dd2-9341-e0da48836813
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 301ef1c7-49cc-4e5a-bdfd-8ed818c445da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ade88d74-6c13-47b8-acb7-79eb7f30d3b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f831e863-1c71-434e-b6c1-9d1a0241ceea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9648aef0-baa3-4b17-ae02-6eb975b165f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd2801a1-218b-4a1d-9c7b-3ace463443c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b1c99d6-0c13-4c5d-ab83-2f9d3f61601a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfc3cf73-5280-4c36-82be-a11ef33ab0cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94662f7e-2701-49d2-b010-161cc5068e9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdfc8cb1-5712-444a-8b68-b12bcb2bbf89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5549601-7ccb-49a2-b2d2-55c58c38d15b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53e312f8-6004-4fec-ae21-9186bffdfb13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05fcbaa3-3785-4ed4-8fe7-4c1a5e844c2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4b3c03f-5c6b-40e9-887a-0a8aba973904
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7dd5b145-80e1-49cd-aa06-80e75936497d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 180df45f-5acc-44fb-98b9-68807cc57c00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7cb11b0d-669a-436e-998f-03fdbb964e78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 291ee296-5f19-45c9-aa39-aebd440330d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd063c8c-9166-4dce-b6e0-f6b305fbf6e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ae51c0a-68a7-403b-99e1-c26af59198ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bdb46b5-5654-41cf-8a38-3e30026b62da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 482b17db-c118-400c-a5e3-44dac00edda9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21c0dd6c-8e4d-4393-afdc-e14b0bc1079f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d3c144c-a2ae-436e-b1b4-134b087e1a7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec2f1673-971e-447b-becc-62fea91d2c37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 827ed7bb-dc02-45df-a610-e2ad5233a5d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05d9e273-8fd2-41fd-8f21-df90b8281d81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 917ad762-a00a-4244-a789-75ef6268db36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83b463e9-f76d-4690-a050-b2938ecd01e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22d6666e-52ca-4c20-af82-a14184f4af70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98d1e401-0a67-4f9d-a67b-c316fbd2e48d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bdb925f8-eea9-4f49-aa2c-6076c1bc9a32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 619fa3fb-dca0-4e1c-ac15-19ece4660f68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53757ddc-3493-47ae-ae81-073d0344b914
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9ed3844-78d3-45a0-b504-b4a4052fc9f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abb7ab60-8ca5-439f-8d18-c24a8020fac2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b0d30fc-813e-421c-b4d1-dfaadeb7b630
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bec7609-5531-4f70-a69d-1d02502e6ac9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae44364f-d30e-4231-abba-f7e081d3f0f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bd7a1a3-3789-4386-8ca5-d0450a71798f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0763fb17-eee7-4de5-b6af-748f4bbe548d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4cfd6be-a1ef-47fc-9b16-9befd8d5bf66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22468903-5c6b-4721-a7e4-70b4563c12b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 579dbe8f-2507-4671-af9e-17dc5e040869
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62b5e89c-485f-4055-944b-992569f1ea44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a80f4bef-82a4-4b27-ae86-537c206f5768
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 902f7bd7-9f21-4bfc-a133-7678e1dd59cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0e98bca-2a89-4faa-917e-09087116b1ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4722e062-013f-4b61-ac4f-db1d13213a45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a390778-6a8f-4fd3-af38-544275d7a5a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 995fbd7f-ab30-417d-9f52-4056cf12f76c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b02d6f11-df3d-4ef8-9773-5209dd7c6d3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42f8f329-6419-474c-8bcd-662d9ca4a8e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0cf52949-279c-4674-bf48-8df5e746f617
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0404bd23-c4d5-41ba-ad7b-4fc9f5ee5f2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5f717e6-abad-4aab-b79a-c8a7b6f4a113
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a2df950-3ad2-4aa1-8b9c-70a1132a717b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93595cb2-4670-487d-9b27-8e18b27ae57b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d481ab4-9ccf-43f3-a5ac-5b426c8989f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5978191-1774-49a1-a93d-2b408f68877c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b7c3109-db75-44c3-a25c-406251b320d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe16ca2e-dc49-4bd9-b5b7-abd5c6a6673b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c66f5d7-34e6-41e4-bc2c-8d2c0295cee6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f276f35-a1f2-4b63-9e76-26e6a7e444c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c195db71-c579-45d9-b398-f371bf2050b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7b59409-2164-4e99-a907-a3fd3806a1ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bbccc95-ef71-465a-9ce0-0c7d5c28762c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dab436a1-ba54-46db-a94b-aec690c6130c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84aba280-7e5c-422c-b083-82d46c588b4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c30578f-a58b-49e2-bde8-f4274e3a8b12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9b5a07c-12ad-4105-bc55-513285c21548
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6fcc1ca-ef8f-4bf4-a281-33baa89bedfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6872deaa-2c19-4165-b27c-5dac6d7dc4b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e523063-0881-4bd3-98ef-dfe4d5355c4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f468748-86aa-482e-a76a-c2939f8d0cfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 507cd869-f63f-49bb-86b0-926d050f9227
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e681070-34d4-4516-982e-836e1a82c5b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ddbb2ec-0cc6-4eab-ae83-de2209d7c0c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 514f6aa3-c13d-4d24-85a7-7d1ea58bcfe0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c4917f3-2730-408a-a263-614ceeda4fd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcfdd2c9-660b-47b7-bbd4-67e79b0d01f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5680862d-4db0-46e2-891c-abb58b17b18c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c7c3742-e1cc-4f72-b1dd-2c766ff60bc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f7fdf13-543d-4119-aa6b-62cd0d37a16d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b09e22e-d256-4bfa-9903-13630ef3a101
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf15141a-89bf-4870-8f48-b17434ba8594
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e21ad54-c286-4616-a421-5dc26b82fc9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c63be7cd-39da-4b65-a0cd-b7d1cf0509a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0dafd496-be13-454e-ba60-874249ffde49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25b64473-1783-44bb-ab06-5b0a862608b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1f274bf-41e6-4d8c-a730-2848f1c5cdd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f65341ca-50ee-43ae-bf6f-db102c9c4229
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c58b4acd-724e-42ee-8000-6804e67ef7f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8dad6c41-60c5-4853-916f-60bd9c23b928
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93db3096-7a7c-44ea-8f49-2807b640a3e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9976433-0416-4727-8312-88908ef0b907
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae547a5a-b2a5-4b2a-9258-a26d3a067158
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52bfdb41-4456-40b7-b621-52a140688cc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f10c3f4-9b94-41bc-8066-b42f8f1c4ed5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7a4f298-713f-4e02-b056-b27a23710cd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10a10947-e60a-455a-9ddb-665b7a3798cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e301554-3a71-4a8b-9ebc-f473372f66dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9e5a17d-78a5-402e-9576-f17531164849
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25826049-7777-4d26-84d1-00e0b0322598
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c901514f-a6d6-432a-a81c-9e2937ee0857
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47ec6077-7486-460f-8ad2-3cef1fc6899f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 938beafe-05a1-472d-8209-6e18b408ae4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 184498b0-9c8b-4e66-b2f2-321abd6798d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98893d89-46a4-4c4b-8593-fff35fd44d33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8940ee3e-b710-4c83-9f0d-045738e415f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6ec2803-6d69-4046-84ae-6e8bddb37d0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6401dad9-907d-4019-b4aa-b1969b03e8f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41ebbfea-597e-4a42-9d5d-c50fd67aeeed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17b254ef-95eb-443b-93cb-1ea67eebdc9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e9748a7-0f33-48be-832b-c0793386200b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 357daede-87e3-4973-a00b-9cb51e736d3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27773fc4-4fc6-4cc8-b97d-f49f2da6ccc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7e1ce01-e455-49a2-bed2-d4f6331eb7c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9018626-4375-40b3-bf42-bb14895d1f22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d9c4cdf-ea74-400e-9823-e2f70387e255
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 088a8652-49ed-4974-bcaf-3e42189e6a72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c2c3933-6e1a-4cef-be39-8be57595581b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9759a339-97c4-485e-83f2-a2684d7afd3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 420ea874-7df5-4b77-bbe0-5d27b6b9d09f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d114631-3f59-4510-9aa8-1219b2d53eda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e4b9603-ed3a-46a9-a2ea-24ecf6ef5f45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45baf55f-0e52-443f-bd8e-45bd92ba4f5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d47c5765-34b0-45e3-92fc-148c8d0f73ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd83908d-7333-4448-b761-b2332fb6dbb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5bb00ec-cf73-49ac-b5e9-99609905cda0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8af191e9-81c7-4f3b-a306-1eea7cc7b7ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f28a2d5-b392-4632-bc00-4b0a1da3db4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11ad855f-e78b-4dc7-a89c-229049fd6072
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a66609bf-db5e-42bd-a513-ab30762f8d43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c42eff80-3108-4d9e-a447-9b36d7ca35e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 490f566e-8d79-496c-b6c0-94b22c6ad907
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 243990e0-5c6f-4595-a242-5c38afef2036
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68077a62-0e75-47ed-a2cf-a1692a990ad1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa7b6dfd-0764-4a0b-985f-171a9519404a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f7ba34a-1dd3-4fc8-9377-272443623f29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e751d1d6-be47-4571-b4bd-cb436f16256b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e20ea2f1-52eb-4948-a8d7-1890aae6a918
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f617efb9-f2ce-48c8-8ca8-9e66a5a75211
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c8d9762-4a56-47bf-8dd3-46908f2e5c00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa923809-9a18-4c20-8138-bb376eed4a1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cf06d34-a1e0-4bd7-928c-5560ab3a3151
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1310c0df-09e9-4772-9700-29f668bd4970
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a2e0b0d-8c15-470f-8c02-cd940dd3dbe1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message daca329d-140e-485c-9c31-9842ea825fb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d5b38f8-d068-4735-b830-1d4d3a6545e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84ef0ea7-5d34-485b-b29f-9588138d9f49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b471a2c0-296b-42c8-adb1-c750c4e3d3cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0963efdf-a4f1-4fd5-801b-0736002edd9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28b505a2-7309-442b-89e4-513029f30166
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80db9729-bec9-46cc-aa7c-66ef4e965277
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42f05d4b-87c8-436b-9f2e-12cec2cb958f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfb7b2a2-bdc4-444f-bf3c-225e29759297
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3713a5d8-f797-4e52-9fff-67553dd6f8ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 831321ed-2be0-42e1-9390-1829abb0588f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72c035dd-8f7f-49fa-a8b4-1e91ed58f7a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4dd9bad6-9e98-46d8-baac-24f08cd3212b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44da44bc-4c88-4fea-b051-e9db16ff7b5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f5ced42-4ddc-41f9-a2f0-4a7da40e3eb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88cd45fb-7fd9-4e4d-ba0d-913c388968fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ec32186-aa1c-4d54-9376-75b39745c27b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b10f6224-b605-49bb-b286-4aa9f9cad8bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1648fae4-983b-4492-8a94-ecec2ad0c442
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f2469c3-a044-44a5-a427-b1da6e1cfd0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 459536fb-eda9-4611-89f8-f60a5edac774
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1467dfc-8f38-4dce-98e4-6a3073561d6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f604026-c46a-475f-9ef2-a3e729b13ef8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 292dc963-6a81-4da9-b92b-aa64f92bbc2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ec4d6b8-e4e4-4fd6-8e24-b5cd810f1b54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee27a635-1a69-4f57-83d3-02d867fc1174
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d0e5251-264c-48d9-bfed-926046839290
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae2e4338-218b-44c3-89c6-c230afb27143
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebe99252-a48f-4300-b305-b273892ed940
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d3b5cd1-0a62-42c6-acb1-69eaede693b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24333e56-f3a3-45a4-8473-71714917299e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b62b4e10-eb93-4dbc-a9c1-4d8b1710befb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3dba28c-7c62-4999-8fb9-74fbe1aa1063
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8ae4f0e-527b-4cb9-8900-513dc02ac856
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c736b49e-35be-4125-bf61-da74c4c3a625
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3749a70-d055-4b11-b56f-7da971f23eea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39085ec3-5929-40c0-a423-6ccfa85a20e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d541ac48-fdb1-4699-8a8d-c48c950eb7dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 335f549a-47b4-427c-a3b6-99d29bdc28a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77854d32-c308-4b18-b46c-14aa8d935c3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b54bfb59-d2ef-44d8-bde0-9bd9f9d5a97c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c48d0b0b-9ed2-4e98-abb4-8921f9aef60d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c583fa46-bf32-4c53-bd6e-ce28135c8268
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d1d4fdb-1e55-467e-80d9-471531b5378e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95d4c652-a276-41af-964a-008b889e45b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83370fb2-89cb-4322-94a3-d96f93b9ccb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65a8ab3b-67a2-4ed6-a068-363443e22610
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4f01ef4-cf09-494c-945e-71ce71580526
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27724638-5b74-42d1-8e0c-c6f11086ec91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7df75a43-8cb1-440d-8f72-1d9c2b1fa850
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46d035ef-6e50-4603-aa63-1441b843e477
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e4316ef-c1de-42cb-a7d8-d2e28c8d79eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f824153-3a9c-4932-a485-6212ca8b9382
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a3156d5-e004-434d-b6b6-dad093510347
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37687e7a-e6f3-426e-85e0-2183afa17f21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8cb8b007-b45f-42bb-8c25-0e1404d3a837
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd43e004-e247-408c-87f0-646f6cc37905
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca23a71f-1c2f-4e64-bfa6-6f8d6f89cc95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65eb6540-ba2f-4297-8f83-652eb533b0fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2755000c-b832-4829-b1f7-80bc90d1beab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e0a2668-4741-45a6-9e16-7a6080953b26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b615cad0-342a-486a-909e-6ab70bc8f22c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45ba26b5-6f85-468a-a38c-9adc4f0dab4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e30b526-3569-4048-89c7-15838482e091
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b5aff32-56a1-49da-acc1-60c0204db9b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cadd93c3-2560-424f-be3f-c0f4bfb63dd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1dac43e0-fc9c-4223-88b6-ea946eef88ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3d25856-38c8-4ab4-b71f-378d396501c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 249e6809-7e9f-4eaa-9f65-397de2374e09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b832f5ad-12ae-4441-b833-950985b3383b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76250d0f-4f15-4c12-a9a7-0ebdeab48686
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b074ab0b-f67d-44f9-aea5-6c5176a967a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b819c1bf-4f09-43ee-9383-6bf1229aaf20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb7293f0-7ed6-4ebb-83b4-5e1811182ae0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5eef5cad-d72f-40a5-8b2b-bdb4fdd6fc86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03371cfa-d634-4c02-b22d-67fce36dea61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bdf3311-dc00-4f91-b234-6a4a2308bc8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98171920-f08c-4773-ab80-3534a0c52914
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba84f1fd-d283-4e08-aeef-68df32b84bb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9bb29b9f-bee7-4c92-b6bc-93fc483917f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd2ff734-0aaa-43ac-bad6-2f121911faa5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc4136a6-eee7-4e90-a3c2-2e5c9f37492c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8acf5d38-d5cc-406f-8274-e58a3b0876c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec32f486-9f9c-4faf-bd3b-6886b85f22f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aae41289-e025-461f-b5df-cdbcbb77955d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2baf6371-d0dc-4f67-88b4-06fc45ee6325
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edb84adb-98c7-4ca6-aa9a-ebe226b007eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99e4e86a-9f81-4d8d-9e40-c1e56b31d02f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aee96fdb-9838-4ed4-8010-242643fee627
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6534229f-897b-474d-a04d-3796047a37d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e49c5b9e-f4df-4e44-a645-9bbc47384119
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78158881-0c5f-40ae-85b6-a6d84ffe6d8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1c7d984-debc-4311-9e0f-ca6201bd971d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b4ca059-3313-4d43-b4bb-7b75cd2924a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38b6642e-fd43-4af3-9e9e-3980a871a1f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e09ef0b-0a84-428c-8790-81bee17624a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7462e0a-20fb-49a6-a0d0-f7a51a612c5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a32ae7cd-6633-4d78-ac4a-bfe19d099883
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe7177d9-8c41-454d-96e5-8b55f32ea99c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d35610a-ae48-4c4c-a42a-e2b29f7699c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0dc8fa5f-3b21-4199-be86-7ca6694df858
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 619c2106-3fee-43f2-aac0-1623ae0d56c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7eba146d-fcdd-4e50-baa7-b4e82fcada1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51a1da8f-9eba-4b80-9ab9-5b251d9670d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a74f616-bf32-41a5-b579-817c3d96cfcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 427cb6bf-17d8-4bf3-a994-cdc1eedc6b8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51192ee6-fad4-4dda-84fc-3409c655ea74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81a53278-e4cd-4217-889d-bd5570bf38b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a7c850b-d303-4975-b212-4ad37c99016e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b841729-de7f-4423-8462-045c7682cd69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d8bb819-ac7f-4347-9d87-13c661767866
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fa18a0a-3c9d-4f3d-beb9-9f415e11b179
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6f4278e-38cb-42c8-a8bf-0d03ab3b029f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b39fc76a-718e-42ab-9f68-5574e7613fd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d0223d7-b8fc-4451-80c5-e170ae7fe3fc
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_12
Server: localhost:8688
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_12
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_12/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_12/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_12/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_12/test_labels.txt

📊 Raw data loaded:
   Train: X=(5148, 24), y=(5148,)
   Test:  X=(1287, 24), y=(1287,)

⚠️  Limiting training data: 5148 → 800 samples
⚠️  Limiting test data: 1287 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_12 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2520, R²: -0.0069

============================================================
🔄 Round 4 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0989, val=0.0753 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0856, val=0.0747 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0859, val=0.0742 (↓), lr=0.001000
   • Epoch   4/100: train=0.0856, val=0.0742, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0856, val=0.0740, patience=2/15, lr=0.001000
   • Epoch  11/100: train=0.0854, val=0.0736, patience=1/15, lr=0.001000
   • Epoch  21/100: train=0.0842, val=0.0730, patience=1/15, lr=0.001000
   📉 Epoch 31: LR reduced 0.001000 → 0.000500
   • Epoch  31/100: train=0.0772, val=0.0749, patience=6/15, lr=0.000500
   📉 Epoch 39: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 4 Summary - Client client_12
   Epochs: 40/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0522
   Val:   Loss=0.0725, RMSE=0.2693, R²=0.0222
============================================================


============================================================
🔄 Round 5 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0936 (↓), lr=0.000250
   • Epoch   2/100: train=0.0809, val=0.0934, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0808, val=0.0939, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0804, val=0.0936, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0804, val=0.0936, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0801, val=0.0936, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 5 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0014
   Val:   Loss=0.0936, RMSE=0.3060, R²=0.0066
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.1098, RMSE: 0.3314, MAE: 0.2734, R²: -0.3219

📊 Round 5 Test Metrics:
   Loss: 0.0852, RMSE: 0.2918, MAE: 0.2528, R²: -0.0250

📊 Round 5 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2539, R²: -0.0103

============================================================
🔄 Round 9 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0908 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.0827, val=0.0887 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.0816, val=0.0880 (↓), lr=0.000063
   • Epoch   4/100: train=0.0812, val=0.0877, patience=1/15, lr=0.000063
   • Epoch   5/100: train=0.0811, val=0.0876, patience=2/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   ✓ Epoch  11/100: train=0.0808, val=0.0874 (↓), lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0807, val=0.0874, patience=10/15, lr=0.000016
   📉 Epoch 23: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 9 Summary - Client client_12
   Epochs: 26/100 (early stopped)
   LR: 0.000063 → 0.000008 (3 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0191
   Val:   Loss=0.0874, RMSE=0.2957, R²=0.0043
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2506, R²: 0.0103

============================================================
🔄 Round 17 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0844 (↓), lr=0.000008
   • Epoch   2/100: train=0.0820, val=0.0844, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0820, val=0.0844, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0820, val=0.0843, patience=3/15, lr=0.000008
   📉 Epoch 5: LR reduced 0.000008 → 0.000004
   • Epoch   5/100: train=0.0820, val=0.0843, patience=4/15, lr=0.000004
   • Epoch  11/100: train=0.0819, val=0.0843, patience=10/15, lr=0.000004
   📉 Epoch 13: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 17 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0103
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0166
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2507, R²: 0.0103

============================================================
🔄 Round 20 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0763 (↓), lr=0.000002
   • Epoch   2/100: train=0.0845, val=0.0763, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0845, val=0.0763, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0845, val=0.0763, patience=3/15, lr=0.000002
   📉 Epoch 5: LR reduced 0.000002 → 0.000001
   • Epoch   5/100: train=0.0845, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 20 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=0.0021
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0415
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2511, R²: 0.0090

📊 Round 20 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2511, R²: 0.0091

============================================================
🔄 Round 23 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 23 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0037
   Val:   Loss=0.0904, RMSE=0.3007, R²=0.0114
============================================================


============================================================
🔄 Round 24 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 24 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0165
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0187
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2510, R²: 0.0094

============================================================
🔄 Round 27 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 27 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0191
   Val:   Loss=0.0885, RMSE=0.2976, R²=-0.0267
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2508, R²: 0.0100

============================================================
🔄 Round 31 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 31 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0101
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0067
============================================================


============================================================
🔄 Round 33 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 33 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0058
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0257
============================================================


============================================================
🔄 Round 35 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 35 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0110
   Val:   Loss=0.0877, RMSE=0.2962, R²=0.0097
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2507, R²: 0.0103

============================================================
🔄 Round 36 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 36 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0050
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0723
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2506, R²: 0.0104

📊 Round 36 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2506, R²: 0.0104

============================================================
🔄 Round 41 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 41 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0246
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0627
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2506, R²: 0.0105

📊 Round 41 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2506, R²: 0.0105

============================================================
🔄 Round 43 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 43 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0049
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0352
============================================================


============================================================
🔄 Round 44 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 44 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0067
   Val:   Loss=0.0747, RMSE=0.2734, R²=0.0297
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2505, R²: 0.0105

📊 Round 44 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2505, R²: 0.0105

============================================================
🔄 Round 48 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 48 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0080
   Val:   Loss=0.0790, RMSE=0.2810, R²=0.0019
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2505, R²: 0.0105

============================================================
🔄 Round 50 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 50 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=0.0051
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0372
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2505, R²: 0.0105

============================================================
🔄 Round 51 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 51 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0158
   Val:   Loss=0.0898, RMSE=0.2997, R²=-0.0158
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2505, R²: 0.0104

============================================================
🔄 Round 53 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 53 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0015
   Val:   Loss=0.0769, RMSE=0.2774, R²=0.0398
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2505, R²: 0.0104

============================================================
🔄 Round 54 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 54 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0115
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0032
============================================================


============================================================
🔄 Round 55 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 55 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0072
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0163
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2505, R²: 0.0104

============================================================
🔄 Round 58 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0935 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0935, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0935, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 58 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0064
   Val:   Loss=0.0935, RMSE=0.3057, R²=0.0119
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2504, R²: 0.0104

============================================================
🔄 Round 60 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 60 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0164
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0190
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2504, R²: 0.0104

============================================================
🔄 Round 61 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 61 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0170
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0106
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2504, R²: 0.0104

📊 Round 61 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2504, R²: 0.0104

============================================================
🔄 Round 63 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 63 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0118
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0088
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2504, R²: 0.0104

📊 Round 63 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2504, R²: 0.0103

📊 Round 63 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2504, R²: 0.0103

============================================================
🔄 Round 70 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 70 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0009
   Val:   Loss=0.0848, RMSE=0.2911, R²=0.0447
============================================================


============================================================
🔄 Round 71 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 71 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0131
   Val:   Loss=0.0779, RMSE=0.2792, R²=0.0016
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2504, R²: 0.0103

============================================================
🔄 Round 73 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0973 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0973, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0973, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0973, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0973, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0973, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0973)

============================================================
📊 Round 73 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2810, R²=0.0143
   Val:   Loss=0.0973, RMSE=0.3120, R²=0.0001
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2504, R²: 0.0103

📊 Round 73 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2504, R²: 0.0103

============================================================
🔄 Round 78 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 78 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0062
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0215
============================================================


============================================================
🔄 Round 79 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 79 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0070
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0275
============================================================


============================================================
🔄 Round 80 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 80 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0034
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0414
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2504, R²: 0.0104

============================================================
🔄 Round 81 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 81 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0135
   Val:   Loss=0.0752, RMSE=0.2742, R²=-0.0005
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2504, R²: 0.0104

📊 Round 81 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2504, R²: 0.0104

============================================================
🔄 Round 86 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 86 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0069
   Val:   Loss=0.0867, RMSE=0.2945, R²=0.0036
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2504, R²: 0.0104

📊 Round 86 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2504, R²: 0.0104

============================================================
🔄 Round 90 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 90 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0076
   Val:   Loss=0.0753, RMSE=0.2745, R²=0.0219
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2504, R²: 0.0104

📊 Round 90 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2504, R²: 0.0104

📊 Round 90 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2504, R²: 0.0104

============================================================
🔄 Round 94 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 94 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0095
   Val:   Loss=0.0892, RMSE=0.2986, R²=0.0122
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2504, R²: 0.0103

============================================================
🔄 Round 100 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 100 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0163
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0666
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2503, R²: 0.0103

============================================================
🔄 Round 104 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 104 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0180
   Val:   Loss=0.0768, RMSE=0.2770, R²=-0.0210
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2503, R²: 0.0103

📊 Round 104 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2503, R²: 0.0103

📊 Round 104 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2503, R²: 0.0103

============================================================
🔄 Round 108 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 108 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0131
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0026
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2503, R²: 0.0103

📊 Round 108 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2503, R²: 0.0103

============================================================
🔄 Round 110 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 110 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=0.0037
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0324
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2503, R²: 0.0103

============================================================
🔄 Round 111 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 111 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0075
   Val:   Loss=0.0855, RMSE=0.2923, R²=0.0218
============================================================


============================================================
🔄 Round 112 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 112 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0124
   Val:   Loss=0.0880, RMSE=0.2966, R²=0.0058
============================================================


============================================================
🔄 Round 113 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 113 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0134
   Val:   Loss=0.0727, RMSE=0.2697, R²=-0.0009
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2503, R²: 0.0104

📊 Round 113 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2503, R²: 0.0104

📊 Round 113 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2503, R²: 0.0104

============================================================
🔄 Round 119 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 119 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0154
   Val:   Loss=0.0734, RMSE=0.2710, R²=-0.0182
============================================================


============================================================
🔄 Round 120 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 120 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0086
   Val:   Loss=0.0844, RMSE=0.2906, R²=0.0069
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2503, R²: 0.0103

📊 Round 120 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2503, R²: 0.0103

============================================================
🔄 Round 122 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 122 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0180
   Val:   Loss=0.0779, RMSE=0.2792, R²=-0.0437
============================================================


============================================================
🔄 Round 125 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 125 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0132
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0015
============================================================


============================================================
🔄 Round 127 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 127 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0154
   Val:   Loss=0.0794, RMSE=0.2817, R²=-0.0075
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2503, R²: 0.0104

============================================================
🔄 Round 129 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 129 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0183
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0180
============================================================


============================================================
🔄 Round 130 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 130 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0101
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0070
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2503, R²: 0.0105

============================================================
🔄 Round 132 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 132 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0052
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0333
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2503, R²: 0.0105

============================================================
🔄 Round 133 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 133 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0052
   Val:   Loss=0.0910, RMSE=0.3016, R²=0.0299
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2503, R²: 0.0105

============================================================
🔄 Round 134 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 134 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0131
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0120
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2503, R²: 0.0105

📊 Round 134 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2503, R²: 0.0105

📊 Round 134 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2503, R²: 0.0105

============================================================
🔄 Round 137 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 137 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0175
   Val:   Loss=0.0915, RMSE=0.3025, R²=-0.0149
============================================================


============================================================
🔄 Round 139 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 139 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0101
   Val:   Loss=0.0797, RMSE=0.2822, R²=0.0152
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2503, R²: 0.0106

============================================================
🔄 Round 141 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 141 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0141
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0010
============================================================


============================================================
🔄 Round 142 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 142 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0129
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0010
============================================================


============================================================
🔄 Round 144 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 144 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0099
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0033
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2503, R²: 0.0106

============================================================
🔄 Round 146 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 146 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0038
   Val:   Loss=0.0810, RMSE=0.2845, R²=0.0374
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2503, R²: 0.0106

============================================================
🔄 Round 148 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 148 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0108
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0097
============================================================


============================================================
🔄 Round 149 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 149 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0092
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0193
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2503, R²: 0.0107

📊 Round 149 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2503, R²: 0.0107

============================================================
🔄 Round 152 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 152 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0120
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0007
============================================================


============================================================
🔄 Round 153 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 153 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0144
   Val:   Loss=0.0749, RMSE=0.2737, R²=-0.0151
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2503, R²: 0.0108

============================================================
🔄 Round 156 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 156 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0125
   Val:   Loss=0.0713, RMSE=0.2670, R²=0.0040
============================================================


============================================================
🔄 Round 159 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 159 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0145
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0085
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2503, R²: 0.0109

📊 Round 159 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2503, R²: 0.0109

📊 Round 159 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2503, R²: 0.0109

============================================================
🔄 Round 163 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 163 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0068
   Val:   Loss=0.0842, RMSE=0.2901, R²=0.0246
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2503, R²: 0.0109

============================================================
🔄 Round 165 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 165 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0095
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0160
============================================================


============================================================
🔄 Round 166 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 166 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0195
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0577
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2503, R²: 0.0109

============================================================
🔄 Round 168 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 168 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0149
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0186
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2503, R²: 0.0110

============================================================
🔄 Round 169 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 169 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0114
   Val:   Loss=0.0886, RMSE=0.2976, R²=0.0111
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2503, R²: 0.0110

============================================================
🔄 Round 173 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 173 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0094
   Val:   Loss=0.0862, RMSE=0.2937, R²=0.0169
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2503, R²: 0.0109

📊 Round 173 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2503, R²: 0.0109

📊 Round 173 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2503, R²: 0.0109

============================================================
🔄 Round 176 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 176 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0109
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0121
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2503, R²: 0.0109

============================================================
🔄 Round 177 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 177 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0114
   Val:   Loss=0.0932, RMSE=0.3053, R²=0.0109
============================================================


============================================================
🔄 Round 178 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 178 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0093
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0037
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2503, R²: 0.0110

📊 Round 178 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2503, R²: 0.0110

============================================================
🔄 Round 181 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 181 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0066
   Val:   Loss=0.0790, RMSE=0.2810, R²=0.0270
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2503, R²: 0.0110

📊 Round 181 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2503, R²: 0.0110

============================================================
🔄 Round 183 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 183 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0143
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0066
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2503, R²: 0.0110

============================================================
🔄 Round 184 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0685 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0685, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0685, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0685, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0685, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0685, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0685)

============================================================
📊 Round 184 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0060
   Val:   Loss=0.0685, RMSE=0.2618, R²=0.0112
============================================================


============================================================
🔄 Round 187 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 187 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0110
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0081
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2503, R²: 0.0111

============================================================
🔄 Round 188 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 188 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0145
   Val:   Loss=0.0756, RMSE=0.2749, R²=-0.0028
============================================================


============================================================
🔄 Round 189 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 189 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0139
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0199
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2503, R²: 0.0111

📊 Round 189 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2503, R²: 0.0111

============================================================
🔄 Round 194 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 194 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0172
   Val:   Loss=0.0826, RMSE=0.2873, R²=-0.0184
============================================================


============================================================
🔄 Round 195 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 195 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0021
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0465
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2502, R²: 0.0111

============================================================
🔄 Round 197 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 197 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0066
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0249
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2502, R²: 0.0111

📊 Round 197 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2502, R²: 0.0112

============================================================
🔄 Round 200 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 200 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0076
   Val:   Loss=0.0882, RMSE=0.2970, R²=0.0217
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2502, R²: 0.0112

============================================================
🔄 Round 201 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 201 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0073
   Val:   Loss=0.0896, RMSE=0.2993, R²=0.0262
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2502, R²: 0.0112

📊 Round 201 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2502, R²: 0.0112

============================================================
🔄 Round 204 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 204 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0169
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0221
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2502, R²: 0.0112

📊 Round 204 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2502, R²: 0.0112

============================================================
🔄 Round 206 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 206 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0134
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0013
============================================================


============================================================
🔄 Round 207 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 207 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0158
   Val:   Loss=0.0802, RMSE=0.2833, R²=-0.0090
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2502, R²: 0.0113

📊 Round 207 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2502, R²: 0.0113

📊 Round 207 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2502, R²: 0.0113

📊 Round 207 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2502, R²: 0.0113

============================================================
🔄 Round 211 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 211 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0025
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0472
============================================================


📊 Round 211 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2502, R²: 0.0114

📊 Round 211 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2502, R²: 0.0114

============================================================
🔄 Round 213 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 213 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0131
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0272
============================================================


📊 Round 213 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2502, R²: 0.0115

============================================================
🔄 Round 216 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 216 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0116
   Val:   Loss=0.0847, RMSE=0.2911, R²=0.0047
============================================================


📊 Round 216 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2502, R²: 0.0115

============================================================
🔄 Round 217 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 217 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0155
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0175
============================================================


📊 Round 217 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2502, R²: 0.0115

============================================================
🔄 Round 218 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 218 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0089
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0198
============================================================


📊 Round 218 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2502, R²: 0.0115

📊 Round 218 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2502, R²: 0.0115

============================================================
🔄 Round 220 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 220 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0119
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0087
============================================================


============================================================
🔄 Round 221 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 221 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0160
   Val:   Loss=0.0888, RMSE=0.2979, R²=-0.0121
============================================================


📊 Round 221 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2502, R²: 0.0115

============================================================
🔄 Round 222 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 222 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0122
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0046
============================================================


📊 Round 222 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2502, R²: 0.0115

📊 Round 222 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2502, R²: 0.0115

📊 Round 222 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2502, R²: 0.0115

============================================================
🔄 Round 226 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 226 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0174
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0143
============================================================


📊 Round 226 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2502, R²: 0.0116

📊 Round 226 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2502, R²: 0.0116

============================================================
🔄 Round 228 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 228 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0163
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0186
============================================================


============================================================
🔄 Round 229 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 229 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0113
   Val:   Loss=0.0888, RMSE=0.2980, R²=0.0124
============================================================


============================================================
🔄 Round 230 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 230 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0055
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0368
============================================================


📊 Round 230 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2502, R²: 0.0116

============================================================
🔄 Round 232 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 232 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0068
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0284
============================================================


============================================================
🔄 Round 234 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 234 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0159
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0099
============================================================


📊 Round 234 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2502, R²: 0.0116

============================================================
🔄 Round 237 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 237 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0106
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0039
============================================================


📊 Round 237 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2502, R²: 0.0116

============================================================
🔄 Round 238 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 238 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0176
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0110
============================================================


============================================================
🔄 Round 239 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 239 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0143
   Val:   Loss=0.0743, RMSE=0.2725, R²=-0.0063
============================================================


============================================================
🔄 Round 240 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 240 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0065
   Val:   Loss=0.0705, RMSE=0.2655, R²=0.0036
============================================================


📊 Round 240 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2502, R²: 0.0116

============================================================
🔄 Round 241 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 241 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0139
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0078
============================================================


📊 Round 241 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2502, R²: 0.0116

============================================================
🔄 Round 242 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 242 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0048
   Val:   Loss=0.0883, RMSE=0.2971, R²=0.0347
============================================================


📊 Round 242 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2502, R²: 0.0116

📊 Round 242 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2502, R²: 0.0116

📊 Round 242 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2502, R²: 0.0116

============================================================
🔄 Round 247 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 247 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0134
   Val:   Loss=0.0789, RMSE=0.2808, R²=0.0040
============================================================


📊 Round 247 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2502, R²: 0.0116

============================================================
🔄 Round 248 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 248 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0059
   Val:   Loss=0.0817, RMSE=0.2857, R²=0.0142
============================================================


📊 Round 248 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2502, R²: 0.0116

============================================================
🔄 Round 252 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 252 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0068
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0188
============================================================


============================================================
🔄 Round 253 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 253 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0128
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0069
============================================================


📊 Round 253 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2502, R²: 0.0117

📊 Round 253 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2502, R²: 0.0117

📊 Round 253 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2502, R²: 0.0117

============================================================
🔄 Round 257 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 257 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0182
   Val:   Loss=0.0744, RMSE=0.2728, R²=-0.0195
============================================================


============================================================
🔄 Round 258 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 258 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0107
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0144
============================================================


📊 Round 258 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2502, R²: 0.0117

============================================================
🔄 Round 259 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 259 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0015
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0498
============================================================


============================================================
🔄 Round 262 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 262 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0034
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0427
============================================================


============================================================
🔄 Round 263 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 263 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0062
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0282
============================================================


📊 Round 263 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2502, R²: 0.0118

📊 Round 263 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2502, R²: 0.0118

============================================================
🔄 Round 267 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 267 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0097
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0137
============================================================


📊 Round 267 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2502, R²: 0.0117

📊 Round 267 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2502, R²: 0.0118

📊 Round 267 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2502, R²: 0.0118

📊 Round 267 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2502, R²: 0.0118

============================================================
🔄 Round 275 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 275 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0147
   Val:   Loss=0.0773, RMSE=0.2779, R²=-0.0017
============================================================


📊 Round 275 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2502, R²: 0.0118

============================================================
🔄 Round 276 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 276 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0125
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0081
============================================================


============================================================
🔄 Round 277 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 277 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0056
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0286
============================================================


📊 Round 277 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2502, R²: 0.0118

📊 Round 277 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2502, R²: 0.0118

📊 Round 277 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2502, R²: 0.0117

============================================================
🔄 Round 285 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 285 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0121
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0104
============================================================


📊 Round 285 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2502, R²: 0.0117

============================================================
🔄 Round 288 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 288 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0083
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0260
============================================================


============================================================
🔄 Round 291 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 291 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0096
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0205
============================================================


📊 Round 291 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2502, R²: 0.0118

📊 Round 291 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2502, R²: 0.0118

📊 Round 291 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2502, R²: 0.0118

============================================================
🔄 Round 295 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 295 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0088
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0021
============================================================


📊 Round 295 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2502, R²: 0.0119

============================================================
🔄 Round 297 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 297 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0037
   Val:   Loss=0.0884, RMSE=0.2973, R²=0.0400
============================================================


📊 Round 297 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2502, R²: 0.0119

============================================================
🔄 Round 298 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 298 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0102
   Val:   Loss=0.0715, RMSE=0.2675, R²=0.0137
============================================================


📊 Round 298 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2502, R²: 0.0119

============================================================
🔄 Round 299 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 299 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0061
   Val:   Loss=0.0927, RMSE=0.3045, R²=0.0315
============================================================


============================================================
🔄 Round 300 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 300 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0164
   Val:   Loss=0.0930, RMSE=0.3050, R²=-0.0039
============================================================


📊 Round 300 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2502, R²: 0.0119

📊 Round 300 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2502, R²: 0.0119

============================================================
🔄 Round 302 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 302 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0129
   Val:   Loss=0.0864, RMSE=0.2940, R²=0.0084
============================================================


📊 Round 302 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2502, R²: 0.0120

📊 Round 302 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2502, R²: 0.0120

============================================================
🔄 Round 308 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 308 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0169
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0074
============================================================


📊 Round 308 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2502, R²: 0.0121

📊 Round 308 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2502, R²: 0.0121

============================================================
🔄 Round 314 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 314 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0144
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0193
============================================================


📊 Round 314 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2502, R²: 0.0121

============================================================
🔄 Round 320 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 320 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0201
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0194
============================================================


📊 Round 320 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2502, R²: 0.0121

============================================================
🔄 Round 323 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 323 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=0.0070
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0147
============================================================


============================================================
🔄 Round 324 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 324 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0107
   Val:   Loss=0.0873, RMSE=0.2955, R²=0.0050
============================================================


============================================================
🔄 Round 325 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 325 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0089
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0085
============================================================


📊 Round 325 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2502, R²: 0.0122

============================================================
🔄 Round 326 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 326 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0066
   Val:   Loss=0.0859, RMSE=0.2930, R²=0.0287
============================================================


============================================================
🔄 Round 327 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 327 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0128
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0271
============================================================


============================================================
🔄 Round 330 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 330 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0130
   Val:   Loss=0.0798, RMSE=0.2824, R²=0.0044
============================================================


📊 Round 330 Test Metrics:
   Loss: 0.0821, RMSE: 0.2864, MAE: 0.2502, R²: 0.0123

============================================================
🔄 Round 332 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 332 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0089
   Val:   Loss=0.0841, RMSE=0.2899, R²=0.0138
============================================================


📊 Round 332 Test Metrics:
   Loss: 0.0821, RMSE: 0.2864, MAE: 0.2502, R²: 0.0123

============================================================
🔄 Round 333 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 333 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=0.0146
   Val:   Loss=0.0881, RMSE=0.2968, R²=0.0024
============================================================


📊 Round 333 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: 0.0123

📊 Round 333 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: 0.0123

============================================================
🔄 Round 337 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 337 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0165
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0124
============================================================


📊 Round 337 Test Metrics:
   Loss: 0.0821, RMSE: 0.2864, MAE: 0.2501, R²: 0.0123

📊 Round 337 Test Metrics:
   Loss: 0.0821, RMSE: 0.2864, MAE: 0.2501, R²: 0.0123

📊 Round 337 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2501, R²: 0.0123

============================================================
🔄 Round 343 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 343 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0133
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0048
============================================================


📊 Round 343 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2501, R²: 0.0122

============================================================
🔄 Round 346 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 346 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0075
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0320
============================================================


📊 Round 346 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2501, R²: 0.0122

📊 Round 346 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2501, R²: 0.0122

============================================================
🔄 Round 349 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 349 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0152
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0266
============================================================


============================================================
🔄 Round 351 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 351 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0156
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0043
============================================================


📊 Round 351 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2501, R²: 0.0122

📊 Round 351 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2501, R²: 0.0122

============================================================
🔄 Round 356 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 356 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0028
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0486
============================================================


📊 Round 356 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2501, R²: 0.0122

============================================================
🔄 Round 358 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 358 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0097
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0082
============================================================


============================================================
🔄 Round 359 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 359 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0061
   Val:   Loss=0.0896, RMSE=0.2994, R²=0.0148
============================================================


📊 Round 359 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2501, R²: 0.0122

📊 Round 359 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2501, R²: 0.0122

============================================================
🔄 Round 365 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 365 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=0.0138
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0042
============================================================


============================================================
🔄 Round 366 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 366 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0115
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0002
============================================================


📊 Round 366 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2501, R²: 0.0122

============================================================
🔄 Round 367 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 367 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0162
   Val:   Loss=0.0798, RMSE=0.2824, R²=-0.0070
============================================================


============================================================
🔄 Round 368 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 368 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0184
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0353
============================================================


============================================================
🔄 Round 369 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 369 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0159
   Val:   Loss=0.0814, RMSE=0.2854, R²=-0.0147
============================================================


📊 Round 369 Test Metrics:
   Loss: 0.0821, RMSE: 0.2864, MAE: 0.2501, R²: 0.0123

📊 Round 369 Test Metrics:
   Loss: 0.0821, RMSE: 0.2864, MAE: 0.2501, R²: 0.0123

============================================================
🔄 Round 375 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 375 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0139
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0030
============================================================


📊 Round 375 Test Metrics:
   Loss: 0.0821, RMSE: 0.2864, MAE: 0.2501, R²: 0.0123

📊 Round 375 Test Metrics:
   Loss: 0.0821, RMSE: 0.2864, MAE: 0.2501, R²: 0.0123

📊 Round 375 Test Metrics:
   Loss: 0.0821, RMSE: 0.2864, MAE: 0.2501, R²: 0.0123

============================================================
🔄 Round 382 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 382 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0234
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0364
============================================================


📊 Round 382 Test Metrics:
   Loss: 0.0821, RMSE: 0.2864, MAE: 0.2501, R²: 0.0123

============================================================
🔄 Round 383 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 383 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0117
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0045
============================================================


============================================================
🔄 Round 388 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 388 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0116
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0134
============================================================


📊 Round 388 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: 0.0123

============================================================
🔄 Round 389 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 389 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0103
   Val:   Loss=0.0855, RMSE=0.2925, R²=0.0190
============================================================


============================================================
🔄 Round 391 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 391 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0142
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0025
============================================================


📊 Round 391 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: 0.0124

============================================================
🔄 Round 393 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 393 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0075
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0219
============================================================


============================================================
🔄 Round 394 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 394 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0117
   Val:   Loss=0.0822, RMSE=0.2866, R²=0.0133
============================================================


📊 Round 394 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: 0.0124

============================================================
🔄 Round 396 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 396 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0169
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0087
============================================================


📊 Round 396 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: 0.0124

============================================================
🔄 Round 397 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 397 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0085
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0260
============================================================


📊 Round 397 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: 0.0124

📊 Round 397 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: 0.0124

📊 Round 397 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: 0.0124

📊 Round 397 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: 0.0124

============================================================
🔄 Round 401 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 401 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0143
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0025
============================================================


📊 Round 401 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: 0.0124

============================================================
🔄 Round 402 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 402 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0150
   Val:   Loss=0.0912, RMSE=0.3020, R²=-0.0109
============================================================


============================================================
🔄 Round 403 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 403 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=0.0117
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0144
============================================================


============================================================
🔄 Round 404 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 404 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0050
   Val:   Loss=0.0871, RMSE=0.2952, R²=0.0332
============================================================


============================================================
🔄 Round 407 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 407 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0150
   Val:   Loss=0.0809, RMSE=0.2843, R²=0.0009
============================================================


📊 Round 407 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: 0.0125

📊 Round 407 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: 0.0125

============================================================
🔄 Round 411 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 411 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0153
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0058
============================================================


📊 Round 411 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: 0.0125

============================================================
🔄 Round 412 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 412 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0131
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0031
============================================================


📊 Round 412 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: 0.0126

============================================================
🔄 Round 414 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 414 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0004
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0588
============================================================


📊 Round 414 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: 0.0126

📊 Round 414 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: 0.0127

📊 Round 414 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: 0.0127

📊 Round 414 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: 0.0127

📊 Round 414 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: 0.0127

📊 Round 414 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: 0.0127

============================================================
🔄 Round 423 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 423 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0192
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0291
============================================================


📊 Round 423 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: 0.0127

📊 Round 423 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: 0.0127

============================================================
🔄 Round 426 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 426 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0134
   Val:   Loss=0.0913, RMSE=0.3021, R²=0.0070
============================================================


📊 Round 426 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: 0.0127

📊 Round 426 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: 0.0127

📊 Round 426 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: 0.0127

============================================================
🔄 Round 431 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 431 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0096
   Val:   Loss=0.0756, RMSE=0.2750, R²=0.0248
============================================================


📊 Round 431 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: 0.0127

📊 Round 431 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: 0.0127

============================================================
🔄 Round 433 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 433 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0125
   Val:   Loss=0.0766, RMSE=0.2767, R²=0.0121
============================================================


📊 Round 433 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: 0.0127

============================================================
🔄 Round 439 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 439 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0129
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0088
============================================================


📊 Round 439 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: 0.0128

📊 Round 439 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: 0.0128

📊 Round 439 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: 0.0128

📊 Round 439 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: 0.0128

============================================================
🔄 Round 443 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 443 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0102
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0130
============================================================


============================================================
🔄 Round 444 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 444 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0125
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0077
============================================================


📊 Round 444 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: 0.0128

============================================================
🔄 Round 445 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 445 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0186
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0131
============================================================


============================================================
🔄 Round 447 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 447 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0195
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0196
============================================================


📊 Round 447 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: 0.0129

============================================================
🔄 Round 450 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 450 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0141
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0060
============================================================


📊 Round 450 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: 0.0130

============================================================
🔄 Round 452 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 452 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0065
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0329
============================================================


============================================================
🔄 Round 453 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 453 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0173
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0082
============================================================


============================================================
🔄 Round 454 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 454 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0132
   Val:   Loss=0.0765, RMSE=0.2765, R²=0.0090
============================================================


📊 Round 454 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2501, R²: 0.0130

📊 Round 454 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2501, R²: 0.0130

📊 Round 454 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2501, R²: 0.0131

============================================================
🔄 Round 459 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 459 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0096
   Val:   Loss=0.0868, RMSE=0.2946, R²=0.0228
============================================================


📊 Round 459 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2501, R²: 0.0131

📊 Round 459 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2501, R²: 0.0131

============================================================
🔄 Round 464 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 464 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0124
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0119
============================================================


📊 Round 464 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2501, R²: 0.0131

📊 Round 464 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2501, R²: 0.0131

============================================================
🔄 Round 466 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 466 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0158
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0086
============================================================


============================================================
🔄 Round 467 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 467 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0115
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0163
============================================================


============================================================
🔄 Round 470 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 470 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0104
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0200
============================================================


============================================================
🔄 Round 471 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 471 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0163
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0023
============================================================


📊 Round 471 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2501, R²: 0.0130

📊 Round 471 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2501, R²: 0.0130

============================================================
🔄 Round 474 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 474 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0015
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0444
============================================================


📊 Round 474 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2501, R²: 0.0130

============================================================
🔄 Round 477 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 477 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0155
   Val:   Loss=0.0814, RMSE=0.2852, R²=-0.0052
============================================================


📊 Round 477 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2501, R²: 0.0131

📊 Round 477 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2501, R²: 0.0131

============================================================
🔄 Round 480 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 480 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0043
   Val:   Loss=0.0797, RMSE=0.2822, R²=0.0377
============================================================


============================================================
🔄 Round 481 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 481 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0111
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0186
============================================================


📊 Round 481 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2501, R²: 0.0131

📊 Round 481 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2501, R²: 0.0131

============================================================
🔄 Round 484 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 484 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0152
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0003
============================================================


📊 Round 484 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2501, R²: 0.0131

============================================================
🔄 Round 485 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 485 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0101
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0234
============================================================


============================================================
🔄 Round 486 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 486 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0102
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0219
============================================================


📊 Round 486 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2501, R²: 0.0131

============================================================
🔄 Round 487 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 487 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0072
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0320
============================================================


📊 Round 487 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2501, R²: 0.0131

📊 Round 487 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2501, R²: 0.0131

============================================================
🔄 Round 489 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 489 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0084
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0183
============================================================


============================================================
🔄 Round 490 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 490 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0067
   Val:   Loss=0.0722, RMSE=0.2687, R²=0.0321
============================================================


📊 Round 490 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2501, R²: 0.0131

============================================================
🔄 Round 494 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 494 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0133
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0067
============================================================


============================================================
🔄 Round 500 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 500 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0116
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0106
============================================================


📊 Round 500 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2501, R²: 0.0131

============================================================
🔄 Round 503 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 503 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0153
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0099
============================================================


📊 Round 503 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2501, R²: 0.0131

============================================================
🔄 Round 504 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 504 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0093
   Val:   Loss=0.0889, RMSE=0.2981, R²=0.0017
============================================================


📊 Round 504 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2501, R²: 0.0131

============================================================
🔄 Round 505 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 505 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0040
   Val:   Loss=0.0911, RMSE=0.3019, R²=0.0184
============================================================


============================================================
🔄 Round 506 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0677 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0677, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0677, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0677, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0677, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0677, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0677)

============================================================
📊 Round 506 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0070
   Val:   Loss=0.0677, RMSE=0.2601, R²=0.0408
============================================================


============================================================
🔄 Round 507 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 507 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0159
   Val:   Loss=0.0862, RMSE=0.2935, R²=-0.0094
============================================================


📊 Round 507 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2501, R²: 0.0131

============================================================
🔄 Round 508 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0978 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0978, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0978, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0978, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0978, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0978, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0978)

============================================================
📊 Round 508 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0186
   Val:   Loss=0.0978, RMSE=0.3127, R²=-0.0071
============================================================


============================================================
🔄 Round 510 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 510 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0141
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0054
============================================================


📊 Round 510 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2501, R²: 0.0132

============================================================
🔄 Round 514 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 514 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0020
   Val:   Loss=0.0869, RMSE=0.2949, R²=0.0502
============================================================


📊 Round 514 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2501, R²: 0.0132

📊 Round 514 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2501, R²: 0.0132

============================================================
🔄 Round 517 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 517 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0192
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0343
============================================================


📊 Round 517 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2501, R²: 0.0132

============================================================
🔄 Round 519 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 519 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0193
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0140
============================================================


============================================================
🔄 Round 520 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 520 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0149
   Val:   Loss=0.0737, RMSE=0.2714, R²=-0.0007
============================================================


============================================================
🔄 Round 522 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 522 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0070
   Val:   Loss=0.0867, RMSE=0.2945, R²=0.0321
============================================================


============================================================
🔄 Round 523 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 523 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0100
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0069
============================================================


📊 Round 523 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2501, R²: 0.0132

============================================================
🔄 Round 525 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 525 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0117
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0168
============================================================


============================================================
🔄 Round 526 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 526 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0243
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0429
============================================================


============================================================
🔄 Round 527 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 527 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0111
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0192
============================================================


============================================================
🔄 Round 528 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 528 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0158
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0006
============================================================


============================================================
🔄 Round 529 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 529 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0106
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0102
============================================================


📊 Round 529 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2501, R²: 0.0132

============================================================
🔄 Round 531 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 531 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0127
   Val:   Loss=0.0755, RMSE=0.2747, R²=0.0041
============================================================


📊 Round 531 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2501, R²: 0.0132

============================================================
🔄 Round 533 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 533 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0105
   Val:   Loss=0.0754, RMSE=0.2745, R²=0.0171
============================================================


📊 Round 533 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2501, R²: 0.0132

============================================================
🔄 Round 538 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 538 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=0.0082
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0274
============================================================


📊 Round 538 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2500, R²: 0.0131

📊 Round 538 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2500, R²: 0.0131

============================================================
🔄 Round 544 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 544 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0193
   Val:   Loss=0.0784, RMSE=0.2799, R²=-0.0292
============================================================


📊 Round 544 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2500, R²: 0.0130

📊 Round 544 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2500, R²: 0.0130

============================================================
🔄 Round 547 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 547 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0111
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0192
============================================================


📊 Round 547 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2500, R²: 0.0130

============================================================
🔄 Round 551 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 551 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0189
   Val:   Loss=0.0915, RMSE=0.3025, R²=-0.0119
============================================================


📊 Round 551 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2500, R²: 0.0130

============================================================
🔄 Round 554 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 554 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0178
   Val:   Loss=0.0859, RMSE=0.2932, R²=-0.0093
============================================================


============================================================
🔄 Round 556 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 556 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0181
   Val:   Loss=0.0892, RMSE=0.2986, R²=-0.0089
============================================================


📊 Round 556 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2500, R²: 0.0131

📊 Round 556 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2500, R²: 0.0131

============================================================
🔄 Round 558 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 558 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0108
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0198
============================================================


============================================================
🔄 Round 559 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 559 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0080
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0322
============================================================


📊 Round 559 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2500, R²: 0.0131

============================================================
🔄 Round 561 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 561 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0104
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0219
============================================================


📊 Round 561 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2500, R²: 0.0132

📊 Round 561 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2500, R²: 0.0132

📊 Round 561 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2500, R²: 0.0132

📊 Round 561 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2500, R²: 0.0132

============================================================
🔄 Round 566 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 566 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0162
   Val:   Loss=0.0814, RMSE=0.2854, R²=-0.0055
============================================================


============================================================
🔄 Round 567 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 567 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0136
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0091
============================================================


📊 Round 567 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2500, R²: 0.0133

============================================================
🔄 Round 570 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 570 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0153
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0035
============================================================


📊 Round 570 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2500, R²: 0.0133

============================================================
🔄 Round 575 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 575 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0103
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0155
============================================================


============================================================
🔄 Round 576 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 576 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0128
   Val:   Loss=0.0719, RMSE=0.2682, R²=0.0133
============================================================


❌ Client client_12 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_status:14, grpc_message:"Socket closed"}"
>
