[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc76af72-2206-4882-947c-4fc70640cc4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8652c9a0-26a3-48dd-975d-6cf145d765f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae9feb07-361a-44b5-bce5-fdf4ebebcd8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 697b8533-f2ea-478a-a28a-8a94c0346237
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cb2e545-76bc-4178-aebb-1c4e3ce322b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42d4df6f-34e0-415d-8188-3ad9651b25c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b7f13b1-a2b4-448c-88ae-a0ec60c76cdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bdccca27-295c-4ec1-9745-1ba9ec440b73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ac425fc-b498-42bf-b787-6ef9af61e088
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d396d71b-7468-4edc-ad50-18be5c9e5e3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 537f1a3d-47d2-419b-9c39-96408473dda1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95a1dac9-a958-4e43-b647-bdcb2e0eb6bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9790362f-bf4b-49c3-9178-488a8f64ca22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60f6c402-86d7-487f-9423-a9582f36a3eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd01ed2f-e47b-4a06-aff7-2006a775627b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0248d2c-695e-46d1-9bdf-f03ea712a614
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfc41114-2075-403e-b622-e40ea3e540b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1954068-3754-4d62-947e-d06fcc4cfbd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97732bfc-fda4-4c95-803c-5aa335e178b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d580c927-4db0-4b30-928c-4dfae22168ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d03a9bb4-7f66-478d-a4b0-07a39dcbb1f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98722b9c-6134-4028-996b-3eba966ba6fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63cd01b5-a3bf-48d7-bf50-f0fa801507b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3a84aa3-9394-4905-918b-713ec3f21678
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9d13120-a252-4b78-bb44-e22ebae22689
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 699ef42e-f9bf-4e36-8348-ee0ec42cc6bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59d4c768-69f1-4b7d-aba5-fafe9a4676c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee1e63cd-5b6e-4157-bc2b-d2c93f58a792
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08f5879d-da89-4649-8a7c-d30f7de3f972
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 078aefd7-a6b6-4769-b4a0-9d328ff9466b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aef564e1-1d31-4b7d-86e1-d65dab43451a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fb27a4d-d47e-4d62-bf7d-1435e6d32949
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 120a37a6-144f-4780-b4a8-b96e5be52daa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8756dd7a-0a37-444a-b596-5d361e48ed79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3092bb2-5060-40fc-a420-2d318823f62f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f332d6d-6024-47aa-8a87-eb043456209c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6b17605-1759-4c50-b98d-27c3044d1853
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ddb105b-a2b1-4da0-a83c-fab0ebc38a63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b497510-5e62-4bc5-b230-cd231f9b3634
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf2a507a-9574-4397-863d-9ba87c05b224
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b449124f-ea7d-4517-8755-e8ad00c6cd74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9cf44443-bdc4-4cb8-9c1d-5faf402afbbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8fa7e93-4c6c-4131-a968-a62a74e61721
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba76e05b-5f72-4c2d-90eb-082f80580f7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d3c1d0e-ea4d-40cf-a1f1-2ac1701b8e73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message affd9ba7-2d7e-480e-a5e2-2e46fcadd467
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4d30dac-342a-43eb-a14e-af995c5bb17e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b55b833-1672-47ae-8413-1785f9636020
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ff484d8-f427-47c3-87d6-57e67d1e7d1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9789fbab-7881-464d-b9ca-701efdea33b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f49d6db-6b1e-44c4-a54b-2fac6d0f9aa0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 225b6621-46db-46c0-bb25-e0d687fc9d0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fc8aa6f-4a61-4668-a46a-6faf5cdaa12b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 386e25ee-639e-478f-8d3b-da21de9a7b3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bae53beb-1a80-4f1c-a286-e6d12f265fb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35c37313-fa6d-4697-a9bc-ddf3d1952ba2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28f00cff-dc15-4645-8546-9b635c141683
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99951edc-aff4-4288-9e55-2d5509fec890
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 395e7536-cd8a-47b3-be75-aab7ae9c625a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c9352af-121b-45b8-a498-29f5e8d88c68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 746b0be9-958a-4114-814d-b050750de15d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55c81ad2-4a62-4166-bc34-ae4195423124
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53affbe1-ece8-41f9-b9aa-09f434ca59c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ca128bf-7814-4014-a33f-e5f96bdc7963
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5554179-b644-48e6-9de2-ed227e29dd07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 869839f1-5db4-4318-a696-ba2179cb9e7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4976f406-3111-407f-b306-d8f14dca38ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b58d7c2-294e-4ff5-8a95-e66af72ebdaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 744327cd-0118-4f3a-a648-4771f9712c89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf0d207c-9a9f-4662-8cd5-4f5a3a3b349e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6cf07d9b-9063-4774-b30e-1077cb99a8b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f022d635-2a0b-425a-99d3-0d545d64e572
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d016b38b-b0f3-4034-92b9-17466e12b45e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5121cfc7-3e38-415f-9b41-579d5ee5b9fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 941e4965-b93d-493b-b277-7aa63b37b710
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ce3a4a5-f957-443a-a194-5a25bd73d684
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8898f43c-5f90-4b6c-98b9-2dc972d03626
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48756601-16e4-4fef-ba0d-20ae1dce8a5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bda554c9-d18e-434b-80fc-45f940ae7c80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16172bc6-d4d0-4e11-9742-e9da82fc5453
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3ea386a-2b65-4302-8a6e-15a4c46a7a45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 578872b9-ea17-409e-81f6-7a86a69edea4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd0441b7-12d9-416d-9aa0-b69286638d21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52d846a0-5e1c-4c50-a341-8afa14fcb30a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bb3ceab-963d-42f2-ac0b-f92658083cb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40204a51-d260-4508-9fbc-b6e772d8a905
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72fd8004-4ce4-42f4-bb34-5823ce0ed65d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 718f65ec-7393-4d13-8b1b-0b5399a4e051
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3065349e-b241-4437-aaef-49f804ab3b74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e72a301e-0222-41f6-91c9-67cf9eb524f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c8dceb3-5796-4418-a066-3a048f711382
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d665ead-a68d-435f-aca2-78e50efeef88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6640bac5-88c7-4d7a-b14b-1d9070fd9049
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2953dc5-ae54-417a-9c1e-2516608e72ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 908439ac-0a43-41e4-a724-d62b39d8f62c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1c11d11-ba55-4ea6-938f-faa51690dd04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d63e57dc-c6fa-418e-b1d1-04795bce8728
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f7c96dd-3af0-4d19-b56f-a53a2090018a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4875df7c-ffb0-45dd-ba51-bce6b82f1c02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e60c345e-6753-4127-8561-ee6c6e699e16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45f03a2d-601e-4a6d-a9ca-09f67e53a758
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb98fa25-f463-4f9a-81ec-d44dbc60d232
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d5dcdeb-5bd1-4b7c-b1ba-4d8753073754
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7db77117-8e64-491b-9607-bf353dffbebd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5760b5e-a7d5-49e6-aeb6-87d77bfba4ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a440f559-33cb-4ef6-af79-b6cac1fd083b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 660cdcb0-fd3c-4569-be30-6276cf01c9be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03bca591-dc9e-4c57-a676-e731fa09b07b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2769be8-6f96-413e-ac03-8477a47a5db8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ef9d388-be2a-4817-99dd-fec20e20c539
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5380701c-655c-4831-bcd1-37c1cc95a76c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fd68fed-aee9-4033-8589-484123a82672
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57dbfc46-f97f-43d4-a2fb-f018b6fba140
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f45a2df-3f39-4cf7-a0d6-5dea5f0aef80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58c4a561-9165-48df-ac30-993c62f864de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e5d4bbb-974c-48fb-857f-8cbba0e6a340
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4dbb848-f07a-436c-b45a-a1344b09c1b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38063bc5-9ad0-4501-aab2-7e88580ff72b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1afa18d9-b82d-4c6c-a917-10e572028df3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 551e771e-0edf-48dd-aec8-41f7fb4c3ba7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b3eeea3-020b-4c3f-abf7-b69c4af86177
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4deb7804-551d-463e-949c-17ff3447bb72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e33b5ea-5a2e-44bc-834c-da4df216500d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0ba04cc-21a4-469f-92fe-233568fda3dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c91894f2-d06a-4423-a3a9-5869795c1150
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ebcad3f-4825-425b-b8f7-2347972af1d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5d92933-f5d7-4203-99b3-f70bac86d6fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c467ee40-d995-4e0b-92de-62f9164e013e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46b8bc74-cfcc-4fb6-b75d-47198149d720
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23c2140c-e66d-4099-9fed-b51b5b3cf42d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a3a915b-af31-487d-b35c-c259db767bd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6798adaf-e3f8-4d20-bde4-623301e39795
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9ce0fc2-b2cb-455e-bb3b-138978676bf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71b0d13c-af68-466d-af5f-6b3805d7a2a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bfec108-7eff-422e-943a-af9357c1b772
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15492af5-8b5f-4288-ad95-b19fabd4b7c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92388f16-c5f8-412f-aa75-72310ad4a452
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61f90772-a877-4ccf-bf9c-0983d3fcad8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04de189c-6c7c-477e-bfc7-ef52e7c187bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a782047-629b-4b0d-ad11-bc55ab3d8948
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfde486c-7d8b-4cb4-9832-9b6d44f57d3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a81ffc52-6419-42f3-8051-8a6d30f9ef07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ac19624-fb0e-4417-a4a7-915189dbe01a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9df56f47-e38d-4093-8a14-8370b2a1f7f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b67fede9-3dca-4807-ba26-03e8b366479d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a4a4cbd-a2bb-4eb2-9e8c-6a7365c00359
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8620a6c-ee46-4632-8b4b-2282f92f56d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f09ab3b4-ba1b-4412-85f3-497beb0b8156
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45d3de4e-278b-4cf7-84b5-adf3beef0409
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 819a56e8-1fe7-4145-878f-f7776c6919a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86e0d79b-7f69-4fb1-8eca-debaa4fe74a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c56a8f8-8168-4e74-9436-9281325e401b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8cebcc0-fb47-446d-8caf-5f12b276e5c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5991cc0-cd76-4495-ab5b-aa0d598f308d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35e9310b-cb63-4ad6-8db7-f20e1cdb80f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5a11b24-49c2-439a-8dc1-a8d55d20744e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f0412e0-1f1e-43b0-9090-a6e3eb826d38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 938e5aaf-7453-4fb6-bff8-054a2fc07e84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 212fd77c-09b9-4d20-855d-ffa27f8c4584
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a3565fa-285a-4244-98cc-62baf71dff34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a28f495-87e8-4e23-aa7e-52ab54386edc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb195fd6-2ad8-418c-9bbd-c93b290ef096
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 708714b6-36ec-4d85-9038-1a9a4a1f5d18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 578c8312-6003-411b-b648-0ce5f48979e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2e97f9e-1fc5-4a29-b343-5cecb042b7d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52df9ad7-538a-4cce-a4ae-bdc476282f1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ec7b357-e88f-4461-81e6-cae4bc751a41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14e6ab94-89fc-487b-94e4-6f30deb1abcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 068826a1-9962-40a9-a9d1-7a00ca55428e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4eded9d-c72e-456d-af2d-29d64390f1aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a484f3d7-ac47-4b7c-b095-a60c74323e94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6091f567-46b3-47e6-824b-87f8f3165b00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 294e9f0c-4194-455e-91bf-faac6646bf34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3dc1680-7c70-4367-aa65-eab2e2a7d79e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0c7c8f0-4cac-4dc1-8f06-4c7317d2d6d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ae0553e-a06e-4ed5-b237-42fa94b448e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bedee26b-0ee4-433c-a3ac-a56c0c80235a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5aca898-ee83-45cd-8f36-828aa979dcf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 636f768b-1465-4cb2-b995-fd1932efe789
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34b30f09-8cf7-4229-8c2f-22e9dd16ce91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1548c700-ddfb-4834-9520-fc53fd71423c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12bae467-c6aa-4880-92fa-568bb9a80db3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b244cfae-5cd0-4abf-a746-07dc19014e98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44765907-cc5e-40c4-9679-9fcc286720f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd329887-0d08-43da-b7ec-1b091fd72483
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30ea9baa-3a08-4264-b09e-f94b7f6dbcab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e953b64-83a3-4ca6-9c01-d4025c5bab90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb9a3743-9168-4ee5-8d92-1b624e44ebfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1074ad40-63b3-4438-a868-53a406dceb6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ead706fd-ad14-49ab-88e7-977b5cd81f1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f2423ab-9cdc-4c36-8882-2bf37e9e29a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebf0a1db-9714-4397-8f87-5cb8b45b9fcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3da977f4-2769-4fa9-b785-c6c8a560273a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d9ca003-b201-49d7-8894-35f9abe84dd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed6b38d5-ef6d-4c83-87c2-0bdaf52942af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4bfd41c-9d0f-4680-a430-caaaea734c9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38ea6f37-844a-41bf-a33c-022936a043f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca0bc45a-9d32-41a0-b71a-aea1e94e1586
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e79bfbb-d0ba-44cc-b26d-9986d6b23424
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1a480c8-e6bf-44de-8919-ef2e8b3d33f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de667b6a-77f7-4d96-866f-457cffa8893e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcf4dfd1-dc55-46df-bcca-05be8e19bd58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc37a33f-5b75-45a5-9462-ab220f067e28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ca55086-b70b-4167-9cca-e5c75f6e866e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c4448f4-d160-4348-a280-25b1d8cb4f3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 611c241b-45d8-4d52-b1ae-56c8715cf295
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6903ae78-a50d-4112-8286-4d9542702900
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 264282a4-7878-4520-870c-8090e082648d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28614fee-b567-4145-b337-ae5970088094
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2409959f-1ab1-41c0-a3d0-4219239925fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2fedebf-e201-4c2a-b4df-52fface5dc85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da568be8-ba07-4aa9-ad75-a3b07f9a49d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36da0241-9563-4d22-9c70-fef762752a38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9798bef3-e866-4594-86a3-51fa51793aae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cedba776-df7f-4187-becd-b14ef389b704
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e4316f4-8f03-4760-97b3-e89f07863ac3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0757cefa-9c81-4790-85c7-73b89f9346b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92ed9246-82f1-404f-aac6-27d771ba87e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66474e27-3685-4c9e-ac44-2b5eeebeae53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0159b809-842e-4c2b-8bab-6a5e261684cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3756bb3d-0223-414f-ba07-950cb4def2b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82686894-3a0e-43bc-ac24-8f8f8809c920
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27c2f111-e6c6-4fbf-b626-16018a7c141f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed0bebc1-2836-4d43-9005-abeba529b84c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42441087-758c-4c5c-bc51-b416ad6f3b85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28599abd-b04b-4042-9e07-b577e08f3caa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68b9606f-a240-408e-8eef-020c9432df2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 214ea5bc-f686-40fd-8e7f-0b944281d637
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e477ad5-31a4-40f2-8905-ac7c8a3ff7a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f7cded7-3ac4-46f0-a6db-b28c61805ea6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7ab68b3-440d-4d97-8c7a-d140a90bf2f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 672444ee-c804-4baf-948b-a9505cf15028
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0db60fb-86c8-47d8-9af3-2b1a97cf8561
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e6c4211-ba21-4584-a3d5-aeb588856a9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ee4bdc8-44ed-4e18-866c-d87a83e1a3cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 221fa13b-6d31-4935-8d76-30fe5a4a8048
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89b362be-d7e7-4a01-875c-53c9e5cb5b86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14bb4236-73a5-43a6-ad43-f0bbf4090ba6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f96f88c8-8200-4f97-a852-a130caff08c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d032c749-5b29-4a8a-b3a5-3f8bdbe22323
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2d7fedc-0b3a-405c-aa5d-a1bc89d53499
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6e1ac0b-1afa-4da1-aac8-3ca12704d221
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 361ec16a-57f4-4e30-9729-ecbc00a0a0bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d58ca69d-3679-4d6b-83bf-a33fc98b21ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16fbc041-b418-4a28-8de3-19a0ee84cb52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b05fadf-c303-4b8c-885a-f1ad9c19dd27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55fe2c73-6911-422e-8686-344ff75af6ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee6e225a-0040-465d-8d69-ebd027380e3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1cabd667-e4d6-44ac-b26f-d60737507149
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e28865c7-1db8-4f95-9611-af6830ce8205
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70df5931-2988-473a-bb47-5cae3bbf7b83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50482660-3f68-4150-8249-c422d09d2ac9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ca4cbbf-6e7e-44cd-b9d9-9cba5a7d767a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 315f3b82-df92-4aac-809b-67989f2fec29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3185285c-17fd-4134-87ea-38112e113098
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a99b4211-6ded-4200-9438-5d2948f4996b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3304cea-7876-44ce-8003-4afa2e94ee63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ae06b80-198f-4846-8884-e5e665f27001
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea4c3123-0f5f-4220-a6f7-f24fab25e0ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3328a3f-e7aa-496c-851b-e8703e8abe8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bea347d-81df-49f0-980e-ea943d824f3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60c67def-8f2f-47b9-9457-493fac755944
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81f4ec5d-208f-42d6-b92f-fe72c579bb20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29df07e2-4e7f-49dc-ace5-602184799faf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db7816e7-d517-49c2-989d-c88619d9322b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9676fee7-3f5a-4fa0-bead-a30543e779dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eae67c89-2589-4e90-b1e6-819a8ed586ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82095d11-9fab-4cda-9d1f-ca52a4715c9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09c3b049-8adc-4a23-90ef-78e0091b06bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 076f1ba7-4f55-4b18-a4a4-a19a9acc4464
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fc857fb-4de4-4161-83dc-dca903f2efd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e3efe4f-981c-449e-8a1f-f57851c2a066
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f341927-59d0-4a1e-8c59-142d5072931b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 056c6620-1128-4a07-84be-278536e52625
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e7099da-231f-419a-8887-55bfbd237e3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fba2d2e-8c68-4a58-a41f-bf13f7c45531
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d4c98be-3a78-4e0c-a800-8f7aa1b70100
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39a9ae89-24da-46b6-8ff5-eed6c25cf71b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d63efa7b-c669-4cbd-a53c-20698161eaaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2891932a-5994-4229-ac61-62d04da559c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb251c54-e16b-4045-b22a-c8df02ed2794
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e18f343d-3d8d-46cd-affe-191580a17ca0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 518f9098-6229-438e-8a1b-3102939b1eb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e1d8cf5-af44-48e6-8a19-9a39b981099a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3c54359-49d0-4d51-b7c1-602442dd90da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 615ac0f7-3dff-45d5-bfaa-eae5395f8f3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de1ead71-5e83-43f9-a153-2ff848d22b54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb651093-0ca2-4e79-8e00-1bef4cee1bfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d245bf0d-3634-462f-b84c-3d86e3a7963f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ca187d9-2f01-4189-9a1f-4b167f65960e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 820fe4a1-ec96-45fd-8b2a-d7376ccc1112
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c736500-5fc3-4040-ac51-9b034f32f069
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcd330ad-aedd-41af-b4b4-f719c7a87291
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87d24399-8e7f-488b-8cf1-b1d4954b4b44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5811d8c3-d33f-4bad-bd9e-d4336e7022aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b56fb6d5-d007-4ba2-91af-633c8dad136d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb255987-e565-41b1-bab4-b7e049ab6d7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2f4685e-cf25-4689-b2bf-14da38cc3f44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 673d9242-b094-4fed-96e7-fb93043fb1b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9812aee2-15ed-4e06-89a8-0b9b77db5cc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 471df0de-0172-49c6-83f8-1b34e955fa52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ee62b38-4913-40a7-b3a6-774ef9791715
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea050fc2-9613-48f6-9bba-fe5daa1411c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e90aecc-89c3-48c7-b275-337b0e23ac28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcb971ca-31a4-445f-a6b3-04eca8cd4cfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 072d7ee0-8771-4b50-8e12-77a37ee60d2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e285278b-8b78-456e-9399-efd2bfddda18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3a77eae-929e-4265-9095-6e4a4788f97a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7398dfbe-4369-40cc-a0f5-c94bdcd36ec8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8244b02-47b3-4352-b101-d40e36bd5e2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bcfa830c-a318-4e2f-876c-1012d37d754c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ac63476-1971-42f5-9a8d-a7b27c632072
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27624c1a-aa7c-44f0-bec7-35d445c1f606
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 507ff89c-12e8-427c-bd41-76031ff32e38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 762cab39-4177-40af-92c3-f91c66e42250
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad402d76-11f4-4672-83f9-1c7f6833f8cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 413941ab-71bf-4c8d-8972-f781c0c34364
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5974ff8-b57d-4c0e-815e-1e2c7a225f4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1408c04-5049-4625-8c83-4f264dd1e42a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4e8b3a7-fd27-43ef-b583-ab3d08bfb375
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3dd7451c-bc7c-4491-b4e3-98ce5487c174
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac8c85f0-b00c-4979-9ff0-2d92d9308884
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4cb25a1-965a-424d-ac5a-42206dc0f491
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ea16ff2-26e5-4841-b3b8-b93af88b1941
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f2e6410-c7a7-49ba-94a2-e3416d834997
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c636772-cb54-48a0-bd82-307282e46f2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bb9b047-0cbb-4b90-baa1-11d209ce5d6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c2a31bf-51d2-4bb3-9a08-e1c8e589d52c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 670a678e-16ff-421a-9a24-9f01942cf58f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89f6be55-3324-493d-bd11-4433fec57197
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bb59999-fe5a-4bb0-ae9d-56e1feb52b70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1e20834-6da3-4223-a0b1-e426dfa377b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b4f387c-98cf-4c3e-8256-4155149505ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f513934-20dd-4d2d-b29e-1458706964aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e560d7bb-74e5-4856-aa58-c3862ab41838
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44b04f38-a0bb-48cd-8de6-32e6d7c85d82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91ca18ea-d538-4139-96bf-a13d6732f7aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a5f3881-c142-4471-825c-5dc852753479
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b960a5aa-8da5-46b3-bbf6-70459c2a8634
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f0136fd-64e3-43fb-80fa-58a2a6bb23ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4772b3e2-814c-4236-8441-140484640e6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbfe2542-c213-47b7-bd07-646194d52712
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef09de79-4938-4a1b-b7c6-289c4e902956
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c58a3ab-1504-46c5-ad74-c411d543d72b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08883045-f138-4461-a23c-359b528fdeec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a920cc40-cff6-48a0-9e64-e8f3e774bc19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09dab784-aa51-4ab5-bf5e-1e1427988b4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67dd9e85-885c-4e91-94b7-5e1c5b2b8cc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf84bef0-516d-43b5-95d3-ec1009f78cb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7351be89-1cf0-43ca-b668-d5e6517751d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53e4d2ec-ca61-4b45-9911-18148dc5a4bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bed29e53-fc2c-400c-bd0c-d72cf45dc0d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68320f5f-d821-4835-bc54-d45ebaea048e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ef2aafb-d98c-411a-a429-e3b1619ddac2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b826b091-31fd-415f-b49a-a34306719531
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c64e477-84c1-4064-ae75-a4981c665eee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 195df855-5cb6-4967-9318-35cc76b35c52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3738e7c4-9b94-421d-b748-a24c4f6704fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86f91845-dce6-4f47-b0be-ab2b6ee7dba0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd4ce6b0-188d-48aa-ba2c-581bae070d1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 646184a2-a54c-43c9-9d35-7a44b77cd379
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81fe3524-b259-49af-8b29-af862254a8a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86ea0699-c0cf-44f1-ba12-09cee02c613c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3eda99e5-8fbe-4107-ac70-0a7732b4a894
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5b68c8f-4be3-4bd8-a381-496b784e853b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59c424dd-9a93-414d-a24a-cbe170598a8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79e124ba-e2e3-47d0-8eaa-c27b7c2db875
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 480f5368-efb7-4050-a3f9-181e89f62ed7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17270ec4-2df7-4045-b6a6-75ae6b25aa92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d404ca1b-401e-46f5-b67d-79ac16b26f07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94763030-af5c-4dff-adc2-733a17402223
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1612552-8c8b-4159-97b5-dfc5004b065c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61e3f10b-7d16-42dc-b271-56dcf11b94d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3caca48f-fbb4-41cb-a303-fb3bc6c7d4ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9084cf28-8272-4fe4-8889-cfa1fba1505d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4366af17-d26f-4e80-96da-56c74fc5171a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e6f6dec-34d4-483c-ae98-a40327232111
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1957af8-af30-4520-81da-25d7d6257f91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ee74d3c-0435-46a4-9fd3-8db006c85b85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 184a1689-17cf-4fba-96ef-0ef107f732e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a445940-e0c5-41f1-9977-fd1e4d71eec3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13487221-591e-402b-bc1c-a8632716b920
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be9bae05-fa37-4418-b842-bb0579ee1d7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d61a127-1aae-4c11-8a90-a193f30524e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de54511b-04a8-4c4c-bdde-453450d3abdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d0290f4-4c33-480c-a3e1-f5c4f6561730
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee885c8b-888a-43b9-b928-34ec285847bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f600d00-0544-4894-a17d-6acebb2d99cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b27732cc-8da3-47bd-bbd2-351619314467
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 567fa3cd-daba-4285-af71-891630206174
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95e4114c-6124-463d-9b6f-05c35738187e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfe7418b-dd15-473b-88fb-8ac532d6c352
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e3f083e-f62c-4cc9-a420-93fc07e6ebce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f2e6944-5ae2-48a4-984d-64796764b78f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f4afd33-1120-4055-8adf-5ea6693a4850
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dab0d75f-dd36-427b-ab01-aa046413106e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebe0d5c4-5a3d-4647-9821-ef853cf4b1ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd87c261-3c54-4597-ade4-b918c21819ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16f31f8d-5821-44f2-9c12-902af39de629
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b6ab426-b036-4501-b547-c145502ee507
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87520b27-1d72-4222-9ada-ff760516f593
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82d78cdf-0e33-4dc7-9f5c-5e0ca8024f04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee60adbd-8103-424b-b06b-64fae4ee5613
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2eb24772-ec6b-4709-ab50-bc6d6b7028bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3af8fc52-ad6c-4ebf-ac2c-8c9e32de7bfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c17179f-dbb0-4665-88f4-704f748fb415
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a8b9f70-2870-4f41-b16a-5f1fe04bb459
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4eddc014-a188-4523-be7b-a3e4bc2d4ed9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82b23feb-f125-4fed-83e6-004668aa1e15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96cd1204-7e02-4e90-9881-e08e7a14c747
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9d9bae6-0318-4b09-80f9-3116b26f7d5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ca81061-eb81-4f3d-ace3-c57bc46f1648
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 680b9441-de93-4c16-83d6-071092d61273
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45d8e52f-1816-403c-84ac-d086230824ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcdde408-0bfc-4f33-8d1c-de52ffd38c68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abb898d8-4fb4-4741-8ce0-7014af9a2d7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa4526bd-6fef-495d-99fc-fd4957645516
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 645c79eb-ed51-4d75-b64d-935b0d56d4ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43b775dd-15c4-455c-b326-2fee49ba3496
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4c80100-1c15-42e0-94c8-5b93ba1ecc91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46db1237-8798-4087-a4fb-8e3609556b1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08e8f26b-a7f7-4d23-9b6f-0dbc85e47e56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9dfee28-3618-4bb5-9d40-13b179035358
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11f35ba6-03fd-47cc-81a0-3592969ba1fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b76f2ea-bce7-4700-931b-31d430dbc2ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba0864e1-e5c2-48a6-9d87-dc88843a74ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7985dcbf-02db-46a2-b849-a6eb957a2f48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68a43542-b6af-412a-a523-1eb2b0361abb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30aa73c4-ffe0-425a-a871-2c448060580a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b00b8bd7-0393-4f47-a800-6632b0c860ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2064b9c3-495a-439a-9f78-011bc81860a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a72c1fea-d6bd-41b0-87d2-eeb100e38577
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0629f4d3-6d04-4445-9ecf-478ed05727f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5ccd7cb-b3af-439b-b8e3-d2b2cc22d669
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b7329db-f3ef-4235-a84a-abf557d82463
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 411ceac9-93f6-4582-99c0-b76cefb70455
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 592e6bd1-bd0d-468b-bab1-c6b4e434b358
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bdf30c36-d83b-4f12-9222-1c457834647d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a52cb444-d2ee-45a5-84ef-1f610cb5d726
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe6f71db-d7b2-4cc8-ba2d-487415bbdf07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c9d9aa9-bbd8-4be7-a43e-194086721a89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 822101c1-a253-4037-9cda-460027ce6411
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b63d5523-15f3-4c7a-be7a-5c34c36f0261
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36dbf0f9-e8a4-4110-914d-c3731181a249
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0d4bf27-a309-4918-8ca7-245b2b477c00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef24d6d5-25c3-4599-b97b-e5fa3d74a051
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 820d4322-048f-44d5-a02b-2de4e5fae2de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6a7ec1a-c9e6-47b0-aac4-74f86eff50ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eace96b3-7782-4f78-85b6-4d91ce380045
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f237763b-da15-4ab9-8e40-bdcd94ffd2b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b67cde47-e9ba-4c33-bb9c-8a346d138eb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5771106-e25c-4c79-9281-213135443eaa
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_13
Server: localhost:8688
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_13
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_13/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_13/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_13/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_13/test_labels.txt

📊 Raw data loaded:
   Train: X=(3174, 24), y=(3174,)
   Test:  X=(794, 24), y=(794,)

⚠️  Limiting training data: 3174 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  785 samples, 5 features
✅ Client client_13 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 3 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1494, val=0.0880 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0862, val=0.0812 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0850, val=0.0792 (↓), lr=0.001000
   • Epoch   4/100: train=0.0842, val=0.0796, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0842, val=0.0796, patience=2/15, lr=0.001000
   📉 Epoch 9: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0833, val=0.0803, patience=8/15, lr=0.000500
   📉 Epoch 17: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 3 Summary - Client client_13
   Epochs: 18/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0125
   Val:   Loss=0.0792, RMSE=0.2815, R²=0.0036
============================================================


📊 Round 3 Test Metrics:
   Loss: 0.1496, RMSE: 0.3868, MAE: 0.3157, R²: -0.8087

📊 Round 3 Test Metrics:
   Loss: 0.1011, RMSE: 0.3180, MAE: 0.2685, R²: -0.2226

📊 Round 3 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2500, R²: -0.0215

============================================================
🔄 Round 7 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0821 (↓), lr=0.000250
   • Epoch   2/100: train=0.0827, val=0.0823, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0824, val=0.0823, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0822, val=0.0825, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0820, val=0.0828, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0811, val=0.0837, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 7 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0204
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0077
============================================================


============================================================
🔄 Round 8 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0910 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.0818, val=0.0899 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.0813, val=0.0893 (↓), lr=0.000063
   • Epoch   4/100: train=0.0811, val=0.0890, patience=1/15, lr=0.000063
   • Epoch   5/100: train=0.0810, val=0.0888, patience=2/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0807, val=0.0885, patience=5/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0806, val=0.0884, patience=15/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 8 Summary - Client client_13
   Epochs: 21/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0211
   Val:   Loss=0.0887, RMSE=0.2978, R²=0.0190
============================================================


============================================================
🔄 Round 9 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0883 (↓), lr=0.000016
   📉 Epoch 2: LR reduced 0.000016 → 0.000008
   ✓ Epoch   2/100: train=0.0869, val=0.0871 (↓), lr=0.000008
   ✓ Epoch   3/100: train=0.0861, val=0.0865 (↓), lr=0.000008
   • Epoch   4/100: train=0.0857, val=0.0861, patience=1/15, lr=0.000008
   ✓ Epoch   5/100: train=0.0853, val=0.0857 (↓), lr=0.000008
   📉 Epoch 10: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0838, val=0.0843, patience=2/15, lr=0.000004
   📉 Epoch 18: LR reduced 0.000004 → 0.000002
   • Epoch  21/100: train=0.0833, val=0.0836, patience=7/15, lr=0.000002
   📉 Epoch 26: LR reduced 0.000002 → 0.000001
   • Epoch  31/100: train=0.0831, val=0.0834, patience=5/15, lr=0.000001
   • Epoch  41/100: train=0.0830, val=0.0833, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 9 Summary - Client client_13
   Epochs: 41/100 (early stopped)
   LR: 0.000016 → 0.000001 (4 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0135
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0119
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2467, R²: 0.0100

============================================================
🔄 Round 11 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 11 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0171
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0098
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2497, R²: -0.0147

📊 Round 11 Test Metrics:
   Loss: 0.0854, RMSE: 0.2923, MAE: 0.2517, R²: -0.0325

============================================================
🔄 Round 13 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0846, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0853, val=0.0843, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 13 Summary - Client client_13
   Epochs: 29/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0127
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0147
============================================================


============================================================
🔄 Round 14 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 14 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0020
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0006
============================================================


============================================================
🔄 Round 16 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 16 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0187
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0245
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2457, R²: 0.0163

============================================================
🔄 Round 18 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 18 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0168
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0436
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2457, R²: 0.0151

============================================================
🔄 Round 22 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 22 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0123
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0487
============================================================


============================================================
🔄 Round 23 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 23 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0195
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0149
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2457, R²: 0.0155

============================================================
🔄 Round 24 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 24 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0177
   Val:   Loss=0.0912, RMSE=0.3020, R²=0.0286
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2457, R²: 0.0161

============================================================
🔄 Round 28 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 28 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0202
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0310
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2457, R²: 0.0163

============================================================
🔄 Round 30 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 30 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0220
   Val:   Loss=0.0916, RMSE=0.3026, R²=0.0256
============================================================


============================================================
🔄 Round 31 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 31 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0160
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0477
============================================================


============================================================
🔄 Round 33 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 33 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0235
   Val:   Loss=0.0715, RMSE=0.2673, R²=0.0216
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2457, R²: 0.0169

============================================================
🔄 Round 34 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 34 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0232
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0218
============================================================


============================================================
🔄 Round 35 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 35 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2897, R²=0.0231
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0204
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2457, R²: 0.0172

============================================================
🔄 Round 38 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 38 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0172
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0309
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2457, R²: 0.0173

============================================================
🔄 Round 39 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 39 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0251
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0166
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2457, R²: 0.0173

============================================================
🔄 Round 40 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 40 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0175
   Val:   Loss=0.0814, RMSE=0.2852, R²=0.0490
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2457, R²: 0.0174

============================================================
🔄 Round 42 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 42 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0257
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0181
============================================================


============================================================
🔄 Round 44 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 44 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0313
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0065
============================================================


============================================================
🔄 Round 45 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 45 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0231
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0147
============================================================


============================================================
🔄 Round 46 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 46 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0242
   Val:   Loss=0.0732, RMSE=0.2706, R²=0.0265
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2458, R²: 0.0175

📊 Round 46 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2458, R²: 0.0175

📊 Round 46 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2458, R²: 0.0176

============================================================
🔄 Round 50 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 50 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0267
   Val:   Loss=0.0859, RMSE=0.2932, R²=0.0097
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2458, R²: 0.0176

============================================================
🔄 Round 51 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 51 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=0.0197
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0326
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2458, R²: 0.0176

============================================================
🔄 Round 53 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 53 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0233
   Val:   Loss=0.0723, RMSE=0.2690, R²=0.0249
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2458, R²: 0.0176

📊 Round 53 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2458, R²: 0.0176

============================================================
🔄 Round 57 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 57 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0241
   Val:   Loss=0.0789, RMSE=0.2810, R²=0.0288
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2458, R²: 0.0176

📊 Round 57 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2458, R²: 0.0176

============================================================
🔄 Round 59 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 59 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0286
   Val:   Loss=0.0838, RMSE=0.2894, R²=0.0110
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2458, R²: 0.0176

============================================================
🔄 Round 60 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 60 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0192
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0424
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2458, R²: 0.0176

📊 Round 60 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2458, R²: 0.0176

📊 Round 60 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2458, R²: 0.0176

📊 Round 60 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2458, R²: 0.0176

📊 Round 60 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2458, R²: 0.0175

============================================================
🔄 Round 70 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 70 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0269
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0139
============================================================


============================================================
🔄 Round 72 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 72 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0272
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0183
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2459, R²: 0.0175

============================================================
🔄 Round 75 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 75 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0263
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0219
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2459, R²: 0.0176

============================================================
🔄 Round 77 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 77 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0298
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0076
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2459, R²: 0.0176

============================================================
🔄 Round 78 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 78 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0236
   Val:   Loss=0.0856, RMSE=0.2925, R²=0.0297
============================================================


============================================================
🔄 Round 79 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 79 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0242
   Val:   Loss=0.0923, RMSE=0.3039, R²=0.0302
============================================================


============================================================
🔄 Round 80 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 80 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0233
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0284
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2458, R²: 0.0176

📊 Round 80 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2458, R²: 0.0176

============================================================
🔄 Round 87 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 87 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0315
   Val:   Loss=0.0876, RMSE=0.2959, R²=0.0034
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2458, R²: 0.0177

📊 Round 87 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2459, R²: 0.0176

============================================================
🔄 Round 93 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 93 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0271
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0193
============================================================


============================================================
🔄 Round 96 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 96 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0221
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0415
============================================================


============================================================
🔄 Round 99 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 99 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0210
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0461
============================================================


============================================================
🔄 Round 102 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 102 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0262
   Val:   Loss=0.0849, RMSE=0.2913, R²=0.0242
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2459, R²: 0.0176

📊 Round 102 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2459, R²: 0.0176

📊 Round 102 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2459, R²: 0.0176

============================================================
🔄 Round 105 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 105 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0200
   Val:   Loss=0.0779, RMSE=0.2790, R²=0.0478
============================================================


============================================================
🔄 Round 107 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 107 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0241
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0333
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2459, R²: 0.0176

📊 Round 107 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2459, R²: 0.0176

============================================================
🔄 Round 111 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 111 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0253
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0224
============================================================


============================================================
🔄 Round 112 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 112 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0273
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0063
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2459, R²: 0.0176

📊 Round 112 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2459, R²: 0.0177

📊 Round 112 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2459, R²: 0.0177

📊 Round 112 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2459, R²: 0.0177

📊 Round 112 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2459, R²: 0.0176

📊 Round 112 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2459, R²: 0.0176

📊 Round 112 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2459, R²: 0.0176

============================================================
🔄 Round 123 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 123 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0278
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0185
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2459, R²: 0.0176

📊 Round 123 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2459, R²: 0.0177

============================================================
🔄 Round 126 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 126 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0328
   Val:   Loss=0.0736, RMSE=0.2713, R²=-0.0173
============================================================


============================================================
🔄 Round 127 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 127 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0242
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0225
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2459, R²: 0.0177

📊 Round 127 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2459, R²: 0.0177

============================================================
🔄 Round 134 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 134 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0257
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0112
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2459, R²: 0.0177

============================================================
🔄 Round 135 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 135 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0288
   Val:   Loss=0.0875, RMSE=0.2957, R²=0.0164
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2459, R²: 0.0177

============================================================
🔄 Round 137 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 137 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0248
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0330
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2459, R²: 0.0177

📊 Round 137 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2459, R²: 0.0178

============================================================
🔄 Round 139 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 139 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0290
   Val:   Loss=0.0769, RMSE=0.2774, R²=0.0103
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2459, R²: 0.0178

============================================================
🔄 Round 143 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 143 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0255
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0161
============================================================


============================================================
🔄 Round 144 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 144 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0226
   Val:   Loss=0.0778, RMSE=0.2790, R²=0.0362
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2459, R²: 0.0178

📊 Round 144 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2458, R²: 0.0178

============================================================
🔄 Round 147 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 147 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0274
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0223
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2458, R²: 0.0178

============================================================
🔄 Round 150 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 150 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0305
   Val:   Loss=0.0775, RMSE=0.2783, R²=0.0043
============================================================


============================================================
🔄 Round 151 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 151 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0225
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0302
============================================================


============================================================
🔄 Round 152 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 152 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0266
   Val:   Loss=0.0745, RMSE=0.2729, R²=0.0222
============================================================


============================================================
🔄 Round 153 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 153 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0239
   Val:   Loss=0.0798, RMSE=0.2824, R²=0.0355
============================================================


============================================================
🔄 Round 155 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 155 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0307
   Val:   Loss=0.0784, RMSE=0.2799, R²=0.0049
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0180

============================================================
🔄 Round 159 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 159 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0291
   Val:   Loss=0.0883, RMSE=0.2972, R²=0.0183
============================================================


============================================================
🔄 Round 160 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 160 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0305
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0065
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0180

============================================================
🔄 Round 162 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 162 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0246
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0345
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0180

📊 Round 162 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0180

============================================================
🔄 Round 164 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 164 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0299
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0002
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0180

============================================================
🔄 Round 166 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 166 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0335
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0016
============================================================


============================================================
🔄 Round 167 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0690 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0690, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0690, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0690, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0689, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0689, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0690)

============================================================
📊 Round 167 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0237
   Val:   Loss=0.0690, RMSE=0.2626, R²=0.0417
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0180

📊 Round 167 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0180

============================================================
🔄 Round 171 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 171 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0319
   Val:   Loss=0.0805, RMSE=0.2836, R²=0.0050
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0180

📊 Round 171 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0180

============================================================
🔄 Round 176 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0673 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0673, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0673, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0673, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0673, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0672, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0673)

============================================================
📊 Round 176 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0289
   Val:   Loss=0.0673, RMSE=0.2594, R²=0.0171
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0180

============================================================
🔄 Round 181 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 181 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0177
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0622
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0181

============================================================
🔄 Round 182 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 182 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0324
   Val:   Loss=0.0745, RMSE=0.2730, R²=0.0017
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0180

============================================================
🔄 Round 183 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 183 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0311
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0010
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0180

============================================================
🔄 Round 184 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 184 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0283
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0176
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0180

📊 Round 184 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0180

📊 Round 184 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0181

============================================================
🔄 Round 190 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 190 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0246
   Val:   Loss=0.0875, RMSE=0.2957, R²=0.0354
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0180

============================================================
🔄 Round 193 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 193 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0268
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.0288
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0180

============================================================
🔄 Round 195 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 195 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0259
   Val:   Loss=0.0847, RMSE=0.2911, R²=0.0291
============================================================


============================================================
🔄 Round 197 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 197 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0258
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0137
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0181

📊 Round 197 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0181

============================================================
🔄 Round 201 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 201 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0263
   Val:   Loss=0.0868, RMSE=0.2946, R²=0.0272
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0181

============================================================
🔄 Round 202 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 202 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=0.0240
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0243
============================================================


============================================================
🔄 Round 203 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 203 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0278
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0252
============================================================


============================================================
🔄 Round 206 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 206 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0272
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0178
============================================================


============================================================
🔄 Round 207 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 207 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0280
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0238
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0181

============================================================
🔄 Round 208 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 208 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0296
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0148
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0181

============================================================
🔄 Round 209 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 209 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0223
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0477
============================================================


============================================================
🔄 Round 210 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 210 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0265
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0265
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0182

============================================================
🔄 Round 216 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 216 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=0.0225
   Val:   Loss=0.0784, RMSE=0.2801, R²=0.0445
============================================================


============================================================
🔄 Round 217 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 217 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=0.0306
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0115
============================================================


📊 Round 217 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0183

============================================================
🔄 Round 220 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 220 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0295
   Val:   Loss=0.0736, RMSE=0.2712, R²=0.0093
============================================================


📊 Round 220 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0183

📊 Round 220 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0183

📊 Round 220 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0183

============================================================
🔄 Round 224 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 224 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0255
   Val:   Loss=0.0767, RMSE=0.2770, R²=0.0350
============================================================


📊 Round 224 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0183

============================================================
🔄 Round 226 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 226 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0155
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0741
============================================================


============================================================
🔄 Round 227 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 227 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0277
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0260
============================================================


📊 Round 227 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0183

📊 Round 227 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0183

📊 Round 227 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0183

📊 Round 227 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0183

============================================================
🔄 Round 233 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 233 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0302
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0051
============================================================


📊 Round 233 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0183

📊 Round 233 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0183

============================================================
🔄 Round 237 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 237 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0254
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0365
============================================================


📊 Round 237 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0183

📊 Round 237 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0183

============================================================
🔄 Round 241 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 241 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0324
   Val:   Loss=0.0909, RMSE=0.3015, R²=0.0103
============================================================


📊 Round 241 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0183

📊 Round 241 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0183

📊 Round 241 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0183

📊 Round 241 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0183

📊 Round 241 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0183

📊 Round 241 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0183

============================================================
🔄 Round 255 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 255 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0279
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0258
============================================================


📊 Round 255 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0183

📊 Round 255 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0183

============================================================
🔄 Round 259 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 259 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0276
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0274
============================================================


============================================================
🔄 Round 260 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 260 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0245
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0324
============================================================


📊 Round 260 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0184

============================================================
🔄 Round 263 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 263 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0245
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0413
============================================================


📊 Round 263 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0184

============================================================
🔄 Round 265 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 265 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0238
   Val:   Loss=0.0913, RMSE=0.3022, R²=0.0376
============================================================


============================================================
🔄 Round 266 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 266 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0284
   Val:   Loss=0.0813, RMSE=0.2850, R²=0.0214
============================================================


📊 Round 266 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0184

📊 Round 266 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0184

============================================================
🔄 Round 270 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 270 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0259
   Val:   Loss=0.0873, RMSE=0.2954, R²=0.0357
============================================================


📊 Round 270 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0184

============================================================
🔄 Round 273 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 273 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0268
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0332
============================================================


============================================================
🔄 Round 275 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 275 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0236
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0401
============================================================


============================================================
🔄 Round 276 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 276 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0273
   Val:   Loss=0.0833, RMSE=0.2887, R²=0.0258
============================================================


📊 Round 276 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0184

============================================================
🔄 Round 279 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 279 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0230
   Val:   Loss=0.0838, RMSE=0.2894, R²=0.0362
============================================================


📊 Round 279 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0184

📊 Round 279 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0185

📊 Round 279 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0184

📊 Round 279 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0184

📊 Round 279 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0184

📊 Round 279 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0184

============================================================
🔄 Round 288 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 288 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2903, R²=0.0308
   Val:   Loss=0.0726, RMSE=0.2695, R²=0.0134
============================================================


📊 Round 288 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0184

============================================================
🔄 Round 289 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 289 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0281
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0284
============================================================


📊 Round 289 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0184

============================================================
🔄 Round 294 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 294 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0325
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0090
============================================================


📊 Round 294 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0185

📊 Round 294 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0185

============================================================
🔄 Round 296 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 296 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0290
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0231
============================================================


📊 Round 296 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0185

📊 Round 296 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0186

📊 Round 296 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2458, R²: 0.0186

============================================================
🔄 Round 301 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 301 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0233
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0439
============================================================


============================================================
🔄 Round 304 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 304 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0301
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0088
============================================================


📊 Round 304 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: 0.0186

============================================================
🔄 Round 312 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 312 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0306
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0141
============================================================


📊 Round 312 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: 0.0186

============================================================
🔄 Round 316 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 316 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0260
   Val:   Loss=0.0930, RMSE=0.3049, R²=0.0071
============================================================


📊 Round 316 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: 0.0186

============================================================
🔄 Round 317 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 317 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0272
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0330
============================================================


============================================================
🔄 Round 318 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 318 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0339
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0038
============================================================


📊 Round 318 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: 0.0187

============================================================
🔄 Round 320 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 320 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0252
   Val:   Loss=0.0728, RMSE=0.2698, R²=0.0319
============================================================


📊 Round 320 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: 0.0187

============================================================
🔄 Round 321 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 321 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0272
   Val:   Loss=0.0787, RMSE=0.2806, R²=0.0274
============================================================


📊 Round 321 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: 0.0187

============================================================
🔄 Round 323 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 323 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0286
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0281
============================================================


📊 Round 323 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: 0.0187

============================================================
🔄 Round 325 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 325 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0215
   Val:   Loss=0.0724, RMSE=0.2691, R²=0.0602
============================================================


📊 Round 325 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: 0.0187

📊 Round 325 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: 0.0188

============================================================
🔄 Round 328 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 328 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0318
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0137
============================================================


============================================================
🔄 Round 330 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 330 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0241
   Val:   Loss=0.0730, RMSE=0.2701, R²=0.0340
============================================================


📊 Round 330 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: 0.0188

============================================================
🔄 Round 333 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0712 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 333 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=0.0221
   Val:   Loss=0.0712, RMSE=0.2668, R²=0.0560
============================================================


📊 Round 333 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: 0.0188

📊 Round 333 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: 0.0188

============================================================
🔄 Round 336 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 336 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=0.0322
   Val:   Loss=0.0779, RMSE=0.2792, R²=0.0136
============================================================


📊 Round 336 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: 0.0188

============================================================
🔄 Round 337 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 337 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0302
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0183
============================================================


📊 Round 337 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: 0.0188

============================================================
🔄 Round 338 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 338 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0271
   Val:   Loss=0.0818, RMSE=0.2859, R²=0.0222
============================================================


============================================================
🔄 Round 339 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 339 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0271
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0175
============================================================


📊 Round 339 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: 0.0188

============================================================
🔄 Round 340 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 340 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0355
   Val:   Loss=0.0733, RMSE=0.2707, R²=-0.0054
============================================================


============================================================
🔄 Round 341 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 341 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0263
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0381
============================================================


============================================================
🔄 Round 342 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 342 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0260
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0382
============================================================


============================================================
🔄 Round 343 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 343 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0233
   Val:   Loss=0.0921, RMSE=0.3035, R²=0.0189
============================================================


📊 Round 343 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: 0.0187

📊 Round 343 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: 0.0187

📊 Round 343 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: 0.0187

📊 Round 343 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: 0.0187

============================================================
🔄 Round 352 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 352 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0273
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0349
============================================================


📊 Round 352 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: 0.0187

============================================================
🔄 Round 353 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 353 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0259
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0202
============================================================


📊 Round 353 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: 0.0187

============================================================
🔄 Round 355 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 355 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0320
   Val:   Loss=0.0855, RMSE=0.2923, R²=0.0009
============================================================


============================================================
🔄 Round 359 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 359 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0274
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0337
============================================================


📊 Round 359 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2458, R²: 0.0186

📊 Round 359 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2458, R²: 0.0186

============================================================
🔄 Round 363 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 363 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0274
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0288
============================================================


============================================================
🔄 Round 366 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 366 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0262
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0395
============================================================


============================================================
🔄 Round 369 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 369 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0308
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0186
============================================================


============================================================
🔄 Round 370 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 370 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0271
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0349
============================================================


📊 Round 370 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: 0.0187

📊 Round 370 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: 0.0187

============================================================
🔄 Round 375 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 375 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0295
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0263
============================================================


📊 Round 375 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: 0.0188

============================================================
🔄 Round 377 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 377 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0262
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0388
============================================================


============================================================
🔄 Round 379 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 379 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0253
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0394
============================================================


============================================================
🔄 Round 380 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 380 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0322
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0155
============================================================


📊 Round 380 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: 0.0187

============================================================
🔄 Round 382 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 382 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0269
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0169
============================================================


📊 Round 382 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: 0.0188

📊 Round 382 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: 0.0187

📊 Round 382 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: 0.0187

============================================================
🔄 Round 387 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 387 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0293
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0244
============================================================


============================================================
🔄 Round 388 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 388 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0329
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0115
============================================================


============================================================
🔄 Round 389 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 389 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0274
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0352
============================================================


============================================================
🔄 Round 390 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 390 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0322
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0147
============================================================


📊 Round 390 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: 0.0188

============================================================
🔄 Round 392 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 392 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0305
   Val:   Loss=0.0838, RMSE=0.2896, R²=0.0099
============================================================


📊 Round 392 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: 0.0188

📊 Round 392 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: 0.0189

============================================================
🔄 Round 394 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 394 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0289
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0282
============================================================


📊 Round 394 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: 0.0188

============================================================
🔄 Round 395 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 395 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0306
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0116
============================================================


📊 Round 395 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: 0.0188

📊 Round 395 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: 0.0188

============================================================
🔄 Round 399 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0699 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0699, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0699, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0699, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 399 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0236
   Val:   Loss=0.0699, RMSE=0.2643, R²=0.0489
============================================================


📊 Round 399 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: 0.0188

📊 Round 399 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: 0.0188

============================================================
🔄 Round 403 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 403 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2884, R²=0.0261
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0413
============================================================


📊 Round 403 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: 0.0189

============================================================
🔄 Round 404 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 404 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0310
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0202
============================================================


📊 Round 404 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: 0.0189

============================================================
🔄 Round 406 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 406 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0143
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0449
============================================================


📊 Round 406 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: 0.0189

============================================================
🔄 Round 409 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 409 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0242
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0450
============================================================


📊 Round 409 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: 0.0189

============================================================
🔄 Round 411 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 411 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0331
   Val:   Loss=0.0900, RMSE=0.3000, R²=0.0044
============================================================


============================================================
🔄 Round 414 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 414 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0339
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0090
============================================================


📊 Round 414 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: 0.0190

============================================================
🔄 Round 416 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 416 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0339
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0069
============================================================


📊 Round 416 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: 0.0190

============================================================
🔄 Round 417 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 417 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0286
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0313
============================================================


📊 Round 417 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: 0.0190

============================================================
🔄 Round 419 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 419 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0302
   Val:   Loss=0.0778, RMSE=0.2790, R²=0.0170
============================================================


📊 Round 419 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: 0.0190

============================================================
🔄 Round 420 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 420 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0257
   Val:   Loss=0.0805, RMSE=0.2838, R²=0.0434
============================================================


============================================================
🔄 Round 421 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 421 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0284
   Val:   Loss=0.0755, RMSE=0.2747, R²=0.0320
============================================================


============================================================
🔄 Round 423 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 423 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0305
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0185
============================================================


📊 Round 423 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: 0.0191

============================================================
🔄 Round 424 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 424 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0287
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0277
============================================================


📊 Round 424 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: 0.0191

============================================================
🔄 Round 426 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 426 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0381
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0107
============================================================


============================================================
🔄 Round 427 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 427 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0350
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0024
============================================================


📊 Round 427 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: 0.0191

============================================================
🔄 Round 428 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0677 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0677, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0677, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0677, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0677, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0677, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0677)

============================================================
📊 Round 428 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0274
   Val:   Loss=0.0677, RMSE=0.2601, R²=0.0341
============================================================


📊 Round 428 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: 0.0191

============================================================
🔄 Round 431 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 431 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0306
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0138
============================================================


📊 Round 431 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: 0.0191

📊 Round 431 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: 0.0191

📊 Round 431 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: 0.0191

📊 Round 431 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: 0.0191

============================================================
🔄 Round 436 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 436 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0287
   Val:   Loss=0.0735, RMSE=0.2711, R²=0.0309
============================================================


============================================================
🔄 Round 438 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 438 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0387
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0204
============================================================


📊 Round 438 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: 0.0191

============================================================
🔄 Round 441 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 441 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0314
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0188
============================================================


📊 Round 441 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: 0.0191

📊 Round 441 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: 0.0191

============================================================
🔄 Round 444 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 444 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0323
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0180
============================================================


============================================================
🔄 Round 445 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 445 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0305
   Val:   Loss=0.0889, RMSE=0.2981, R²=0.0258
============================================================


📊 Round 445 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2457, R²: 0.0192

============================================================
🔄 Round 446 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 446 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0294
   Val:   Loss=0.0763, RMSE=0.2763, R²=0.0266
============================================================


📊 Round 446 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2457, R²: 0.0192

============================================================
🔄 Round 448 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 448 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0323
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0184
============================================================


📊 Round 448 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2457, R²: 0.0192

📊 Round 448 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2457, R²: 0.0192

============================================================
🔄 Round 450 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 450 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0268
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0101
============================================================


📊 Round 450 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2457, R²: 0.0192

📊 Round 450 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2457, R²: 0.0192

============================================================
🔄 Round 452 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 452 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0318
   Val:   Loss=0.0887, RMSE=0.2978, R²=0.0214
============================================================


📊 Round 452 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: 0.0193

📊 Round 452 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: 0.0193

📊 Round 452 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: 0.0193

============================================================
🔄 Round 460 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 460 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0304
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0158
============================================================


============================================================
🔄 Round 461 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 461 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0341
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0090
============================================================


📊 Round 461 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: 0.0193

============================================================
🔄 Round 463 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 463 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0258
   Val:   Loss=0.0894, RMSE=0.2991, R²=0.0433
============================================================


📊 Round 463 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: 0.0193

============================================================
🔄 Round 465 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 465 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0252
   Val:   Loss=0.0902, RMSE=0.3003, R²=0.0443
============================================================


============================================================
🔄 Round 466 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 466 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0277
   Val:   Loss=0.0856, RMSE=0.2927, R²=0.0374
============================================================


📊 Round 466 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: 0.0193

============================================================
🔄 Round 468 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 468 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0298
   Val:   Loss=0.0826, RMSE=0.2873, R²=0.0288
============================================================


📊 Round 468 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2457, R²: 0.0193

📊 Round 468 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2457, R²: 0.0192

============================================================
🔄 Round 474 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 474 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0321
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0199
============================================================


📊 Round 474 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2457, R²: 0.0192

============================================================
🔄 Round 476 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 476 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0298
   Val:   Loss=0.0745, RMSE=0.2730, R²=0.0294
============================================================


📊 Round 476 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: 0.0193

============================================================
🔄 Round 479 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 479 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0332
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0118
============================================================


📊 Round 479 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: 0.0193

============================================================
🔄 Round 482 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 482 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0283
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0309
============================================================


📊 Round 482 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: 0.0193

============================================================
🔄 Round 484 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 484 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0335
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0145
============================================================


📊 Round 484 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: 0.0193

📊 Round 484 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: 0.0193

============================================================
🔄 Round 491 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 491 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0339
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0041
============================================================


============================================================
🔄 Round 493 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 493 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0235
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0400
============================================================


📊 Round 493 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: 0.0193

============================================================
🔄 Round 499 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 499 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0320
   Val:   Loss=0.0747, RMSE=0.2734, R²=-0.0056
============================================================


============================================================
🔄 Round 501 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 501 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0310
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0222
============================================================


📊 Round 501 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: 0.0193

📊 Round 501 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: 0.0193

============================================================
🔄 Round 503 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 503 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0307
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0263
============================================================


============================================================
🔄 Round 505 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 505 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0347
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0091
============================================================


📊 Round 505 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: 0.0193

============================================================
🔄 Round 506 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 506 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0294
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0219
============================================================


📊 Round 506 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: 0.0193

============================================================
🔄 Round 508 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 508 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0287
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0310
============================================================


📊 Round 508 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: 0.0193

============================================================
🔄 Round 509 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 509 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0374
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0047
============================================================


============================================================
🔄 Round 510 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 510 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0302
   Val:   Loss=0.0884, RMSE=0.2972, R²=0.0279
============================================================


📊 Round 510 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: 0.0194

============================================================
🔄 Round 511 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 511 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0325
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0194
============================================================


============================================================
🔄 Round 512 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 512 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0361
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0032
============================================================


📊 Round 512 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: 0.0194

============================================================
🔄 Round 513 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 513 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0369
   Val:   Loss=0.0923, RMSE=0.3038, R²=0.0050
============================================================


📊 Round 513 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: 0.0194

📊 Round 513 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: 0.0194

📊 Round 513 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: 0.0194

============================================================
🔄 Round 522 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 522 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0281
   Val:   Loss=0.0760, RMSE=0.2758, R²=0.0380
============================================================


============================================================
🔄 Round 523 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 523 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0360
   Val:   Loss=0.0896, RMSE=0.2994, R²=0.0063
============================================================


📊 Round 523 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: 0.0194

📊 Round 523 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: 0.0194

============================================================
🔄 Round 527 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 527 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0300
   Val:   Loss=0.0882, RMSE=0.2970, R²=0.0286
============================================================


📊 Round 527 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: 0.0194

📊 Round 527 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: 0.0194

📊 Round 527 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: 0.0194

============================================================
🔄 Round 530 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 530 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0291
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0290
============================================================


📊 Round 530 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: 0.0194

📊 Round 530 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: 0.0194

============================================================
🔄 Round 535 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 535 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0276
   Val:   Loss=0.0878, RMSE=0.2964, R²=0.0378
============================================================


📊 Round 535 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: 0.0193

============================================================
🔄 Round 539 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 539 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0226
   Val:   Loss=0.0853, RMSE=0.2920, R²=0.0528
============================================================


📊 Round 539 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: 0.0193

============================================================
🔄 Round 546 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 546 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0343
   Val:   Loss=0.0790, RMSE=0.2810, R²=0.0017
============================================================


📊 Round 546 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2457, R²: 0.0192

📊 Round 546 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2457, R²: 0.0192

============================================================
🔄 Round 550 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0695 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0695, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0695, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0695, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0695, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0696, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0695)

============================================================
📊 Round 550 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0280
   Val:   Loss=0.0695, RMSE=0.2637, R²=0.0291
============================================================


📊 Round 550 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2457, R²: 0.0192

============================================================
🔄 Round 552 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 552 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0301
   Val:   Loss=0.0765, RMSE=0.2767, R²=0.0155
============================================================


============================================================
🔄 Round 554 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 554 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0278
   Val:   Loss=0.0863, RMSE=0.2937, R²=0.0276
============================================================


📊 Round 554 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2457, R²: 0.0192

============================================================
🔄 Round 555 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 555 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0284
   Val:   Loss=0.0745, RMSE=0.2729, R²=0.0328
============================================================


============================================================
🔄 Round 557 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 557 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0308
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0262
============================================================


📊 Round 557 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2457, R²: 0.0192

============================================================
🔄 Round 561 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 561 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0307
   Val:   Loss=0.0888, RMSE=0.2980, R²=0.0259
============================================================


============================================================
🔄 Round 562 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 562 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0257
   Val:   Loss=0.0756, RMSE=0.2749, R²=0.0398
============================================================


📊 Round 562 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: 0.0193

============================================================
🔄 Round 564 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 564 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0377
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0065
============================================================


📊 Round 564 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: 0.0194

============================================================
🔄 Round 569 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 569 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0316
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0205
============================================================


📊 Round 569 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: 0.0193

📊 Round 569 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: 0.0193

============================================================
🔄 Round 575 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 575 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0329
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0093
============================================================


📊 Round 575 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: 0.0193

❌ Client client_13 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_status:14, grpc_message:"Socket closed"}"
>
