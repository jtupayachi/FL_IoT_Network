[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86de8f74-fa54-4aff-a4a6-cacfbc6d4bd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3c8608f-c918-4efd-83e2-ae4d9ed25fac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e610522-c16d-42f3-a331-f587dd3b5dd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c90fe026-0030-4443-93cb-1185eba971bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e84f5d8-a4e5-4460-ae22-abd77914b3e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a149e267-1525-4bff-a814-c7620a3da3c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea66932a-5448-479f-b169-9c7a4dd6d22d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b14c86a-d277-4908-8a98-7debb601cc98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12aa2e1c-8d4b-4424-8879-3005b9f63c7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e80a8283-8d04-4ae7-9758-7735189ba3b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b476024-c8d1-4496-b821-e84c96fa30a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f753a6c-d37a-4708-a5e8-42d3f933c8ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88f63de1-e504-4d91-997a-f3f8e9ecdea4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c120b182-38df-46a0-8da6-01e17c1d5349
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0477e839-014e-404b-86d4-21d644930c9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e702f1be-06d3-4ed2-bf59-8bb6baa1b324
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8f268aa-5eff-4b0b-bfaf-b923caebb8af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9718a6d2-a360-487b-8fea-d4e66234a6ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d5432c1-082a-47c5-9b34-69d52aa7e39e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa5116ce-7ad1-433d-85a8-6e8865817247
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6dd23d7-4502-49dd-9962-727e444fa9b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbd62e0a-3a74-40f2-8a82-73159670036c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34d5b5fa-5609-43af-8529-991a2cb07135
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d68d954-2296-46b5-9651-de8465a42b03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 009a5ed3-58ec-43f9-a431-d63c3877d294
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 087c6166-f498-4713-8c8a-14bead48956a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d15d4bd5-98c9-403f-9fa4-1902a07ed313
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 328efacf-d47b-44a6-9ffe-379157cda289
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 825803c8-3fbe-479b-b147-4a76f88bc8ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afe88f5d-f541-4929-b02e-9571a23bcfa7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0939cfe1-1632-4d9b-8616-badf32802a32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1399e3c-2f84-434b-a512-7bece65135b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8491f18-c7f1-4b6e-ada1-a75012c087db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd20cfda-9623-49ae-b152-461fb5d8156d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78e95b5d-6954-497a-8dcc-863d06a6e62a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f16d7269-a4b3-40b9-8397-673f790382ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21b66ecc-dba8-439f-bc95-81b9d7485e31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ce627ab-cd81-47b6-a2b1-dfcc4a9df33d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5785e812-b055-4016-a5d0-b61b8ced3724
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c2d428f-6f04-4faa-ad51-cd76a39d029c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9cf583f6-dd91-472c-b396-9e0a1a9770c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9cd11606-026a-440c-a803-b11770e103ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 559bb559-0f42-400f-ae52-4d41ceac0a55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f271cfd-aa4a-433e-a8b1-57fc02ccc7ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9feaf7da-95b2-4a5a-8b3c-03ec23261052
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 840b0b10-13d5-4f0d-821f-1724ec7fe694
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afa6c4bf-6819-4ccb-8299-7046069b121a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be9661d1-9257-4942-b4e9-821dcbbe6bef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f9cde76-efb8-4020-ba8e-5942b7fb2d65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e620c9e1-3c4c-4641-a63a-5dfc43b7d077
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c00608b-8326-454c-ab6e-bf5dc50c1f99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf7bd7f2-95f5-4792-b845-6f6234f8ff69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 259ca834-b988-4a21-8f4e-853f7f7b8cb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2addac67-9d12-4eca-acd9-14262ff587f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d82ab02-933f-40b0-9f1b-6c5e2763ca11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d11770a0-26a6-4b31-850f-4550132fd4eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8865010a-ffeb-42ff-8c17-d5d524f5bc53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e290c95-c725-4fde-8f09-de4d37d0cc0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5cfd3fe-7acc-4702-b630-6e508f7f1c18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29be2827-64c4-4390-ac65-b45e0d3b2031
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 424330a1-95e7-4d4e-a329-bbe0e24c147b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a5ab158-2be3-478c-90d2-467f6d2e9259
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2293d266-7ca0-4638-81d4-fb8845c8acd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64375f48-7522-45eb-9804-7d534b6fe9b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82e4eab8-4c3c-4698-9c6b-7732395c3498
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dae49d18-3b8c-42b3-bf16-d9dca3b464a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d752b97e-f89f-427c-bebc-1617ebd0f128
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 055a84ee-1df2-4948-91eb-80d0948a9266
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6e52c24-46e7-4670-b0dd-fc9beffa9513
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef7eba9c-2ebb-41c9-944a-0826a69e33b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7f7bf46-e024-4702-9835-f61d1f47037a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d38f4cce-fab1-4092-b0da-a99b4ab85a30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afd5c87d-64bf-4fba-bfd0-89ba9c97c085
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d00f23c-e3ea-41c7-b51f-e896967c78e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e73bc652-116f-4a35-87d9-8138d6d0a78a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c342d13-890c-48c5-a23b-40a892440cb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2984599c-dbb4-419f-858f-e94c292a07bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 751f020d-1a35-4b86-9309-833b47e5b7ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2417dea0-e6af-4fad-9f2b-65d196db9006
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69b8b78b-c1b6-4191-b28f-1de7d7ba8005
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c113acfc-f36a-43f1-8662-c5c813fccb70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a957b8e0-b8f4-41ec-a166-5f59681ac9d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 305985bc-e660-4604-a014-1239df48542f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54f778e0-96cc-45b9-b67a-48f79c183f0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83aa974f-5967-4985-9cba-9ae208ae1775
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ac6e374-40fb-4cc9-9397-537aea3b4e0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8476d703-d755-43f2-bf6a-d2c0f2c3e6ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84eb65c0-802d-4430-8e40-3d454cc08837
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11244f6e-d81e-4011-ad7b-b2a0acfdf428
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b0095a3-dcca-46a2-94e1-face92e4cd16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d0c4f01-c54a-48d6-a6a6-561daa2c9ba7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 744b385f-c660-4871-be07-e558635d10e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1422fbc8-1b71-4550-b968-5c9e6d12da14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90e99c98-acd6-44c9-a9c7-428f8b329e0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e9783ca-6342-402d-bb9d-23a723e09bc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1053db6-4c28-4a93-afbc-e97877f6ab1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dccfdd1e-5659-4f48-9653-6fe004bd776d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 312c67ad-57aa-4379-992c-deec05181d4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7247e0b6-d2d7-4ed1-b5f1-c4eb1e9c19d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f929faa-c232-4719-89f6-6045111ae2db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfbd8e18-37d6-4416-a0cd-62cbf7230588
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58b8dbc5-f522-414e-8945-7662668019b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 277af8c0-1e55-4905-9769-9e43b4e1354e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ace60ce-4047-4bf7-af3f-da2a3e64a79b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f319018-64f4-47cc-9a51-6c07af706ae2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 568f6c77-d7dc-4abe-b535-8af9fe697a65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3743c81b-ca7f-4d57-b4b9-8e1cc4ad0c2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ebddde9-f40b-4d58-8917-9c5c284bef76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7efaac4-a80a-47db-800a-34f898f3c611
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 071da91c-2a5f-4ad9-bcd5-7a03a30edb14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebd895c3-d0f6-460d-9dd5-374200065a08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf2a5b98-0657-4c71-9e4b-1620049202b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8c0efc1-6980-4ded-bdd4-92ccb4bc392f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb8c6570-9690-46d2-904f-230637d5c4b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8209eda0-ac60-460a-8e02-64ac73e6edf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dccfc6da-dba7-47b6-88ed-8ebd08894268
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6ac022d-ac58-4454-a18a-d27eee7d24f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e594cec-05d1-41b9-b061-e0ce857d334a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 295603c5-81ab-4ee7-8bdb-f67dd08c2019
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4a073e2-def8-4a14-9116-6217270ac295
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0271873-a15e-4205-8dd2-b1683d583c73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f017d690-1967-4c8f-872f-bc6e3c8d67eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a976710-2428-475a-9dc7-6c6812aa3f9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58adebb7-d8c5-49e3-852d-147986ff10f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0fb5656-68f1-4142-a642-e4a2f8e9a5f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f76ba3f-ebb9-4847-a89b-4be1769da341
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 568dc318-6509-485d-a92b-8f773747b050
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86cdd965-e28e-45ad-8012-2433a93d78fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 079499e1-c948-4b39-8a6f-6c9646de6cf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc3ce6b7-05e3-456b-999b-b0aada9e50dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a45830ae-aa44-4134-bcf3-2d3690423cbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b1f4528-5842-4f72-8f2d-7cf0036ea7ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 036e0aa6-c888-4e6d-8a00-88d32c1889e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a36d1ea3-6b6b-43ba-9b4e-821e33faf52c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b927a0d-4fe8-4986-a1f9-5c9b983ab953
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1c8fc9e-fda5-42ef-bc81-91147b9285fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4623c05-8f19-42cf-bfa7-9d56f58ea5a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9c1de88-5f9c-4e05-8975-106bcf4e8b4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6154589-7815-4b92-8030-7c9f1cf5ab18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3730c673-366a-4b06-b3d3-e6fc739e59a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec010ef1-4c6b-4473-8a0b-eb7e757da7e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f58f65dc-d9ec-4bc9-8155-b9097478a431
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 006d469a-c391-4767-ade3-34131822bf83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ced2628-7424-44ee-8593-57dc20ea8469
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 309f2ef7-42ed-4686-9aba-a4d590b034d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfedefd7-6e57-4938-9e3e-77616a570fe3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f9abad9-96ac-4b85-b301-e7dfe59ccf57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b8e28ba-85b9-4efe-9bdc-945d5fa76fe0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9980ad56-cba4-4b40-815c-7100ecc6937b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d65a75ac-cec9-4053-9595-cfaf277fd63b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aaf56f83-b1fa-4883-abc0-072de3bdea64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc67995a-316d-4705-a907-ff5af315fbfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9451d152-44d4-4a5d-ba20-7f2279095b97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a5f29f5-d56b-439c-8862-f0a9805714a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b751af93-a4fc-4748-b35c-d43ea229bd05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0717571-7e22-4bab-bda8-6ec3bb87db0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45b001b5-b080-4783-92e2-458960077deb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5515ff32-d34d-4f16-a24f-cd036d99fbb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4835311f-1f6b-410a-853d-75f084cd59ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e4289ff-acb2-4211-a56d-16bf7a146f7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d29e33d2-e658-464d-b2c2-70c9ef67883d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c99a5e36-6de2-4ff3-8981-4b2b7b1add2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 673bb3c0-4871-49a5-b50c-51008bd3d204
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3545584a-ff80-45a3-b0df-b711f24bc45f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4abbe9b9-5d08-4f6a-bda5-23303169052f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af65b3b0-41a6-4800-b5c9-5f743ae4319d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b7615c9-a642-418b-b893-5c961d543c72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f2f97b2-889d-49d3-9238-213b8fb26491
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cde4ac74-5a4a-4e8f-9971-3dc0a6ca63ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d6f5cea-e98e-4c11-a905-47d0e10150b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cc758b2-d942-4ec3-90f2-e7e58e1cb268
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58fa4fa7-3f94-4edc-a3b1-7e54e14f7500
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33d51315-59de-4180-9bb4-5209552f862b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b69337d-fc33-4023-9e5d-2ddfe0db3511
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef109e72-2b38-488e-95a1-1810af501907
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 067ef19a-9da3-4bec-84ef-2e0731150d5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d491f00-eb81-47c8-9102-96ddf40300c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abcb180b-576c-44f9-b4ad-68a52f7188c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60d92f3a-fcf3-418e-8005-57f9eb6c194e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a12b5fb-00f0-46c6-815f-9c6ec0b85878
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f20274b-7eae-4f5a-b753-66a6abdffce7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a94c32b9-33bc-4abf-b7bc-f959de31ad91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26202da0-95da-418a-afc0-b38632fda6dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa6f39ad-56d7-4b2e-a9d6-93f9d042666d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea1859d2-8f9d-467e-a6b9-acf81c34541f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54492a61-4e5e-4f52-8f39-d612f61686d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52b5a9ff-a8c2-4266-84c6-32a0c3df0107
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 880b1fbd-0504-4fcf-a23a-cffdeebfb8ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbb81516-5d0b-4e84-96e5-be0a25468658
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12f25a13-6fe9-47a4-ab5b-ae50f9961bd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8b7754b-ff20-44ea-a753-737bf4dc7383
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a27290ad-bf03-4152-9a30-ce649f286fb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5339e232-8fc9-48d9-a810-1f867102a031
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09451583-68a9-41df-b536-1195d7a5bc86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 001491fc-df1c-432a-b639-79ef143a21e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97d718b5-60e0-4376-94b2-a8efca5b6abb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97bf49fd-3275-49cf-9672-2c4c23a572bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d9b715b-844f-4768-865a-eadaa9d81f0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09c60c7b-e476-431c-a1e7-3602891ccc4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6feeb9a-35b0-4659-aa0d-2d4ec22638d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7f1b2f0-d244-464f-bd77-d9a3378efd23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1654577f-a18d-4016-a528-ccc977605629
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 395ee4d3-8cdc-4dd6-87e0-44cb9e3b7817
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4657800d-9163-407d-b22a-03322641507d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b3a2c58-2396-4efb-a7c1-294af36bde63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 103e8c05-dcb7-4d9e-8416-c7a63ce95702
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55aa0ed0-3ce6-4aa0-9cce-7f2472e0ffd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2307887-b688-42c8-a2bf-87d1fac22cfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f04ff4f-da73-43e0-9b05-62621dceb7e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbf1d8d4-04e2-4827-9c17-ddf3a2e90138
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b034cdc-651f-4b79-b6a2-735917ddc6b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3369408-86c2-4e75-84a1-559ec3c97ce5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbe18592-a65a-4a37-ba74-5901c191cb63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a29ae11-f7cc-4857-8723-de98c4f8d957
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 219bcef8-bb12-4a4f-be36-9294fde74d92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54a633e2-0fca-4816-a34d-00e7efc73dc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 628fc78d-9a3d-4511-be36-5d54309e0f0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c1934b9-6adb-40d1-ba0b-8818022b6014
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69082465-3450-4edf-b08b-bd6b017be94f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ebe23d5-fad0-42db-92ba-ff528572efcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ff1c82f-ae46-4a19-9ffe-18fefb90be63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85aedb6c-6190-4c1a-8b79-019184fe40af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59d98899-17f6-4cf0-8fa1-7b808beebd29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 959ef89f-e2b6-41b5-948a-7e9c3a3cdca1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b1d130e-7b98-45cf-9e20-5e676972bce6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94f97b95-d1d5-4e4d-9527-7edc94d6e720
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd8190ad-e7e7-4c73-86b4-14aa4ea482bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 699877b5-48e4-4106-8aa1-cb110cb28a52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a573942b-2490-45a9-8a5f-5e0163619d21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c2c812c-575c-4481-81cd-068aba31ccb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fb29cdb-7286-4a66-a6a2-0d22aaf21175
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2e86a29-42e5-4df5-ab7c-6ef9f6089f84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afa4bb11-1327-412a-9604-e20ab4dc5fe6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9e05614-6f0a-447e-b4a8-b04f789bee0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 746fe621-3736-4c17-9dd8-76b63d82ac64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 021119d4-dff4-40b8-82bf-7a8137bbde8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b664581c-2bba-42be-9c89-1e48b326b71c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 028f00c7-2448-47ac-9f3e-fb72704716ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f78ed5b-da08-4db7-9a62-aa0cd1a43555
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b30b209-95b2-44b2-9388-073fcdc25e5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f94eb870-7761-4312-99bd-51f39427125e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c977c9c-bda8-4e5e-99b3-cd7e209724f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a036cfd7-6e87-4f26-9499-4673085d52ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2f2fce9-aaaa-4318-b0c7-bafd94795878
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4ad3140-9bfa-493e-bede-04f49734eb70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c393437-381b-4fbd-ad32-811ad7b0c956
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6254bead-16a5-49cb-bde4-faccec4e297a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87bcb038-328d-43eb-9c7f-c3555a9373fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18524be5-56be-486a-a445-e0ad0d281800
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b237607f-52cd-4419-9a6a-bb8cf3246a12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9b48bed-1a4e-4e38-8558-5a079bed506c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad516a4c-8fd3-4b28-84d5-645ca24610bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94f8689e-9e45-4a4e-a902-0cc5603c737d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea450858-49e6-49c8-a0f7-c86777c1bf74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df3ccf64-4544-4b97-be79-a7387d830c5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2cafcdd-29d8-43ce-b5d3-38e410fb01cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88abe5b1-9f76-4728-b4e6-22f5292b3b3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3f3136a-5f53-46bb-8b04-43d22bfb68a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29e155b6-5204-4f28-ac2d-de2878fa8375
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c368a20b-b64d-4dc1-83f9-62a36b7eb6a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a85e756e-054c-4d13-85c7-0cd6d877f793
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ae3a714-24b7-4a45-8f43-02949ba53bbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8257d0d5-1bf5-4e41-8a5b-fec2d26813d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3771c64-5846-491a-a7c3-16537b094dda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ad9d96b-e2f1-49bc-9f4f-735a145d9f9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87428bc7-9c55-4c31-9598-73b5b7105923
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a0c4095-af8c-4e1e-abae-ef0abf27e3c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34bd3280-1471-43a6-bff1-e1284da70d3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5db66b4-05c7-432d-9ab3-f02d45d815e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2059fbc2-9eeb-4f74-93c5-35b73fd68ddc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8604aef5-4b3e-4eea-8d00-5002b5b45e1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f75fe32-663d-4e36-b3cc-50f7d5ce2a6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf41447d-62e5-47b2-b6a6-b79830d27a7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10a331b4-cff7-49b0-8618-c652cd474748
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dcc5a2dc-1b77-43f2-a062-e659f2e12979
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df8bad93-6b17-4d34-970b-26205eae2041
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d19dc64d-5204-46e7-86b6-d185fb47ec1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b4a09d4-16fb-4639-af83-5ca42160faae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 661f60a6-8ef2-441a-aaf1-9cb34e2b9bd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a0132fe-5799-48d7-b050-5eda0af32713
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3b480ed-19d8-485e-8414-c4a45469f125
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ccbc91b-c480-4f93-9302-e1dc773a0884
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6441b5df-5a3c-4f32-a497-660f09936cf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d9c94d0-4b47-47a5-b2a0-be91badde3c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d12026b-a76c-4be3-9310-1375c91c347b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1314b825-fd7f-4bbf-b7c5-6e9cfbbe9857
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 736c4897-e05a-4fc0-a186-298ced306dd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50947506-f61b-4c03-be41-0cb2f644ffe3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e47ebce1-1d26-4833-96b5-e20ce1a71a2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c54cfbb2-76f2-4af4-8998-135a2f6ed912
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65238a05-9e0d-4af2-8899-d43f3f5e04bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93409420-4492-4bf9-965a-aa3d73127841
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b42fa76-092a-45d1-b019-88bfaf3bd876
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b56a7a4d-84c0-413a-88cd-3933d001bb94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a78f36e-bcd5-4d3c-b1f3-f8a870157a41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6be080b9-60c7-4793-8906-dbb4a08dfbdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa6c921f-33f6-4d3d-a33e-8e83c2c458bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e605f3b-735d-4f59-a2d8-7b76ab7f4241
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c16628ae-fef0-4f4e-820f-1d7c3b254e1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf8c87b8-ba01-4cf7-8012-1cb59fb3f189
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e50fe9b-00c2-4fd5-bdf1-2905493a401c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8544d06f-ccaa-4fd7-96cb-f87b0b24a529
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 436d3ea2-b373-40a8-9198-a05941c8901e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd177599-5833-45c3-b73c-983eeb73f863
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7243444c-1cf2-4c5e-82f6-250e9265d3f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddd0c15d-2f87-4f82-8d27-83a69aa3cbfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a730e6c-f363-44c2-83c1-1862ffb87e79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f26e9d1-7c74-41d4-9a2d-87c43283a99f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e35a9f9d-1d7b-4289-9f6d-f59298fb710e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec96c034-3de6-4a7d-bf8f-81cf02dc07a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc7a071e-d963-4264-81c9-57c2e78877d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48fa2497-95db-41c3-a44a-dceba718c3c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82101845-cec7-4935-b5dc-dc862bc38356
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b6674d4-c895-425f-af3e-19a871e6bbd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25561543-656c-4140-997f-a828247ef98e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5fa836d-7839-4698-834b-2b32a88c0503
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ccbfdd7c-f284-430b-aae0-61e012c96b9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efc17223-5b21-4d9b-9692-44b9daa935a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6af4f57c-3cda-4b99-9473-c32b7d53589f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e643161d-7bb6-45a2-ad5b-bb37f423a5c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05fdf67a-2cde-4dba-ac42-063cf5d8f8ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a319ef77-3ea3-4916-8837-4f0bda7df4f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef76a9a2-93d5-4bf4-b232-653a073ad18d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47eb1bcc-5556-4f5f-b929-8092645a695a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c53d6255-1abb-4d7e-94a3-a156c43e9c4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e9fd252-78cc-4f20-9410-1e885ad1fa0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfbd90fc-3933-45af-8088-c2454169de77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46c21ed9-d341-424e-9b24-3e40cc49e9f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7508280-3946-46db-9943-81806268cf5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a305dde5-94ef-4fcc-9c0b-805dbd9fbda1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3fd494f-5b9e-4836-90f5-22f0ce47e20e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21e18a76-899e-404d-8781-7b19759912c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b10eca9b-12ab-47b6-96bb-3edc586044df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2588348c-48d2-4b2a-a298-35db5cfc7648
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f879ef6-03bb-4a55-8431-0a2620480e7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb9141cd-6619-40d4-9bc4-3897b5228464
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 908c6092-2e59-4a5d-a9cb-cbfc5c4a7dd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b331fe5-bb93-40f0-8cc5-6b1ebd8da82a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6f1960d-4ef8-4f1b-a6a2-78936bddf3d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7119f7ca-f6b8-480b-81e6-287a80ad417c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a937e7f9-89d7-4e26-99fe-583229a34580
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fccd32a-bbaf-4065-a9ae-b942a589c47b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ccf8256-bd7d-444f-a3b3-028b1ad431dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bac9fd3-2f87-4b2b-8d2e-73229dc37c8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a7e2812-86cf-4268-a9d5-129400a995dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfec2382-046f-4a98-9ef7-5432534cfa86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e75b8763-956c-4359-b512-16e47f90daab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6f9ec98-97f5-4b0d-9a50-3f2d28bcd1a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89d6fc73-e4e3-401f-92b5-bc5207c8cfe5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13e1f85e-9d0e-420b-8a26-cb20eb521031
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d37d9f59-1a9d-4733-a9cf-f5ff98c3650b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d76ddeaa-006f-4813-8198-93cd758cb4e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5914ed4-88a4-4f76-9243-92e9da6ba6cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d1afe93-5d67-4d30-ba9b-f4d1f5a34ca7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50109e92-5c41-41f7-a368-72f2adf6be56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d4ec10c-0edd-4a7f-881c-2b487f4589e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89fde377-1cb9-4d9e-99c1-7c5ac821416c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5249173b-b876-4d92-a73b-5b939853ae6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f29721a-cc53-49a7-8601-275b719b844e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17232444-1745-45b3-ad18-dc612fea1703
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f75a2344-dc15-45f1-b6ac-2f7cf7d3611a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47f50abf-8727-4599-bb3d-ed67e4bde671
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c627a50a-f37c-4b2f-93f6-8495bc09cee7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55d3b33a-16e4-40ea-a9f5-091f8e11ad8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 514a4421-88db-4704-bd02-ff182ef3a7a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8140a92-d7c3-4577-8423-8f52a5d55161
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2669feda-98ab-42dc-b02e-2e363cbb603d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81736ca7-0255-4cbe-8b26-d0466f657396
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58838d8d-a4f8-4382-84fe-84802bcf0648
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 614c188c-9ca3-44da-be92-c19f668b5a25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6568c43c-f89d-484b-99fd-d33ca22fa788
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa06c580-05c1-4475-a094-62c8794b269c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a99375f-e281-4379-b1ca-360f2328434b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0cbb878a-b3af-42fd-9e10-56f342e809d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 216197ac-bf09-4451-a88d-605c711644f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eee619b6-79bc-4df1-b501-5082ed0e650e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message defbe423-de27-4295-8a27-602462e1422d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e98a0bc3-c373-4a4f-b798-64d4a856290c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42566acb-1559-4820-a3f4-3323f7cd728b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f80b7987-eda2-4149-9505-77760aaed510
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 861feeb0-c5e9-4e62-95ee-358661ca7d3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16e1438f-8255-423f-bad5-e6dcfd521a98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04103bba-ce3c-4aca-b241-f618eeb9e21f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c498df2e-c2c3-4f3e-911f-b73ba52923fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd67b7c1-538d-4a3e-b993-1817e9f3ca0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 595bf566-5452-45ac-b484-fdeeea8e67a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64691665-4cbe-457b-90a3-efad691d7649
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68659d24-a4cf-4801-9fd0-0e00d23f7853
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df2955b4-b034-47ea-bd2b-2a2e6220523c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1820dae-fdea-4581-a723-fa2b83a9accd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0073c29b-b737-4238-907f-4359b7b039e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3597b9f2-4587-4309-8b0d-58abe72ac175
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90416440-fb26-4303-8497-fb41aecd0720
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8cce8b52-7f77-4023-b83f-7bc37b26db06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 280ebda7-cd5c-4cc9-9858-95393e71c8fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 627f2c7e-0c45-4dfb-97d9-9e3a1dbe3e17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0cf414e-0bde-40bc-a1c9-19860f513fca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ef31a23-5304-450f-ae05-391c08bf31c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89c24b02-c93f-48aa-8e63-bfd102883048
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec26410a-19fd-431f-b4fd-ffc23bdc0ec3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52a7a8ed-384c-4854-a33d-cebaa391e563
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 862fcef7-ce86-4b65-baf9-1ba12f359c38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47628214-6d62-4305-a614-8dde3a1c2574
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d41e9a5-b298-460e-b308-e8c1061af578
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c53bfb1-1052-4b31-894e-82920f7931d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 893756e4-5091-47d5-bb69-fbab7c02322a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ff28e88-aa90-4dd8-bb6a-bde27bd066af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be5c93bd-2c2d-46fd-a83f-f8710b083f48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3c8dc3d-32be-4367-8200-961633a65bf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53e4e502-ef1d-404f-a539-910ef365d466
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb86fad7-749f-4040-b102-1f109d8be726
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6abbd4e2-83a3-41b0-a470-7fc620883861
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a372e3d7-3849-45b0-b415-8f441616c75b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b703ea22-4645-4958-9062-1ed0b7d73cd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbc9f7a4-cc14-4bd7-9ca1-60ee0b8bf567
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72a982bc-647e-4b3a-a63e-eec8870076e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d94fd096-5cec-42db-97ad-d4b65fe54e33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f1d39bc-adae-42af-a96a-21dc41b755fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 872024e2-3cd2-415e-8c65-71c1812208f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dff1f4bc-4863-48c8-a59c-b95c7c264631
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d357ff0c-25a5-4faf-8fe8-7ea36b3fb6fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ee953a0-7e67-44d9-a27d-93a4658bc4bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17b85838-cfaf-4de7-8832-865b492a71ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac25d8a5-792a-4305-9c5c-c4d9d92780c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c97395d9-10da-45b2-bfee-2bc2a0f18b07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7e4fc3c-9194-4b9f-a76f-e644e1e19109
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fd09206-6c52-4e37-9576-2154fd86f222
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1845ae99-0519-4231-90bd-b0839296309e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee96a9be-e43a-4a49-8b48-43ae3a4cd589
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5aa2b9bd-fd60-4446-819e-281a9b45b35d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ceb195a-c813-4608-8765-0f30a69ad42e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46608652-daf6-48a6-95c2-3a5fa9123df6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22c229be-516a-4f3f-9e20-a76ee707f16f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ece0cdf-2133-4e07-8ca0-2d08474c7130
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67724d86-625c-4f3a-b0ee-06ef845be42b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79ba45f0-c56a-4193-8afd-561001310ad7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89e7e9d2-b35c-4aa6-8949-947867e8f397
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca40dad8-4ea0-4884-a57f-a29f22ce35e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79bbde77-1b6c-4c25-8b93-b039a0f20846
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1a6dedf-73f1-4606-807f-7f4a7bb8d20d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 818e11a4-dcda-4987-8967-3a2e3791f097
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 784d9b9b-682b-4f68-821d-d34fc126c931
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_14
Server: localhost:8688
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_14
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_14/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_14/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_14/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_14/test_labels.txt

📊 Raw data loaded:
   Train: X=(5733, 24), y=(5733,)
   Test:  X=(1434, 24), y=(1434,)

⚠️  Limiting training data: 5733 → 800 samples
⚠️  Limiting test data: 1434 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_14 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 1 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1971, val=0.0931 (↓), lr=0.001000
   • Epoch   2/100: train=0.0932, val=0.0951, patience=1/15, lr=0.001000
   ✓ Epoch   3/100: train=0.0854, val=0.0916 (↓), lr=0.001000
   • Epoch   4/100: train=0.0849, val=0.0916, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0850, val=0.0916, patience=2/15, lr=0.001000
   📉 Epoch 10: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0838, val=0.0920, patience=8/15, lr=0.000500
   📉 Epoch 18: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 1 Summary - Client client_14
   Epochs: 18/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0050
   Val:   Loss=0.0916, RMSE=0.3026, R²=0.0052
============================================================


📊 Round 1 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2484, R²: -0.0033

============================================================
🔄 Round 2 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0836 (↓), lr=0.000250
   • Epoch   2/100: train=0.0874, val=0.0836, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0871, val=0.0835, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0870, val=0.0836, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0869, val=0.0836, patience=4/15, lr=0.000250
   📉 Epoch 9: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0865, val=0.0839, patience=10/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 2 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000125 (1 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=0.0005
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0067
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.3811, RMSE: 0.6174, MAE: 0.5461, R²: -3.6076

============================================================
🔄 Round 3 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000125 → 0.000063
   ✓ Epoch   1/100: train=0.2427, val=0.1093 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.0959, val=0.0908 (↓), lr=0.000063
   • Epoch   3/100: train=0.0857, val=0.0912, patience=1/15, lr=0.000063
   • Epoch   4/100: train=0.0851, val=0.0915, patience=2/15, lr=0.000063
   • Epoch   5/100: train=0.0851, val=0.0913, patience=3/15, lr=0.000063
   📉 Epoch 9: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0850, val=0.0912, patience=9/15, lr=0.000031
   📉 Epoch 17: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 3 Summary - Client client_14
   Epochs: 17/100 (early stopped)
   LR: 0.000125 → 0.000016 (3 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0165
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0013
============================================================


============================================================
🔄 Round 4 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1529, val=0.1514 (↓), lr=0.000016
   ✓ Epoch   2/100: train=0.1350, val=0.1340 (↓), lr=0.000016
   ✓ Epoch   3/100: train=0.1204, val=0.1217 (↓), lr=0.000016
   ✓ Epoch   4/100: train=0.1102, val=0.1132 (↓), lr=0.000016
   ✓ Epoch   5/100: train=0.1031, val=0.1071 (↓), lr=0.000016
   📉 Epoch 8: LR reduced 0.000016 → 0.000008
   ✓ Epoch  11/100: train=0.0888, val=0.0951 (↓), lr=0.000008
   📉 Epoch 16: LR reduced 0.000008 → 0.000004
   ✓ Epoch  21/100: train=0.0862, val=0.0926 (↓), lr=0.000004
   📉 Epoch 24: LR reduced 0.000004 → 0.000002
   • Epoch  31/100: train=0.0857, val=0.0922, patience=10/15, lr=0.000002
   📉 Epoch 32: LR reduced 0.000002 → 0.000001
   • Epoch  41/100: train=0.0856, val=0.0920, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 4 Summary - Client client_14
   Epochs: 50/100 (early stopped)
   LR: 0.000016 → 0.000001 (4 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0009
   Val:   Loss=0.0921, RMSE=0.3035, R²=-0.0083
============================================================


============================================================
🔄 Round 6 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1088, val=0.1089 (↓), lr=0.000001
   • Epoch   2/100: train=0.1086, val=0.1087, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1084, val=0.1084, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1082, val=0.1082 (↓), lr=0.000001
   • Epoch   5/100: train=0.1080, val=0.1080, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1068, val=0.1069, patience=1/15, lr=0.000001
   ✓ Epoch  21/100: train=0.1052, val=0.1053 (↓), lr=0.000001
   • Epoch  31/100: train=0.1038, val=0.1039, patience=2/15, lr=0.000001
   • Epoch  41/100: train=0.1025, val=0.1027, patience=4/15, lr=0.000001
   • Epoch  51/100: train=0.1014, val=0.1015, patience=4/15, lr=0.000001
   • Epoch  61/100: train=0.1003, val=0.1005, patience=4/15, lr=0.000001
   • Epoch  71/100: train=0.0993, val=0.0995, patience=4/15, lr=0.000001
   • Epoch  81/100: train=0.0984, val=0.0985, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.0975, val=0.0976 (↓), lr=0.000001

============================================================
📊 Round 6 Summary - Client client_14
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0969, RMSE=0.3112, R²=-0.1178
   Val:   Loss=0.0969, RMSE=0.3112, R²=-0.1195
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2491, R²: -0.0136

📊 Round 6 Test Metrics:
   Loss: 0.0847, RMSE: 0.2909, MAE: 0.2496, R²: -0.0234

📊 Round 6 Test Metrics:
   Loss: 0.0890, RMSE: 0.2983, MAE: 0.2536, R²: -0.0757

📊 Round 6 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2496, R²: -0.0201

📊 Round 6 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2486, R²: -0.0026

============================================================
🔄 Round 11 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 11 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2949, R²=-0.0017
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0180
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2502, R²: -0.0240

============================================================
🔄 Round 14 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 14 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0165
   Val:   Loss=0.0903, RMSE=0.3005, R²=0.0137
============================================================


============================================================
🔄 Round 15 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 15 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2979, R²=0.0056
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0280
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0833, RMSE: 0.2885, MAE: 0.2491, R²: -0.0065

📊 Round 15 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2492, R²: -0.0082

============================================================
🔄 Round 19 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 19 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=-0.0083
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0202
============================================================


============================================================
🔄 Round 20 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 20 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2994, R²=-0.0080
   Val:   Loss=0.0759, RMSE=0.2754, R²=0.0193
============================================================


============================================================
🔄 Round 21 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 21 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0007
   Val:   Loss=0.0925, RMSE=0.3041, R²=-0.0160
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2493, R²: -0.0109

============================================================
🔄 Round 24 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 24 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=-0.0044
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0009
============================================================


============================================================
🔄 Round 26 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0998 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0998, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0998, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0998, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0998, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0997, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0998)

============================================================
📊 Round 26 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0066
   Val:   Loss=0.0998, RMSE=0.3159, R²=-0.0586
============================================================


============================================================
🔄 Round 29 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0941 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0941, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0941, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0941, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0942, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0941)

============================================================
📊 Round 29 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0034
   Val:   Loss=0.0941, RMSE=0.3068, R²=-0.0324
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2492, R²: -0.0092

📊 Round 29 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2492, R²: -0.0086

============================================================
🔄 Round 32 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 32 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=0.0024
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0127
============================================================


============================================================
🔄 Round 34 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 34 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0045
   Val:   Loss=0.0938, RMSE=0.3062, R²=-0.0228
============================================================


============================================================
🔄 Round 35 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 35 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0053
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0312
============================================================


============================================================
🔄 Round 36 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0962 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0962, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0962, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0962, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0962, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0962, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0962)

============================================================
📊 Round 36 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0011
   Val:   Loss=0.0962, RMSE=0.3102, R²=-0.0013
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0833, RMSE: 0.2887, MAE: 0.2491, R²: -0.0077

============================================================
🔄 Round 38 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 38 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0035
   Val:   Loss=0.0896, RMSE=0.2994, R²=-0.0096
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2491, R²: -0.0072

============================================================
🔄 Round 43 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0953 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0953, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0953, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0953, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0953, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0953, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0953)

============================================================
📊 Round 43 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0038
   Val:   Loss=0.0953, RMSE=0.3087, R²=-0.0067
============================================================


============================================================
🔄 Round 44 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 44 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0057
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0471
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2491, R²: -0.0067

============================================================
🔄 Round 45 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0959 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0959, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0959, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0960, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0960, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0960, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0959)

============================================================
📊 Round 45 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0098
   Val:   Loss=0.0959, RMSE=0.3097, R²=0.0318
============================================================


============================================================
🔄 Round 46 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 46 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0020
   Val:   Loss=0.0914, RMSE=0.3023, R²=0.0168
============================================================


============================================================
🔄 Round 47 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 47 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0063
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0227
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2491, R²: -0.0065

============================================================
🔄 Round 49 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 49 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0016
   Val:   Loss=0.0909, RMSE=0.3015, R²=0.0024
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2490, R²: -0.0063

============================================================
🔄 Round 50 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0955 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0955, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0955, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0955, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0955, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0955, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0955)

============================================================
📊 Round 50 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0036
   Val:   Loss=0.0955, RMSE=0.3090, R²=-0.0016
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2490, R²: -0.0062

============================================================
🔄 Round 52 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0935, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 52 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2909, R²=0.0049
   Val:   Loss=0.0934, RMSE=0.3057, R²=-0.0101
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2490, R²: -0.0062

📊 Round 52 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2490, R²: -0.0061

============================================================
🔄 Round 57 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 57 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0031
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0143
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2490, R²: -0.0059

📊 Round 57 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2490, R²: -0.0059

============================================================
🔄 Round 60 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 60 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=0.0049
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0089
============================================================


============================================================
🔄 Round 62 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 62 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=0.0023
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0061
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2490, R²: -0.0057

============================================================
🔄 Round 63 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 63 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=0.0003
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0363
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2490, R²: -0.0057

📊 Round 63 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2490, R²: -0.0056

============================================================
🔄 Round 66 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 66 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0036
   Val:   Loss=0.0918, RMSE=0.3029, R²=0.0012
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2490, R²: -0.0056

============================================================
🔄 Round 69 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 69 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=-0.0004
   Val:   Loss=0.0766, RMSE=0.2767, R²=0.0135
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2490, R²: -0.0055

============================================================
🔄 Round 71 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 71 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0094
   Val:   Loss=0.0913, RMSE=0.3021, R²=-0.0401
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2490, R²: -0.0054

============================================================
🔄 Round 74 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0953 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0953, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0953, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0953, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0953, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0953, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0953)

============================================================
📊 Round 74 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0063
   Val:   Loss=0.0953, RMSE=0.3087, R²=-0.0071
============================================================


============================================================
🔄 Round 75 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0974 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0974, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0974, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0974, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0974, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0973, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0974)

============================================================
📊 Round 75 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0004
   Val:   Loss=0.0974, RMSE=0.3120, R²=0.0157
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2490, R²: -0.0054

📊 Round 75 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2490, R²: -0.0053

📊 Round 75 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2489, R²: -0.0053

============================================================
🔄 Round 80 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 80 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0015
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0024
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2489, R²: -0.0053

============================================================
🔄 Round 84 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 84 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0035
   Val:   Loss=0.0931, RMSE=0.3051, R²=-0.0140
============================================================


============================================================
🔄 Round 85 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 85 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0058
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0060
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0831, RMSE: 0.2884, MAE: 0.2489, R²: -0.0052

📊 Round 85 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2489, R²: -0.0052

📊 Round 85 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2489, R²: -0.0052

============================================================
🔄 Round 91 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 91 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2959, R²=-0.0066
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0434
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2489, R²: -0.0052

============================================================
🔄 Round 92 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 92 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=0.0003
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0087
============================================================


============================================================
🔄 Round 94 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 94 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0088
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0184
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2489, R²: -0.0051

============================================================
🔄 Round 95 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 95 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=0.0056
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0094
============================================================


============================================================
🔄 Round 96 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 96 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0015
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0212
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2489, R²: -0.0051

============================================================
🔄 Round 98 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 98 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2916, R²=0.0028
   Val:   Loss=0.0914, RMSE=0.3022, R²=-0.0003
============================================================


============================================================
🔄 Round 99 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0985 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0985, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0985, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0985, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0985, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0986, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0985)

============================================================
📊 Round 99 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0042
   Val:   Loss=0.0985, RMSE=0.3138, R²=-0.0267
============================================================


============================================================
🔄 Round 100 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0953 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0953, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0953, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0953, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0953, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0953, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0953)

============================================================
📊 Round 100 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0029
   Val:   Loss=0.0953, RMSE=0.3087, R²=-0.0206
============================================================


============================================================
🔄 Round 101 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 101 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2952, R²=0.0069
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0196
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2489, R²: -0.0050

============================================================
🔄 Round 104 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 104 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=0.0017
   Val:   Loss=0.0882, RMSE=0.2970, R²=0.0107
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2489, R²: -0.0050

============================================================
🔄 Round 107 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 107 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0005
   Val:   Loss=0.0927, RMSE=0.3045, R²=0.0097
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2489, R²: -0.0049

📊 Round 107 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2489, R²: -0.0049

📊 Round 107 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2489, R²: -0.0049

📊 Round 107 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2489, R²: -0.0049

📊 Round 107 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2489, R²: -0.0048

============================================================
🔄 Round 117 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 117 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0066
   Val:   Loss=0.0854, RMSE=0.2923, R²=0.0417
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2489, R²: -0.0048

📊 Round 117 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2489, R²: -0.0048

============================================================
🔄 Round 120 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 120 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2959, R²=0.0012
   Val:   Loss=0.0814, RMSE=0.2852, R²=-0.0079
============================================================


============================================================
🔄 Round 121 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 121 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0071
   Val:   Loss=0.0871, RMSE=0.2952, R²=-0.0203
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2489, R²: -0.0048

============================================================
🔄 Round 126 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 126 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=0.0023
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0098
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2489, R²: -0.0047

============================================================
🔄 Round 130 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 130 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0059
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0124
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2489, R²: -0.0046

============================================================
🔄 Round 131 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 131 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=0.0048
   Val:   Loss=0.0810, RMSE=0.2845, R²=-0.0009
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2489, R²: -0.0046

📊 Round 131 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2489, R²: -0.0046

============================================================
🔄 Round 136 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0941 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0941, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0941, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0941, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0941, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0941, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0941)

============================================================
📊 Round 136 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0071
   Val:   Loss=0.0941, RMSE=0.3068, R²=-0.0088
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2489, R²: -0.0046

📊 Round 136 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2489, R²: -0.0046

============================================================
🔄 Round 139 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 139 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=-0.0054
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0419
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2489, R²: -0.0046

📊 Round 139 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2489, R²: -0.0046

============================================================
🔄 Round 143 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0957 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0957, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0957, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0957, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0957, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0957, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0957)

============================================================
📊 Round 143 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0036
   Val:   Loss=0.0957, RMSE=0.3093, R²=-0.0079
============================================================


============================================================
🔄 Round 144 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 144 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=0.0036
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0244
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2489, R²: -0.0045

============================================================
🔄 Round 151 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 151 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2932, R²=0.0035
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0073
============================================================


============================================================
🔄 Round 153 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 153 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0054
   Val:   Loss=0.0863, RMSE=0.2937, R²=0.0350
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2488, R²: -0.0044

============================================================
🔄 Round 155 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 155 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=0.0017
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0033
============================================================


============================================================
🔄 Round 158 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 158 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=0.0011
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0093
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2488, R²: -0.0044

============================================================
🔄 Round 160 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 160 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0022
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0090
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2488, R²: -0.0044

============================================================
🔄 Round 161 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 161 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=0.0093
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0239
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2488, R²: -0.0044

============================================================
🔄 Round 162 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 162 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0080
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0147
============================================================


============================================================
🔄 Round 163 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 163 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0036
   Val:   Loss=0.0936, RMSE=0.3060, R²=0.0207
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2488, R²: -0.0043

📊 Round 163 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2488, R²: -0.0043

📊 Round 163 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2488, R²: -0.0043

============================================================
🔄 Round 168 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 168 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=0.0019
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0102
============================================================


============================================================
🔄 Round 169 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 169 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0010
   Val:   Loss=0.0891, RMSE=0.2985, R²=0.0090
============================================================


============================================================
🔄 Round 170 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 170 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0023
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0265
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2488, R²: -0.0043

============================================================
🔄 Round 173 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 173 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2928, R²=0.0065
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0077
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2488, R²: -0.0043

📊 Round 173 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2488, R²: -0.0042

============================================================
🔄 Round 175 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 175 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0023
   Val:   Loss=0.0868, RMSE=0.2946, R²=0.0083
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2488, R²: -0.0042

============================================================
🔄 Round 176 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 176 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=0.0081
   Val:   Loss=0.0747, RMSE=0.2733, R²=-0.0234
============================================================


============================================================
🔄 Round 179 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 179 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=0.0017
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0110
============================================================


============================================================
🔄 Round 180 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 180 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=0.0025
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0087
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2488, R²: -0.0042

============================================================
🔄 Round 181 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 181 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0145
   Val:   Loss=0.0851, RMSE=0.2918, R²=-0.0438
============================================================


============================================================
🔄 Round 183 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 183 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0053
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0125
============================================================


============================================================
🔄 Round 184 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 184 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2976, R²=0.0157
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0904
============================================================


============================================================
🔄 Round 185 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 185 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=0.0075
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0155
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2488, R²: -0.0041

============================================================
🔄 Round 186 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 186 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0029
   Val:   Loss=0.0868, RMSE=0.2947, R²=0.0066
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2488, R²: -0.0041

📊 Round 186 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2488, R²: -0.0041

📊 Round 186 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2488, R²: -0.0041

============================================================
🔄 Round 192 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 192 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=0.0082
   Val:   Loss=0.0806, RMSE=0.2838, R²=-0.0226
============================================================


============================================================
🔄 Round 193 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 193 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0019
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0074
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2488, R²: -0.0040

📊 Round 193 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2488, R²: -0.0040

============================================================
🔄 Round 196 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 196 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0073
   Val:   Loss=0.0887, RMSE=0.2977, R²=-0.0172
============================================================


============================================================
🔄 Round 198 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 198 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0053
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0050
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2488, R²: -0.0040

============================================================
🔄 Round 200 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 200 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=0.0043
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0104
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2488, R²: -0.0040

============================================================
🔄 Round 202 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 202 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=0.0156
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0533
============================================================


============================================================
🔄 Round 203 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 203 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=0.0075
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0126
============================================================


============================================================
🔄 Round 204 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 204 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0147
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0434
============================================================


============================================================
🔄 Round 205 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 205 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=-0.0025
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0243
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2488, R²: -0.0039

📊 Round 205 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2488, R²: -0.0039

📊 Round 205 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2488, R²: -0.0039

============================================================
🔄 Round 215 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 215 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=0.0055
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0041
============================================================


📊 Round 215 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2488, R²: -0.0038

📊 Round 215 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2488, R²: -0.0038

📊 Round 215 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2488, R²: -0.0038

============================================================
🔄 Round 221 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 221 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0107
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0254
============================================================


📊 Round 221 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2488, R²: -0.0038

📊 Round 221 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2487, R²: -0.0038

📊 Round 221 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2487, R²: -0.0037

============================================================
🔄 Round 231 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0989 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0989, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0989, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0989, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0989, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0989, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0989)

============================================================
📊 Round 231 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0003
   Val:   Loss=0.0989, RMSE=0.3145, R²=0.0111
============================================================


============================================================
🔄 Round 233 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 233 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=0.0023
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0094
============================================================


📊 Round 233 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2487, R²: -0.0037

============================================================
🔄 Round 234 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 234 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=-0.0003
   Val:   Loss=0.0830, RMSE=0.2880, R²=0.0201
============================================================


📊 Round 234 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2487, R²: -0.0037

============================================================
🔄 Round 241 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 241 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=-0.0035
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0334
============================================================


📊 Round 241 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2487, R²: -0.0037

============================================================
🔄 Round 242 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 242 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=0.0031
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0064
============================================================


📊 Round 242 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2487, R²: -0.0036

============================================================
🔄 Round 244 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 244 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0061
   Val:   Loss=0.0911, RMSE=0.3018, R²=-0.0052
============================================================


============================================================
🔄 Round 245 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 245 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0114
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0270
============================================================


============================================================
🔄 Round 246 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 246 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=0.0001
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0127
============================================================


============================================================
🔄 Round 249 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 249 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0052
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0068
============================================================


📊 Round 249 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2487, R²: -0.0036

📊 Round 249 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2487, R²: -0.0036

📊 Round 249 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2487, R²: -0.0036

============================================================
🔄 Round 253 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 253 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0062
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0065
============================================================


📊 Round 253 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2487, R²: -0.0036

📊 Round 253 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2487, R²: -0.0036

============================================================
🔄 Round 256 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 256 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=0.0080
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0126
============================================================


============================================================
🔄 Round 258 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 258 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2954, R²=0.0017
   Val:   Loss=0.0826, RMSE=0.2873, R²=0.0067
============================================================


📊 Round 258 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2487, R²: -0.0035

============================================================
🔄 Round 264 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 264 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0025
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0285
============================================================


📊 Round 264 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2487, R²: -0.0035

📊 Round 264 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2487, R²: -0.0035

============================================================
🔄 Round 266 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 266 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0041
   Val:   Loss=0.0926, RMSE=0.3042, R²=-0.0219
============================================================


📊 Round 266 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2487, R²: -0.0035

📊 Round 266 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2487, R²: -0.0035

📊 Round 266 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2487, R²: -0.0035

============================================================
🔄 Round 269 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 269 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0038
   Val:   Loss=0.0915, RMSE=0.3026, R²=0.0034
============================================================


📊 Round 269 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2487, R²: -0.0035

📊 Round 269 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2487, R²: -0.0035

============================================================
🔄 Round 274 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 274 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=0.0072
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0113
============================================================


📊 Round 274 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2487, R²: -0.0035

📊 Round 274 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2487, R²: -0.0035

📊 Round 274 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2487, R²: -0.0035

============================================================
🔄 Round 281 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 281 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=0.0016
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0123
============================================================


============================================================
🔄 Round 282 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0942, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0942, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0942, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0943, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 282 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0061
   Val:   Loss=0.0942, RMSE=0.3070, R²=-0.0091
============================================================


============================================================
🔄 Round 285 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 285 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0061
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0063
============================================================


📊 Round 285 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2487, R²: -0.0035

📊 Round 285 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2487, R²: -0.0035

============================================================
🔄 Round 288 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 288 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=0.0018
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0084
============================================================


📊 Round 288 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2487, R²: -0.0035

📊 Round 288 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2487, R²: -0.0035

📊 Round 288 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2487, R²: -0.0034

============================================================
🔄 Round 296 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 296 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0113
   Val:   Loss=0.0910, RMSE=0.3016, R²=-0.0264
============================================================


📊 Round 296 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2487, R²: -0.0034

============================================================
🔄 Round 299 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 299 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0060
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0060
============================================================


📊 Round 299 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2487, R²: -0.0034

============================================================
🔄 Round 300 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 300 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0041
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0026
============================================================


============================================================
🔄 Round 301 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 301 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0122
   Val:   Loss=0.0927, RMSE=0.3044, R²=-0.0291
============================================================


📊 Round 301 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2487, R²: -0.0034

============================================================
🔄 Round 302 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.1020 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.1020, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.1020, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.1020, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.1020, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.1020, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1020)

============================================================
📊 Round 302 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0120
   Val:   Loss=0.1020, RMSE=0.3194, R²=-0.0241
============================================================


📊 Round 302 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2487, R²: -0.0034

📊 Round 302 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2487, R²: -0.0033

============================================================
🔄 Round 305 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 305 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=0.0058
   Val:   Loss=0.0841, RMSE=0.2901, R²=-0.0242
============================================================


📊 Round 305 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2487, R²: -0.0033

============================================================
🔄 Round 307 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 307 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0034
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0309
============================================================


📊 Round 307 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2487, R²: -0.0033

============================================================
🔄 Round 308 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 308 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=0.0051
   Val:   Loss=0.0785, RMSE=0.2801, R²=-0.0058
============================================================


📊 Round 308 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2487, R²: -0.0033

📊 Round 308 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2487, R²: -0.0033

📊 Round 308 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2487, R²: -0.0033

============================================================
🔄 Round 313 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 313 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=0.0003
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0163
============================================================


📊 Round 313 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2487, R²: -0.0033

============================================================
🔄 Round 315 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 315 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0138
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0409
============================================================


============================================================
🔄 Round 316 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 316 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0005
   Val:   Loss=0.0850, RMSE=0.2916, R²=0.0105
============================================================


============================================================
🔄 Round 318 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 318 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0019
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0100
============================================================


============================================================
🔄 Round 321 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 321 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2959, R²=0.0058
   Val:   Loss=0.0814, RMSE=0.2854, R²=-0.0091
============================================================


📊 Round 321 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2487, R²: -0.0033

📊 Round 321 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2487, R²: -0.0033

📊 Round 321 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2487, R²: -0.0033

📊 Round 321 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2487, R²: -0.0032

============================================================
🔄 Round 326 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 326 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0013
   Val:   Loss=0.0868, RMSE=0.2947, R²=0.0128
============================================================


📊 Round 326 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2487, R²: -0.0032

============================================================
🔄 Round 329 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 329 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0047
   Val:   Loss=0.0936, RMSE=0.3060, R²=-0.0053
============================================================


📊 Round 329 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2487, R²: -0.0032

📊 Round 329 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2487, R²: -0.0032

============================================================
🔄 Round 332 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 332 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0092
   Val:   Loss=0.0911, RMSE=0.3019, R²=-0.0179
============================================================


============================================================
🔄 Round 334 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 334 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=0.0037
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0072
============================================================


📊 Round 334 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2487, R²: -0.0032

============================================================
🔄 Round 335 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 335 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=0.0143
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0507
============================================================


============================================================
🔄 Round 336 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 336 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0101
   Val:   Loss=0.0939, RMSE=0.3064, R²=-0.0256
============================================================


📊 Round 336 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2487, R²: -0.0032

📊 Round 336 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2487, R²: -0.0032

============================================================
🔄 Round 338 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 338 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0038
   Val:   Loss=0.0907, RMSE=0.3012, R²=0.0027
============================================================


============================================================
🔄 Round 339 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 339 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0065
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0344
============================================================


📊 Round 339 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2487, R²: -0.0032

============================================================
🔄 Round 341 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 341 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0011
   Val:   Loss=0.0873, RMSE=0.2954, R²=0.0138
============================================================


📊 Round 341 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2487, R²: -0.0031

============================================================
🔄 Round 343 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 343 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=0.0003
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0176
============================================================


📊 Round 343 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2487, R²: -0.0031

============================================================
🔄 Round 344 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 344 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0056
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0103
============================================================


============================================================
🔄 Round 345 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0935 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0935, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0935, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 345 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0094
   Val:   Loss=0.0935, RMSE=0.3057, R²=-0.0274
============================================================


📊 Round 345 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2487, R²: -0.0031

📊 Round 345 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2487, R²: -0.0031

📊 Round 345 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2487, R²: -0.0031

📊 Round 345 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2487, R²: -0.0031

============================================================
🔄 Round 350 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 350 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0019
   Val:   Loss=0.0920, RMSE=0.3033, R²=-0.0042
============================================================


============================================================
🔄 Round 353 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 353 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0081
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0131
============================================================


============================================================
🔄 Round 355 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 355 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0032
   Val:   Loss=0.0871, RMSE=0.2951, R²=0.0187
============================================================


============================================================
🔄 Round 356 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 356 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0013
   Val:   Loss=0.0902, RMSE=0.3003, R²=0.0127
============================================================


📊 Round 356 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2486, R²: -0.0031

============================================================
🔄 Round 357 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0957 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0957, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0957, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0957, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0957, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0958, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0957)

============================================================
📊 Round 357 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0063
   Val:   Loss=0.0957, RMSE=0.3094, R²=0.0277
============================================================


============================================================
🔄 Round 360 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 360 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=-0.0017
   Val:   Loss=0.0868, RMSE=0.2947, R²=0.0194
============================================================


============================================================
🔄 Round 362 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 362 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0012
   Val:   Loss=0.0880, RMSE=0.2966, R²=0.0018
============================================================


📊 Round 362 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2486, R²: -0.0031

📊 Round 362 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2486, R²: -0.0031

📊 Round 362 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2486, R²: -0.0031

📊 Round 362 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2486, R²: -0.0031

============================================================
🔄 Round 370 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 370 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0040
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0200
============================================================


📊 Round 370 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2486, R²: -0.0031

📊 Round 370 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2486, R²: -0.0031

📊 Round 370 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2486, R²: -0.0031

📊 Round 370 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2486, R²: -0.0031

📊 Round 370 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2486, R²: -0.0031

============================================================
🔄 Round 378 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 378 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0034
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0338
============================================================


📊 Round 378 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2486, R²: -0.0031

============================================================
🔄 Round 380 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 380 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0054
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0027
============================================================


📊 Round 380 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2486, R²: -0.0031

============================================================
🔄 Round 381 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 381 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0092
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0223
============================================================


============================================================
🔄 Round 382 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 382 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0073
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0122
============================================================


============================================================
🔄 Round 384 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 384 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=0.0074
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0221
============================================================


📊 Round 384 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2486, R²: -0.0030

📊 Round 384 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2486, R²: -0.0030

📊 Round 384 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2486, R²: -0.0030

============================================================
🔄 Round 392 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0956 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0956, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0956, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0956, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0956, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0956, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0956)

============================================================
📊 Round 392 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0073
   Val:   Loss=0.0956, RMSE=0.3092, R²=-0.0095
============================================================


📊 Round 392 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2486, R²: -0.0030

============================================================
🔄 Round 394 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0955 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0955, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0955, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0955, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0955, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0955, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0955)

============================================================
📊 Round 394 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0018
   Val:   Loss=0.0955, RMSE=0.3091, R²=0.0072
============================================================


============================================================
🔄 Round 395 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 395 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=0.0045
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0072
============================================================


============================================================
🔄 Round 399 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 399 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=0.0065
   Val:   Loss=0.0778, RMSE=0.2790, R²=-0.0090
============================================================


📊 Round 399 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2486, R²: -0.0030

📊 Round 399 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2486, R²: -0.0029

============================================================
🔄 Round 405 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0980 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0980, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0980, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0980, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0980, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0980, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0980)

============================================================
📊 Round 405 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0098
   Val:   Loss=0.0980, RMSE=0.3131, R²=-0.0339
============================================================


============================================================
🔄 Round 407 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 407 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=0.0069
   Val:   Loss=0.0776, RMSE=0.2785, R²=-0.0126
============================================================


📊 Round 407 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2486, R²: -0.0029

============================================================
🔄 Round 408 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 408 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0096
   Val:   Loss=0.0914, RMSE=0.3023, R²=-0.0270
============================================================


============================================================
🔄 Round 409 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 409 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=0.0034
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0044
============================================================


📊 Round 409 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2486, R²: -0.0029

============================================================
🔄 Round 415 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 415 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=0.0018
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0051
============================================================


📊 Round 415 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2486, R²: -0.0029

============================================================
🔄 Round 416 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0948 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0948, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0948, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0948, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0948, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0948, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0948)

============================================================
📊 Round 416 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0019
   Val:   Loss=0.0948, RMSE=0.3079, R²=0.0216
============================================================


📊 Round 416 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2486, R²: -0.0029

============================================================
🔄 Round 418 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 418 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0048
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0345
============================================================


📊 Round 418 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2486, R²: -0.0029

============================================================
🔄 Round 421 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 421 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=0.0031
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0035
============================================================


📊 Round 421 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2486, R²: -0.0029

============================================================
🔄 Round 422 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 422 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0056
   Val:   Loss=0.0902, RMSE=0.3004, R²=-0.0162
============================================================


📊 Round 422 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2486, R²: -0.0029

============================================================
🔄 Round 423 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 423 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0088
   Val:   Loss=0.0862, RMSE=0.2937, R²=-0.0180
============================================================


📊 Round 423 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2486, R²: -0.0029

============================================================
🔄 Round 424 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 424 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=0.0066
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0089
============================================================


============================================================
🔄 Round 427 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 427 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0045
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0203
============================================================


📊 Round 427 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2486, R²: -0.0029

============================================================
🔄 Round 428 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 428 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0031
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0288
============================================================


============================================================
🔄 Round 430 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 430 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0042
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0121
============================================================


📊 Round 430 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2486, R²: -0.0029

============================================================
🔄 Round 432 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 432 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0033
   Val:   Loss=0.0886, RMSE=0.2976, R²=0.0052
============================================================


============================================================
🔄 Round 433 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 433 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0003
   Val:   Loss=0.0932, RMSE=0.3053, R²=0.0151
============================================================


📊 Round 433 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2486, R²: -0.0029

📊 Round 433 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2486, R²: -0.0029

📊 Round 433 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2486, R²: -0.0029

📊 Round 433 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2486, R²: -0.0029

📊 Round 433 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2486, R²: -0.0029

📊 Round 433 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2486, R²: -0.0029

📊 Round 433 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2486, R²: -0.0029

📊 Round 433 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2486, R²: -0.0029

============================================================
🔄 Round 443 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 443 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0045
   Val:   Loss=0.0888, RMSE=0.2979, R²=-0.0032
============================================================


📊 Round 443 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2486, R²: -0.0029

📊 Round 443 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2486, R²: -0.0029

============================================================
🔄 Round 449 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 449 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0034
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0012
============================================================


📊 Round 449 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2486, R²: -0.0028

============================================================
🔄 Round 457 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 457 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0007
   Val:   Loss=0.0929, RMSE=0.3047, R²=0.0133
============================================================


============================================================
🔄 Round 458 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 458 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=0.0046
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0014
============================================================


============================================================
🔄 Round 461 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 461 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=0.0038
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0019
============================================================


============================================================
🔄 Round 463 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 463 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0021
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0101
============================================================


============================================================
🔄 Round 464 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 464 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=0.0113
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0298
============================================================


📊 Round 464 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2486, R²: -0.0027

📊 Round 464 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2486, R²: -0.0027

============================================================
🔄 Round 468 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 468 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=-0.0015
   Val:   Loss=0.0906, RMSE=0.3010, R²=0.0228
============================================================


============================================================
🔄 Round 469 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 469 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0132
   Val:   Loss=0.0913, RMSE=0.3022, R²=-0.0338
============================================================


📊 Round 469 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2486, R²: -0.0027

============================================================
🔄 Round 470 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 470 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2986, R²=0.0017
   Val:   Loss=0.0749, RMSE=0.2737, R²=0.0131
============================================================


📊 Round 470 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2486, R²: -0.0027

📊 Round 470 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2486, R²: -0.0027

============================================================
🔄 Round 478 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 478 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2981, R²=0.0022
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0043
============================================================


📊 Round 478 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2486, R²: -0.0027

============================================================
🔄 Round 482 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.1004 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.1004, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.1004, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.1004, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.1004, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.1004, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1004)

============================================================
📊 Round 482 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0073
   Val:   Loss=0.1004, RMSE=0.3168, R²=-0.0084
============================================================


📊 Round 482 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2486, R²: -0.0027

📊 Round 482 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2486, R²: -0.0027

============================================================
🔄 Round 485 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 485 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0007
   Val:   Loss=0.0874, RMSE=0.2957, R²=0.0118
============================================================


📊 Round 485 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2486, R²: -0.0027

📊 Round 485 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2486, R²: -0.0027

============================================================
🔄 Round 488 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 488 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0033
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0044
============================================================


📊 Round 488 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2486, R²: -0.0027

📊 Round 488 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2486, R²: -0.0027

📊 Round 488 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2486, R²: -0.0027

============================================================
🔄 Round 492 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 492 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=0.0036
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0080
============================================================


============================================================
🔄 Round 494 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 494 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0096
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0220
============================================================


📊 Round 494 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2486, R²: -0.0027

📊 Round 494 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2486, R²: -0.0027

📊 Round 494 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2486, R²: -0.0026

📊 Round 494 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2486, R²: -0.0026

============================================================
🔄 Round 499 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 499 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0042
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0026
============================================================


============================================================
🔄 Round 502 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 502 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0040
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0052
============================================================


============================================================
🔄 Round 503 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 503 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=0.0044
   Val:   Loss=0.0814, RMSE=0.2854, R²=-0.0033
============================================================


📊 Round 503 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2486, R²: -0.0027

============================================================
🔄 Round 504 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 504 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0033
   Val:   Loss=0.0914, RMSE=0.3023, R²=0.0001
============================================================


============================================================
🔄 Round 505 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 505 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0023
   Val:   Loss=0.0929, RMSE=0.3047, R²=0.0244
============================================================


📊 Round 505 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2486, R²: -0.0026

============================================================
🔄 Round 508 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 508 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=0.0008
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0142
============================================================


📊 Round 508 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2486, R²: -0.0026

============================================================
🔄 Round 511 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 511 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2964, R²=0.0096
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0236
============================================================


============================================================
🔄 Round 513 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 513 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=0.0008
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0149
============================================================


============================================================
🔄 Round 514 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 514 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=0.0041
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0013
============================================================


📊 Round 514 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2486, R²: -0.0026

📊 Round 514 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2486, R²: -0.0026

📊 Round 514 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2486, R²: -0.0026

============================================================
🔄 Round 519 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0909, val=0.0687 (↓), lr=0.000001
   • Epoch   2/100: train=0.0909, val=0.0687, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0909, val=0.0687, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0908, val=0.0687, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0908, val=0.0687, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0908, val=0.0687, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0687)

============================================================
📊 Round 519 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0907, RMSE=0.3012, R²=-0.0012
   Val:   Loss=0.0687, RMSE=0.2620, R²=0.0113
============================================================


============================================================
🔄 Round 521 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 521 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0022
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0098
============================================================


📊 Round 521 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2486, R²: -0.0026

============================================================
🔄 Round 523 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 523 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0033
   Val:   Loss=0.0895, RMSE=0.2991, R²=0.0045
============================================================


============================================================
🔄 Round 524 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 524 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0001
   Val:   Loss=0.0888, RMSE=0.2980, R²=0.0168
============================================================


📊 Round 524 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2486, R²: -0.0026

============================================================
🔄 Round 528 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 528 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=0.0055
   Val:   Loss=0.0852, RMSE=0.2920, R²=-0.0038
============================================================


============================================================
🔄 Round 529 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 529 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0068
   Val:   Loss=0.0907, RMSE=0.3012, R²=-0.0169
============================================================


📊 Round 529 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2486, R²: -0.0026

📊 Round 529 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2486, R²: -0.0026

📊 Round 529 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2486, R²: -0.0026

📊 Round 529 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2486, R²: -0.0026

============================================================
🔄 Round 536 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0901, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0901, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 536 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2999, R²=0.0022
   Val:   Loss=0.0718, RMSE=0.2680, R²=0.0019
============================================================


📊 Round 536 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2486, R²: -0.0025

============================================================
🔄 Round 540 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 540 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0067
   Val:   Loss=0.0916, RMSE=0.3026, R²=-0.0095
============================================================


============================================================
🔄 Round 541 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 541 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0078
   Val:   Loss=0.0903, RMSE=0.3006, R²=0.0319
============================================================


📊 Round 541 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2486, R²: -0.0025

============================================================
🔄 Round 545 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 545 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=0.0048
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0070
============================================================


============================================================
🔄 Round 546 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0948 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0948, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0948, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0948, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0948, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0948, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0948)

============================================================
📊 Round 546 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0029
   Val:   Loss=0.0948, RMSE=0.3079, R²=0.0070
============================================================


📊 Round 546 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2486, R²: -0.0026

============================================================
🔄 Round 551 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 551 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=0.0032
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0047
============================================================


📊 Round 551 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2486, R²: -0.0026

============================================================
🔄 Round 552 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 552 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0039
   Val:   Loss=0.0882, RMSE=0.2970, R²=0.0328
============================================================


📊 Round 552 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2486, R²: -0.0026

============================================================
🔄 Round 553 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 553 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=0.0032
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0065
============================================================


============================================================
🔄 Round 554 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0944 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0944, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0944, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0944, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0944, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0944, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0944)

============================================================
📊 Round 554 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0183
   Val:   Loss=0.0944, RMSE=0.3072, R²=-0.0520
============================================================


============================================================
🔄 Round 555 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0976 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0976, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0976, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0976, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0976, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0976, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0976)

============================================================
📊 Round 555 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0137
   Val:   Loss=0.0976, RMSE=0.3124, R²=-0.0321
============================================================


📊 Round 555 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2486, R²: -0.0026

============================================================
🔄 Round 557 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 557 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0070
   Val:   Loss=0.0939, RMSE=0.3064, R²=-0.0286
============================================================


============================================================
🔄 Round 559 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 559 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0034
   Val:   Loss=0.0886, RMSE=0.2976, R²=0.0008
============================================================


============================================================
🔄 Round 560 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 560 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0069
   Val:   Loss=0.0926, RMSE=0.3043, R²=-0.0078
============================================================


📊 Round 560 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2486, R²: -0.0025

📊 Round 560 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2486, R²: -0.0025

============================================================
🔄 Round 563 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 563 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0014
   Val:   Loss=0.0895, RMSE=0.2992, R²=0.0108
============================================================


📊 Round 563 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2486, R²: -0.0025

============================================================
🔄 Round 564 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0906, val=0.0695 (↓), lr=0.000001
   • Epoch   2/100: train=0.0906, val=0.0695, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0906, val=0.0695, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0906, val=0.0695, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0906, val=0.0695, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0906, val=0.0695, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0695)

============================================================
📊 Round 564 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0905, RMSE=0.3008, R²=-0.0043
   Val:   Loss=0.0695, RMSE=0.2636, R²=0.0365
============================================================


============================================================
🔄 Round 565 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 565 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0011
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0116
============================================================


📊 Round 565 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2486, R²: -0.0025

============================================================
🔄 Round 570 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 570 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=0.0033
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0041
============================================================


📊 Round 570 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2486, R²: -0.0025

📊 Round 570 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2486, R²: -0.0025

📊 Round 570 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2486, R²: -0.0025

============================================================
🔄 Round 574 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 574 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0030
   Val:   Loss=0.0856, RMSE=0.2925, R²=0.0266
============================================================


📊 Round 574 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2486, R²: -0.0025

============================================================
🔄 Round 576 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 576 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0086
   Val:   Loss=0.0927, RMSE=0.3044, R²=-0.0190
============================================================


❌ Client client_14 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_message:"Socket closed", grpc_status:14}"
>
