[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb112010-3456-412b-8a3f-2b56df09ee06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67cce244-bf0f-4753-9e9e-8f8269778dc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9a9de3b-2952-451c-86c3-2410d02e6f7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd77f7c0-3f67-43f0-a7df-dc2d9d9b7d68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2459ec8-d537-4d60-bebf-c6b70c53c42c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76ad85d8-c37f-4816-9f94-8255ed82fc4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0c0e3b7-3f27-4b05-b25d-79d490a3b949
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32d27d58-aca3-4af5-8fe9-f0afbb9bf7e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 366e252b-ba32-4b1c-af43-71bf3a164264
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfee67db-d64e-4aab-b9fe-e50cf0a3d22f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71aabead-0b47-4608-9b7b-30b6c036943a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b09bfc4-6b74-4833-9986-b2189c1f93e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27cedda3-1824-4530-a64a-f380d6baeada
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a628926-c873-4c2e-9978-9ed8c2ec52a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a198499f-ebdf-4d29-807f-baf5b60f336e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fa01877-5a5d-4834-b30b-172c04d6ef66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c1ed382-3545-4783-86c0-f1ea8bf5d44d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6de9c266-103d-43bc-88af-7959b1881048
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d1f1a16-1a52-4b7d-bfe9-f78e0a0e8bb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35315722-0cd9-40e4-8fbc-e22a03a3e5bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 974cb308-ed4d-401d-9540-1a490c564e1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c94d7ed-67d0-49e3-8b3f-a692bfb00403
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e31892a8-6165-4fe1-ad91-40f7a4080d17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af12f967-c615-4131-a617-1505e58f6429
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0a6c6e5-054d-49af-8886-b79571346500
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9b1bb91-32c1-4599-b02a-840658d88162
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3a29661-0103-4e22-a303-becb75c5a8c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 690a7bd6-8958-476b-924d-afe0ff144faf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78792796-6f73-47d2-bced-fca21f7ac585
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d58f2d3-698a-4059-a7fd-6a3b980bffe0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b59adae-8c88-4f54-a873-49d7d199373f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c1fc9fb-8c10-49de-a466-d14ba2464318
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83c9fce5-aae6-4888-b89c-3e09ace18659
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1843a8e-00c6-46c7-bdaf-1930d39196f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52500ff9-5ada-4519-a03e-919bea61ec25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fa67338-1831-422d-aa0c-ca5f9bdc18bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f9275c1-3591-4a30-be81-749fc98dd8fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e35a8e73-a09e-4d9d-9590-81eaf06026a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 977b6562-1f36-4171-b43f-f16fd158cbbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9d0e3a7-9562-497c-b3c6-456e90d8c4a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63b3620f-fa1a-4fef-b203-0212eca9355b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5da5f23e-1032-473f-b91b-83ab1f18a772
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c0da2e9-b574-4c45-a507-d74a1cb5bdf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92e6eecb-3ddd-4d14-844f-5270224e6ac7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b161f7f9-4cae-4b05-8dca-dd6218d1499e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8fd0b55-7fe3-4479-8e9b-6cf90dcc393f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 468da64e-3c82-47d7-95f9-42ee41c1ed1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87a53a02-6658-4e61-932f-b1e540d2179c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f49e5790-c8ea-4796-baa8-05de6a373bc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9178e1ec-a9bc-4ec8-8756-669ebc7e71f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d3c244b-1b3d-43f1-ab8a-87eccaa3be5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c280520-e541-42d1-aebe-fa3c52d92d27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa4afe41-debe-4bc9-875a-766ead4eb6f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fddf8c54-6d73-480c-a58c-af1d9c8ff0c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c5d343c-d210-467a-a97a-1842ec7d501a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4058400e-343e-4db0-a11b-b0635902f045
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e97e809-592e-4d20-83ad-9ddad7bed2e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 527ba4c1-762b-44d6-a6a4-fe00f120eab1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d180cd96-18e2-49ba-a949-f3666c5b81ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fce59c0-3dcf-40a3-8ef0-f3c732b25785
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4aa513b-c6de-44b8-b348-d4c1ab202b71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63c9e3de-1770-4e3d-9122-caa09fcb457a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eda0c048-4dbc-449d-bd0f-b1474e86ff0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 909fc425-d1ed-4bda-84db-5f17c87ab83a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 064573c2-71f6-4607-b41d-8a76aeb03149
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9704fda6-0346-49cd-b9de-be9122f48017
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7464381-15f6-47c0-a1db-e12d8478cfa6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac7150a4-622a-4c81-9ef5-97cb78a2fc34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91e72c2e-92ff-4abe-823e-67637bb3b8df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b3096c7-cd81-4912-9315-c0e562d47018
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20b65c3a-bcaf-463d-9154-2343a341ad6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0dc761b-7c5e-4cb5-97ee-2189def3899a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19931fe6-5a3c-4eff-ac35-a941d2529601
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 493d6390-ba7f-499c-b279-4b66e03d6503
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1121e1a3-e0af-42bb-ac0f-5fdd692a49e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c75ec41a-17f4-4704-8fc3-55954a9b4d26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29d8dcb8-d41a-4d72-9555-fcc3d6798c08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7dc390c0-768e-4ded-9456-8de6418fc7a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3b718a1-56d5-4d44-8c3f-d7fc4f08a524
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7cae1ab-eb79-4b62-9312-b5da9f4235bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 082ed9b7-96ea-431a-9119-7b18770f97b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e35d82b1-028d-4a2d-863e-b0a6a89f35d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f7df2a9-f1af-456f-9c25-8c0a96edbba2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9ffd63e-8060-4808-8e6c-d0824269e012
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8c5bccf-7747-4b9d-9e45-360d19f71bea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5cd4cee-b85c-4532-bec9-2b59c30f032f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f21f66eb-9be7-4630-ba22-f7dcae874928
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7d17434-b2a1-4b25-b2c0-ceeee095dc09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbc7e83e-fc19-44b3-8b40-4c5e3d0cb2bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 898ed249-90ea-4f31-b19a-c7f7d89921cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88c7c887-a591-4732-8482-9647637b2099
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a20e8071-cf70-4f8a-9601-3452766d9fa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d46092d6-f524-47e8-9550-a2ea16df37aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fc63f6d-fa1d-42fd-a033-3b8e5955ea2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36705654-cb00-4bde-b1e0-de6b93b52c97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1238d530-adc3-48d1-b001-e80a283c5857
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eabef589-99af-480a-989e-74e5ec2a1261
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4166314-6d92-4eb6-9f8a-0c60c5f5160f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba65f86e-c10c-4d44-b130-8265429ebb38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acf6c41b-4595-4720-89db-6bee9962330f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0de542ed-9760-4527-bbf7-d9b6e98ad461
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f93fac68-bc51-44c4-b506-d42ad311129d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1dc11e4-b942-4b98-a32f-59f8da98ef7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29e437b2-9dfb-498c-9a4d-7140fd3954be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a2e4f03-6c38-477d-ba2b-addf0310afb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42688d2f-819e-49f8-acdf-f965f4034e70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 972e4658-df4e-49e0-bee2-5cafb670afd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b966c743-301a-4ad3-a706-7182c8f3d7f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3dc7d1d8-810e-4d03-a57d-898495d01935
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 415e99d8-5816-48cc-9474-99f9d18b028c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3696a419-3d12-477b-8f1f-5ed30bdc7a29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b32d821-3c9b-4a22-891d-6f273dc767d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2353eaea-149b-42cc-b225-4eed04a3279e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ac43ada-d240-4789-9792-3e17287fcfe9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b6468a4-8d62-45cd-bbe1-5c099ca4e9c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed61805c-b09c-4f92-b479-401be4bc1f17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c95dc775-ec51-42fd-87d0-aede001902d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ccc10931-9208-42ce-8534-fc68f316ba46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b5a7524-951c-4cae-8a91-b8551f083a3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9743d2d-42eb-42d1-a16a-90f1484803d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d7cadaf-5f42-40e8-9b1d-eb4c2d2505bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1132c81-ff6c-4aec-93b1-f9a281ca28e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a9f61e6-9bb8-4017-9278-68bf5d3740d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aeb72352-1307-421c-aaa3-1a7d164aa1fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26230db3-97b9-4575-9224-8817f2070031
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a8bf7e8-15af-442f-847e-211c439448fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cad39a1e-2798-43e8-b5ce-1dc2ac1f2960
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a69e1b9-e2c8-415c-be8e-0c15843f56b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6c5f97e-d90d-4cde-ab89-c8b016195666
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1fa96ca-e2d6-4c6b-9f75-467653fca121
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f3656f4-4f64-494f-bed3-224f95a75cec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 758a9b34-2da0-445f-82f5-39b9ae2e6e19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6931ab3-b236-461d-aa3d-766360d4f120
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38336e2f-530e-4cdc-95c6-7c78e72cef03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e019fd09-501b-4861-8274-0534ed873cdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9761b16e-bc34-49c2-9512-f183a853f9c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ffcc5b7-e691-4e6c-ad92-9d2d05b452a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc3c8988-c491-49e2-a939-e6c7e32f452b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1cb7ca3-0b35-40b5-812a-cbfb4915ca22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2859f645-40c7-4a87-b70b-5af74e73fd9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be196ca5-c13a-4834-9556-7bd37bfabeb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68187ced-ce59-4791-a604-aea95e665edb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71585246-5962-418e-b4e0-723bf312e209
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f91b6cac-225a-4c7a-a967-7a8c01680119
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 912a419f-7f84-469f-b0b4-38125cc1962e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e97e5bf-7d4f-422d-8b8f-3f2d54c60a56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70a6eb7d-2704-4489-8857-26e87e603422
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d8ef9ff-f222-4a2b-8716-2ab767ea01f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b4d9528-8e7e-48c0-8037-a4704e84a427
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdd2efb8-215a-4fb4-8f1e-31bdd5c46a0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5a8a86a-aecb-42ae-8fd1-a240b8901c76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3ef15d2-1a5a-4bae-a432-c7e3eb327194
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37148d6e-69ff-4be5-acd6-2e17fbf2a08e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84e9826e-7ac9-4766-9e9c-fa51f7cd1b33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fe53aee-02ae-40c1-a99e-1969a416b6e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abed2cce-17ec-4826-ae87-cdaa8ac20edd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf0dd328-7c26-4750-815a-d14a04a30ca9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2168daea-33ce-4891-a167-2336ed5f2113
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e07625f-ec97-4f40-a15b-92cfee80db9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bfd9a48-96d9-47d7-947e-a03edfa474a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2612ca2f-04f1-4e88-8fd6-b43b302273a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fae90af7-53dd-4318-9d1d-1b6ad0328c26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ee63366-ff7a-490a-bd08-c2c1099f720c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc24bacb-66cc-4628-871d-5f3b0ed92a7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1dba1f18-950c-4886-8e7d-373a48f60264
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a537d252-b28f-4451-a802-f97852501b69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c329b0c7-c86d-4f31-a47e-1318904b9f7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa675443-645a-4d2b-8b75-94c43a19cae2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b93c735d-af95-4b3e-b88b-f86d00c554ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c59d4879-9978-4368-8756-945beccf334b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ee79ee5-1308-4a11-a8e4-4bedb378b0b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c3765f1-58ef-4f72-9192-71bce1568bfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac0ca2f0-d0a0-4441-be3b-a12efba0e26d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3bfecbb-f693-4f16-a4d7-4bfe3690384f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73a90fe3-00ba-43a8-ab1b-92638be7c6ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ee5e6a4-991f-44cf-b4d9-9828695fe693
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19ad43ff-d16f-41ae-bf38-b8835e06a83a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c004504d-c96a-4eaa-a80d-4a764d9ac21e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 706baf9c-67be-4218-8ccc-7217ca69d7ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d7a3bb7-a9fb-47c2-a373-3e65a6f26f96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80e0039b-4f28-4a22-a620-14c60c2b5b87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e00cd2ea-baf3-4eb3-a0c4-e49dfd4138d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b1aa299-98b3-4072-af4d-6de5274eb147
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a396db5f-d1c4-4299-9daf-af6f12f569ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33b5e3e2-c3bb-41c4-b842-6801100406d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37e6b730-029d-4b89-9d82-fc739013c3c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d99d0a75-33f4-4f78-a6e0-7b13ee443ffc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 295bd7b0-6554-4b34-a320-071822f3859c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3487073-1af7-48b9-a30d-2edee62e2b2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6800a6ec-b797-4398-947c-f551c09363d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7ec59fb-dc2c-444d-903d-9c416e102d39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e30d1dd5-d4f2-46f4-ab04-3ee3a96aac4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a80bd2b-ab31-4df4-a167-52e0175b6fbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7aebb645-92a2-4f71-9c4a-d1f6557d3e49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8504ad65-9e5f-4d2b-a559-7e91cfe1fd55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f89d30c-d336-4117-b1e0-c2fca7fb721c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05dd234b-e366-4510-852f-cd944414df41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5de9cb2d-725a-4564-9de0-7e85196c42f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44cfd132-48f9-4984-b80d-2a1418cf9be3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fca5abfe-65f7-4103-89d0-13eca321e145
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de27e550-8291-4ee0-8df8-4e83712199dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4e58c9a-af74-4d7d-8fad-f9c24dcb57a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5d802c4-3b15-4ef9-a26a-a808d51352b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83b1ed2d-2ea8-4f53-90bb-6d639835a905
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 886df876-6e35-4ea9-83e2-f39f3ddb5960
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ccde9a3-1963-4e36-ba7a-78023117472a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eebce0ad-943b-4723-9695-2ea6bc925ee8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ba261c5-4463-43b3-90ab-c0b185a9b892
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72076596-e2c3-4d07-9585-c1a364c0d740
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52596eb3-c211-4adf-b8e2-b2168c0cb15e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c71dbc7-e4e6-4e3c-a69c-eaf859165bdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e941d670-d945-4eab-a09a-c0f583b29e35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31eb01f9-7fab-473a-816b-ed6455c58ad7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58d59a1b-41c5-471c-bbcb-bea1a18a04e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58f79547-64aa-4413-ad1c-952d0f081bc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 697359a9-4e01-4d8a-96fc-22dea6d1b8c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd60c21e-ffcc-4e46-a00f-17e2e4dc0d27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 630117e8-f421-4641-bc77-e89125e4a227
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9bf4736-fe1e-4bf9-a0bf-c407b8f6881c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56f9c660-1bcb-43b0-8cb6-6e3f2a627893
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89937adc-e33e-469e-8104-8291ed837602
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b5c79d8-9f9e-4482-bde9-74709a43d7c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 013a9303-45db-4468-8523-a2bf8ed00c77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf978e5e-11e5-4414-adce-9c3c96c87f82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c6f1edd-3275-405d-970e-34ef7f4d4def
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3621912d-6838-4e13-844a-1cd1f1bee8f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc9773b8-f376-4d4d-bb4b-9a401e05dab3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4685fcc0-c0e9-433c-a812-bb24477d702f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7c11708-9a89-44f4-8340-33a939f08309
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae857cd1-3041-48d7-8189-9bc1a5ae0f3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8065906-6b5c-4be1-8099-f6e60753a18a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c4a7840-9209-4081-9a45-326a52125392
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a26969b-598e-4889-a563-459f02a79779
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 365ff541-7f03-40fc-bbb2-cea235aa89ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b61d590-6be1-4945-ba26-eab847d1a294
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c494c360-b33d-44be-8737-5664a50fde6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8610e0ba-7d57-431e-94cc-8a23f88a1df4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c052476-ae09-423a-82c6-71c1ee4d2192
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53b72313-21f3-45dc-a827-8c877021db2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0ca7961-3d24-4b86-882b-384c8a61ae2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 490823be-7124-4a53-8d5b-e49a2be838ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad97876f-2677-4b18-892a-a3501cfd05ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e79b7fa-fb77-4169-9df2-18e87baede19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04904a5d-1b49-4787-a9c2-66a46cea4272
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc297018-835d-47a6-952a-d3baecda51a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f2083ff-7131-412d-bcc1-3ca6219b7a64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0de5ba2d-2dde-46a5-b7e9-a9160c1cb5a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 514e3d06-8bf0-46db-9c10-327cefb629b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 349606d0-040a-4783-a23b-2c202f823631
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f122f2b-709f-4d9f-a919-ad63e7f23d48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2ffc64c-c7a9-44bc-84e3-9bd98dd7692a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c5b8b6b-7734-4370-9a63-a16ca83d8544
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14d2e355-5b8f-41ec-8c93-738a720a42a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e59bd3d1-4f99-49e4-89ef-007512bb442c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a34e9dcb-75ef-48fb-9c48-e8fbc979a065
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2c49b26-9e86-49f6-b1af-27c420941842
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02b459d2-6491-4458-9cc1-899b229773dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ab99a2c-4c84-485b-8873-2ad0841f9092
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46bee238-71c4-4c0a-8956-f8a74beb91cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94025e68-cf48-46de-bd73-2787e314d727
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a3626e7-72aa-47e3-bdd7-edfcc9432382
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9eb098a-ddb5-471a-a916-1cf07222681c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08580645-2eaa-4bc8-b940-db3f79ce6bb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab4975c9-2e55-40cf-9cc4-bd9df676c4f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3326527d-d457-46e2-a0cb-968ae2139e4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 254749da-481c-4288-9e62-994fb7f9a896
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0f0fcbb-6fa3-43eb-804c-60440c4fd2b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33009805-f8c6-49e3-adb6-c796ee64c04a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 038ff499-75cb-4041-9674-76e56153b248
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ce96d00-35bb-4ed9-991a-6335d6ba8229
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cc4e5be-bbf6-4ed4-8887-1b35a8b4240b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66c654d1-cbdf-44e6-ae6b-45d730fee89c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25550c09-3d77-4792-9059-1af9b8c6bc2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b3024eb-99e8-45ee-9dba-e3aa3a1fc028
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0088cb9d-6cee-44f3-8991-2c96e3439ba9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 871e692a-06ec-4865-8292-ac77a1597408
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7657bbc3-00a4-4bc2-969e-2990fc976f6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89414265-46fc-4f5b-b200-979975ebdec5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a7de5df-7189-4584-a946-6f622965f2ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c544cc25-ce2c-4c28-924c-755a035d79ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e1e3e2d-78bb-46e4-bdf9-395b505a2eb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67ba4ef0-1d5d-4f11-ae5f-434225aac59a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d838e731-0c89-41eb-a5c2-235c249647c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 320581ee-57e4-44fb-bb31-e6f8ab147e1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae549046-e056-41ff-9f0d-81f2e65d4c3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3313ed13-ab0e-4c09-a7bd-309875557bb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43e21f18-6021-4560-a981-3b85ec3843c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87284a5d-61b8-4e0f-b591-6178ac0a84b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d6ca8b2-657d-4371-bb4e-3f7f1cc54c8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d475d2c8-c3c2-4626-b119-5c09d2350ccf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4db6c758-cb40-4ebe-ad0f-79217431c62d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbe0bd91-011b-4d71-b5bd-352e27a4bcdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9174e617-27af-4623-80a8-c165bec36d14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2823c42-bab0-4c86-ab14-7067b5fab4d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f3fbd0a-79ec-4857-918a-f1370a8c3f1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2a8a0b5-24d9-4930-8083-ff806597f315
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cc615e3-da18-4537-ac84-ce2c51de5a61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a17afbcf-17c3-4a2b-b9d1-895fdaac4fe1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53223ef4-7203-40aa-9acf-5436e7e5eb33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb640c67-6ffd-4d02-9f84-14649c595baf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85c05611-1826-4c40-bf9c-60603638fb2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5977402-76c7-4333-bfc9-9982ae075be6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b08c3ee8-f7b3-4768-b9df-cb5dcf336aeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be177285-7b08-4d35-8166-a78567de0a7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1867eb5-5b24-4c49-99c0-7337b54224b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf854158-318b-4acd-ac6e-da04cb6ac30c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 396c7b47-5df9-4668-a02d-aee8bbddb463
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1db7795c-5485-487d-a493-2cd20ee1ecab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad358818-8779-42c8-87f7-e64334b3f63c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6fe59b3-dc8f-42c3-bd0a-ab6244c423db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfff9f4c-94ee-4bf5-b5fc-723fd1406550
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f01a2c9-0466-48db-b31d-b32b46a16978
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c75e1ee-132a-4cf6-bff9-d962a647cf53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61894d9c-f334-45fa-b16e-344537102420
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 125c2f6b-e8de-437b-94b5-8ce6ac6c5ad9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59b8fed1-e804-45e9-8f51-1f853e00332d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be1fa142-5e30-4561-a1c1-ed9abb6d76d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8b1f0b5-a7da-435b-a260-face6aa39314
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0903c832-b710-46e9-a964-47f2e6103310
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9f03058-1dfc-4f33-aa41-285460a36460
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4917eafc-9c8a-4d44-befb-538b9ccab770
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b891c1f1-7d2f-4bbf-8825-85f4ea8bef3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fb1dc81-9a97-4248-a982-e2e7557a5907
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b65a661a-a00b-4d76-b5f8-f0cd2e7f39ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f5ce875-45c8-49f9-a57c-096a491aae02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2c9dbf7-d32c-4e6c-af63-4c9908e504bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35c78d91-01ab-4e43-95fc-4109b2105a69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4488845-1bc9-489a-96c8-05f4f21484a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61f879f3-2af3-4340-84f2-a2be00f19e48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 588aa7f1-7e54-417f-8558-feade9777706
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a7898d9-f02b-44d0-9e49-d2f5f29149a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fab21693-8ba2-42f4-9d53-74ce6b99ce6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc0322fc-bb61-48ec-8686-8c7268d687d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99e566c7-23b0-4c96-a267-c2873ca706bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2112f5d7-794b-4249-bd68-73bc1d283339
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df68705b-305d-4faa-b564-b61e29a86529
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c60f8486-1a62-4acd-930c-51f2c1da2ee5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0af5ab83-9daf-49c2-ad96-524d8d1ef319
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d653e51-2e58-45ee-8080-021c8aeec713
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce1634cc-d9bd-4025-b025-f6c35c299840
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c056b4f2-92a7-4d52-86c7-9b1ae0cc8f12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a327de8-a51f-4c42-87a6-5efe0aa87971
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75a63d3b-9693-4153-9a71-8fe15f054015
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce31beab-f6d7-4840-bd6d-319cc627ff51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f4a023b-2a03-42b4-91ba-0b1ce1509f98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15cc1675-f4a2-4f56-90d4-ee9c1a596635
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9b4829e-970c-4658-a4cd-0c9ccb34d7a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7eb6c83e-628d-46d3-9a09-a8a93b0677ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99cb3b42-17ad-4799-960a-f928e89b729b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c9b586a-27ab-4703-8752-ef755d45ecb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c57330f8-3d32-40d0-89ca-de86d0f767a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52bd3ed1-26e5-47f1-abaa-4a266b0e3061
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f12df842-f928-48d8-871a-139c65891831
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c389a243-48e6-4e89-88d1-3f65b6e5b295
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73f507b5-f9d7-4bb8-b4cb-3ac8daa50761
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77bc9f99-5d32-440e-a464-dd4ce0a74dc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d890df99-4980-4bd6-a230-265c309cbdc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1fd5572-ea87-4d6f-9692-63f33c2af470
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7a8cb4c-a556-4a2f-bbd1-6e0bb3df26b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a7ababe-a110-40b5-be18-f8d90e8295f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31671122-719c-45cd-b0fe-9758367f698a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ecb0c29-592f-4b81-8444-e6f1b99f80a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e800bf9c-1c02-4eec-a1bc-a9bb89b68840
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aeae5df4-6ba6-4ef1-af0e-1e409667f4b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a684210f-e84a-4905-a136-0aadabb61597
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13aa370d-f638-4601-b9b0-09474276d896
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7541042-414e-4b20-906f-4122bf7a1fc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1721c09e-a409-4700-b755-e9921c46d77a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 270aa0c8-c79c-4efd-a3f9-0cb8a26f4cef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16fd7d27-634f-40a8-b13a-eff2524bc95e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c25bd506-7796-4670-bb5d-9cc569826d5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e40689a-51ca-4a62-be04-03fefa396a58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5354dd21-c14b-43af-aa4b-ba6f2679c435
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b21ad1ce-fc4f-4d15-9260-29779d878a45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74ad19cb-b107-4e5a-b262-96dc1b7621ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84680c1a-d976-4563-8117-c1df631e0339
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 360956d9-61d0-4407-8284-8cc548f21b69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a65df01b-d03a-463e-bffa-5f82299efbce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a54b6bb9-1060-4ec2-a5ad-de09e7e74cb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a5f77fd-738e-4f47-a358-e7b1412833a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a516193-88d6-47f8-80aa-87985f321894
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f770bfaf-4872-4af4-ad7e-b05c4727466b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 020dd7be-faee-4d16-95ef-e90c3e2e9732
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c334b8b8-3253-4887-bbd3-d51588c5419e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b58ca46-74fb-4c83-97ef-dc5facb753a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26e0724d-343d-4cc9-8e9e-9c12f37d32e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e30fed4b-20ee-47b4-b8ab-353aea20ec71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef08cb6e-6c24-4b0f-804e-69e1b4505f4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b893866-a7d1-42ac-bb26-e703d9c6f024
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96c6bc7c-4cd1-4954-a26b-e75821a8ee98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0566767c-0fc0-456c-be2f-d944970fa23c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebd45ee2-1933-4fd9-9d3d-63cf09d71b99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 354532a4-f589-4ab3-ab6c-5fbac8e5e0c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d902d10-c563-4ef3-a29f-b2b5d887e8e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6cdd785e-5956-48aa-9238-a8fbed5e6b4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ceb9c1f-0583-414a-bca5-0a5eb75c97e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33b9c951-e069-429f-9cd4-0d0e3b1db047
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3278c733-f38e-4ea8-9968-e8f0635ef2b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7982a86-437a-4c23-b71e-d4d8f41578ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcc40fdc-3f88-442e-9bc8-f0e43a664f1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c524e67-f068-4fe1-968f-f0b6c1dea24a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f01d88a9-d096-49b0-bd4c-bee8d41f113f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73587c43-96fd-4091-83e1-b23e08fc3d61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de1aabdc-eb90-46a7-84f2-e8c5f07df483
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc29eed9-634d-4d5c-982e-ab7fb408a020
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 699ddc0d-2a7e-45f8-816e-84008d4b778e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a91a90a3-a16e-4a87-b121-dd1b29d32cda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bd0b86a-f58a-4baf-84cd-8dee169b58b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69f8892f-3b26-42d3-90e6-9fde734f4b23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa47b221-6dd3-4d72-856d-8cffa925e14e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 051bb8b4-ac02-48a5-bbd3-24e5c84aa606
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4a3a1af-7eaf-48e5-b316-243560eb671e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91c29ca5-fd17-46c5-9a20-23b8c8db5d00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3726a320-29bc-460e-a75f-84b698e2fad7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00b6faf6-93b2-4f52-a7c3-40c010ccbb44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b1e6828-fd29-4699-8071-1046e02b4b7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4aaed7c1-4436-4c0b-8581-a7f41b3c7981
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67437171-93f1-479d-80c5-2222a331b88d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6925d9c-643a-4d37-a864-ed6a551c83a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0b4f08f-1321-4979-a5c5-8458e30ec34d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c752d99-820f-441c-84ca-c3609fb1206f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 426657f5-550e-4aaf-a12e-a2f6928ef003
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 520c29bf-b3ad-43fa-b9fe-1452c58a1b48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd1de0ec-7f08-46e0-9de2-ce3ecdea37e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6db99652-d498-4f11-bd7f-111386184c5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad66d642-757c-4e77-814c-7ab430d9b601
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc7f4a00-6ba5-4e0c-b538-e707cc89594b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e8d9116-2361-4b78-a657-3871b9cf3379
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 221eb7e2-61c3-466d-8df5-c53fbc2fe4aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bde20e1-76b2-4f09-8958-493bb6a77bd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88cc9f54-6eb3-459a-b580-8af7dc9a0219
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08e11735-66fd-4b93-b9e3-63606e873c90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bff3424c-7a42-4475-8286-40b28dd84abf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67ff0d91-24e8-4407-a6c4-13e8843a6e74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8ec82b0-e115-43b2-b12e-763e28339575
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c355e38e-eedf-4a3f-ad1e-37878ee5477d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f345fdc1-46f2-47cb-a617-4f37c307fea6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5aea57d-ab85-4b74-871d-35ec19b932dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8bda40b7-cce5-4e68-80b0-5acafcc529e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a66f9de3-17cd-4355-a870-4cf89cc70c5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b563ae7-6c4d-4760-a9b5-93338ebd25d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd292336-a1f3-41cb-8f64-82e0f6a17a1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ee8468d-8b3b-4631-ad24-47535593a217
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5a9afea-50f8-42e4-9b5b-4c51a7faf313
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fb5b436-e304-4211-951b-dec4d48d69e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 454842cd-9cea-49aa-abe6-3a9018e3c942
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4fa41162-25e5-46ce-8b2d-76f51e02150b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a94bece-8d89-495f-aa63-7817ff1868a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac5e8798-041e-4e07-8ae7-5dc304a90539
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0b67348-7f10-4a64-88e7-066343a7f7c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7de2a39b-7c24-41bf-aad9-dd66228e3d7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abf35098-3da1-4f6c-a6b7-c9f45f1e6aba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0182a862-6136-4c10-a078-4c26e306e59f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7e73cf1-37c3-4f26-84b9-847f4f0acd80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac506ac8-1b01-466c-8363-b4bb28ae761c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccbf773b-9169-49cc-9607-d1b0f857bf12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76621d4a-428d-404b-b273-e0e3628a6605
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c214a8e-14b7-4d60-b02a-57de2b8dee91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a52c6290-5025-4f12-9c02-13472c89fc31
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_16
Server: localhost:8688
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_16
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_16/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_16/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_16/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_16/test_labels.txt

📊 Raw data loaded:
   Train: X=(3836, 24), y=(3836,)
   Test:  X=(959, 24), y=(959,)

⚠️  Limiting training data: 3836 → 800 samples
⚠️  Limiting test data: 959 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_16 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 2 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0774 (↓), lr=0.001000
   • Epoch   2/100: train=0.0800, val=0.0780, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0800, val=0.0782, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0799, val=0.0780, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0798, val=0.0778, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0787, val=0.0767, patience=2/15, lr=0.000500
   ✓ Epoch  21/100: train=0.0778, val=0.0758 (↓), lr=0.000500
   📉 Epoch 30: LR reduced 0.000500 → 0.000250
   • Epoch  31/100: train=0.0758, val=0.0757, patience=10/15, lr=0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 2 Summary - Client client_16
   Epochs: 36/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0293
   Val:   Loss=0.0758, RMSE=0.2752, R²=0.0288
============================================================


============================================================
🔄 Round 3 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1701, val=0.0832 (↓), lr=0.000250
   📉 Epoch 2: LR reduced 0.000250 → 0.000125
   ✓ Epoch   2/100: train=0.0861, val=0.0826 (↓), lr=0.000125
   ✓ Epoch   3/100: train=0.0815, val=0.0772 (↓), lr=0.000125
   ✓ Epoch   4/100: train=0.0807, val=0.0760 (↓), lr=0.000125
   • Epoch   5/100: train=0.0806, val=0.0760, patience=1/15, lr=0.000125
   📉 Epoch 10: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0805, val=0.0761, patience=7/15, lr=0.000063
   📉 Epoch 18: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 3 Summary - Client client_16
   Epochs: 19/100 (early stopped)
   LR: 0.000250 → 0.000031 (3 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0019
   Val:   Loss=0.0760, RMSE=0.2757, R²=-0.0417
============================================================


📊 Round 3 Test Metrics:
   Loss: 0.1464, RMSE: 0.3826, MAE: 0.3155, R²: -0.8743

📊 Round 3 Test Metrics:
   Loss: 0.1039, RMSE: 0.3224, MAE: 0.2659, R²: -0.3304

============================================================
🔄 Round 6 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1116, val=0.0930 (↓), lr=0.000031
   ✓ Epoch   2/100: train=0.1023, val=0.0861 (↓), lr=0.000031
   ✓ Epoch   3/100: train=0.0952, val=0.0818 (↓), lr=0.000031
   ✓ Epoch   4/100: train=0.0905, val=0.0790 (↓), lr=0.000031
   ✓ Epoch   5/100: train=0.0873, val=0.0772 (↓), lr=0.000031
   • Epoch  11/100: train=0.0804, val=0.0748, patience=2/15, lr=0.000031
   📉 Epoch 16: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0796, val=0.0756, patience=12/15, lr=0.000016
   📉 Epoch 24: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 6 Summary - Client client_16
   Epochs: 24/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0069
   Val:   Loss=0.0748, RMSE=0.2734, R²=0.0046
============================================================


============================================================
🔄 Round 7 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0842 (↓), lr=0.000008
   • Epoch   2/100: train=0.0827, val=0.0838, patience=1/15, lr=0.000008
   ✓ Epoch   3/100: train=0.0823, val=0.0834 (↓), lr=0.000008
   • Epoch   4/100: train=0.0820, val=0.0831, patience=1/15, lr=0.000008
   ✓ Epoch   5/100: train=0.0817, val=0.0827 (↓), lr=0.000008
   📉 Epoch 8: LR reduced 0.000008 → 0.000004
   ✓ Epoch  11/100: train=0.0807, val=0.0816 (↓), lr=0.000004
   📉 Epoch 16: LR reduced 0.000004 → 0.000002
   • Epoch  21/100: train=0.0801, val=0.0808, patience=4/15, lr=0.000002
   📉 Epoch 24: LR reduced 0.000002 → 0.000001
   • Epoch  31/100: train=0.0799, val=0.0806, patience=14/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 7 Summary - Client client_16
   Epochs: 32/100 (early stopped)
   LR: 0.000008 → 0.000001 (3 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0097
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0244
============================================================


============================================================
🔄 Round 8 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 8 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=-0.0004
   Val:   Loss=0.0878, RMSE=0.2964, R²=-0.0018
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2441, R²: -0.0483

============================================================
🔄 Round 10 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 10 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0117
   Val:   Loss=0.0760, RMSE=0.2757, R²=-0.0123
============================================================


============================================================
🔄 Round 11 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 11 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0007
   Val:   Loss=0.0760, RMSE=0.2757, R²=-0.0260
============================================================


============================================================
🔄 Round 12 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  21/100: train=0.0799, val=0.0889, patience=6/15, lr=0.000001
   • Epoch  31/100: train=0.0794, val=0.0884, patience=7/15, lr=0.000001
   • Epoch  41/100: train=0.0790, val=0.0880, patience=6/15, lr=0.000001
   • Epoch  51/100: train=0.0787, val=0.0877, patience=2/15, lr=0.000001
   • Epoch  61/100: train=0.0784, val=0.0873, patience=12/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 12 Summary - Client client_16
   Epochs: 64/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=-0.0071
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0316
============================================================


============================================================
🔄 Round 15 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 15 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0006
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0540
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2354, R²: 0.0237

📊 Round 15 Test Metrics:
   Loss: 0.0761, RMSE: 0.2759, MAE: 0.2353, R²: 0.0255

============================================================
🔄 Round 17 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 17 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0049
   Val:   Loss=0.0776, RMSE=0.2787, R²=0.0403
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2354, R²: 0.0251

============================================================
🔄 Round 19 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 19 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0183
   Val:   Loss=0.0769, RMSE=0.2773, R²=-0.0142
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2356, R²: 0.0238

============================================================
🔄 Round 21 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 21 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0158
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0235
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2357, R²: 0.0234

============================================================
🔄 Round 22 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 22 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0200
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0088
============================================================


============================================================
🔄 Round 23 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 23 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2806, R²=0.0224
   Val:   Loss=0.0752, RMSE=0.2742, R²=-0.0034
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0762, RMSE: 0.2761, MAE: 0.2356, R²: 0.0241

📊 Round 23 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2355, R²: 0.0246

============================================================
🔄 Round 30 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 30 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0166
   Val:   Loss=0.0721, RMSE=0.2685, R²=0.0060
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0761, RMSE: 0.2759, MAE: 0.2354, R²: 0.0253

📊 Round 30 Test Metrics:
   Loss: 0.0761, RMSE: 0.2759, MAE: 0.2354, R²: 0.0255

============================================================
🔄 Round 36 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 36 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0180
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0079
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0761, RMSE: 0.2759, MAE: 0.2354, R²: 0.0257

============================================================
🔄 Round 38 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 38 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0097
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0366
============================================================


============================================================
🔄 Round 41 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0647 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0647, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0647, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0647, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0647, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0647, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0647)

============================================================
📊 Round 41 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0171
   Val:   Loss=0.0647, RMSE=0.2544, R²=0.0057
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0761, RMSE: 0.2758, MAE: 0.2353, R²: 0.0260

📊 Round 41 Test Metrics:
   Loss: 0.0761, RMSE: 0.2758, MAE: 0.2353, R²: 0.0260

📊 Round 41 Test Metrics:
   Loss: 0.0761, RMSE: 0.2758, MAE: 0.2353, R²: 0.0260

📊 Round 41 Test Metrics:
   Loss: 0.0761, RMSE: 0.2758, MAE: 0.2353, R²: 0.0261

============================================================
🔄 Round 49 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 49 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0214
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0247
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0761, RMSE: 0.2758, MAE: 0.2353, R²: 0.0262

📊 Round 49 Test Metrics:
   Loss: 0.0761, RMSE: 0.2758, MAE: 0.2353, R²: 0.0262

============================================================
🔄 Round 54 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0706 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0705, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0706)

============================================================
📊 Round 54 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0128
   Val:   Loss=0.0706, RMSE=0.2656, R²=0.0180
============================================================


============================================================
🔄 Round 55 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 55 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0032
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0372
============================================================


============================================================
🔄 Round 56 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 56 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0092
   Val:   Loss=0.0757, RMSE=0.2752, R²=0.0314
============================================================


============================================================
🔄 Round 58 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 58 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0192
   Val:   Loss=0.0728, RMSE=0.2699, R²=-0.0169
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0761, RMSE: 0.2758, MAE: 0.2353, R²: 0.0263

============================================================
🔄 Round 60 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 60 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0220
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0217
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0761, RMSE: 0.2758, MAE: 0.2353, R²: 0.0263

📊 Round 60 Test Metrics:
   Loss: 0.0761, RMSE: 0.2758, MAE: 0.2353, R²: 0.0263

📊 Round 60 Test Metrics:
   Loss: 0.0761, RMSE: 0.2758, MAE: 0.2353, R²: 0.0263

============================================================
🔄 Round 64 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 64 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=0.0087
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0275
============================================================


============================================================
🔄 Round 66 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 66 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0040
   Val:   Loss=0.0780, RMSE=0.2792, R²=0.0453
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0761, RMSE: 0.2758, MAE: 0.2353, R²: 0.0263

============================================================
🔄 Round 68 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 68 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2749, R²=0.0076
   Val:   Loss=0.0899, RMSE=0.2999, R²=0.0214
============================================================


============================================================
🔄 Round 70 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 70 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0108
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0178
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0761, RMSE: 0.2758, MAE: 0.2353, R²: 0.0263

============================================================
🔄 Round 72 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0699 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0699, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0699, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0698, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 72 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0088
   Val:   Loss=0.0699, RMSE=0.2644, R²=0.0028
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0761, RMSE: 0.2758, MAE: 0.2353, R²: 0.0263

============================================================
🔄 Round 73 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 73 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0072
   Val:   Loss=0.0764, RMSE=0.2765, R²=0.0232
============================================================


============================================================
🔄 Round 74 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 74 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0147
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0045
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0761, RMSE: 0.2758, MAE: 0.2353, R²: 0.0263

📊 Round 74 Test Metrics:
   Loss: 0.0761, RMSE: 0.2758, MAE: 0.2353, R²: 0.0263

============================================================
🔄 Round 76 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 76 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0068
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0315
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0761, RMSE: 0.2758, MAE: 0.2353, R²: 0.0264

============================================================
🔄 Round 78 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 78 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0136
   Val:   Loss=0.0760, RMSE=0.2756, R²=0.0046
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0761, RMSE: 0.2758, MAE: 0.2353, R²: 0.0264

============================================================
🔄 Round 79 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 79 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0113
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0144
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0761, RMSE: 0.2758, MAE: 0.2353, R²: 0.0264

============================================================
🔄 Round 82 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0692 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0691, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0691, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0691, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0691, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0691, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0692)

============================================================
📊 Round 82 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0144
   Val:   Loss=0.0692, RMSE=0.2630, R²=-0.0008
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0760, RMSE: 0.2758, MAE: 0.2353, R²: 0.0265

============================================================
🔄 Round 83 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 83 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0148
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0008
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0760, RMSE: 0.2758, MAE: 0.2353, R²: 0.0265

============================================================
🔄 Round 87 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0704, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0704, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0704, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0704, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 87 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0022
   Val:   Loss=0.0704, RMSE=0.2654, R²=0.0522
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0760, RMSE: 0.2758, MAE: 0.2353, R²: 0.0265

============================================================
🔄 Round 88 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 88 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0124
   Val:   Loss=0.0729, RMSE=0.2699, R²=-0.0007
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0760, RMSE: 0.2758, MAE: 0.2353, R²: 0.0265

📊 Round 88 Test Metrics:
   Loss: 0.0760, RMSE: 0.2758, MAE: 0.2353, R²: 0.0265

📊 Round 88 Test Metrics:
   Loss: 0.0760, RMSE: 0.2758, MAE: 0.2352, R²: 0.0265

============================================================
🔄 Round 92 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 92 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0071
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0249
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0760, RMSE: 0.2758, MAE: 0.2352, R²: 0.0265

============================================================
🔄 Round 96 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 96 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0048
   Val:   Loss=0.0757, RMSE=0.2752, R²=0.0372
============================================================


============================================================
🔄 Round 97 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 97 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0142
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0013
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0761, RMSE: 0.2758, MAE: 0.2353, R²: 0.0264

📊 Round 97 Test Metrics:
   Loss: 0.0761, RMSE: 0.2758, MAE: 0.2352, R²: 0.0264

============================================================
🔄 Round 100 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 100 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0148
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0106
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0761, RMSE: 0.2758, MAE: 0.2352, R²: 0.0264

📊 Round 100 Test Metrics:
   Loss: 0.0761, RMSE: 0.2758, MAE: 0.2352, R²: 0.0264

============================================================
🔄 Round 104 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 104 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0082
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0027
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0761, RMSE: 0.2758, MAE: 0.2352, R²: 0.0264

============================================================
🔄 Round 107 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 107 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0231
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0774
============================================================


============================================================
🔄 Round 108 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 108 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0101
   Val:   Loss=0.0725, RMSE=0.2692, R²=0.0146
============================================================


============================================================
🔄 Round 109 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 109 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=0.0220
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0452
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0760, RMSE: 0.2758, MAE: 0.2352, R²: 0.0265

📊 Round 109 Test Metrics:
   Loss: 0.0760, RMSE: 0.2758, MAE: 0.2352, R²: 0.0265

============================================================
🔄 Round 112 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 112 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0009
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0448
============================================================


============================================================
🔄 Round 113 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 113 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2745, R²=0.0210
   Val:   Loss=0.0914, RMSE=0.3024, R²=-0.0246
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0760, RMSE: 0.2758, MAE: 0.2352, R²: 0.0265

============================================================
🔄 Round 114 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 114 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0047
   Val:   Loss=0.0730, RMSE=0.2702, R²=0.0307
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0760, RMSE: 0.2758, MAE: 0.2352, R²: 0.0265

============================================================
🔄 Round 115 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 115 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0006
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0515
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0760, RMSE: 0.2758, MAE: 0.2352, R²: 0.0265

📊 Round 115 Test Metrics:
   Loss: 0.0760, RMSE: 0.2758, MAE: 0.2352, R²: 0.0265

============================================================
🔄 Round 121 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 121 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0072
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0244
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0760, RMSE: 0.2758, MAE: 0.2352, R²: 0.0265

============================================================
🔄 Round 123 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 123 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0098
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0067
============================================================


============================================================
🔄 Round 124 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 124 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0122
   Val:   Loss=0.0848, RMSE=0.2913, R²=0.0012
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0760, RMSE: 0.2758, MAE: 0.2352, R²: 0.0266

============================================================
🔄 Round 125 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0704, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0704, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0704, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 125 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0112
   Val:   Loss=0.0704, RMSE=0.2653, R²=-0.0101
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0760, RMSE: 0.2758, MAE: 0.2352, R²: 0.0266

============================================================
🔄 Round 128 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 128 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2749, R²=0.0137
   Val:   Loss=0.0907, RMSE=0.3011, R²=-0.0015
============================================================


============================================================
🔄 Round 129 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 129 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0001
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0483
============================================================


============================================================
🔄 Round 131 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0742, val=0.0967 (↓), lr=0.000001
   • Epoch   2/100: train=0.0742, val=0.0967, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0742, val=0.0967, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0742, val=0.0967, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0742, val=0.0966, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0741, val=0.0966, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0967)

============================================================
📊 Round 131 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0741, RMSE=0.2721, R²=0.0223
   Val:   Loss=0.0967, RMSE=0.3110, R²=-0.0294
============================================================


============================================================
🔄 Round 133 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 133 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2781, R²=0.0132
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0009
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2352, R²: 0.0267

📊 Round 133 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2352, R²: 0.0267

============================================================
🔄 Round 137 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 137 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0069
   Val:   Loss=0.0763, RMSE=0.2763, R²=0.0175
============================================================


============================================================
🔄 Round 138 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 138 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0154
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0109
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2352, R²: 0.0267

📊 Round 138 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2352, R²: 0.0267

📊 Round 138 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2352, R²: 0.0267

============================================================
🔄 Round 142 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 142 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0184
   Val:   Loss=0.0758, RMSE=0.2753, R²=-0.0244
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2352, R²: 0.0268

📊 Round 142 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2352, R²: 0.0268

============================================================
🔄 Round 145 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 145 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0085
   Val:   Loss=0.0760, RMSE=0.2756, R²=0.0054
============================================================


============================================================
🔄 Round 146 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 146 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0164
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0139
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2352, R²: 0.0268

📊 Round 146 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2352, R²: 0.0269

============================================================
🔄 Round 150 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 150 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0100
   Val:   Loss=0.0811, RMSE=0.2847, R²=0.0009
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2352, R²: 0.0269

============================================================
🔄 Round 151 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0697 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0697, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0697, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0697, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0698, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0697)

============================================================
📊 Round 151 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0003
   Val:   Loss=0.0697, RMSE=0.2640, R²=0.0419
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2352, R²: 0.0269

============================================================
🔄 Round 153 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 153 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2794, R²=0.0138
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0029
============================================================


============================================================
🔄 Round 154 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 154 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0112
   Val:   Loss=0.0793, RMSE=0.2815, R²=0.0095
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2352, R²: 0.0270

============================================================
🔄 Round 156 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 156 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0113
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0049
============================================================


============================================================
🔄 Round 157 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 157 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0018
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0411
============================================================


============================================================
🔄 Round 163 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 163 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=0.0168
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0139
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2352, R²: 0.0271

============================================================
🔄 Round 165 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 165 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2776, R²=0.0179
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0293
============================================================


============================================================
🔄 Round 168 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 168 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2747, R²=0.0093
   Val:   Loss=0.0909, RMSE=0.3016, R²=0.0046
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2352, R²: 0.0271

📊 Round 168 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2352, R²: 0.0271

📊 Round 168 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2352, R²: 0.0271

📊 Round 168 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2352, R²: 0.0271

============================================================
🔄 Round 175 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 175 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0131
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0037
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2352, R²: 0.0271

============================================================
🔄 Round 176 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 176 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0154
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0154
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2352, R²: 0.0271

📊 Round 176 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2352, R²: 0.0271

============================================================
🔄 Round 178 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 178 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0005
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0487
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2352, R²: 0.0271

============================================================
🔄 Round 186 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0698 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0698, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0698, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0698, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0698, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0698, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0698)

============================================================
📊 Round 186 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0128
   Val:   Loss=0.0698, RMSE=0.2643, R²=-0.0013
============================================================


============================================================
🔄 Round 187 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 187 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2783, R²=-0.0008
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0373
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2352, R²: 0.0272

📊 Round 187 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2352, R²: 0.0272

============================================================
🔄 Round 191 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 191 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0064
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0264
============================================================


============================================================
🔄 Round 192 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 192 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2790, R²=0.0123
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0035
============================================================


============================================================
🔄 Round 193 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 193 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0137
   Val:   Loss=0.0737, RMSE=0.2715, R²=-0.0094
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2352, R²: 0.0272

============================================================
🔄 Round 194 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 194 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0093
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0138
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2352, R²: 0.0272

📊 Round 194 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2352, R²: 0.0272

📊 Round 194 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2352, R²: 0.0272

============================================================
🔄 Round 202 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 202 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0097
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0105
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2352, R²: 0.0273

📊 Round 202 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2352, R²: 0.0273

============================================================
🔄 Round 206 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 206 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0014
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0332
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2352, R²: 0.0273

📊 Round 206 Test Metrics:
   Loss: 0.0760, RMSE: 0.2756, MAE: 0.2352, R²: 0.0273

============================================================
🔄 Round 209 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 209 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0167
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0152
============================================================


============================================================
🔄 Round 210 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 210 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0109
   Val:   Loss=0.0735, RMSE=0.2710, R²=0.0091
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0760, RMSE: 0.2756, MAE: 0.2352, R²: 0.0274

============================================================
🔄 Round 211 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 211 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0080
   Val:   Loss=0.0741, RMSE=0.2722, R²=-0.0176
============================================================


📊 Round 211 Test Metrics:
   Loss: 0.0760, RMSE: 0.2756, MAE: 0.2352, R²: 0.0274

============================================================
🔄 Round 212 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 212 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0039
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0171
============================================================


📊 Round 212 Test Metrics:
   Loss: 0.0760, RMSE: 0.2756, MAE: 0.2352, R²: 0.0275

📊 Round 212 Test Metrics:
   Loss: 0.0760, RMSE: 0.2756, MAE: 0.2352, R²: 0.0275

📊 Round 212 Test Metrics:
   Loss: 0.0760, RMSE: 0.2756, MAE: 0.2352, R²: 0.0275

============================================================
🔄 Round 216 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 216 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0111
   Val:   Loss=0.0749, RMSE=0.2738, R²=0.0098
============================================================


📊 Round 216 Test Metrics:
   Loss: 0.0760, RMSE: 0.2756, MAE: 0.2352, R²: 0.0275

============================================================
🔄 Round 217 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 217 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0204
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0285
============================================================


============================================================
🔄 Round 221 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 221 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0020
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0448
============================================================


============================================================
🔄 Round 225 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 225 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0119
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0036
============================================================


📊 Round 225 Test Metrics:
   Loss: 0.0760, RMSE: 0.2756, MAE: 0.2352, R²: 0.0275

============================================================
🔄 Round 227 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 227 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2765, R²=0.0119
   Val:   Loss=0.0871, RMSE=0.2951, R²=0.0076
============================================================


============================================================
🔄 Round 228 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 228 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0102
   Val:   Loss=0.0797, RMSE=0.2822, R²=0.0093
============================================================


============================================================
🔄 Round 231 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 231 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0170
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0201
============================================================


============================================================
🔄 Round 232 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0701, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0701, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0701, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 232 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0104
   Val:   Loss=0.0702, RMSE=0.2649, R²=0.0025
============================================================


============================================================
🔄 Round 236 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 236 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0111
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0027
============================================================


📊 Round 236 Test Metrics:
   Loss: 0.0760, RMSE: 0.2756, MAE: 0.2352, R²: 0.0275

📊 Round 236 Test Metrics:
   Loss: 0.0760, RMSE: 0.2756, MAE: 0.2352, R²: 0.0276

============================================================
🔄 Round 242 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 242 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0107
   Val:   Loss=0.0732, RMSE=0.2705, R²=0.0097
============================================================


📊 Round 242 Test Metrics:
   Loss: 0.0760, RMSE: 0.2756, MAE: 0.2352, R²: 0.0276

============================================================
🔄 Round 244 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 244 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0109
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0099
============================================================


============================================================
🔄 Round 245 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 245 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0164
   Val:   Loss=0.0746, RMSE=0.2731, R²=-0.0177
============================================================


============================================================
🔄 Round 247 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 247 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0162
   Val:   Loss=0.0750, RMSE=0.2738, R²=-0.0158
============================================================


📊 Round 247 Test Metrics:
   Loss: 0.0760, RMSE: 0.2756, MAE: 0.2352, R²: 0.0276

📊 Round 247 Test Metrics:
   Loss: 0.0760, RMSE: 0.2756, MAE: 0.2352, R²: 0.0275

============================================================
🔄 Round 252 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 252 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0098
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0119
============================================================


============================================================
🔄 Round 253 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 253 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0011
   Val:   Loss=0.0806, RMSE=0.2838, R²=0.0424
============================================================


============================================================
🔄 Round 254 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 254 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0154
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0068
============================================================


📊 Round 254 Test Metrics:
   Loss: 0.0760, RMSE: 0.2756, MAE: 0.2352, R²: 0.0276

============================================================
🔄 Round 257 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 257 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0156
   Val:   Loss=0.0739, RMSE=0.2719, R²=-0.0137
============================================================


📊 Round 257 Test Metrics:
   Loss: 0.0760, RMSE: 0.2756, MAE: 0.2352, R²: 0.0276

============================================================
🔄 Round 260 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 260 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0141
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0035
============================================================


📊 Round 260 Test Metrics:
   Loss: 0.0760, RMSE: 0.2756, MAE: 0.2352, R²: 0.0276

📊 Round 260 Test Metrics:
   Loss: 0.0760, RMSE: 0.2756, MAE: 0.2352, R²: 0.0276

============================================================
🔄 Round 262 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0702, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0701, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 262 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0081
   Val:   Loss=0.0702, RMSE=0.2649, R²=0.0216
============================================================


📊 Round 262 Test Metrics:
   Loss: 0.0760, RMSE: 0.2756, MAE: 0.2352, R²: 0.0277

============================================================
🔄 Round 264 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 264 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0130
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0174
============================================================


📊 Round 264 Test Metrics:
   Loss: 0.0760, RMSE: 0.2756, MAE: 0.2352, R²: 0.0277

📊 Round 264 Test Metrics:
   Loss: 0.0760, RMSE: 0.2756, MAE: 0.2352, R²: 0.0277

📊 Round 264 Test Metrics:
   Loss: 0.0760, RMSE: 0.2756, MAE: 0.2352, R²: 0.0277

============================================================
🔄 Round 268 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 268 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0122
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0053
============================================================


============================================================
🔄 Round 269 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 269 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=0.0112
   Val:   Loss=0.0743, RMSE=0.2725, R²=0.0089
============================================================


📊 Round 269 Test Metrics:
   Loss: 0.0760, RMSE: 0.2756, MAE: 0.2352, R²: 0.0277

============================================================
🔄 Round 273 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 273 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0136
   Val:   Loss=0.0738, RMSE=0.2716, R²=-0.0038
============================================================


📊 Round 273 Test Metrics:
   Loss: 0.0760, RMSE: 0.2756, MAE: 0.2352, R²: 0.0277

============================================================
🔄 Round 276 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 276 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0162
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0134
============================================================


📊 Round 276 Test Metrics:
   Loss: 0.0760, RMSE: 0.2756, MAE: 0.2352, R²: 0.0277

============================================================
🔄 Round 277 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 277 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0097
   Val:   Loss=0.0790, RMSE=0.2810, R²=0.0142
============================================================


📊 Round 277 Test Metrics:
   Loss: 0.0760, RMSE: 0.2756, MAE: 0.2352, R²: 0.0277

📊 Round 277 Test Metrics:
   Loss: 0.0760, RMSE: 0.2756, MAE: 0.2352, R²: 0.0277

============================================================
🔄 Round 280 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 280 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0124
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0044
============================================================


============================================================
🔄 Round 283 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 283 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0132
   Val:   Loss=0.0854, RMSE=0.2923, R²=0.0006
============================================================


📊 Round 283 Test Metrics:
   Loss: 0.0760, RMSE: 0.2756, MAE: 0.2352, R²: 0.0277

📊 Round 283 Test Metrics:
   Loss: 0.0760, RMSE: 0.2756, MAE: 0.2352, R²: 0.0277

============================================================
🔄 Round 289 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 289 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0053
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0306
============================================================


📊 Round 289 Test Metrics:
   Loss: 0.0760, RMSE: 0.2756, MAE: 0.2352, R²: 0.0276

============================================================
🔄 Round 291 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 291 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0099
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0126
============================================================


📊 Round 291 Test Metrics:
   Loss: 0.0760, RMSE: 0.2756, MAE: 0.2352, R²: 0.0277

============================================================
🔄 Round 292 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 292 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0140
   Val:   Loss=0.0717, RMSE=0.2678, R²=-0.0105
============================================================


============================================================
🔄 Round 294 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 294 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0106
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0113
============================================================


============================================================
🔄 Round 297 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 297 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0220
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0435
============================================================


📊 Round 297 Test Metrics:
   Loss: 0.0759, RMSE: 0.2756, MAE: 0.2352, R²: 0.0278

============================================================
🔄 Round 300 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 300 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2790, R²=0.0071
   Val:   Loss=0.0814, RMSE=0.2854, R²=0.0249
============================================================


============================================================
🔄 Round 301 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0705, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 301 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0025
   Val:   Loss=0.0705, RMSE=0.2656, R²=0.0451
============================================================


📊 Round 301 Test Metrics:
   Loss: 0.0759, RMSE: 0.2756, MAE: 0.2352, R²: 0.0278

============================================================
🔄 Round 302 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 302 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.0086
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0198
============================================================


📊 Round 302 Test Metrics:
   Loss: 0.0759, RMSE: 0.2756, MAE: 0.2352, R²: 0.0278

============================================================
🔄 Round 303 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 303 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0046
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0288
============================================================


📊 Round 303 Test Metrics:
   Loss: 0.0759, RMSE: 0.2756, MAE: 0.2352, R²: 0.0278

============================================================
🔄 Round 305 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 305 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0122
   Val:   Loss=0.0750, RMSE=0.2738, R²=-0.0060
============================================================


📊 Round 305 Test Metrics:
   Loss: 0.0759, RMSE: 0.2756, MAE: 0.2352, R²: 0.0278

============================================================
🔄 Round 309 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 309 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2774, R²=0.0122
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0103
============================================================


============================================================
🔄 Round 310 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 310 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0082
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0143
============================================================


📊 Round 310 Test Metrics:
   Loss: 0.0759, RMSE: 0.2756, MAE: 0.2352, R²: 0.0278

============================================================
🔄 Round 313 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 313 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0109
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0089
============================================================


============================================================
🔄 Round 315 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 315 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0221
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0378
============================================================


============================================================
🔄 Round 317 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 317 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0128
   Val:   Loss=0.0840, RMSE=0.2899, R²=0.0022
============================================================


============================================================
🔄 Round 319 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 319 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2781, R²=0.0046
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0352
============================================================


📊 Round 319 Test Metrics:
   Loss: 0.0759, RMSE: 0.2756, MAE: 0.2352, R²: 0.0279

============================================================
🔄 Round 321 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 321 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0179
   Val:   Loss=0.0736, RMSE=0.2714, R²=-0.0230
============================================================


📊 Round 321 Test Metrics:
   Loss: 0.0759, RMSE: 0.2756, MAE: 0.2352, R²: 0.0279

============================================================
🔄 Round 323 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 323 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0130
   Val:   Loss=0.0780, RMSE=0.2792, R²=0.0037
============================================================


============================================================
🔄 Round 326 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 326 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=0.0068
   Val:   Loss=0.0793, RMSE=0.2815, R²=0.0284
============================================================


📊 Round 326 Test Metrics:
   Loss: 0.0759, RMSE: 0.2756, MAE: 0.2352, R²: 0.0280

============================================================
🔄 Round 329 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 329 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0014
   Val:   Loss=0.0778, RMSE=0.2790, R²=0.0240
============================================================


============================================================
🔄 Round 330 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 330 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0097
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0169
============================================================


📊 Round 330 Test Metrics:
   Loss: 0.0759, RMSE: 0.2756, MAE: 0.2352, R²: 0.0280

============================================================
🔄 Round 333 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 333 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2774, R²=0.0173
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0139
============================================================


📊 Round 333 Test Metrics:
   Loss: 0.0759, RMSE: 0.2756, MAE: 0.2352, R²: 0.0280

============================================================
🔄 Round 335 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 335 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0104
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0149
============================================================


📊 Round 335 Test Metrics:
   Loss: 0.0759, RMSE: 0.2756, MAE: 0.2352, R²: 0.0280

📊 Round 335 Test Metrics:
   Loss: 0.0759, RMSE: 0.2756, MAE: 0.2352, R²: 0.0280

📊 Round 335 Test Metrics:
   Loss: 0.0759, RMSE: 0.2756, MAE: 0.2352, R²: 0.0280

📊 Round 335 Test Metrics:
   Loss: 0.0759, RMSE: 0.2756, MAE: 0.2352, R²: 0.0280

📊 Round 335 Test Metrics:
   Loss: 0.0759, RMSE: 0.2756, MAE: 0.2352, R²: 0.0279

============================================================
🔄 Round 347 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 347 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0083
   Val:   Loss=0.0732, RMSE=0.2706, R²=0.0229
============================================================


📊 Round 347 Test Metrics:
   Loss: 0.0759, RMSE: 0.2756, MAE: 0.2352, R²: 0.0279

📊 Round 347 Test Metrics:
   Loss: 0.0759, RMSE: 0.2756, MAE: 0.2352, R²: 0.0279

============================================================
🔄 Round 351 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 351 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0154
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0185
============================================================


📊 Round 351 Test Metrics:
   Loss: 0.0759, RMSE: 0.2756, MAE: 0.2352, R²: 0.0279

============================================================
🔄 Round 354 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 354 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2779, R²=0.0126
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0040
============================================================


📊 Round 354 Test Metrics:
   Loss: 0.0759, RMSE: 0.2756, MAE: 0.2352, R²: 0.0279

📊 Round 354 Test Metrics:
   Loss: 0.0759, RMSE: 0.2756, MAE: 0.2352, R²: 0.0279

============================================================
🔄 Round 356 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 356 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0007
   Val:   Loss=0.0729, RMSE=0.2701, R²=0.0581
============================================================


============================================================
🔄 Round 358 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 358 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0151
   Val:   Loss=0.0755, RMSE=0.2748, R²=-0.0079
============================================================


📊 Round 358 Test Metrics:
   Loss: 0.0759, RMSE: 0.2756, MAE: 0.2352, R²: 0.0279

📊 Round 358 Test Metrics:
   Loss: 0.0759, RMSE: 0.2756, MAE: 0.2352, R²: 0.0279

📊 Round 358 Test Metrics:
   Loss: 0.0759, RMSE: 0.2756, MAE: 0.2352, R²: 0.0279

📊 Round 358 Test Metrics:
   Loss: 0.0759, RMSE: 0.2756, MAE: 0.2352, R²: 0.0279

============================================================
🔄 Round 365 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 365 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0175
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0147
============================================================


============================================================
🔄 Round 366 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 366 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2763, R²=0.0046
   Val:   Loss=0.0876, RMSE=0.2960, R²=0.0284
============================================================


📊 Round 366 Test Metrics:
   Loss: 0.0759, RMSE: 0.2756, MAE: 0.2352, R²: 0.0279

📊 Round 366 Test Metrics:
   Loss: 0.0759, RMSE: 0.2756, MAE: 0.2352, R²: 0.0279

============================================================
🔄 Round 368 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0687 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0687, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0687, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0687, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0687, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0687, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0687)

============================================================
📊 Round 368 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0052
   Val:   Loss=0.0687, RMSE=0.2620, R²=0.0575
============================================================


📊 Round 368 Test Metrics:
   Loss: 0.0759, RMSE: 0.2756, MAE: 0.2352, R²: 0.0279

📊 Round 368 Test Metrics:
   Loss: 0.0759, RMSE: 0.2756, MAE: 0.2352, R²: 0.0279

============================================================
🔄 Round 370 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 370 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0130
   Val:   Loss=0.0736, RMSE=0.2713, R²=-0.0010
============================================================


============================================================
🔄 Round 371 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0683 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0683, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0683, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0683, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0683, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0683, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0683)

============================================================
📊 Round 371 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0072
   Val:   Loss=0.0683, RMSE=0.2614, R²=0.0240
============================================================


============================================================
🔄 Round 373 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0684 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0684, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0684, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0684, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0684, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0683, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0684)

============================================================
📊 Round 373 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0132
   Val:   Loss=0.0684, RMSE=0.2615, R²=-0.0006
============================================================


============================================================
🔄 Round 374 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 374 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0108
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0111
============================================================


📊 Round 374 Test Metrics:
   Loss: 0.0759, RMSE: 0.2756, MAE: 0.2352, R²: 0.0280

============================================================
🔄 Round 376 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0682 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0682, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0682, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0682, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0682, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0681, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0682)

============================================================
📊 Round 376 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0091
   Val:   Loss=0.0682, RMSE=0.2612, R²=0.0193
============================================================


📊 Round 376 Test Metrics:
   Loss: 0.0759, RMSE: 0.2756, MAE: 0.2352, R²: 0.0280

📊 Round 376 Test Metrics:
   Loss: 0.0759, RMSE: 0.2756, MAE: 0.2352, R²: 0.0280

📊 Round 376 Test Metrics:
   Loss: 0.0759, RMSE: 0.2756, MAE: 0.2352, R²: 0.0279

📊 Round 376 Test Metrics:
   Loss: 0.0759, RMSE: 0.2756, MAE: 0.2352, R²: 0.0279

📊 Round 376 Test Metrics:
   Loss: 0.0759, RMSE: 0.2756, MAE: 0.2352, R²: 0.0279

📊 Round 376 Test Metrics:
   Loss: 0.0759, RMSE: 0.2756, MAE: 0.2352, R²: 0.0279

============================================================
🔄 Round 387 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 387 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0108
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0058
============================================================


📊 Round 387 Test Metrics:
   Loss: 0.0759, RMSE: 0.2756, MAE: 0.2352, R²: 0.0280

============================================================
🔄 Round 388 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 388 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0143
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0061
============================================================


📊 Round 388 Test Metrics:
   Loss: 0.0759, RMSE: 0.2756, MAE: 0.2352, R²: 0.0280

📊 Round 388 Test Metrics:
   Loss: 0.0759, RMSE: 0.2756, MAE: 0.2352, R²: 0.0280

============================================================
🔄 Round 390 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 390 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0218
   Val:   Loss=0.0841, RMSE=0.2901, R²=-0.0437
============================================================


============================================================
🔄 Round 392 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 392 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0058
   Val:   Loss=0.0709, RMSE=0.2663, R²=0.0246
============================================================


📊 Round 392 Test Metrics:
   Loss: 0.0759, RMSE: 0.2756, MAE: 0.2352, R²: 0.0280

📊 Round 392 Test Metrics:
   Loss: 0.0759, RMSE: 0.2756, MAE: 0.2352, R²: 0.0280

============================================================
🔄 Round 396 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 396 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=0.0159
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0173
============================================================


📊 Round 396 Test Metrics:
   Loss: 0.0759, RMSE: 0.2756, MAE: 0.2352, R²: 0.0280

============================================================
🔄 Round 398 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 398 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0131
   Val:   Loss=0.0725, RMSE=0.2692, R²=-0.0250
============================================================


📊 Round 398 Test Metrics:
   Loss: 0.0759, RMSE: 0.2756, MAE: 0.2352, R²: 0.0280

============================================================
🔄 Round 400 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 400 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0170
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0166
============================================================


📊 Round 400 Test Metrics:
   Loss: 0.0759, RMSE: 0.2756, MAE: 0.2352, R²: 0.0280

📊 Round 400 Test Metrics:
   Loss: 0.0759, RMSE: 0.2756, MAE: 0.2352, R²: 0.0280

============================================================
🔄 Round 403 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 403 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2819, R²=0.0023
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0430
============================================================


============================================================
🔄 Round 407 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 407 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0169
   Val:   Loss=0.0822, RMSE=0.2866, R²=-0.0399
============================================================


============================================================
🔄 Round 408 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 408 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0099
   Val:   Loss=0.0743, RMSE=0.2726, R²=0.0068
============================================================


📊 Round 408 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0281

📊 Round 408 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0281

============================================================
🔄 Round 412 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 412 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0033
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0404
============================================================


============================================================
🔄 Round 413 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 413 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0142
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0002
============================================================


============================================================
🔄 Round 414 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 414 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0108
   Val:   Loss=0.0775, RMSE=0.2783, R²=0.0128
============================================================


============================================================
🔄 Round 416 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 416 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0090
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0195
============================================================


============================================================
🔄 Round 417 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 417 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0136
   Val:   Loss=0.0718, RMSE=0.2679, R²=-0.0068
============================================================


============================================================
🔄 Round 419 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 419 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2785, R²=0.0102
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0031
============================================================


============================================================
🔄 Round 420 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0691 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0691, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0691, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0691, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0691, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0690, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0691)

============================================================
📊 Round 420 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0049
   Val:   Loss=0.0691, RMSE=0.2628, R²=0.0385
============================================================


============================================================
🔄 Round 421 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 421 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0073
   Val:   Loss=0.0748, RMSE=0.2735, R²=0.0247
============================================================


📊 Round 421 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0282

============================================================
🔄 Round 422 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 422 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0089
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0194
============================================================


============================================================
🔄 Round 426 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 426 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0137
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0085
============================================================


📊 Round 426 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0282

============================================================
🔄 Round 427 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 427 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0115
   Val:   Loss=0.0762, RMSE=0.2761, R²=-0.0085
============================================================


============================================================
🔄 Round 428 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 428 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0109
   Val:   Loss=0.0763, RMSE=0.2763, R²=0.0133
============================================================


📊 Round 428 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0282

📊 Round 428 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0282

============================================================
🔄 Round 432 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 432 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2769, R²=0.0159
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0207
============================================================


📊 Round 432 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0282

============================================================
🔄 Round 434 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 434 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0012
   Val:   Loss=0.0733, RMSE=0.2708, R²=0.0624
============================================================


📊 Round 434 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0282

============================================================
🔄 Round 436 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 436 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0119
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0080
============================================================


📊 Round 436 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0282

============================================================
🔄 Round 437 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 437 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0112
   Val:   Loss=0.0721, RMSE=0.2686, R²=0.0115
============================================================


============================================================
🔄 Round 438 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 438 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0010
   Val:   Loss=0.0760, RMSE=0.2756, R²=0.0380
============================================================


📊 Round 438 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0282

📊 Round 438 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0282

============================================================
🔄 Round 441 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 441 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0090
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0075
============================================================


📊 Round 441 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0282

============================================================
🔄 Round 442 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 442 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2769, R²=0.0033
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0188
============================================================


============================================================
🔄 Round 444 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 444 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0113
   Val:   Loss=0.0744, RMSE=0.2727, R²=0.0113
============================================================


============================================================
🔄 Round 446 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 446 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0045
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0368
============================================================


📊 Round 446 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0283

============================================================
🔄 Round 448 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 448 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0093
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0204
============================================================


============================================================
🔄 Round 449 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 449 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0013
   Val:   Loss=0.0736, RMSE=0.2714, R²=0.0127
============================================================


============================================================
🔄 Round 450 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 450 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0115
   Val:   Loss=0.0814, RMSE=0.2852, R²=0.0130
============================================================


📊 Round 450 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0283

============================================================
🔄 Round 451 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 451 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0170
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0110
============================================================


============================================================
🔄 Round 452 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 452 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0082
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0249
============================================================


📊 Round 452 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0284

============================================================
🔄 Round 453 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0693 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0693, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0693, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0693, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0693, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0692, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0693)

============================================================
📊 Round 453 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0075
   Val:   Loss=0.0693, RMSE=0.2633, R²=0.0305
============================================================


📊 Round 453 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0284

============================================================
🔄 Round 456 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 456 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2803, R²=0.0079
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0226
============================================================


============================================================
🔄 Round 457 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 457 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0069
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0307
============================================================


📊 Round 457 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0284

============================================================
🔄 Round 458 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 458 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0153
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0236
============================================================


📊 Round 458 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0284

============================================================
🔄 Round 460 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 460 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0171
   Val:   Loss=0.0750, RMSE=0.2739, R²=-0.0118
============================================================


============================================================
🔄 Round 461 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 461 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0151
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0047
============================================================


============================================================
🔄 Round 462 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 462 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0108
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0148
============================================================


============================================================
🔄 Round 464 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 464 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0101
   Val:   Loss=0.0793, RMSE=0.2817, R²=0.0168
============================================================


📊 Round 464 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0284

📊 Round 464 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0284

============================================================
🔄 Round 468 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 468 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0077
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0271
============================================================


📊 Round 468 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0284

============================================================
🔄 Round 474 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 474 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0163
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0063
============================================================


📊 Round 474 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0284

============================================================
🔄 Round 475 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 475 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0088
   Val:   Loss=0.0730, RMSE=0.2701, R²=0.0083
============================================================


📊 Round 475 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0284

============================================================
🔄 Round 476 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 476 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0157
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0211
============================================================


📊 Round 476 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0284

📊 Round 476 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0284

📊 Round 476 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0284

============================================================
🔄 Round 482 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 482 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0095
   Val:   Loss=0.0744, RMSE=0.2727, R²=0.0217
============================================================


============================================================
🔄 Round 483 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 483 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0139
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0021
============================================================


📊 Round 483 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0285

============================================================
🔄 Round 484 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 484 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0114
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.0106
============================================================


📊 Round 484 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0284

============================================================
🔄 Round 487 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 487 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=0.0081
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0230
============================================================


============================================================
🔄 Round 488 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 488 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=0.0073
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0192
============================================================


============================================================
🔄 Round 489 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 489 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0018
   Val:   Loss=0.0732, RMSE=0.2706, R²=0.0424
============================================================


============================================================
🔄 Round 496 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 496 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0042
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0126
============================================================


============================================================
🔄 Round 497 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 497 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0117
   Val:   Loss=0.0774, RMSE=0.2781, R²=0.0126
============================================================


============================================================
🔄 Round 498 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 498 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0144
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0011
============================================================


📊 Round 498 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0284

============================================================
🔄 Round 501 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 501 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0065
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0319
============================================================


📊 Round 501 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0284

📊 Round 501 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0284

============================================================
🔄 Round 505 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 505 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0121
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0098
============================================================


============================================================
🔄 Round 506 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 506 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0139
   Val:   Loss=0.0848, RMSE=0.2913, R²=0.0032
============================================================


============================================================
🔄 Round 508 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 508 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0151
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0015
============================================================


============================================================
🔄 Round 509 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 509 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0086
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0224
============================================================


📊 Round 509 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0284

============================================================
🔄 Round 510 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0687 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0687, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0687, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0686, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0686, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0685, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0687)

============================================================
📊 Round 510 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0126
   Val:   Loss=0.0687, RMSE=0.2621, R²=-0.0208
============================================================


📊 Round 510 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0284

============================================================
🔄 Round 511 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 511 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0193
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0165
============================================================


📊 Round 511 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0285

============================================================
🔄 Round 512 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 512 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0123
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0103
============================================================


============================================================
🔄 Round 513 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 513 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0148
   Val:   Loss=0.0888, RMSE=0.2979, R²=-0.0273
============================================================


📊 Round 513 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0285

📊 Round 513 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0285

============================================================
🔄 Round 517 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 517 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0224
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0329
============================================================


📊 Round 517 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0285

============================================================
🔄 Round 518 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 518 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0075
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0296
============================================================


============================================================
🔄 Round 519 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 519 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0125
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0105
============================================================


📊 Round 519 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0285

============================================================
🔄 Round 520 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 520 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2810, R²=0.0074
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0309
============================================================


============================================================
🔄 Round 521 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0701 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0701, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0701, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0701, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0701, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0701)

============================================================
📊 Round 521 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0101
   Val:   Loss=0.0701, RMSE=0.2648, R²=0.0191
============================================================


📊 Round 521 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0284

============================================================
🔄 Round 524 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 524 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0124
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0092
============================================================


📊 Round 524 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0284

📊 Round 524 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0284

============================================================
🔄 Round 526 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 526 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0074
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0089
============================================================


📊 Round 526 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0284

============================================================
🔄 Round 527 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 527 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0128
   Val:   Loss=0.0721, RMSE=0.2685, R²=0.0045
============================================================


📊 Round 527 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0284

📊 Round 527 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0284

📊 Round 527 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0284

============================================================
🔄 Round 533 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 533 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2796, R²=0.0147
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0006
============================================================


📊 Round 533 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0284

📊 Round 533 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0284

📊 Round 533 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0284

📊 Round 533 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0284

============================================================
🔄 Round 538 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 538 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0081
   Val:   Loss=0.0793, RMSE=0.2817, R²=0.0255
============================================================


============================================================
🔄 Round 539 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 539 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0066
   Val:   Loss=0.0814, RMSE=0.2854, R²=0.0309
============================================================


============================================================
🔄 Round 542 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 542 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0102
   Val:   Loss=0.0753, RMSE=0.2745, R²=0.0130
============================================================


📊 Round 542 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0283

📊 Round 542 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0282

📊 Round 542 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0282

📊 Round 542 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0282

============================================================
🔄 Round 550 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 550 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0086
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0199
============================================================


📊 Round 550 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0282

📊 Round 550 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0282

📊 Round 550 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0282

============================================================
🔄 Round 556 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0688 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0688, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0687, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0687, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0687, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0687, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0688)

============================================================
📊 Round 556 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0079
   Val:   Loss=0.0688, RMSE=0.2622, R²=0.0258
============================================================


============================================================
🔄 Round 557 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 557 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0156
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0170
============================================================


📊 Round 557 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0283

============================================================
🔄 Round 558 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 558 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0118
   Val:   Loss=0.0769, RMSE=0.2774, R²=0.0066
============================================================


📊 Round 558 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0283

============================================================
🔄 Round 560 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 560 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0108
   Val:   Loss=0.0743, RMSE=0.2726, R²=0.0123
============================================================


📊 Round 560 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0284

============================================================
🔄 Round 565 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0695 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0695, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0694, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0694, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0694, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0694, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0695)

============================================================
📊 Round 565 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0155
   Val:   Loss=0.0695, RMSE=0.2636, R²=-0.0060
============================================================


📊 Round 565 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0284

============================================================
🔄 Round 569 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 569 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0149
   Val:   Loss=0.0752, RMSE=0.2742, R²=-0.0143
============================================================


📊 Round 569 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0284

📊 Round 569 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0284

📊 Round 569 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0284

📊 Round 569 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0284

============================================================
🔄 Round 574 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 574 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0069
   Val:   Loss=0.0784, RMSE=0.2799, R²=0.0302
============================================================


📊 Round 574 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2352, R²: 0.0284

============================================================
🔄 Round 575 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 575 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0048
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0282
============================================================


❌ Client client_16 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_status:14, grpc_message:"Socket closed"}"
>
