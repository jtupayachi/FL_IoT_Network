[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77286045-5f87-4038-afd6-89c6e4b2e283
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efc79875-36ae-480e-946a-c1c2a12a474d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12df0244-cdbd-45b1-a159-27208144d33c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c9ea51b-83cb-4984-8c1e-ce58c1f68ace
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b7cd322-4d42-4254-9859-23a22823442e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc10134f-351e-4b38-a96d-fe5785bdbf63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d43b06f-2643-499d-8dd5-0bd75c9e31f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c66b76fd-203e-4329-b324-a2bef75c631d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b72f23ac-39b7-4357-9b81-47c460aaa4b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1716f5c-785f-4b6d-8ead-4dc4dec65b99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 784ac7fa-633b-4ab5-bb01-0c20319266ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a0a5af1-ff47-416c-8855-d8612912d6e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da3759c1-2db1-4092-a874-a7dcbaedd9d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5702b91-95ff-4750-ba0b-f68d5971f53e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 794c4567-fd50-4d8a-b421-a2c2f11ddd18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea61049b-8988-479b-adf6-844b097c2402
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53f59d32-6554-4999-a10c-3db3fda4f45d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b934c910-8875-4fb4-b589-bbbe7194f394
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa6ee6c9-fc7d-4d0a-8699-a024b066a800
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5d789a9-a705-4200-9302-67ea38270268
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b57521e0-d8f2-4fc9-bcbc-e46bf776f19e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5329b46e-844b-4315-841f-1695d9796662
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c0dcd39-a51b-49b4-af3d-854bb03d53d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f89e1c5e-090f-423f-a110-396ee26c9ef2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 018cb2da-56ee-4d95-8055-0c01466cb360
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b2c64aa-bee5-4832-becb-e7125a638262
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a4543aa-f787-4a17-ac8f-a98bc8453704
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74ecb1f7-035d-4e4c-ac3e-51975634beeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ddaa679-f020-451a-b759-04b6fec581d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f8161c0-980f-418e-9bc3-d38b24852545
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2bcdcc7-45c5-42e3-9aa9-0ad1b4beb308
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 484e0ac1-7c09-4cd1-ab44-314e49d9c9af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6f416b5-81ed-4bcf-a165-2991413e9a96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f3ee201-3784-4548-8cf0-0340538a3242
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7dac9c67-920b-4aa0-9445-03b3d2e5b82b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6934ea0-8d29-4f07-8e66-73e0c79e14a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cce4ef9d-0400-4df3-9cc3-e6b9dbcccf57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb0dbafc-88a0-4360-8b14-4ac884289557
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93ef6a1c-756e-481b-8b00-ad8bbd6a51c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b563e7b-3a55-4bbd-8b0f-7b9185742484
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2124528e-e127-40e8-81f6-662be1ce3018
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6abfa618-53f1-43bc-8111-fb4c1fbe206c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92464888-1738-48e6-8b5c-35a0a9918e1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf285559-cb5f-471f-89d9-35133a66f707
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b02a0329-c215-4be9-a3be-78177cef62c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abe9aae0-ddbd-4a02-b228-f6550fddbcd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd5527f6-04ef-4292-ae10-ad68afae781f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 519a8f14-fd47-4bfe-833e-dbd5a00bebfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b06dd29-1c83-4d0d-a790-dd2f21a729bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 564c59a6-410a-443b-8d55-ff884687d943
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67cea1e9-350c-4701-831e-9eee75420c9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a779ab08-499d-42b9-acfc-efd64df33822
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7641e6fd-7132-4cb9-a8f4-ff2c23a2558f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f83269a7-2b55-437b-a84f-b5f6b53cdd34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 823bfa43-b7dc-46e3-b350-691974a89b53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95389f57-7ebc-41ef-81b4-5e0843d6ea84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1e6045c-680c-4c35-bded-792df4ddcf14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d2ddffe-cda2-4367-86fd-25dda11a8a9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 279a7115-4c75-4dc2-a7e4-af1644245976
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8987113-f6bf-403c-8c39-14185bce757a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce993a57-aadd-4b6b-9c21-c2057aa8e01f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57d0287a-058a-4f74-a2ab-52b89f5cca59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 440b7044-ac61-44d2-a720-99868c651b22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4b764f0-74c3-489d-8b1d-2301c4237974
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29a691ce-38ac-4237-9ddd-9e1444211dab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5d400e3-ac07-4f1c-b858-e165390ea3bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00a4dfb1-07cb-4bd2-ad48-daf9b67304d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4299b814-397f-4b1c-a914-de0dfaeee97f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fe6fbd8-03a2-4714-a62d-ef35e8768295
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ca9a51c-307e-4308-a3ed-8d289476bf13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87abb070-93c7-4aad-ac34-434b244db562
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5dd96282-3d04-488d-9bb9-f64826f73380
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f5936a7-15c2-4801-b60e-037e344705ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0119d4ee-361a-4d0b-abc0-d87e88d7c898
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb09669e-885d-49e1-bad6-c41d40908e35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 132efeda-877b-44cd-bbac-ddc33dd1a967
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28223b89-2a27-4a88-aab4-461c91b2f870
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4db8c651-bd0d-4043-af5b-2523ae6d877b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc679de4-e6d4-41bf-bad4-b7c113cf269c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a16e5acd-99e2-4217-a235-e780de20f05d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13304b21-a612-4d18-99e2-508f9126155e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4bca6cd-5e5c-42df-82f9-0c349241c80b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1549e701-65bf-4773-bc49-e5f44309568a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee47e5a0-233e-4652-b690-2f79e05c360a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23ebd557-4917-4de1-9271-500f63617123
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b9c7d1b-c035-4393-a50b-c99162911fca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72443381-6e79-41d9-a2ba-7a1997759731
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47327370-b5fa-44dd-831e-e759fd306794
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06c313f9-16a6-49e3-b254-699ce55723a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43fe1e82-7a5e-4ee8-80c4-061c80d59bc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da9fed0c-75ea-4390-9e3a-f080611ecebb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbab2e68-6367-42ab-975c-9097ab1f5d85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1efcefb-bb2d-4328-b9f6-8cc11a5d2f73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24f4bbed-7d13-467b-9e46-b847afa42857
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50fe121c-c061-4008-8d36-403c63068cef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af1d2baa-d84a-484b-9c64-f7e580a782be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2988d447-aaf9-4b60-b24d-5b8e93f16d11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a3339c7-54b9-44a8-bbb9-af450cd157df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5834d6a5-c4ef-4bd8-8edf-0c5ab87a5580
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ffe9a6e-8ce7-49f3-af53-98b4c0c8a371
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e06cc19d-7944-4174-b5f2-76bdbbb63c63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0381813-e4c8-461c-95dc-36c6679442a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7924eb9-a31e-4dd9-92e7-cb8eb806d62f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7468a149-960c-495f-9640-342b6685a183
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5517bea-5a29-41d8-b694-cf46cc293d7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82c45845-8aac-4f22-a90f-387c2cb37292
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0396fc30-bd4e-4d71-b3f9-2695bb933dec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fbad810-946c-4aeb-a39a-90e95ae426db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3854a3d-fa50-4c35-af83-9841e342dc32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 895a3096-77b3-401c-9f87-258da415d497
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e71b8f83-50f3-47aa-a828-b481b0bf75a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e323a31-2825-4582-8705-1271ee7e1d06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5eedcb21-2fb5-433a-9ee3-75747960797a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a329dc3-46b1-492b-a271-c9a60b0861a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8eeabb58-2d29-4d64-939f-583d5877e307
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d985d93-23d1-4e3e-876d-d9260da254cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5427b1c-5755-436a-a2fa-1e12587479c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fed23e53-72c6-4012-ba40-8d25a60423d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06cfad3d-fb9f-40ee-8a33-89d7dbdccbe0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76f7a8af-9a99-43fb-b8ce-c1a79afd1301
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c477e14b-4b9d-487b-86c1-bb214adff566
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38578357-60fd-4750-9b93-7e2a4ba37816
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3eaa4896-b449-4202-8baf-399b0e41b28c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a063313-00cc-4e85-bc16-9bb5b4f56fa3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 100bffa5-a233-4b0e-811d-d505ec39ebf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee97b492-073b-4c06-b3b9-807623c88739
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f1533ea-f63e-403a-a663-032ba7016d2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c40de00c-07d1-4e43-9310-63dcde8103c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b55ab61d-7d6d-40cf-94e0-1ceace8e6097
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b75f812-52ee-4ec8-bdd6-1f6f648c90ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e01d4b26-f967-40b0-a8b6-cbad7126f0e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f5d17e9-2c9d-47f1-826c-20b82d33b6a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60d8ff9f-f4c6-4708-a05b-51971cd5ec1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef72acc5-ae60-4d99-b1c2-09156f5be98d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7eca2641-99c3-48d7-b84e-93c388d47eb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d99f33f-c5e2-470f-bcac-cc44e3326561
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9321c004-5779-40b4-9d0a-2fa4387d6ca3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 169b4edd-ec43-4ad7-b916-cbd814d22ecc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d85e0167-2a61-41bb-a549-61f2e3dea610
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 520eaa87-dc66-497f-b236-44a9f2c39ced
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 964835d8-f627-4483-b415-c356c23d6ea2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 239288d1-11d9-4d85-ab4a-302f02d1fafb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0529e6a1-480e-4cce-8e6f-6a2689e71556
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4db0f59-9ff4-4e24-ad11-357c9babaad0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f65c2b88-3d59-4967-bada-b472d142d5c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5c7a056-2f4e-43f1-beea-c2d5beb6666a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d284bdb-7bff-44b5-810d-8432bc00b92d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7904daf8-c647-4adc-8f0a-9f8ba20df327
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31bdfee4-090b-4e5f-a9dd-79db76a25fd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82a4a41e-db7a-4d30-ac42-73309d41590e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87723fd8-6ecb-46df-998d-7cf8bbe31b4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cc837f1-1ce4-47e0-bd21-024c1c6cc389
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5241127e-1234-4b41-9244-cbdf24e990b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e69bd3cd-2e3b-4d4b-9d5f-5042f31bac26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9b6c342-76b4-4f50-9730-3216f71cab1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c563ee63-b78d-4a3f-b0ea-98e46fcd2040
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f0f8029-07b8-4c7f-ab1c-af736a45937c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 508658d0-52cb-4cef-80c5-f7e92697da1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6473ed5b-1c2d-4f5e-98d7-a3e5262d3121
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1014983f-72ef-4fde-b403-5b6ba74d8db2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e1f5c7d-af76-4ac5-b05e-9cb3dd9e6472
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8f6e9dd-cc65-466a-83c0-fd0f51fff55e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c28a803-b48c-4c46-836c-d2a453842b11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 666e38de-9f75-42c1-9136-3f10a0c5f72a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c140c910-edf9-4963-8c43-07007cd4a630
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c182789b-d9df-4b58-8a68-42cd1bffe3d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32894f38-90fc-4d81-b792-5915b06bf191
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a7d569f-3b9e-41dc-ae80-32a4399a43b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6508f5f8-02c2-4d51-878e-717e9dbf1265
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fff31856-2e5e-4d10-8e58-6b37f4905ce8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fd4e1a3-ab55-4918-a366-b49d6b1bac0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c6eeda4-a4b7-46af-9dbe-2d63ca11f0ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6b95214-8204-4e08-bbc5-3e2983c9a40b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbd8079c-fb9c-4d09-84ca-09fe5f9f72ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a250974f-2109-4642-8dff-993d08927270
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da898fde-769c-473f-84d0-3d1ef48981cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08b0b3ac-c28d-4383-a89b-a7d3034abf5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15849ef7-fcc3-45f2-985a-77549ca31155
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 143b51fb-3652-42d9-a3df-2a787d5a6830
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa35c4cf-6c8a-418d-b89f-530f373b35dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4fe8c68-196f-4f9c-af68-e9d7b9ddc396
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message faa2a22b-7a22-4635-b923-b9e84f6093e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69faa7f2-6daa-439b-8f32-55a39a69310f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5184d882-4546-4e0e-a75f-0e7a25ab15d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b20959ae-43ea-410f-ba05-ce61b4a8f2b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ceb9d309-7bf0-4362-b4fd-adeb0592dc5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cb40d47-62ea-4f3a-82ab-58c2de8f9679
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f624345-0873-4232-8454-d57d48029b27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15977fd1-e534-4eb2-b871-99fec5b16f78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4732038b-7124-4fc4-a439-8ab29f7b9237
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d33b9f2-f7f1-462d-9a98-cab98a1bc21e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0bb998e-3cbe-42e5-b93e-b98615700624
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9f5322a-f3ed-43f6-97dc-292ffbc05113
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fd2564b-e3db-429d-971c-10c0d5f5bad3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5d018a2-ad5c-43c8-be54-601bea0f4926
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b1da9c4-a4c4-494a-96fd-51f98115286d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf8e644b-b64a-4c36-aff9-de441f1c7bca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d54e173-a398-4a6b-bc08-7e6a8d3786e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91204db1-63a0-4a17-9b26-136f07b745c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 208356fa-4aef-4686-96cd-b5eac488870a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86b7b22d-8f2d-4d97-a2be-cb8dedcbc3b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd5656f0-32e9-4ee9-a308-0873b987e177
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ef67a50-44c9-4049-9cc0-709936b7761c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06b79df0-54b7-4ea9-a7a6-a8b73c262edf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4adfaec5-e84f-4057-8928-f04ea7146623
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 400fae42-d647-4df7-a6bc-5caea16f1a9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac845182-12a7-43fc-8db8-405120567176
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33f96e91-6103-4b00-b129-f34d2ce24793
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7099f0e3-7ab7-42c4-9ca7-c2066772861d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29368cfd-8768-492b-bb33-9a28e3a86c8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac221950-1baa-4905-9515-4a2f683494fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 886ce70d-9f33-44d1-99f5-ad01c39844df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c68c9a0-2657-4a36-97ad-fd5fa5664b99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d173eaa2-0d1e-4d92-a506-4a34491b8c2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c34aa1ed-6bb5-4029-b137-7c478dd25a5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e57c7643-fd1d-4a96-8ce7-38161208585a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2cee6401-861d-4909-a24a-1f5e77daa10d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8874a14a-2115-44ac-a026-af7480bbdf68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f8069b4-aef6-446c-b670-78916887e24a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ab173f8-33a6-4027-8b79-aba81fce161c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85aecc16-8bfc-48ea-a26f-73421574275b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93533c31-a813-423e-91d8-0d08719858d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6306e6e4-0b94-4265-a569-fff8a371dee0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 248120c5-6132-47c5-8c31-f633d70428d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6110072e-a16e-4c60-a586-809ce3bb23cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 951cd7e3-cc36-4f2d-a726-9a117bbf2f8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ed7be4f-aaae-41da-86a3-e52f5a1b614d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message feda9dd3-d320-4e54-9a24-1995e2d4d61e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a12569ad-66b9-4605-bdba-1be71447148e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bf4f4ea-ee56-428e-ba9b-a809c239c22a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cfb0f76-5da7-488b-b7ed-1c9aab68f2b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41b1bb29-6669-42cb-b0de-3488643454b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4dfaf7d7-5324-4c0f-84bb-8ee1555049ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba3df77d-cf2c-4826-b1e1-228ff9adc8c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 179e74a9-9148-4a15-a273-ce36fcaabd5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e2a3093-77b1-4963-927b-b7507a79941f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b457c72f-657e-4711-9540-64185325006a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6e98689-627f-4df9-bea4-412726beb4a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c35ac957-7459-48cf-bccb-97ffb55365a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92cb7299-783c-405b-8ffd-a3950874a76b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00598846-fff7-411c-b9fc-8dbfda1c0eac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2807c72b-0849-4418-a5c6-96df7868fa06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b931e68-4091-49cf-a93b-018aba88fd49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 323be9a1-006d-4e10-a8a0-e8afd1e20674
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 287fc903-985f-48df-8171-4129c9c31762
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb241280-dcbc-4f7f-94f6-c0e77a62f1e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0e7bb41-32ad-4103-9370-8d149e446560
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddeec638-5772-4ebc-86e0-83e2b2793696
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cbc6d45-c724-4eaa-8bf0-d06ea45751bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f42bc02c-e7ec-4a15-b4b1-16fcb98ab6a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95b561b8-453e-47bb-bbd9-cdbfba2e9ae1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd29aec8-ec5d-4954-8e3f-f0d8bae372ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43db2efa-16e8-43c6-99a6-00b5cdd93b15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66ede7df-bb24-499f-ba4d-6825b63189fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message babecb98-3dce-4453-a442-db878bf2fa8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d51990c7-d52c-47a8-bfa2-7e5acc55951a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67a19eef-51a3-47dc-bfac-94c979df3e78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee4e9463-9bf7-44e2-ba21-3d918340d702
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fe34bd6-3974-4449-ae40-a2c24cb9823f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18637940-dce7-4bf1-bd4d-b178613c5d9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d981da2-ccfa-477c-902d-f5d7f314ca6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7d4e2d8-d057-4c07-8735-8dcaf5af9219
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f83126bf-ecc8-40cf-ae62-dedadfead133
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7566008c-4ab0-4a86-916a-3c408ddcc1fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ae3e53d-4496-4f3a-9864-5fa92f4a1cf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9902b379-e987-4fbc-9ee3-f07bb08039dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8becc771-b677-4ca3-a276-1663ada1c8e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d12df698-1998-4860-9637-f3fdd79e3292
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df7d4a08-67f3-4a7b-ac9b-adbd7813c606
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81d7a47d-4911-4bce-985e-f36c9dc70f1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca927197-0bf7-4526-9d67-de7f412bda85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7abb7981-49b6-42f5-9402-f44157a9f014
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c37388c-3887-4bb0-84c2-46cface83b60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fd718e2-c4e2-4a52-9827-0ed63f8f7e2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3822e409-c767-47c6-a6ca-daef13331efd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52ca5c4b-99d8-4f95-9cb0-42b52bff9277
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 482c2893-e970-4e5e-82ed-7ca9518b9709
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3925a138-d22d-40ac-9fd0-322c603256c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message deb10757-f5d2-478f-af65-2c8f17af8080
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 369e51b2-8fd4-4129-852b-75c79624e35e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 348bd378-7ad5-4447-8531-6c350cde92f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5cc2162-c274-4fb1-af12-991a84453f9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70323199-7d53-4b1f-a770-64aef1971989
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a9a4fa4-1000-4c72-b2c0-40593f740e15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 466d3c97-b759-4ad7-9ad7-8fd898f7e167
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fba9865-ee17-4840-9189-cd928137e66b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a50c0127-daf5-448f-8404-607a4618bdae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9753658-e92f-427e-9412-0e26658c74df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02ee945d-982f-4523-9686-a6291f6f3420
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c68ff4a1-b122-4df3-8151-be07beaa41e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12dd86c1-0757-4f22-ad3c-2099ced43aff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 699e1567-b34c-4311-944e-e91f2e52c621
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4bc500f-b089-414a-a33b-fc7c8486172a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce880274-5982-48a2-b9fd-93035c76436b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f764bb20-56a4-4c14-af6b-10b5055de6f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a980ba2-1a61-4780-a633-e37eafe47095
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 107643c6-558c-4c89-a712-a1e785555fa3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d7b61cb-9817-41d0-80d6-3b4781d07302
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2038c30-0426-48ad-83cb-66ef77b5d665
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a31c38e-daf2-4e31-a35e-755ef8b0dcf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 294d44d0-274c-45fe-bb28-5b02fd0177d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b7acf1b-f8c3-4b35-a53a-ba571b8efaa7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e148b02-20ee-4ad0-b982-9bcd1a0c78e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1402f85-a1e2-492d-b359-18327fcb58f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29818467-368b-42f1-8a20-7cb3ce19a443
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d66693e-eda0-4947-8368-cbedd4fbebac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0bae4b1-4c5e-4f38-ab42-e6c57f04e2d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a3a10f8-4169-4ff4-9526-c9d0f5b14305
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae1936be-131a-44f0-9baf-ab52c488e9dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 713df67a-7a26-4f78-b2e6-f94fb5035ae5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 124399c6-baa8-4b37-b9fe-9c6f356cb9ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c61303bd-ce9d-49dc-8d74-b601a7c09aa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9f17920-8044-4766-85c7-be8f8c625e40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08f2fcca-1275-4639-8b7e-0c7a88daba69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f10d9870-f0e5-4ef8-8cef-0d55088aadcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d515f6d-c152-4510-8220-4b1c0395afc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 131d3c47-cc32-4f2f-85b2-58f58b2cff5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81e89f6a-d224-47d2-a321-c22c2d02da0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29284b46-235d-4ba9-b884-5898a0235a12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e77b18e-a5e6-4a48-aeb7-3f6ec271078b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1917fcfe-642d-47b6-957f-182e032cbc07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fb62440-21fd-410a-9c1a-8d39249875d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e4920b6-e33b-4a1a-9c21-09b31438467b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44786880-9011-4760-9e8d-68f42cd08d4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9f7ce0f-9163-447e-a1b3-368a5a83bf95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe7ac36c-a82d-43f3-9b94-4b7871ee7bfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3856c92-3ca1-4cc9-9c9d-c4dc734f544f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99e83c11-3a43-4ed1-8190-7e43167ba3d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 154d071a-5fca-4cf1-81fc-c32ba8abd22e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d514053-d87b-4bc8-bac7-a0b38d933f1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7aff9c94-2fca-4f03-92b7-5f1a647c71a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53ce8245-d2bc-4629-8508-a524311ef4c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7efd6933-9196-4362-9032-eb7295e1f98c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0cb27e6f-abef-498e-bfc2-5709e7ab7a1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b702b4f8-8374-48ba-891e-7c47fa2ca3b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17c84dbf-dd84-4fda-8ec9-6b14a1799d21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17b5e89f-ea17-4d3f-8a45-379f38a23063
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae8db462-62f1-4789-91a2-f435273bb4cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26ced284-0b1d-4702-96f5-3dd3fa53ec3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12ba93f3-b3e3-4d25-9f03-475235d36a22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d435aaf6-cd7a-4be1-9d7f-309c6aaf48c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ceeefabb-c468-4864-83f1-15290bed7456
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 324af26c-1392-4d9d-a874-02206bcdf8af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a8876db-ae2a-4fbf-8805-fd005d545099
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e54bb29-ca4f-4c68-8631-f4b086aefc8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a77a3601-53a1-4392-83a3-b801c398c2cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd56b5aa-85d9-4e1d-b316-4fcb4c508e1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b2bf513-206f-4075-9ef3-049acaac12f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4676b9e3-d116-4654-a837-77f5e634f569
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 361877bc-ddd0-4c62-8607-05b95f4bd555
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 496a3044-540c-406c-9a38-609d6a9f6eeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d007f36a-eb02-4a67-92a8-04d7132663fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52b4722e-351f-43d2-ab07-9b95cde9d280
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65655b28-7f3e-41dc-9374-a074adb06027
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1150692-f0c7-470a-afcb-d01aa79ca7b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4cff35e-2439-451c-b2b3-04b73bdd485b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9f16ac8-4359-4cea-991d-37e046418d09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f83f9be-eb8a-4beb-a0a0-ad04cce9c781
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 912b05b9-7674-4b27-89f4-1e62ae9ef588
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4edab859-3097-450f-9c88-e6683f21d66c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5232e141-5b3f-4b61-90c9-91743e0dab5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fcc9ba4-a011-419b-9e00-d28764f76686
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95264dab-34c1-4e79-90e1-c1df0bb0235a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3b59357-1b09-4d46-ae3d-7da200be03b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fd5de77-4675-45e3-b21e-796a08b4a250
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21edcaf0-c908-4538-b92e-7b46ce791f09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6143c3d-f088-4781-889f-22b6412b432a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfc60ab6-99ba-431d-b025-d1894443a720
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 058b68bd-7fb6-432f-8c22-e17f838806ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0eff6ac-b63d-4faf-a677-2d9146807224
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a126b82-f69e-4205-a881-ce47b60c4d32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f58731ab-77b3-4923-8d3d-a25f63e90a06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 020080a6-dae6-4107-b715-9572065f7bf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bcd0ff5-0c8c-4591-b749-5977fa39d29c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 526c1943-be49-41f3-8d6c-0083c9c33a2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe532b58-48d5-4d21-8e3f-9d23b2907533
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bf4a329-7d33-49c4-add9-e689461d7499
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 936fae4c-304c-4e08-b071-0c1fa80340ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3a5c00c-7e34-4b9c-ac13-880b622c8367
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc633aad-cf1e-42aa-8b03-a33b18996730
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88de6269-e99a-41a3-8183-90071d56ab40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c74dee19-6fe2-4775-b7bc-25676fba5d2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c29d0a9-991b-427a-b4c2-f4460eaf4f6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6be1c47-e6cf-494c-a1d7-1a648e2f2260
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dad5ece7-34f9-4484-abb4-e0c38a88d48e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a888305-b602-463d-9269-123e91c4eed3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65da3101-f68d-4d67-98b1-88eaeb5d3446
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85d5293d-c83b-4721-bd00-43dcadd0e6ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08f02cdf-39ed-4a5c-af05-bcdb1348c223
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5626229b-a0e9-47af-a84a-7516c3b2e910
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e029a57-c27c-4936-828e-d9c13b117042
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50eb85e1-f8e9-4e7a-9533-29529d33e004
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3af8499-2b69-4e2d-900f-9de8b4e139de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10267644-2cc3-42a6-bb85-9962cbaecbbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f43a7297-87a6-458b-8b00-61f4d44e9431
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d427fe5-e4af-481b-9510-02fe21e39df4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7cc1068-e13d-48a5-b8f1-7a5e37301ec2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a3ae7df-f0e7-40f9-99d2-0f2163d8224c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4018ee83-df76-45d8-b18a-e3f1889bb9e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78a47191-8a76-49bc-960f-1b12ebc9b527
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df5a9df2-ff1d-4dd2-b21a-b2709f07a4cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83ce3128-f3e6-40cb-a2dd-2ed21e34df96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6159d0f2-4f89-4c63-9ee4-f0652e5c7eb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d6627d1-94de-4d13-a9ba-2707defe66eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b1e8e65-f2e1-4fc9-8f41-b8cfd7990ddc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 345983af-9d40-4466-8998-4ef3ea7a58ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44107249-3f39-48d2-9f9d-33265432a019
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78f9b6be-3ddb-4d25-9f0f-d5da196837e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c94fd09-2904-489e-865f-4220358e5022
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e36dd78-e286-4eb9-be7e-8719cc53032e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5d61524-6fe3-4889-8354-896abd3f759b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8afc58b2-87cb-4e72-96d8-13dc00e96bfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 665d3b6d-fdd3-4fc6-8def-dc6dbd6b5f73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03e2f85b-52c6-4c76-8052-6fe8db0e5b85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f0084ac-2b96-4596-9648-d74c24b6e42f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40bcd155-8179-414c-8c0c-faa288815ecd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bcb7bf4-30ec-45b9-bc4d-e8ed498cfacf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34a7d559-8b74-4cf5-8171-eb40b5b910e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e204fd52-5202-4eda-b267-cf0b2391fa5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24937791-2aaf-4314-ab02-fe52c8b88513
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fbc867d-accc-4971-a7bb-4465e3a7309e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce61378f-5f91-4e01-b404-e4b55bc27da1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de674343-2c2f-4722-8a62-901bacb01cc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 742b967d-f0e1-42a2-81cf-30b610e6c12e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 431a0722-780b-4377-9787-37c1c6091a57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5de3ff08-b089-4a1c-98ab-7df2682b39e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 987fdb0e-d59b-405e-a200-e104d6ad53d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 203c3cce-ac33-4abb-a9e2-dd00de5af31f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 129d4357-8846-430c-ae1d-855c84fdedf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2439746e-8196-42f0-97fb-9b9a7a61d630
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b00bf815-eeee-4089-acd0-e53ce64bf90f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 003aa0f9-86f6-4998-a9a0-b335e7360cb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ecb255f-c0fa-42d5-94e3-d1add0aa075e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7635f0c-3f5e-4b8b-a928-d4460e1e9622
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2aa2f3b-1003-4fba-ac57-e3c749a366a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3491778-bc3f-4fdc-a316-028ab3e87afc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69c52ebe-49ee-4890-bfad-6e41d751efcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f439218-dc4e-4bca-959f-0bf75533d733
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5d4fcea-2815-4a9e-a855-04ce26c63bd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d01ee4b-e5c6-469a-8879-bfe038a3d578
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a8280f5-101d-4626-abaa-2444efbd7f98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d01132a-85c8-4e28-98de-6bfaae9918c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fefc0b7e-46ec-47fe-9d30-a42ea0463262
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03eef12a-152e-4b3f-a704-3e2824a0d913
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a906dac-d34c-49d9-8996-b9bba4467f1b
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_17
Server: localhost:8688
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_17
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_17/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_17/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_17/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_17/test_labels.txt

📊 Raw data loaded:
   Train: X=(4164, 24), y=(4164,)
   Test:  X=(1042, 24), y=(1042,)

⚠️  Limiting training data: 4164 → 800 samples
⚠️  Limiting test data: 1042 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_17 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.1476, RMSE: 0.3841, MAE: 0.3127, R²: -0.8222

============================================================
🔄 Round 5 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0921 (↓), lr=0.001000
   • Epoch   2/100: train=0.0820, val=0.0923, patience=1/15, lr=0.001000
   ✓ Epoch   3/100: train=0.0809, val=0.0911 (↓), lr=0.001000
   ✓ Epoch   4/100: train=0.0808, val=0.0906 (↓), lr=0.001000
   ✓ Epoch   5/100: train=0.0803, val=0.0900 (↓), lr=0.001000
   ✓ Epoch  11/100: train=0.0750, val=0.0853 (↓), lr=0.001000
   • Epoch  21/100: train=0.0646, val=0.0821, patience=4/15, lr=0.001000
   📉 Epoch 23: LR reduced 0.001000 → 0.000500
   📉 Epoch 31: LR reduced 0.000500 → 0.000250
   • Epoch  31/100: train=0.0560, val=0.0875, patience=14/15, lr=0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 5 Summary - Client client_17
   Epochs: 32/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0663, RMSE=0.2574, R²=0.1917
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.1344
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.1062, RMSE: 0.3259, MAE: 0.2732, R²: -0.3114

📊 Round 5 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2458, R²: -0.0050

============================================================
🔄 Round 8 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0781 (↓), lr=0.000250
   • Epoch   2/100: train=0.0820, val=0.0783, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0817, val=0.0780, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0814, val=0.0778, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0810, val=0.0778, patience=4/15, lr=0.000250
   • Epoch  11/100: train=0.0789, val=0.0774, patience=3/15, lr=0.000250
   • Epoch  21/100: train=0.0745, val=0.0768, patience=3/15, lr=0.000250
   • Epoch  31/100: train=0.0705, val=0.0759, patience=1/15, lr=0.000250
   📉 Epoch 39: LR reduced 0.000250 → 0.000125
   • Epoch  41/100: train=0.0677, val=0.0759, patience=11/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 8 Summary - Client client_17
   Epochs: 45/100 (early stopped)
   LR: 0.000250 → 0.000125 (1 reductions)
   Train: Loss=0.0705, RMSE=0.2655, R²=0.1760
   Val:   Loss=0.0760, RMSE=0.2756, R²=0.0467
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2443, R²: -0.0144

============================================================
🔄 Round 9 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0794 (↓), lr=0.000125
   📉 Epoch 2: LR reduced 0.000125 → 0.000063
   ✓ Epoch   2/100: train=0.0805, val=0.0786 (↓), lr=0.000063
   • Epoch   3/100: train=0.0802, val=0.0785, patience=1/15, lr=0.000063
   • Epoch   4/100: train=0.0801, val=0.0784, patience=2/15, lr=0.000063
   • Epoch   5/100: train=0.0800, val=0.0783, patience=3/15, lr=0.000063
   📉 Epoch 10: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0795, val=0.0779, patience=2/15, lr=0.000031
   📉 Epoch 18: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0791, val=0.0776, patience=12/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 9 Summary - Client client_17
   Epochs: 24/100 (early stopped)
   LR: 0.000125 → 0.000016 (3 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0590
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0752
============================================================


============================================================
🔄 Round 10 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0787 (↓), lr=0.000016
   📉 Epoch 2: LR reduced 0.000016 → 0.000008
   • Epoch   2/100: train=0.0798, val=0.0784, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0796, val=0.0782, patience=2/15, lr=0.000008
   ✓ Epoch   4/100: train=0.0794, val=0.0781 (↓), lr=0.000008
   • Epoch   5/100: train=0.0793, val=0.0780, patience=1/15, lr=0.000008
   📉 Epoch 10: LR reduced 0.000008 → 0.000004
   ✓ Epoch  11/100: train=0.0789, val=0.0776 (↓), lr=0.000004
   📉 Epoch 18: LR reduced 0.000004 → 0.000002
   • Epoch  21/100: train=0.0787, val=0.0774, patience=10/15, lr=0.000002
   📉 Epoch 26: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 10 Summary - Client client_17
   Epochs: 26/100 (early stopped)
   LR: 0.000016 → 0.000001 (4 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0709
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0543
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0758, RMSE: 0.2753, MAE: 0.2380, R²: 0.0641

============================================================
🔄 Round 11 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 11 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0772
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0734
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0754, RMSE: 0.2746, MAE: 0.2373, R²: 0.0688

📊 Round 11 Test Metrics:
   Loss: 0.0747, RMSE: 0.2733, MAE: 0.2360, R²: 0.0775

============================================================
🔄 Round 16 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 16 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2744, R²=0.0934
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0661
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2354, R²: 0.0801

📊 Round 16 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2351, R²: 0.0797

============================================================
🔄 Round 21 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 21 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0832
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0914
============================================================


============================================================
🔄 Round 22 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 22 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0813
   Val:   Loss=0.0740, RMSE=0.2721, R²=0.0792
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2350, R²: 0.0803

📊 Round 22 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2350, R²: 0.0804

============================================================
🔄 Round 25 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 25 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=0.0749
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.1195
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2350, R²: 0.0806

============================================================
🔄 Round 26 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0746, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0746, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0746, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0745, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 26 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0747, RMSE=0.2733, R²=0.0872
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0839
============================================================


============================================================
🔄 Round 27 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 27 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0807
   Val:   Loss=0.0742, RMSE=0.2724, R²=0.1079
============================================================


============================================================
🔄 Round 29 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 29 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0822
   Val:   Loss=0.0734, RMSE=0.2710, R²=0.1050
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2350, R²: 0.0813

============================================================
🔄 Round 31 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 31 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=0.0771
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.1248
============================================================


============================================================
🔄 Round 32 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 32 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2761, R²=0.0882
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0760
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2351, R²: 0.0816

============================================================
🔄 Round 33 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 33 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0864
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0924
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2351, R²: 0.0817

📊 Round 33 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2351, R²: 0.0818

============================================================
🔄 Round 35 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 35 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0870
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0886
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2351, R²: 0.0818

📊 Round 35 Test Metrics:
   Loss: 0.0743, RMSE: 0.2727, MAE: 0.2351, R²: 0.0819

============================================================
🔄 Round 37 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0701 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0701, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0700, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0700, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0701)

============================================================
📊 Round 37 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0792
   Val:   Loss=0.0701, RMSE=0.2647, R²=0.1208
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0743, RMSE: 0.2727, MAE: 0.2351, R²: 0.0819

============================================================
🔄 Round 39 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0694 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0694, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0694, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0694, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0694, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0694, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0694)

============================================================
📊 Round 39 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0834
   Val:   Loss=0.0694, RMSE=0.2635, R²=0.1103
============================================================


============================================================
🔄 Round 40 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 40 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2736, R²=0.0812
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.1000
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2351, R²: 0.0821

📊 Round 40 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2351, R²: 0.0821

============================================================
🔄 Round 44 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0688 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0688, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0688, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0688, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0688, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0688, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0688)

============================================================
📊 Round 44 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2810, R²=0.0877
   Val:   Loss=0.0688, RMSE=0.2623, R²=0.0874
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2351, R²: 0.0821

📊 Round 44 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2351, R²: 0.0821

============================================================
🔄 Round 48 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 48 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2772, R²=0.0873
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0958
============================================================


============================================================
🔄 Round 49 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 49 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0834
   Val:   Loss=0.0759, RMSE=0.2756, R²=0.1081
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2351, R²: 0.0822

============================================================
🔄 Round 50 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 50 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0905
   Val:   Loss=0.0743, RMSE=0.2726, R²=0.0828
============================================================


============================================================
🔄 Round 51 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0699 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0699, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0699, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0699, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 51 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0785
   Val:   Loss=0.0699, RMSE=0.2644, R²=0.1325
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2351, R²: 0.0822

============================================================
🔄 Round 53 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 53 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0868
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0968
============================================================


============================================================
🔄 Round 54 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 54 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2765, R²=0.0875
   Val:   Loss=0.0785, RMSE=0.2803, R²=0.0954
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2352, R²: 0.0822

============================================================
🔄 Round 57 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 57 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0906
   Val:   Loss=0.0719, RMSE=0.2682, R²=0.0792
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2352, R²: 0.0823

============================================================
🔄 Round 58 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 58 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0929
   Val:   Loss=0.0732, RMSE=0.2706, R²=0.0735
============================================================


============================================================
🔄 Round 59 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 59 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2754, R²=0.0815
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.1168
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2352, R²: 0.0823

📊 Round 59 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2352, R²: 0.0823

============================================================
🔄 Round 63 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 63 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0838
   Val:   Loss=0.0738, RMSE=0.2717, R²=0.0963
============================================================


============================================================
🔄 Round 65 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 65 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0952
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0661
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2352, R²: 0.0823

📊 Round 65 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2352, R²: 0.0822

============================================================
🔄 Round 70 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 70 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0845
   Val:   Loss=0.0736, RMSE=0.2713, R²=0.1097
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2352, R²: 0.0822

============================================================
🔄 Round 71 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 71 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0879
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0953
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2352, R²: 0.0822

============================================================
🔄 Round 72 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0658 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0658, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0658, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0658, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0658, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0658, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0658)

============================================================
📊 Round 72 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0789
   Val:   Loss=0.0658, RMSE=0.2565, R²=0.1197
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2352, R²: 0.0823

============================================================
🔄 Round 74 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0745, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 74 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0745, RMSE=0.2730, R²=0.0982
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0485
============================================================


============================================================
🔄 Round 75 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 75 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2774, R²=0.0897
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0871
============================================================


============================================================
🔄 Round 76 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 76 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0932
   Val:   Loss=0.0714, RMSE=0.2672, R²=0.0715
============================================================


============================================================
🔄 Round 77 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 77 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0971
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0544
============================================================


============================================================
🔄 Round 80 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 80 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0870
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0997
============================================================


============================================================
🔄 Round 81 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 81 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2746, R²=0.0889
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0764
============================================================


============================================================
🔄 Round 83 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 83 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2765, R²=0.0916
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0768
============================================================


============================================================
🔄 Round 85 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 85 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2756, R²=0.0887
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0907
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2352, R²: 0.0825

============================================================
🔄 Round 86 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 86 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2734, R²=0.0944
   Val:   Loss=0.0851, RMSE=0.2918, R²=0.0584
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2352, R²: 0.0826

📊 Round 86 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2352, R²: 0.0825

============================================================
🔄 Round 96 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 96 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0872
   Val:   Loss=0.0733, RMSE=0.2707, R²=0.0992
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2352, R²: 0.0825

============================================================
🔄 Round 98 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 98 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0739
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.1480
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2352, R²: 0.0825

============================================================
🔄 Round 99 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 99 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0885
   Val:   Loss=0.0732, RMSE=0.2705, R²=0.0942
============================================================


============================================================
🔄 Round 100 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 100 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2776, R²=0.0856
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.1062
============================================================


============================================================
🔄 Round 101 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 101 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0851
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.1075
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2352, R²: 0.0825

📊 Round 101 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2352, R²: 0.0825

============================================================
🔄 Round 104 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 104 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0932
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0708
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2352, R²: 0.0825

📊 Round 104 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2352, R²: 0.0825

📊 Round 104 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2352, R²: 0.0825

📊 Round 104 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2352, R²: 0.0825

📊 Round 104 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2352, R²: 0.0826

============================================================
🔄 Round 113 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 113 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2758, R²=0.0790
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.1290
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0743, RMSE: 0.2725, MAE: 0.2352, R²: 0.0826

📊 Round 113 Test Metrics:
   Loss: 0.0743, RMSE: 0.2725, MAE: 0.2352, R²: 0.0827

📊 Round 113 Test Metrics:
   Loss: 0.0743, RMSE: 0.2725, MAE: 0.2352, R²: 0.0827

📊 Round 113 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2352, R²: 0.0826

============================================================
🔄 Round 124 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 124 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0924
   Val:   Loss=0.0760, RMSE=0.2758, R²=0.0785
============================================================


============================================================
🔄 Round 126 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 126 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0891
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0916
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0743, RMSE: 0.2725, MAE: 0.2352, R²: 0.0827

============================================================
🔄 Round 128 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 128 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0965
   Val:   Loss=0.0740, RMSE=0.2720, R²=0.0606
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0743, RMSE: 0.2725, MAE: 0.2352, R²: 0.0828

============================================================
🔄 Round 132 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 132 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0879
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0981
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0743, RMSE: 0.2725, MAE: 0.2352, R²: 0.0828

============================================================
🔄 Round 133 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 133 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0907
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0798
============================================================


============================================================
🔄 Round 135 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0678 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0678, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0677, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0677, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0677, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0677, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0678)

============================================================
📊 Round 135 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0858
   Val:   Loss=0.0678, RMSE=0.2603, R²=0.1046
============================================================


============================================================
🔄 Round 136 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0736, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0736, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0735, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0735, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0735, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0735, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 136 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0733, RMSE=0.2708, R²=0.0817
   Val:   Loss=0.0907, RMSE=0.3011, R²=0.1159
============================================================


============================================================
🔄 Round 139 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 139 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0850
   Val:   Loss=0.0749, RMSE=0.2737, R²=0.1105
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0743, RMSE: 0.2725, MAE: 0.2352, R²: 0.0830

📊 Round 139 Test Metrics:
   Loss: 0.0743, RMSE: 0.2725, MAE: 0.2352, R²: 0.0830

📊 Round 139 Test Metrics:
   Loss: 0.0743, RMSE: 0.2725, MAE: 0.2352, R²: 0.0830

============================================================
🔄 Round 145 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0737, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0737, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0737, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0737, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0737, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0736, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 145 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0738, RMSE=0.2717, R²=0.0905
   Val:   Loss=0.0887, RMSE=0.2978, R²=0.0810
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0743, RMSE: 0.2725, MAE: 0.2352, R²: 0.0830

============================================================
🔄 Round 148 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 148 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0960
   Val:   Loss=0.0728, RMSE=0.2698, R²=0.0552
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0742, RMSE: 0.2725, MAE: 0.2352, R²: 0.0832

============================================================
🔄 Round 151 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 151 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2765, R²=0.0894
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0869
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0742, RMSE: 0.2725, MAE: 0.2352, R²: 0.0832

============================================================
🔄 Round 152 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0647 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0647, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0647, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0648, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0648, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0648, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0647)

============================================================
📊 Round 152 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0804
   Val:   Loss=0.0647, RMSE=0.2544, R²=0.0962
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0742, RMSE: 0.2725, MAE: 0.2352, R²: 0.0833

📊 Round 152 Test Metrics:
   Loss: 0.0742, RMSE: 0.2725, MAE: 0.2352, R²: 0.0833

============================================================
🔄 Round 154 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 154 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0864
   Val:   Loss=0.0755, RMSE=0.2747, R²=0.1058
============================================================


============================================================
🔄 Round 157 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 157 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0841
   Val:   Loss=0.0744, RMSE=0.2727, R²=0.1140
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0742, RMSE: 0.2724, MAE: 0.2351, R²: 0.0834

============================================================
🔄 Round 158 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 158 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2737, R²=0.0932
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0774
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0742, RMSE: 0.2724, MAE: 0.2351, R²: 0.0834

============================================================
🔄 Round 163 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 163 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0894
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0855
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0742, RMSE: 0.2724, MAE: 0.2351, R²: 0.0835

============================================================
🔄 Round 165 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 165 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0848
   Val:   Loss=0.0737, RMSE=0.2716, R²=0.1128
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0742, RMSE: 0.2724, MAE: 0.2351, R²: 0.0835

============================================================
🔄 Round 168 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 168 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0898
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0836
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0742, RMSE: 0.2724, MAE: 0.2351, R²: 0.0835

📊 Round 168 Test Metrics:
   Loss: 0.0742, RMSE: 0.2724, MAE: 0.2351, R²: 0.0835

============================================================
🔄 Round 170 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 170 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0884
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0885
============================================================


============================================================
🔄 Round 172 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 172 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0916
   Val:   Loss=0.0710, RMSE=0.2665, R²=0.0845
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0742, RMSE: 0.2724, MAE: 0.2351, R²: 0.0835

============================================================
🔄 Round 175 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 175 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0919
   Val:   Loss=0.0732, RMSE=0.2705, R²=0.0693
============================================================


============================================================
🔄 Round 177 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 177 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0979
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0603
============================================================


============================================================
🔄 Round 178 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 178 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=0.0910
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0777
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0742, RMSE: 0.2724, MAE: 0.2351, R²: 0.0836

============================================================
🔄 Round 181 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 181 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0891
   Val:   Loss=0.0765, RMSE=0.2765, R²=0.0947
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0742, RMSE: 0.2724, MAE: 0.2351, R²: 0.0836

📊 Round 181 Test Metrics:
   Loss: 0.0742, RMSE: 0.2724, MAE: 0.2351, R²: 0.0836

📊 Round 181 Test Metrics:
   Loss: 0.0742, RMSE: 0.2724, MAE: 0.2351, R²: 0.0836

============================================================
🔄 Round 188 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 188 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0860
   Val:   Loss=0.0764, RMSE=0.2765, R²=0.1032
============================================================


============================================================
🔄 Round 189 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 189 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2746, R²=0.0889
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0963
============================================================


============================================================
🔄 Round 190 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 190 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0862
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.1073
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0742, RMSE: 0.2724, MAE: 0.2351, R²: 0.0837

📊 Round 190 Test Metrics:
   Loss: 0.0742, RMSE: 0.2724, MAE: 0.2351, R²: 0.0837

📊 Round 190 Test Metrics:
   Loss: 0.0742, RMSE: 0.2724, MAE: 0.2351, R²: 0.0837

============================================================
🔄 Round 197 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 197 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0898
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0882
============================================================


============================================================
🔄 Round 198 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0736, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0736, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0736, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0736, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0736, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0736, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 198 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0738, RMSE=0.2716, R²=0.0906
   Val:   Loss=0.0887, RMSE=0.2979, R²=0.0881
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0742, RMSE: 0.2724, MAE: 0.2351, R²: 0.0837

============================================================
🔄 Round 199 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0698 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0698, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0698, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0698, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0698, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0698, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0698)

============================================================
📊 Round 199 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0893
   Val:   Loss=0.0698, RMSE=0.2642, R²=0.0956
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0742, RMSE: 0.2724, MAE: 0.2351, R²: 0.0838

📊 Round 199 Test Metrics:
   Loss: 0.0742, RMSE: 0.2724, MAE: 0.2351, R²: 0.0838

============================================================
🔄 Round 203 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 203 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0940
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0764
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0742, RMSE: 0.2724, MAE: 0.2351, R²: 0.0838

📊 Round 203 Test Metrics:
   Loss: 0.0742, RMSE: 0.2724, MAE: 0.2351, R²: 0.0839

============================================================
🔄 Round 209 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 209 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0836
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.1161
============================================================


============================================================
🔄 Round 212 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0657 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0657, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0657, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0657, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0657, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0657, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0657)

============================================================
📊 Round 212 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0828
   Val:   Loss=0.0657, RMSE=0.2563, R²=0.1253
============================================================


============================================================
🔄 Round 213 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 213 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0931
   Val:   Loss=0.0711, RMSE=0.2666, R²=0.0787
============================================================


============================================================
🔄 Round 214 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 214 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0849
   Val:   Loss=0.0727, RMSE=0.2696, R²=0.1128
============================================================


📊 Round 214 Test Metrics:
   Loss: 0.0742, RMSE: 0.2723, MAE: 0.2351, R²: 0.0841

============================================================
🔄 Round 216 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 216 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0914
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0815
============================================================


============================================================
🔄 Round 217 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 217 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0888
   Val:   Loss=0.0742, RMSE=0.2724, R²=0.0973
============================================================


📊 Round 217 Test Metrics:
   Loss: 0.0742, RMSE: 0.2723, MAE: 0.2351, R²: 0.0841

📊 Round 217 Test Metrics:
   Loss: 0.0742, RMSE: 0.2723, MAE: 0.2351, R²: 0.0841

============================================================
🔄 Round 220 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 220 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0888
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0893
============================================================


============================================================
🔄 Round 222 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 222 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0891
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.0967
============================================================


============================================================
🔄 Round 223 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 223 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0812
   Val:   Loss=0.0709, RMSE=0.2664, R²=0.1288
============================================================


📊 Round 223 Test Metrics:
   Loss: 0.0742, RMSE: 0.2723, MAE: 0.2351, R²: 0.0841

============================================================
🔄 Round 225 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 225 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0917
   Val:   Loss=0.0756, RMSE=0.2750, R²=0.0871
============================================================


📊 Round 225 Test Metrics:
   Loss: 0.0742, RMSE: 0.2723, MAE: 0.2351, R²: 0.0842

============================================================
🔄 Round 226 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 226 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2739, R²=0.0893
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0961
============================================================


============================================================
🔄 Round 228 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 228 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0988
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0549
============================================================


📊 Round 228 Test Metrics:
   Loss: 0.0742, RMSE: 0.2723, MAE: 0.2351, R²: 0.0842

============================================================
🔄 Round 229 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0732, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0732, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0732, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0731, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0731, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0731, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 229 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0734, RMSE=0.2708, R²=0.0976
   Val:   Loss=0.0903, RMSE=0.3005, R²=0.0658
============================================================


📊 Round 229 Test Metrics:
   Loss: 0.0742, RMSE: 0.2723, MAE: 0.2350, R²: 0.0843

📊 Round 229 Test Metrics:
   Loss: 0.0742, RMSE: 0.2723, MAE: 0.2350, R²: 0.0843

============================================================
🔄 Round 231 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 231 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.1014
   Val:   Loss=0.0748, RMSE=0.2735, R²=0.0397
============================================================


============================================================
🔄 Round 234 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 234 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0873
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0707
============================================================


📊 Round 234 Test Metrics:
   Loss: 0.0742, RMSE: 0.2723, MAE: 0.2351, R²: 0.0843

============================================================
🔄 Round 235 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0749, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 235 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2739, R²=0.1010
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0521
============================================================


============================================================
🔄 Round 236 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0675 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0675, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0675, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0675, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0675, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0675, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0675)

============================================================
📊 Round 236 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2812, R²=0.0963
   Val:   Loss=0.0675, RMSE=0.2597, R²=0.0636
============================================================


📊 Round 236 Test Metrics:
   Loss: 0.0741, RMSE: 0.2723, MAE: 0.2351, R²: 0.0843

============================================================
🔄 Round 239 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0728, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0728, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0728, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0728, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0728, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0728, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 239 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0728, RMSE=0.2699, R²=0.0955
   Val:   Loss=0.0923, RMSE=0.3038, R²=0.0761
============================================================


📊 Round 239 Test Metrics:
   Loss: 0.0741, RMSE: 0.2723, MAE: 0.2350, R²: 0.0843

============================================================
🔄 Round 240 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0699 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0699, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0699, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 240 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=0.0866
   Val:   Loss=0.0699, RMSE=0.2644, R²=0.0852
============================================================


📊 Round 240 Test Metrics:
   Loss: 0.0741, RMSE: 0.2723, MAE: 0.2351, R²: 0.0843

============================================================
🔄 Round 242 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 242 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2752, R²=0.0877
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0940
============================================================


============================================================
🔄 Round 243 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 243 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0897
   Val:   Loss=0.0730, RMSE=0.2701, R²=0.0944
============================================================


📊 Round 243 Test Metrics:
   Loss: 0.0741, RMSE: 0.2723, MAE: 0.2351, R²: 0.0843

📊 Round 243 Test Metrics:
   Loss: 0.0741, RMSE: 0.2723, MAE: 0.2351, R²: 0.0843

============================================================
🔄 Round 249 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 249 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0808
   Val:   Loss=0.0714, RMSE=0.2672, R²=0.1283
============================================================


============================================================
🔄 Round 250 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 250 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0929
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0733
============================================================


============================================================
🔄 Round 251 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 251 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0965
   Val:   Loss=0.0735, RMSE=0.2711, R²=0.0627
============================================================


📊 Round 251 Test Metrics:
   Loss: 0.0741, RMSE: 0.2723, MAE: 0.2351, R²: 0.0843

============================================================
🔄 Round 252 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 252 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0867
   Val:   Loss=0.0748, RMSE=0.2735, R²=0.1061
============================================================


============================================================
🔄 Round 255 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 255 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0911
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0907
============================================================


📊 Round 255 Test Metrics:
   Loss: 0.0741, RMSE: 0.2723, MAE: 0.2350, R²: 0.0844

============================================================
🔄 Round 257 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 257 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0958
   Val:   Loss=0.0731, RMSE=0.2703, R²=0.0590
============================================================


============================================================
🔄 Round 258 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 258 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.1017
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0459
============================================================


============================================================
🔄 Round 259 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0744, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 259 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0746, RMSE=0.2731, R²=0.1039
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0371
============================================================


📊 Round 259 Test Metrics:
   Loss: 0.0741, RMSE: 0.2723, MAE: 0.2350, R²: 0.0844

============================================================
🔄 Round 261 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0746, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0746, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0746, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0745, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 261 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0747, RMSE=0.2732, R²=0.0928
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0803
============================================================


📊 Round 261 Test Metrics:
   Loss: 0.0741, RMSE: 0.2723, MAE: 0.2350, R²: 0.0845

============================================================
🔄 Round 262 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0705, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 262 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0942
   Val:   Loss=0.0705, RMSE=0.2655, R²=0.0577
============================================================


📊 Round 262 Test Metrics:
   Loss: 0.0741, RMSE: 0.2723, MAE: 0.2350, R²: 0.0845

============================================================
🔄 Round 263 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 263 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.0880
   Val:   Loss=0.0743, RMSE=0.2726, R²=0.0995
============================================================


📊 Round 263 Test Metrics:
   Loss: 0.0741, RMSE: 0.2723, MAE: 0.2350, R²: 0.0846

============================================================
🔄 Round 264 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 264 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0937
   Val:   Loss=0.0726, RMSE=0.2694, R²=0.0799
============================================================


============================================================
🔄 Round 265 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 265 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0879
   Val:   Loss=0.0720, RMSE=0.2683, R²=0.0870
============================================================


============================================================
🔄 Round 267 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 267 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0893
   Val:   Loss=0.0749, RMSE=0.2737, R²=0.0990
============================================================


============================================================
🔄 Round 268 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 268 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=0.0932
   Val:   Loss=0.0790, RMSE=0.2810, R²=0.0741
============================================================


============================================================
🔄 Round 269 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0688 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0688, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0688, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0688, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0688, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0688, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0688)

============================================================
📊 Round 269 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0855
   Val:   Loss=0.0688, RMSE=0.2623, R²=0.1156
============================================================


============================================================
🔄 Round 271 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 271 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0882
   Val:   Loss=0.0720, RMSE=0.2683, R²=0.0936
============================================================


📊 Round 271 Test Metrics:
   Loss: 0.0741, RMSE: 0.2723, MAE: 0.2350, R²: 0.0846

📊 Round 271 Test Metrics:
   Loss: 0.0741, RMSE: 0.2723, MAE: 0.2350, R²: 0.0846

📊 Round 271 Test Metrics:
   Loss: 0.0741, RMSE: 0.2723, MAE: 0.2350, R²: 0.0846

============================================================
🔄 Round 276 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 276 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0893
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0841
============================================================


============================================================
🔄 Round 277 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0735, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0735, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0735, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0735, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0735, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0735, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 277 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0734, RMSE=0.2710, R²=0.0895
   Val:   Loss=0.0898, RMSE=0.2996, R²=0.0885
============================================================


📊 Round 277 Test Metrics:
   Loss: 0.0741, RMSE: 0.2722, MAE: 0.2350, R²: 0.0847

============================================================
🔄 Round 279 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 279 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0821
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.1265
============================================================


============================================================
🔄 Round 280 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 280 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0971
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0644
============================================================


📊 Round 280 Test Metrics:
   Loss: 0.0741, RMSE: 0.2722, MAE: 0.2350, R²: 0.0847

============================================================
🔄 Round 282 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 282 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2774, R²=0.0939
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0748
============================================================


📊 Round 282 Test Metrics:
   Loss: 0.0741, RMSE: 0.2722, MAE: 0.2350, R²: 0.0847

📊 Round 282 Test Metrics:
   Loss: 0.0741, RMSE: 0.2722, MAE: 0.2350, R²: 0.0847

============================================================
🔄 Round 285 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 285 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0849
   Val:   Loss=0.0751, RMSE=0.2741, R²=0.1099
============================================================


📊 Round 285 Test Metrics:
   Loss: 0.0741, RMSE: 0.2723, MAE: 0.2350, R²: 0.0847

============================================================
🔄 Round 287 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 287 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2774, R²=0.0857
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.1133
============================================================


============================================================
🔄 Round 288 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0737, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0737, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0737, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0737, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0737, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0736, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 288 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0739, RMSE=0.2718, R²=0.0970
   Val:   Loss=0.0880, RMSE=0.2966, R²=0.0693
============================================================


============================================================
🔄 Round 290 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 290 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.1027
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0417
============================================================


📊 Round 290 Test Metrics:
   Loss: 0.0741, RMSE: 0.2722, MAE: 0.2350, R²: 0.0847

============================================================
🔄 Round 292 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0659 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0659, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0659, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0659, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0659, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0658, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0659)

============================================================
📊 Round 292 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0801
   Val:   Loss=0.0659, RMSE=0.2567, R²=0.1400
============================================================


============================================================
🔄 Round 294 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 294 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0928
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0850
============================================================


📊 Round 294 Test Metrics:
   Loss: 0.0741, RMSE: 0.2722, MAE: 0.2350, R²: 0.0848

📊 Round 294 Test Metrics:
   Loss: 0.0741, RMSE: 0.2722, MAE: 0.2350, R²: 0.0848

📊 Round 294 Test Metrics:
   Loss: 0.0741, RMSE: 0.2722, MAE: 0.2350, R²: 0.0848

📊 Round 294 Test Metrics:
   Loss: 0.0741, RMSE: 0.2722, MAE: 0.2350, R²: 0.0849

============================================================
🔄 Round 303 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0692 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0692, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0692, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0692, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0692, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0692, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0692)

============================================================
📊 Round 303 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0920
   Val:   Loss=0.0692, RMSE=0.2631, R²=0.0782
============================================================


📊 Round 303 Test Metrics:
   Loss: 0.0741, RMSE: 0.2722, MAE: 0.2350, R²: 0.0849

📊 Round 303 Test Metrics:
   Loss: 0.0741, RMSE: 0.2722, MAE: 0.2350, R²: 0.0849

📊 Round 303 Test Metrics:
   Loss: 0.0741, RMSE: 0.2722, MAE: 0.2350, R²: 0.0849

============================================================
🔄 Round 307 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 307 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0925
   Val:   Loss=0.0727, RMSE=0.2696, R²=0.0860
============================================================


============================================================
🔄 Round 309 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 309 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0857
   Val:   Loss=0.0739, RMSE=0.2719, R²=0.1120
============================================================


============================================================
🔄 Round 310 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 310 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0921
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0864
============================================================


📊 Round 310 Test Metrics:
   Loss: 0.0741, RMSE: 0.2722, MAE: 0.2350, R²: 0.0850

============================================================
🔄 Round 311 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 311 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0968
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0705
============================================================


📊 Round 311 Test Metrics:
   Loss: 0.0741, RMSE: 0.2722, MAE: 0.2350, R²: 0.0850

============================================================
🔄 Round 315 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 315 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0882
   Val:   Loss=0.0710, RMSE=0.2664, R²=0.1058
============================================================


📊 Round 315 Test Metrics:
   Loss: 0.0741, RMSE: 0.2722, MAE: 0.2350, R²: 0.0851

============================================================
🔄 Round 318 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 318 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0981
   Val:   Loss=0.0768, RMSE=0.2772, R²=0.0643
============================================================


📊 Round 318 Test Metrics:
   Loss: 0.0741, RMSE: 0.2722, MAE: 0.2349, R²: 0.0851

📊 Round 318 Test Metrics:
   Loss: 0.0741, RMSE: 0.2722, MAE: 0.2349, R²: 0.0852

📊 Round 318 Test Metrics:
   Loss: 0.0741, RMSE: 0.2722, MAE: 0.2349, R²: 0.0852

============================================================
🔄 Round 324 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 324 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=0.0863
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.1082
============================================================


============================================================
🔄 Round 325 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 325 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2783, R²=0.0954
   Val:   Loss=0.0736, RMSE=0.2713, R²=0.0750
============================================================


📊 Round 325 Test Metrics:
   Loss: 0.0741, RMSE: 0.2722, MAE: 0.2349, R²: 0.0852

📊 Round 325 Test Metrics:
   Loss: 0.0741, RMSE: 0.2722, MAE: 0.2349, R²: 0.0852

============================================================
🔄 Round 328 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 328 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0860
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.1104
============================================================


📊 Round 328 Test Metrics:
   Loss: 0.0741, RMSE: 0.2722, MAE: 0.2349, R²: 0.0852

============================================================
🔄 Round 329 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 329 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2761, R²=0.1084
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0199
============================================================


📊 Round 329 Test Metrics:
   Loss: 0.0741, RMSE: 0.2722, MAE: 0.2349, R²: 0.0853

============================================================
🔄 Round 335 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0673 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0673, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0673, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0673, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0673, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0673, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0673)

============================================================
📊 Round 335 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0849
   Val:   Loss=0.0673, RMSE=0.2595, R²=0.1221
============================================================


📊 Round 335 Test Metrics:
   Loss: 0.0741, RMSE: 0.2721, MAE: 0.2349, R²: 0.0853

============================================================
🔄 Round 336 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0665 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0665, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0665, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0665, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0665, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0665, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0665)

============================================================
📊 Round 336 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0911
   Val:   Loss=0.0665, RMSE=0.2578, R²=0.0889
============================================================


============================================================
🔄 Round 338 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 338 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2752, R²=0.0906
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0940
============================================================


============================================================
🔄 Round 339 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 339 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0949
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0732
============================================================


📊 Round 339 Test Metrics:
   Loss: 0.0741, RMSE: 0.2722, MAE: 0.2349, R²: 0.0853

📊 Round 339 Test Metrics:
   Loss: 0.0741, RMSE: 0.2722, MAE: 0.2349, R²: 0.0853

📊 Round 339 Test Metrics:
   Loss: 0.0741, RMSE: 0.2722, MAE: 0.2349, R²: 0.0853

📊 Round 339 Test Metrics:
   Loss: 0.0741, RMSE: 0.2722, MAE: 0.2349, R²: 0.0852

============================================================
🔄 Round 347 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 347 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.1003
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0561
============================================================


============================================================
🔄 Round 349 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 349 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0931
   Val:   Loss=0.0793, RMSE=0.2817, R²=0.0696
============================================================


============================================================
🔄 Round 350 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 350 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0835
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.1224
============================================================


📊 Round 350 Test Metrics:
   Loss: 0.0741, RMSE: 0.2722, MAE: 0.2350, R²: 0.0852

============================================================
🔄 Round 356 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 356 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0868
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.1094
============================================================


============================================================
🔄 Round 357 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 357 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2763, R²=0.0897
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0961
============================================================


📊 Round 357 Test Metrics:
   Loss: 0.0741, RMSE: 0.2722, MAE: 0.2350, R²: 0.0852

============================================================
🔄 Round 358 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 358 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2752, R²=0.0896
   Val:   Loss=0.0806, RMSE=0.2838, R²=0.0741
============================================================


============================================================
🔄 Round 361 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 361 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0933
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0821
============================================================


============================================================
🔄 Round 362 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 362 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=0.0889
   Val:   Loss=0.0788, RMSE=0.2808, R²=0.0990
============================================================


📊 Round 362 Test Metrics:
   Loss: 0.0741, RMSE: 0.2722, MAE: 0.2349, R²: 0.0853

============================================================
🔄 Round 366 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 366 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0953
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0420
============================================================


📊 Round 366 Test Metrics:
   Loss: 0.0741, RMSE: 0.2722, MAE: 0.2349, R²: 0.0853

============================================================
🔄 Round 370 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 370 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2778, R²=0.0890
   Val:   Loss=0.0747, RMSE=0.2734, R²=0.1018
============================================================


📊 Round 370 Test Metrics:
   Loss: 0.0741, RMSE: 0.2721, MAE: 0.2349, R²: 0.0854

============================================================
🔄 Round 371 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 371 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0856
   Val:   Loss=0.0729, RMSE=0.2700, R²=0.1135
============================================================


============================================================
🔄 Round 372 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 372 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0857
   Val:   Loss=0.0757, RMSE=0.2752, R²=0.1158
============================================================


📊 Round 372 Test Metrics:
   Loss: 0.0741, RMSE: 0.2721, MAE: 0.2349, R²: 0.0855

============================================================
🔄 Round 374 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 374 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0945
   Val:   Loss=0.0723, RMSE=0.2690, R²=0.0642
============================================================


📊 Round 374 Test Metrics:
   Loss: 0.0741, RMSE: 0.2721, MAE: 0.2349, R²: 0.0855

📊 Round 374 Test Metrics:
   Loss: 0.0741, RMSE: 0.2721, MAE: 0.2349, R²: 0.0855

============================================================
🔄 Round 378 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 378 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0916
   Val:   Loss=0.0798, RMSE=0.2824, R²=0.0903
============================================================


============================================================
🔄 Round 379 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 379 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2767, R²=0.0874
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0975
============================================================


📊 Round 379 Test Metrics:
   Loss: 0.0741, RMSE: 0.2721, MAE: 0.2349, R²: 0.0855

📊 Round 379 Test Metrics:
   Loss: 0.0741, RMSE: 0.2721, MAE: 0.2349, R²: 0.0855

📊 Round 379 Test Metrics:
   Loss: 0.0741, RMSE: 0.2721, MAE: 0.2349, R²: 0.0855

============================================================
🔄 Round 382 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 382 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0906
   Val:   Loss=0.0774, RMSE=0.2781, R²=0.0914
============================================================


📊 Round 382 Test Metrics:
   Loss: 0.0741, RMSE: 0.2721, MAE: 0.2349, R²: 0.0855

============================================================
🔄 Round 385 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 385 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2743, R²=0.0837
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.1134
============================================================


============================================================
🔄 Round 386 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 386 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2756, R²=0.0882
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0927
============================================================


============================================================
🔄 Round 388 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 388 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=0.0930
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0839
============================================================


📊 Round 388 Test Metrics:
   Loss: 0.0740, RMSE: 0.2721, MAE: 0.2349, R²: 0.0856

============================================================
🔄 Round 393 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 393 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0951
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0635
============================================================


============================================================
🔄 Round 394 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0698 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0698, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0698, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0698, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0698, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0697, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0698)

============================================================
📊 Round 394 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=0.0917
   Val:   Loss=0.0698, RMSE=0.2642, R²=0.0906
============================================================


📊 Round 394 Test Metrics:
   Loss: 0.0740, RMSE: 0.2721, MAE: 0.2349, R²: 0.0857

📊 Round 394 Test Metrics:
   Loss: 0.0740, RMSE: 0.2721, MAE: 0.2349, R²: 0.0857

📊 Round 394 Test Metrics:
   Loss: 0.0740, RMSE: 0.2721, MAE: 0.2349, R²: 0.0857

============================================================
🔄 Round 405 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 405 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0955
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0742
============================================================


============================================================
🔄 Round 406 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 406 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2739, R²=0.0945
   Val:   Loss=0.0830, RMSE=0.2882, R²=0.0433
============================================================


📊 Round 406 Test Metrics:
   Loss: 0.0740, RMSE: 0.2721, MAE: 0.2349, R²: 0.0858

============================================================
🔄 Round 410 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0670 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0670, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0670, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0670, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0670, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0670, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0670)

============================================================
📊 Round 410 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2812, R²=0.0873
   Val:   Loss=0.0670, RMSE=0.2588, R²=0.1140
============================================================


📊 Round 410 Test Metrics:
   Loss: 0.0740, RMSE: 0.2721, MAE: 0.2349, R²: 0.0858

📊 Round 410 Test Metrics:
   Loss: 0.0740, RMSE: 0.2721, MAE: 0.2349, R²: 0.0859

============================================================
🔄 Round 413 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0705, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 413 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0793
   Val:   Loss=0.0705, RMSE=0.2656, R²=0.1398
============================================================


📊 Round 413 Test Metrics:
   Loss: 0.0740, RMSE: 0.2721, MAE: 0.2348, R²: 0.0859

📊 Round 413 Test Metrics:
   Loss: 0.0740, RMSE: 0.2721, MAE: 0.2348, R²: 0.0860

============================================================
🔄 Round 418 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0671 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0671, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0671, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0671, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0671, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0671, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0671)

============================================================
📊 Round 418 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0875
   Val:   Loss=0.0671, RMSE=0.2591, R²=0.1063
============================================================


📊 Round 418 Test Metrics:
   Loss: 0.0740, RMSE: 0.2721, MAE: 0.2348, R²: 0.0860

============================================================
🔄 Round 420 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 420 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0906
   Val:   Loss=0.0749, RMSE=0.2736, R²=0.0976
============================================================


📊 Round 420 Test Metrics:
   Loss: 0.0740, RMSE: 0.2720, MAE: 0.2348, R²: 0.0860

============================================================
🔄 Round 423 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0689 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0689, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0689, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0689, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0689, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0689, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0689)

============================================================
📊 Round 423 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2803, R²=0.0875
   Val:   Loss=0.0689, RMSE=0.2625, R²=0.1010
============================================================


============================================================
🔄 Round 426 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0746, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0746, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0745, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 426 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0745, RMSE=0.2729, R²=0.0971
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0477
============================================================


============================================================
🔄 Round 429 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 429 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2756, R²=0.0936
   Val:   Loss=0.0793, RMSE=0.2815, R²=0.0730
============================================================


📊 Round 429 Test Metrics:
   Loss: 0.0740, RMSE: 0.2720, MAE: 0.2348, R²: 0.0861

============================================================
🔄 Round 431 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 431 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0872
   Val:   Loss=0.0748, RMSE=0.2735, R²=0.1081
============================================================


📊 Round 431 Test Metrics:
   Loss: 0.0740, RMSE: 0.2720, MAE: 0.2348, R²: 0.0861

📊 Round 431 Test Metrics:
   Loss: 0.0740, RMSE: 0.2720, MAE: 0.2348, R²: 0.0861

📊 Round 431 Test Metrics:
   Loss: 0.0740, RMSE: 0.2720, MAE: 0.2348, R²: 0.0861

============================================================
🔄 Round 435 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 435 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2761, R²=0.0947
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0820
============================================================


📊 Round 435 Test Metrics:
   Loss: 0.0740, RMSE: 0.2720, MAE: 0.2348, R²: 0.0861

📊 Round 435 Test Metrics:
   Loss: 0.0740, RMSE: 0.2720, MAE: 0.2348, R²: 0.0861

📊 Round 435 Test Metrics:
   Loss: 0.0740, RMSE: 0.2720, MAE: 0.2348, R²: 0.0861

============================================================
🔄 Round 442 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 442 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2770, R²=0.0950
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0724
============================================================


📊 Round 442 Test Metrics:
   Loss: 0.0740, RMSE: 0.2720, MAE: 0.2348, R²: 0.0862

📊 Round 442 Test Metrics:
   Loss: 0.0740, RMSE: 0.2720, MAE: 0.2348, R²: 0.0862

📊 Round 442 Test Metrics:
   Loss: 0.0740, RMSE: 0.2720, MAE: 0.2348, R²: 0.0862

📊 Round 442 Test Metrics:
   Loss: 0.0740, RMSE: 0.2720, MAE: 0.2348, R²: 0.0862

============================================================
🔄 Round 452 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 452 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2761, R²=0.0904
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0962
============================================================


============================================================
🔄 Round 455 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 455 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0887
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.1022
============================================================


============================================================
🔄 Round 456 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0649 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0649, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0649, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0649, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0649, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0649, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0649)

============================================================
📊 Round 456 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0885
   Val:   Loss=0.0649, RMSE=0.2547, R²=0.1098
============================================================


============================================================
🔄 Round 458 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 458 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2781, R²=0.0889
   Val:   Loss=0.0736, RMSE=0.2713, R²=0.0950
============================================================


📊 Round 458 Test Metrics:
   Loss: 0.0740, RMSE: 0.2720, MAE: 0.2348, R²: 0.0864

📊 Round 458 Test Metrics:
   Loss: 0.0740, RMSE: 0.2720, MAE: 0.2348, R²: 0.0864

============================================================
🔄 Round 462 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 462 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0983
   Val:   Loss=0.0747, RMSE=0.2734, R²=0.0667
============================================================


============================================================
🔄 Round 466 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 466 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0865
   Val:   Loss=0.0715, RMSE=0.2673, R²=0.1167
============================================================


📊 Round 466 Test Metrics:
   Loss: 0.0740, RMSE: 0.2720, MAE: 0.2348, R²: 0.0864

📊 Round 466 Test Metrics:
   Loss: 0.0740, RMSE: 0.2720, MAE: 0.2348, R²: 0.0864

============================================================
🔄 Round 468 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 468 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0846
   Val:   Loss=0.0728, RMSE=0.2698, R²=0.1174
============================================================


📊 Round 468 Test Metrics:
   Loss: 0.0740, RMSE: 0.2720, MAE: 0.2348, R²: 0.0864

============================================================
🔄 Round 469 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 469 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0914
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0902
============================================================


============================================================
🔄 Round 473 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 473 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2735, R²=0.0893
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0902
============================================================


============================================================
🔄 Round 474 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 474 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0898
   Val:   Loss=0.0711, RMSE=0.2667, R²=0.0919
============================================================


============================================================
🔄 Round 475 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0696 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0696, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0696, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0697, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0697, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0696)

============================================================
📊 Round 475 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0980
   Val:   Loss=0.0696, RMSE=0.2639, R²=0.0370
============================================================


📊 Round 475 Test Metrics:
   Loss: 0.0740, RMSE: 0.2720, MAE: 0.2348, R²: 0.0865

📊 Round 475 Test Metrics:
   Loss: 0.0740, RMSE: 0.2720, MAE: 0.2348, R²: 0.0865

📊 Round 475 Test Metrics:
   Loss: 0.0740, RMSE: 0.2720, MAE: 0.2348, R²: 0.0865

============================================================
🔄 Round 479 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 479 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2774, R²=0.0911
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0795
============================================================


📊 Round 479 Test Metrics:
   Loss: 0.0740, RMSE: 0.2720, MAE: 0.2348, R²: 0.0865

============================================================
🔄 Round 481 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 481 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.1018
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0495
============================================================


📊 Round 481 Test Metrics:
   Loss: 0.0740, RMSE: 0.2720, MAE: 0.2348, R²: 0.0866

============================================================
🔄 Round 483 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 483 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2742, R²=0.0937
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0819
============================================================


============================================================
🔄 Round 484 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 484 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2744, R²=0.1034
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0487
============================================================


📊 Round 484 Test Metrics:
   Loss: 0.0740, RMSE: 0.2720, MAE: 0.2348, R²: 0.0866

============================================================
🔄 Round 485 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 485 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0985
   Val:   Loss=0.0790, RMSE=0.2810, R²=0.0675
============================================================


📊 Round 485 Test Metrics:
   Loss: 0.0740, RMSE: 0.2720, MAE: 0.2348, R²: 0.0866

============================================================
🔄 Round 489 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0746, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0746, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0746, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0745, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 489 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0746, RMSE=0.2731, R²=0.0899
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0995
============================================================


============================================================
🔄 Round 490 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0736, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0736, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0736, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0735, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0735, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0735, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 490 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0735, RMSE=0.2712, R²=0.1030
   Val:   Loss=0.0889, RMSE=0.2981, R²=0.0544
============================================================


📊 Round 490 Test Metrics:
   Loss: 0.0740, RMSE: 0.2720, MAE: 0.2348, R²: 0.0866

============================================================
🔄 Round 491 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 491 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0888
   Val:   Loss=0.0720, RMSE=0.2684, R²=0.1083
============================================================


📊 Round 491 Test Metrics:
   Loss: 0.0740, RMSE: 0.2720, MAE: 0.2348, R²: 0.0866

============================================================
🔄 Round 492 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 492 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=0.0994
   Val:   Loss=0.0805, RMSE=0.2838, R²=0.0655
============================================================


============================================================
🔄 Round 493 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 493 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0946
   Val:   Loss=0.0722, RMSE=0.2688, R²=0.0801
============================================================


📊 Round 493 Test Metrics:
   Loss: 0.0740, RMSE: 0.2720, MAE: 0.2348, R²: 0.0866

📊 Round 493 Test Metrics:
   Loss: 0.0740, RMSE: 0.2720, MAE: 0.2348, R²: 0.0866

============================================================
🔄 Round 496 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 496 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=0.0905
   Val:   Loss=0.0785, RMSE=0.2801, R²=0.0875
============================================================


📊 Round 496 Test Metrics:
   Loss: 0.0740, RMSE: 0.2720, MAE: 0.2348, R²: 0.0866

📊 Round 496 Test Metrics:
   Loss: 0.0740, RMSE: 0.2720, MAE: 0.2348, R²: 0.0866

============================================================
🔄 Round 500 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0744, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0744, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0744, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0744, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0744, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0744, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 500 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0745, RMSE=0.2729, R²=0.1030
   Val:   Loss=0.0852, RMSE=0.2918, R²=0.0536
============================================================


============================================================
🔄 Round 502 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 502 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0919
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.0710
============================================================


📊 Round 502 Test Metrics:
   Loss: 0.0740, RMSE: 0.2720, MAE: 0.2348, R²: 0.0866

📊 Round 502 Test Metrics:
   Loss: 0.0740, RMSE: 0.2720, MAE: 0.2348, R²: 0.0866

============================================================
🔄 Round 505 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 505 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0946
   Val:   Loss=0.0738, RMSE=0.2717, R²=0.0803
============================================================


📊 Round 505 Test Metrics:
   Loss: 0.0740, RMSE: 0.2720, MAE: 0.2348, R²: 0.0866

📊 Round 505 Test Metrics:
   Loss: 0.0740, RMSE: 0.2720, MAE: 0.2348, R²: 0.0866

============================================================
🔄 Round 507 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0704, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 507 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0956
   Val:   Loss=0.0705, RMSE=0.2655, R²=0.0767
============================================================


============================================================
🔄 Round 509 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 509 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2745, R²=0.1018
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0565
============================================================


📊 Round 509 Test Metrics:
   Loss: 0.0740, RMSE: 0.2720, MAE: 0.2347, R²: 0.0867

📊 Round 509 Test Metrics:
   Loss: 0.0740, RMSE: 0.2719, MAE: 0.2347, R²: 0.0867

============================================================
🔄 Round 513 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 513 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0829
   Val:   Loss=0.0729, RMSE=0.2700, R²=0.1102
============================================================


📊 Round 513 Test Metrics:
   Loss: 0.0740, RMSE: 0.2719, MAE: 0.2347, R²: 0.0867

============================================================
🔄 Round 519 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 519 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2747, R²=0.0897
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0833
============================================================


📊 Round 519 Test Metrics:
   Loss: 0.0740, RMSE: 0.2719, MAE: 0.2347, R²: 0.0867

📊 Round 519 Test Metrics:
   Loss: 0.0740, RMSE: 0.2719, MAE: 0.2347, R²: 0.0867

============================================================
🔄 Round 521 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0664 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0664, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0664, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0664, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0664, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0664, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0664)

============================================================
📊 Round 521 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0853
   Val:   Loss=0.0664, RMSE=0.2577, R²=0.1184
============================================================


📊 Round 521 Test Metrics:
   Loss: 0.0740, RMSE: 0.2719, MAE: 0.2347, R²: 0.0867

📊 Round 521 Test Metrics:
   Loss: 0.0740, RMSE: 0.2719, MAE: 0.2347, R²: 0.0867

============================================================
🔄 Round 524 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 524 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0959
   Val:   Loss=0.0770, RMSE=0.2776, R²=0.0788
============================================================


📊 Round 524 Test Metrics:
   Loss: 0.0740, RMSE: 0.2720, MAE: 0.2348, R²: 0.0867

📊 Round 524 Test Metrics:
   Loss: 0.0740, RMSE: 0.2719, MAE: 0.2347, R²: 0.0867

============================================================
🔄 Round 530 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 530 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0914
   Val:   Loss=0.0730, RMSE=0.2702, R²=0.0968
============================================================


============================================================
🔄 Round 531 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 531 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0882
   Val:   Loss=0.0742, RMSE=0.2724, R²=0.1091
============================================================


📊 Round 531 Test Metrics:
   Loss: 0.0740, RMSE: 0.2719, MAE: 0.2347, R²: 0.0867

============================================================
🔄 Round 534 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0635 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0635, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0635, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0635, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0635, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0635, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0635)

============================================================
📊 Round 534 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.1003
   Val:   Loss=0.0635, RMSE=0.2520, R²=0.0436
============================================================


📊 Round 534 Test Metrics:
   Loss: 0.0740, RMSE: 0.2719, MAE: 0.2347, R²: 0.0867

============================================================
🔄 Round 537 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 537 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0926
   Val:   Loss=0.0727, RMSE=0.2697, R²=0.0927
============================================================


📊 Round 537 Test Metrics:
   Loss: 0.0740, RMSE: 0.2719, MAE: 0.2348, R²: 0.0867

============================================================
🔄 Round 538 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 538 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0965
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.0748
============================================================


📊 Round 538 Test Metrics:
   Loss: 0.0740, RMSE: 0.2719, MAE: 0.2348, R²: 0.0867

📊 Round 538 Test Metrics:
   Loss: 0.0740, RMSE: 0.2719, MAE: 0.2348, R²: 0.0867

📊 Round 538 Test Metrics:
   Loss: 0.0740, RMSE: 0.2719, MAE: 0.2348, R²: 0.0867

📊 Round 538 Test Metrics:
   Loss: 0.0740, RMSE: 0.2719, MAE: 0.2348, R²: 0.0867

📊 Round 538 Test Metrics:
   Loss: 0.0740, RMSE: 0.2719, MAE: 0.2348, R²: 0.0867

============================================================
🔄 Round 543 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 543 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0957
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0771
============================================================


📊 Round 543 Test Metrics:
   Loss: 0.0740, RMSE: 0.2720, MAE: 0.2348, R²: 0.0867

📊 Round 543 Test Metrics:
   Loss: 0.0740, RMSE: 0.2720, MAE: 0.2348, R²: 0.0866

============================================================
🔄 Round 547 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 547 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0935
   Val:   Loss=0.0741, RMSE=0.2723, R²=0.0772
============================================================


============================================================
🔄 Round 548 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 548 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0950
   Val:   Loss=0.0717, RMSE=0.2678, R²=0.0784
============================================================


📊 Round 548 Test Metrics:
   Loss: 0.0740, RMSE: 0.2720, MAE: 0.2348, R²: 0.0866

============================================================
🔄 Round 549 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0689 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0689, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0688, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0688, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0688, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0688, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0689)

============================================================
📊 Round 549 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0906
   Val:   Loss=0.0689, RMSE=0.2624, R²=0.1016
============================================================


============================================================
🔄 Round 550 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 550 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2763, R²=0.0949
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0834
============================================================


📊 Round 550 Test Metrics:
   Loss: 0.0740, RMSE: 0.2720, MAE: 0.2348, R²: 0.0867

============================================================
🔄 Round 551 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0749, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 551 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2739, R²=0.0888
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.1040
============================================================


📊 Round 551 Test Metrics:
   Loss: 0.0740, RMSE: 0.2719, MAE: 0.2348, R²: 0.0867

📊 Round 551 Test Metrics:
   Loss: 0.0740, RMSE: 0.2719, MAE: 0.2348, R²: 0.0867

============================================================
🔄 Round 554 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 554 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2752, R²=0.0946
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0844
============================================================


📊 Round 554 Test Metrics:
   Loss: 0.0740, RMSE: 0.2719, MAE: 0.2348, R²: 0.0867

============================================================
🔄 Round 562 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0749, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0748, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0748, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0748, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0748, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 562 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2740, R²=0.0941
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0843
============================================================


============================================================
🔄 Round 563 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0748, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0748, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0748, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0748, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 563 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2737, R²=0.0944
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0860
============================================================


📊 Round 563 Test Metrics:
   Loss: 0.0739, RMSE: 0.2719, MAE: 0.2347, R²: 0.0869

============================================================
🔄 Round 564 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 564 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2785, R²=0.0953
   Val:   Loss=0.0727, RMSE=0.2697, R²=0.0755
============================================================


============================================================
🔄 Round 565 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 565 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2741, R²=0.0883
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.1066
============================================================


============================================================
🔄 Round 566 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0742, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0742, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0741, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0741, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0741, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0741, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 566 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0742, RMSE=0.2723, R²=0.0840
   Val:   Loss=0.0863, RMSE=0.2937, R²=0.1054
============================================================


📊 Round 566 Test Metrics:
   Loss: 0.0739, RMSE: 0.2719, MAE: 0.2347, R²: 0.0869

📊 Round 566 Test Metrics:
   Loss: 0.0739, RMSE: 0.2719, MAE: 0.2347, R²: 0.0869

============================================================
🔄 Round 568 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 568 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.1055
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0361
============================================================


📊 Round 568 Test Metrics:
   Loss: 0.0739, RMSE: 0.2719, MAE: 0.2347, R²: 0.0870

============================================================
🔄 Round 574 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 574 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0968
   Val:   Loss=0.0713, RMSE=0.2670, R²=0.0745
============================================================


============================================================
🔄 Round 575 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0712 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 575 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0943
   Val:   Loss=0.0712, RMSE=0.2668, R²=0.0861
============================================================


============================================================
🔄 Round 576 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 576 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0921
   Val:   Loss=0.0717, RMSE=0.2677, R²=0.0949
============================================================


❌ Client client_17 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_status:14, grpc_message:"Socket closed"}"
>
