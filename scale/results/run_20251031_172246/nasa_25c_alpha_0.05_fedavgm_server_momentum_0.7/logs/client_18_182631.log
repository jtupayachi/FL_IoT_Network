[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8bab6721-9af6-4ef2-ad68-2b3af1a34255
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e0a00af-314e-4665-8308-4611455927af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64f3cbff-0cb4-4b40-8725-363fb503dd9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7942591-b137-42b9-9f4d-f04c41c6ae20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36bc1c3b-b514-4247-b6b3-81c6f6d29742
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84a3f611-c783-4428-8de1-da24f40b7f93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74129361-d0dc-45eb-b479-32c1e18452a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24d5550e-4e3d-4efc-a388-6b4cfe2ac276
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b22de39a-c98c-45d0-b3b7-4ffd0475606b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e49e94e4-7303-4eb5-aafa-adf9508b0c8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7b78e3c-fdc9-4a28-9e6b-524dd8c70aca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f97cbf27-1ffa-4801-84f4-b649390c5f15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6b295b3-afa8-4612-82e8-5f5c8f193fe4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d816987a-f0e4-4cde-89ad-7e2c4b23acfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74d2cdd4-fb12-414a-990e-ab742e3ffe01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7c7bbaa-57db-4131-a72e-6114014bbbde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61dd6392-7b91-4f3a-a653-69966fbeae9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92610e7a-e0d6-40ed-9936-3e9acc77d169
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bace50c9-c6ac-4ac1-93cb-2f1f50748a1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2dcbe322-c616-4aa2-9d62-0acf65ab2312
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb6fbefc-97ca-4f56-b9de-ac5607a3329e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f04b68d-a75f-4560-8d7b-e142c956378c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be0af6ea-d4b6-446c-af9f-07c46e6c290c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5fd3c89-9492-42e2-8143-71d902db1fef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 522a3208-e154-48b8-aef0-a5aa9b7df848
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da15d891-3628-4493-b981-882fd9110437
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13d3053e-718e-497a-9c22-5a1237fa95b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8daf5d90-24b8-4a9f-987e-fcad22bdc683
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f68052d-7d4a-414f-9c5c-e5c4fd276108
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b7454ab-c9ec-4e11-958f-99838fc9de4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 876536e3-6ef1-4948-a5dd-233541aa9e3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25de261e-272b-4f91-bc09-e2962235caaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d67035bc-f449-4b3e-9357-597fad29d72d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 506599a5-59c6-49b6-9c31-b88cc4c592ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a8d609d-c561-40f2-8ac6-8408a72dd2b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 158fa6e0-a5c9-4a76-8e8f-ebdd63d59b41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d59dc512-3d9e-4b6a-8ae7-7befee5f76b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2668aa4-b07e-458c-a61b-408bb4d9e503
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3e3a31a-08c0-4597-9f69-ed05653d2c3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 499fd4c7-b8cb-4948-a66d-1a7e714a3453
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d093dfc-e126-49b7-a02b-070310bfad86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77e73afd-1144-4730-ba04-b6d4f865c743
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6ce38ee-2917-4173-b1ae-8faed1b2713d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3e17029-7233-4c63-9eaf-717a4a39731b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbdb43c4-3e4c-4cf1-b0af-64850fb5d050
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ee8935f-6daa-4f04-b5df-7ce9c9b97cb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cde65c2d-ce3f-4cd8-b2f1-81931282f7ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cb9d501-4359-4da6-8b8e-ea6e0638a6d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2dca00da-d828-4ebc-8d66-2f11c058378a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8e60580-2c0a-4f21-965a-644f314ca6c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1438f9a8-b3e6-4d69-b5e8-7e7a95c561b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f8744ee-3e8d-4868-8ebe-96b75743cd1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ab8c17a-6e1f-4849-afb6-fae58c8f6aae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2de9ec0f-db27-4704-9b54-3c26e8f4155e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 161990f0-186b-4233-b38d-fb4ce5113197
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a018653-6b16-4476-86fa-6c926b140d89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02b52d34-d069-4a49-85b7-bf584acde54a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86452c6c-6934-48c0-a910-b0239d1f3c0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6546e6c2-e1d1-4fdc-b3ef-457363a89865
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f108938-957c-4d9c-9105-27f1aa9e3afb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbf9c4db-189e-4eaa-83d2-bd4b41fb1dd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2906cece-74ac-40c9-be73-0b8c3eed1cf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90036630-b836-4f99-9f73-3ca2a1454c51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60ca9421-b66a-4ddc-8674-3b45432b6eff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a9862c8-8344-4bc1-8fbe-7cf851ced82e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message caf280d8-c2a8-495e-9dba-d7638f2695e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cba467b-5f20-491a-9af7-85a96098dd33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 883fbb05-8714-4bbe-b56b-6c1968f569e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cf175e0-589a-4354-a1ac-54cf4a26883f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7bae422-3614-446e-b477-d863b8034a16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26e5de9f-fc00-4a1f-aea2-803a51a69699
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fbf936e-4a11-4be8-9dd1-04fa91959cc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c440144e-d75b-4d7e-a0d2-f920a572e417
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ddf8c502-987c-4594-8a74-518515ae2dc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d38a6c9-66da-48c6-8ffb-9a5bd54376b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d614a53-8f13-4bad-b492-7dc32336bab2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f253eec-4df3-46c4-a7d6-ca1c8db0292d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bef61875-a792-47ac-9892-7b036c9624e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3cb3a00-aef4-40ba-9b3e-fa6af5f68c7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea3b12ab-ddec-445a-a937-27cb4ef7fcd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 301b1bc4-e032-471f-b95a-b4eccb37fbb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf8021b6-8b0f-473b-824c-ea175b591590
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65eae3a4-c265-4fa5-ac54-ed3f8ddc7c38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fb70458-7fb7-4751-aad4-5a51402ab540
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1ee97a3-d494-4b17-85f0-5746aa02371e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24769f75-7e09-482a-b53a-01b06d6fcee0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a32fdcbf-7b56-423a-a12c-2b77035808e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92de36ce-e1ae-42ef-b635-f17068b6b25c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 012c8e8c-bcfb-42f1-9837-2b3aa4f9cef8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae7c38ad-eb58-4f4a-91d0-55f1db24a2e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ed4813e-41f3-41a6-8a43-d7d3c5cae8cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d922a3e0-970a-4be3-afb1-f6fc92a82660
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e30b0cc6-220b-4e6c-9265-2bd63b23b457
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 617e886f-1ead-45df-8fbb-2174d4d7ff7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3406fb59-397b-4d86-950e-2fa0c23025ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a68bf0f-1098-4151-9b62-ade5ed9d4618
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97cee70b-7d0e-424b-9a7f-b4c3e21de642
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b1f9ee6-50f8-4353-81ba-916626c74eef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e5b9d52-f579-4588-bd74-cee7de85917c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8cf4391d-2ab8-4a3d-8bdb-8c9139f5e1bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7229daa0-f78a-486d-9b51-f7807f11e9db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47f89573-5e15-4e22-a847-07bcf2a1f0b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a22ff50-07de-44f9-adca-df36bd7ada9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f10d4cd4-28eb-4ff7-bb09-c35b16471660
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e04a5725-8d18-49fa-bfcb-af8c9ce22256
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d93893fd-1feb-4d30-98ae-52ed4665ccee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e32e552a-b43e-4375-b94f-d8a984d83811
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3b9900d-53a0-4f7c-a2fc-390588aba93b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53deaf75-9974-4abc-ae4e-c8af67b8b2d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 568e483f-534b-4b14-a17e-4240aafeb544
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c09d6242-c6fc-43ac-9af9-54cbabb5e0e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fef11bd-8a8d-44bd-baaf-ef4acc04874c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2014a9d7-fef3-4766-896c-a4581837e4d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb0c6b0c-9fe9-4627-9561-4fb330bfc275
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04d066fc-049b-4b7d-993c-b8438b2afbc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11d4b37a-608f-4ccc-87ca-f8a32b8970af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2ca68ae-4712-4c25-912e-72cdcdc99836
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f07fac5-74cc-4433-92fb-1a46c77a7f05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7593458a-d0ac-4284-aa11-56d59537d595
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64e28bf3-a4a7-4d7e-a509-c1f0d57ff5d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf076d4e-e28f-4a18-aaa4-b102bfbcd2fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0eb3f4f-02fb-429f-bb5d-a288bc18fab5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efad7289-11c3-490f-92cb-64b04895551e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d05c14e3-1791-4686-8aa5-a002e00c87d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44e43320-bc09-4d96-a630-da2fe90e3910
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba6f50d2-d42a-4787-92d3-c19514f87636
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 705ca419-fdde-4264-be28-9d11f02f4805
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08fd6cd6-44cc-4851-8629-c05662eedded
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30cb9743-3faa-46a5-a458-594d1c045a91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fd6f4ca-bdea-4a58-b3cb-97e0d11bfb36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a9cce7b-2c29-4450-9548-1791e2e90de1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e303dff-71a1-4ff8-a3c6-84c5ad49bf21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45b97a4b-2c30-4c3f-93f3-4ce3d000e7da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e4adab9-77d1-42c8-8d86-44d7c1bbf4c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b34149f3-7ae8-48a3-b012-69c27ffd6d8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4808cd0-421e-444e-9d55-8342b8044e85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c4ce0c2-f2b1-45ca-8032-704cd3aa48f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bae48ce5-cae4-4174-a83a-2e94e36f1b07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e3eda5d-3581-41b0-9cd3-3840c417602f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60303457-58f0-4660-9bd7-85f230dcb818
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 841c4861-0378-4071-8bf8-7fe0c0b4c12a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7efa7916-06bd-4299-85e4-e1fbd0756dd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efe2d34c-cedc-4b7b-b402-78c52a6d935b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c491e00-875e-412b-b983-bb05b1a181d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cb8e42a-1702-4956-9053-69b129da6256
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 130b8965-503b-4b93-8a7c-7e23b2ccac4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35508730-c9ab-4326-a6c5-40109abdb4dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 805c3fb6-359a-4bdd-97bd-b221da5b86dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 061e29f8-ccd6-4a78-bb41-5c75eb6162ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44ebdd7a-f418-4a7c-9eec-6349fc8ac9fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56093f50-4cf7-48f3-bb08-8c3550422e01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a9c7e77-b017-47e3-b60e-24c0e36b5ec3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3788a763-4535-4c18-9275-dae65a8d2f27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8975bf7e-8ddd-49f0-a2d6-1a4f3e667e5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1cc55841-8f8e-4bbe-a80b-44d89f60d1b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa3a1073-844b-49ac-a75a-c1253744bdf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b49a10af-311d-4429-913b-29c43701aa0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5c449d4-b4e2-48c9-af99-b190d6a3a5ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d923a41-9848-4c0b-81ae-5e313108f268
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b7869d2-4a06-49f2-b6c3-10aaa4a7bdbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4e0dc2c-8d89-4db9-ac32-b074c92fa7ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ff83cb8-4069-4c74-a63a-13b31ec3761b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebbdc7e8-abd8-4654-b396-b56832bd62ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 376eb36b-e795-4068-8327-14ace88cd7e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64ea3a98-1f46-4727-95c0-853ecbf689d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aad7a56b-75d1-491b-aa2a-7c14f6a9a4c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message debddfbb-724c-4002-bcce-aedbd8a93682
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a2bb408-a373-489c-bbfc-c3774f0b3bb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2abc4b93-e8c9-44c0-b1f8-36f0e4ecd205
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f80337b-d2e9-40f2-90a0-2e36c5dce46d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d78e746-f56c-4e49-8870-60cc07e562ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac238d40-e202-4d3e-a4d1-0764c6ad6a60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4794b470-2308-4c33-84e4-d6576b5c02da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f8de1d0-9141-4c20-9584-d058d103074e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eec3cbb8-24c1-45b9-a8aa-2301d7b6b916
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2ce3b2e-ab15-4906-afe5-78fe25fc2b45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 295e66ff-c35b-4f00-9d36-603011765357
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2278039-2f83-416c-bc6c-e0cd1f0bcb79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8994f5c0-59db-4ac8-9e10-38aa18962f5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21193838-6e07-46af-89cc-6bc53983e4a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e97baf4-efb9-4f58-a84b-b6d685f880a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbdeaa9c-3153-4ab6-a740-fd5c449cc913
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f666500-1676-489f-a48c-d08a08146025
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e8e197d-832d-4cf4-bd7b-3299b420ed17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb8a2ccc-a339-48a7-8a9a-1ad1c837f255
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74af5b17-95d4-4bdf-9a26-9bf21e0d813f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcf235b8-3da8-4cdc-b8fb-4d7d1fd8a1e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f32a3abb-7633-4aaa-98eb-6cb63eba6513
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22c798e4-f49c-4309-af7f-39f47745ff5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5b8db06-f5dc-46b5-a5e2-dccc2ebf90bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message daa87767-3146-41bf-8550-38dc2eb00f94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b980b54-a99d-4bd6-bb4f-7d09a20ec19d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab919c52-0702-4852-add1-9bbe3d1f1ea6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b798c7b-4696-4939-a632-f5b1a98337f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92072007-6bd4-4007-9320-ff73751eef4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a2e0653-0d51-4650-aa7a-c90a08df840b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b41cc7ec-5513-4dec-8a41-c8c5bb7ab4da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9308dcc1-0dd2-460b-afe7-d2c49e769ff3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eeceed1f-e6cc-448d-abda-57fccb2b2465
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 992a473f-1224-465f-a8d1-08849e00afa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d689770-9583-491c-ab4c-d391cff32927
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64bc58a8-2f93-4c7f-9c49-fe511c5e0678
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13aaec9b-139c-400b-872d-c522b9c8eec9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2f852ce-c1f0-4bed-b680-cba80d25d5c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 884f920c-6c2a-434c-bbde-a9d373915931
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dcff5da2-2a29-4698-a64f-049b501abdba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb7438b2-beb9-48c3-b3c0-d645f6185d4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e1d3b62-6258-4ce4-b3b0-893da8da95da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19293dc2-d71c-4db4-ab9d-c568115df194
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40b95ed6-b15f-4b5e-8086-cb4242d3b550
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f82ea30-5211-4d22-8327-83015c84db9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67a58d72-eb37-4a2e-8e89-39d4afe7db33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8be86b97-0b11-4606-a120-d4dfa465cf37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b5080fd-9483-435b-8095-faa57d042f3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dae5a811-6112-4d1c-87ec-eb97bf316f0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ca90d13-e84b-4493-be50-5af6a28658eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abe0c873-31dc-49e3-9c17-29bf590a61ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b06456a-7d4e-4d74-b7f9-d45c149402cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37ccd509-4b6e-43ce-9e94-1ae160713277
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93e3ca43-ad17-4bcd-af40-111637e01730
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 330ee4fd-1a6d-464d-8c00-4fdfe9dda564
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e54dd76a-2843-4074-af75-b82915563fee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c057e494-b79b-47d1-9b92-cbd4b174a973
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4411e8ca-9881-49c3-b941-1e19a14eb37e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fc5af7c-f627-4303-88fb-a93e64c6556e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27bb7ba9-d0f7-43ab-b242-d0c11986f311
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eede9598-a26d-4054-933e-84ddcf705163
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5912a08f-ea28-4fd6-ba14-68ad1f43dd29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79c402a7-808a-4716-969f-876465021351
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64c73f6f-e3e4-490a-8f28-a5f64317c267
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ef12fe6-7e77-49ac-87dd-78c9196d93b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53f03f76-b046-4c64-9f97-5266836b7a8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 631d79e1-43d4-4bf9-8422-21caa3af5968
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bccf98b-6f2c-4b20-821f-f2e508c4c4ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b8e9366-7f9b-4cd0-8924-119d622f496f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06954316-2380-461b-804c-11dc350deefa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4be854d9-7278-4c1a-961a-400cd77b34ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afd6c2aa-78a7-40d1-918f-d5b76bb09a34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee8723df-2b23-4625-accd-c94f6cae6be4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12efc754-b5bc-4dd5-816d-ffef45f6c476
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea8ffd24-db00-4bc7-b9db-7d904c385057
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7d8850a-9b30-4e6e-bd00-42bd894dc4d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05913e7c-3c5a-4b62-b25f-7d7dbf98f054
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec576dee-78bc-4466-9f95-25e8c5c08138
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 582afb31-2728-4d5b-87ba-37b1c5454261
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d28b1aa-3771-41d6-b78c-0c3abda2b860
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message decf27b9-57ff-4716-912a-a079726a2cdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf311a2e-7734-4c63-886f-b88b8e0aee24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bdd021b2-98c3-4c5a-afd4-178f6778ad30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fa36cb1-4c47-49d1-b939-874d97a53595
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5a68d09-4cc9-432a-af31-e6026385a16f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5599f0a9-2e71-4b60-b69a-f0232eaa0564
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dcce5315-e903-48ea-996e-31e7fc4353a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2a28865-1566-47ba-9b65-e987b4ff9c8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b18f5956-dfdd-4ce2-b005-55f0d1c9571e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d67d8f10-1319-4229-a131-6990131e1ee7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8bdf432-8343-4886-91ae-4622eba49eb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c6c8cdc-8a82-41ea-b162-70f0730d12e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b38706bd-98de-4c5d-b85e-a731369cd12d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bfc9f3c-890a-464e-ab53-dacdc0b548b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49ac5201-cf79-4c39-804b-c180bc180c34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6cd47c44-acd9-49c2-8f74-27cf88271770
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6f0f83b-218c-49e0-96bf-768e9d4f71ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6cf33e23-7e9c-48df-a7c1-f47e1749f81f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1ad88c3-5c7e-4969-b4e8-a16f42e1c6a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ad31d89-ce62-46c7-b647-9ebf1e032c0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07b2279d-ea29-4b86-9cfd-d8aa35d59a8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28d30482-f144-49e2-83b4-877403e2244c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52039114-2a0a-48be-b9e3-74cc1122fd75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 142de758-32d5-4192-8f1f-7151396ffb2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message adf177f0-abcd-42d4-84cd-dbc1887f535d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98af11e0-8d32-4931-a7a7-eedad23b4f60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1ca69cc-56b0-4c64-8930-e100ecae640e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1e49b9f-90ba-4df3-8e8e-cd80ef8adbe0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f104cd3a-5a69-457a-bd90-d94e8a22f0e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b3abf3f-fd86-4a48-961d-b753f265aac5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 521334aa-a4f9-46af-9372-6fd67d5919c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 834c9f54-5c5c-4f05-92ff-04404ba791e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55b059ed-4bef-49cb-a90a-fa4277e357e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48f1de8b-1539-4ee9-af53-95633f20e3c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75e5ec9f-8c2c-4cce-b187-e45478908100
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71cfbd7b-fabb-4bdc-84d5-42dd5ebfbef7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a92874fc-cddc-4cb7-9e77-c065d1203176
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cefb225b-e754-44aa-8372-ab700075d452
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2b633a3-8d9a-4bc7-8a30-eaf8376a3d7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b97958a0-0b65-40f9-a093-7fc3da2c2356
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49434c0a-8b63-4f19-9926-187b175dacad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7ef1dc5-c321-4fc1-8f28-c4ff492333c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2e89e3e-5032-41bc-b1ce-41cecf8d7376
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b203c1d0-9c7b-4357-be2b-ba790a0290d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd87320c-5b0d-4d87-871b-43e033cf9314
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4142cdeb-aed1-4c49-8dbc-a017e7b0dced
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aaf3c7d7-0a78-4662-903c-308f8a3c9b1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d110906-ad1f-4eab-a903-0a4a14aabd92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ce4ea4c-ca55-49eb-aa0e-18bc5687ed67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f6a626d-49f6-446c-bdbb-2d2e78ba118c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62495def-01fc-425e-bfc6-39149f996627
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86a1568e-f7db-4020-aeb6-d1c899e03570
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2676a34-3c9c-48dc-a3ec-e75326b9eaaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b7424a5-0626-448d-afe1-a37886143435
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd660ad6-0d62-47ff-a6dc-9803453b476b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 207ae2f2-2517-43e8-afa0-6e50eff97cd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 183e7b50-ff19-4729-a023-b4566708a9a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 030d4a44-0b3b-4323-968c-dbc81cc21ec6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a0a39e9-27db-41fc-a0c0-528caa64d05a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25db1193-ca83-4630-ae02-8f73c1efc505
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21aefe20-e166-48fa-bfa3-1427fae0aab4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22653387-9231-49f3-8c11-3a9b44180e76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7750ed2-abe9-452f-89fe-641e3f4ea715
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87f47299-6995-4b8c-bb9b-a20299bc0416
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9b5da47-5ce9-445f-8ab8-edf79ba7f0ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a2813a8-9730-4312-8a74-acdbc05da169
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b505d3aa-f35c-4e42-a659-dbc22aecc72c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4b8075e-7a27-4a14-8af2-42fb8c5e62a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3857b73c-ff51-4289-ab23-f0a2c029cb84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8b2f4ae-8635-43c6-bf77-4a57a0d56535
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b227fe65-6427-4289-8106-4c14be140aa5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43d30d44-8f58-4777-b048-26da61a70912
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c52967d6-f98d-4298-9e14-8769534dfcb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7fd117c-981e-4ec7-b74c-ddf9dc2c676f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37a61762-f314-4831-b457-cde94fe22267
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad06ec65-c8d6-45b4-8cb9-8aa4b40a71d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18ea7aaa-4899-4dce-ae40-f73cb469b55b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56663a4c-6857-4fde-a243-682df0b98161
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 074ae0b8-fee3-45ef-a9cd-32e13f8977df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e3e76f2-b2e0-421e-ace7-6a884e774b96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44463e7d-4033-4d6d-9ae7-f57d0bea26bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4e46131-f74a-4959-99b2-fe89ee400097
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fa2102e-4dd5-4c06-a6d7-33d792634e6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82aaa85f-4608-4260-8bdf-c60096546bac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a296338-dbfe-4ca7-b56a-92547ff336bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b09ed05-a079-4404-9b2b-e28d37302ad5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4726231-6442-4f72-9c3c-ca9c3a57f932
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93e26412-a313-4c71-a0d7-1aecbfefe8da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a79f6398-7837-481e-88d8-6150be31e117
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fc6baf6-382a-4d34-93d2-c0eb0583a423
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63a204ca-cf8f-451e-93b0-72f7066dc2d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f142caf-0618-44a4-9d8a-564b18c54e0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5d51028-892e-4633-8564-e4bae25c9a13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33e12125-029f-4b99-a347-558634e033fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cef3b034-86ee-4b19-b0f4-40dfb77b7f36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2c9a237-4522-4b89-8741-fafb2e6f0d52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e83ff6d3-daa4-4cac-bc61-5541ac6095ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b340152d-2af6-4534-a8e8-5347d2809ace
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4535b156-e1b0-4239-af66-49d363c8256b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fcc6da0-ee19-40ad-9b6f-face82dec80b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc98f97e-2fef-4813-857c-4989cd45014d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfb26bed-451c-4c7d-a689-39159a214623
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70f7c6fa-14a7-4e30-99fb-2c5251b85a4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24693481-9476-48d1-bf42-2bd567068c69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da17d5fd-70ff-4517-90a7-56afc7a5532f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4014824-c2e0-407a-b50e-83a94d77bb09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a02fa904-e12f-4f57-9c51-57340a0f30fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6db58b9-881f-4354-8009-b8b57578a9a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6f67d34-222f-4d31-bcc5-74ed3019f23e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5a94967-d535-487b-9fa9-ae04a93f6662
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 140555bf-c6e5-43c1-819e-366729074e91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29f69c8d-4517-4c79-a545-e96d4a2d96ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7de90098-70ec-42b4-ba3f-015f0b90b8d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 016f1589-c7c3-4064-a54c-f3bac600af34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90f84952-97ad-4ee7-b2e1-b42cb07bf71d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b91ba09a-e3a7-48d3-a3e2-55c31bb58599
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2856321-c9ae-4533-8756-9fc0a463667e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94b415a9-90d2-484e-bfe4-4770e5b25c69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 581c8d23-79a4-45c2-979c-874bcced25df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5aa49d08-a1b1-4619-b9c1-881e5d432abd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55a2f4bc-68fe-4264-a23e-316cbe16512e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57b20661-ca9a-4e6e-afc4-725175fabf88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16eaf760-17eb-4df1-903b-78629fb7da3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c21522e-2832-45b2-a6e4-fb5c5f232209
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8dba7e49-81dc-439e-ac03-256e206b016d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37f2e11c-262e-4d5b-b2c9-f62f4765ee84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4016109-2d92-4fa4-9ee8-8e7ce506af6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe1ac81b-f8f6-4bf9-9d2f-b8f14ccb8ded
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7135eb4-d4bb-4ba8-938e-3712475bd052
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92844f08-fa71-40ac-a6ea-db3c74500379
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46ead1b9-c202-455a-ba79-442dda7715fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff471902-4601-4b40-9347-475271ca65a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4940f885-38a5-4a07-9519-4f7218fc9965
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6f0377a-d4bf-44af-8137-76b5a5abf221
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3a2e198-ea61-41dd-b4c5-bf5f9930edcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11d471a3-4e95-4726-afe0-8afd1e0ab98d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f563f3c-ac3f-43b6-9050-f959599d82bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd2f59ac-7eaf-4881-9f60-bf4313d78e7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23c7a7b1-ff8b-4f24-9980-2c243a81d358
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c55d8fe1-9703-4b46-9eb4-9f580c9b28dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7790ba74-d438-4a26-9809-9a8ca8d2bd37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fd89d37-6839-4f3c-ad49-d738c6e8d6f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 204c097f-7ab6-4419-915a-d2ce0665b042
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 563e60a1-54c5-44a2-8115-1a0fda79d132
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46c06eb1-de72-480b-80ae-9ec49a8877be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 476d7b38-251a-480c-a7dc-33415f744fea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0eea07af-eca1-42be-a689-23aeb133009f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dca495e1-2e44-40e7-b34b-aa0754080b22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e8c18b5-5b2f-4cce-93b4-4559be08375a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44b1c888-cd49-40db-8090-43e8ad01fbe8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15dd2bc7-31f9-4b45-9af3-6a1f6e3d87da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f7388dc-890a-4722-b793-cd5442d5e011
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb527f69-bb71-45ff-8d35-2c47023643b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6ae835e-d046-4c8f-b7bd-0f7e790399bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bd1294c-5aab-4ddd-b6ea-0901826972f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d63dd47-155e-4f43-b28e-80fbc4d2c920
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdbd13ba-2f66-4386-8e61-60a0bfb49856
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89c27781-ca09-4603-a147-ebea0078849b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81579d54-f958-4f88-950e-7808d1c9eb66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8d1dffc-1e1d-4235-80d0-75731174663e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51eaa850-79c8-421c-85be-c67e79b65ed2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d81b2d88-651f-48f0-a1f5-809b2f2f2d59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 548fe38f-dab4-45f1-8a90-5b2682dcf0df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5afca6b-c515-4e7a-8618-19b2e890dfd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80abedc2-6aff-4429-a092-488dd5e82ca4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aae2a9d8-fe60-4be0-a437-b1d62b5e574a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8075d108-ce97-4bb7-a3f3-8d165ab7a693
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e38b5acc-77e8-4f1e-9a86-76ea47ec75e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bea6765f-c354-47fa-a67c-abac2e053444
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27e329af-7245-4518-9843-6bce864bcfa0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3831d1b7-8e54-4319-b75b-17ac9924e1b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b151d69-defc-4d6c-ac2a-347e1ca210bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12547bdb-0ef4-4fbb-83be-9693bed0f7c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a65e69bb-b1b9-49be-b04a-12bd08100de5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a56e7ea-533e-4415-9ad5-f1effdd474bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2348f89e-3b36-4bf8-8eed-647081d8ed3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d458a7b4-274e-42d2-80d1-df67a354c33e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9878bb9-f606-48bb-8cf4-53224c3a698d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5660da5b-e6c7-4c61-9009-54df6b34382f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96e3f235-67e9-4c64-9121-5c22d8868051
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee00eaf8-362c-41e6-99be-df85e0b382d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5dfcd44f-5529-4008-b1ff-98ca0179cb2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d4f92f0-6134-4a1f-b753-2525124f5d20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f84caed3-738c-457a-bf10-30bcb2b2fac7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1597e8d1-df4d-494c-8723-b4ac69f99278
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1bd996a-b95f-4e39-87bb-55d02d8cb4f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97e9a981-1676-4501-9983-e10b2759eb93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6857bfed-6f3f-4b44-bb92-0ea5bc36a627
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43295968-d704-40c1-a99c-8b435cb8a9c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4af203f3-0623-4a51-bdb7-c0c112dc1c8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7523644-1643-4b86-ae83-68dae529fee9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f4d36df-e598-4322-ab78-8cd0a86b0263
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e443e59-135e-4f55-9fb7-2f0322ead917
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56448eb8-d06a-4c86-be4f-79ca3acf508b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98d447d7-db0b-41a4-b01b-e14498ab3206
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5feb2010-439d-46cb-8e18-fd664c37c298
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa7acb63-361f-46a0-a954-9039bdec80f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5df1c422-0caf-4b81-905f-a934dba77990
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11b8ba20-7b42-494c-966b-6eec2257b38e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 509f0be8-5db1-45fd-8702-ef053ad78cbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec5a9e54-ffb8-4025-ae22-abe2201388fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d577630a-fe69-4702-b42c-2a7d3ee80a4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1c437a0-dc6c-4cb6-a892-b6d21eed9c83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 311ad411-2b86-40f4-b335-e573d08ef150
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63b278dc-5a1a-4be1-8fa0-64ccb2bf8180
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1136383-cc12-47fa-b8fd-5b8cbe6149de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08baf817-5875-449d-bf6c-37d754a39780
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01cf9028-0845-4a31-83eb-96ecd7482686
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e847abfd-1210-48f5-b458-6bee7e95dede
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7504a14a-d722-439d-8082-e1f6541aa7ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2574a743-d3ae-47a0-9f11-0e4c42b7603a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2231ace0-cd09-4d83-bb9a-3afc20b80a71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d844283-1c19-42c8-b8e7-1a429fa92797
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_18
Server: localhost:8688
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_18
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_18/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_18/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_18/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_18/test_labels.txt

📊 Raw data loaded:
   Train: X=(3505, 24), y=(3505,)
   Test:  X=(877, 24), y=(877,)

⚠️  Limiting training data: 3505 → 800 samples
⚠️  Limiting test data: 877 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_18 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 2 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0869 (↓), lr=0.001000
   • Epoch   2/100: train=0.0796, val=0.0878, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0795, val=0.0875, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0794, val=0.0872, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0792, val=0.0871, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0784, val=0.0862, patience=3/15, lr=0.000500
   • Epoch  21/100: train=0.0778, val=0.0860, patience=13/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 2 Summary - Client client_18
   Epochs: 23/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0218
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0111
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.4005, RMSE: 0.6328, MAE: 0.5686, R²: -4.1928

📊 Round 2 Test Metrics:
   Loss: 0.0891, RMSE: 0.2985, MAE: 0.2482, R²: -0.1552

============================================================
🔄 Round 7 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0775 (↓), lr=0.000500
   • Epoch   2/100: train=0.0810, val=0.0773, patience=1/15, lr=0.000500
   • Epoch   3/100: train=0.0806, val=0.0771, patience=2/15, lr=0.000500
   • Epoch   4/100: train=0.0803, val=0.0770, patience=3/15, lr=0.000500
   ✓ Epoch   5/100: train=0.0800, val=0.0770 (↓), lr=0.000500
   • Epoch  11/100: train=0.0788, val=0.0767, patience=6/15, lr=0.000500
   📉 Epoch 17: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 7 Summary - Client client_18
   Epochs: 20/100 (early stopped)
   LR: 0.000500 → 0.000250 (1 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0240
   Val:   Loss=0.0770, RMSE=0.2774, R²=0.0151
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2526, R²: -0.1275

============================================================
🔄 Round 10 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0757 (↓), lr=0.000250
   • Epoch   2/100: train=0.0805, val=0.0757, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0802, val=0.0758, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0800, val=0.0758, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0798, val=0.0759, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0790, val=0.0761, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 10 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0226
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0067
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0765, RMSE: 0.2766, MAE: 0.2363, R²: 0.0080

📊 Round 10 Test Metrics:
   Loss: 0.0758, RMSE: 0.2754, MAE: 0.2364, R²: 0.0167

============================================================
🔄 Round 17 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0829 (↓), lr=0.000063
   • Epoch   2/100: train=0.0783, val=0.0828, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0782, val=0.0829, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0781, val=0.0829, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0781, val=0.0828, patience=4/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0779, val=0.0828, patience=10/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 17 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0228
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0153
============================================================


============================================================
🔄 Round 18 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0877 (↓), lr=0.000016
   • Epoch   2/100: train=0.0776, val=0.0879, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0773, val=0.0880, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0772, val=0.0882, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0770, val=0.0884, patience=4/15, lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0767, val=0.0890, patience=10/15, lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 18 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=0.0090
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0296
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2386, R²: 0.0030

============================================================
🔄 Round 20 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0857 (↓), lr=0.000004
   • Epoch   2/100: train=0.0783, val=0.0857, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0783, val=0.0856, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0782, val=0.0855, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0782, val=0.0855, patience=4/15, lr=0.000004
   📉 Epoch 7: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0780, val=0.0853, patience=10/15, lr=0.000002
   📉 Epoch 15: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 20 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=0.0144
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0101
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: -0.0001

📊 Round 20 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2389, R²: 0.0005

============================================================
🔄 Round 25 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 25 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0115
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0181
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0769, RMSE: 0.2774, MAE: 0.2387, R²: 0.0023

📊 Round 25 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2386, R²: 0.0029

============================================================
🔄 Round 29 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 29 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2803, R²=0.0107
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0224
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0767, RMSE: 0.2770, MAE: 0.2384, R²: 0.0049

============================================================
🔄 Round 30 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 30 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0217
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0139
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0767, RMSE: 0.2769, MAE: 0.2383, R²: 0.0056

============================================================
🔄 Round 31 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 31 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0080
   Val:   Loss=0.0852, RMSE=0.2920, R²=0.0320
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0766, RMSE: 0.2768, MAE: 0.2383, R²: 0.0062

============================================================
🔄 Round 32 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 32 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2829, R²=0.0114
   Val:   Loss=0.0780, RMSE=0.2794, R²=0.0233
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0766, RMSE: 0.2768, MAE: 0.2382, R²: 0.0068

📊 Round 32 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2381, R²: 0.0072

📊 Round 32 Test Metrics:
   Loss: 0.0765, RMSE: 0.2766, MAE: 0.2380, R²: 0.0080

============================================================
🔄 Round 37 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 37 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0134
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0308
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0764, RMSE: 0.2765, MAE: 0.2380, R²: 0.0088

============================================================
🔄 Round 38 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 38 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0228
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0004
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2379, R²: 0.0092

============================================================
🔄 Round 45 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 45 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0163
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0296
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0763, RMSE: 0.2761, MAE: 0.2377, R²: 0.0112

============================================================
🔄 Round 46 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 46 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0184
   Val:   Loss=0.0887, RMSE=0.2979, R²=0.0235
============================================================


============================================================
🔄 Round 49 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 49 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0217
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0003
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2376, R²: 0.0123

============================================================
🔄 Round 51 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 51 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0225
   Val:   Loss=0.0882, RMSE=0.2970, R²=0.0088
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0761, RMSE: 0.2759, MAE: 0.2375, R²: 0.0126

============================================================
🔄 Round 53 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 53 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0109
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0101
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0761, RMSE: 0.2759, MAE: 0.2375, R²: 0.0128

📊 Round 53 Test Metrics:
   Loss: 0.0761, RMSE: 0.2759, MAE: 0.2375, R²: 0.0129

============================================================
🔄 Round 55 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 55 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0201
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0218
============================================================


============================================================
🔄 Round 58 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 58 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0197
   Val:   Loss=0.0713, RMSE=0.2670, R²=0.0255
============================================================


============================================================
🔄 Round 60 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 60 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0167
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0340
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0760, RMSE: 0.2758, MAE: 0.2373, R²: 0.0140

============================================================
🔄 Round 64 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 64 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0146
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0438
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2373, R²: 0.0144

📊 Round 64 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2373, R²: 0.0146

============================================================
🔄 Round 69 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 69 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0209
   Val:   Loss=0.0738, RMSE=0.2716, R²=0.0231
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2373, R²: 0.0147

============================================================
🔄 Round 72 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 72 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2790, R²=0.0221
   Val:   Loss=0.0849, RMSE=0.2913, R²=0.0166
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0760, RMSE: 0.2756, MAE: 0.2372, R²: 0.0150

============================================================
🔄 Round 78 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 78 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0235
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0043
============================================================


============================================================
🔄 Round 79 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 79 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0281
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0042
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0760, RMSE: 0.2756, MAE: 0.2372, R²: 0.0152

============================================================
🔄 Round 81 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 81 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0195
   Val:   Loss=0.0736, RMSE=0.2712, R²=0.0295
============================================================


============================================================
🔄 Round 83 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 83 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0330
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0291
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0759, RMSE: 0.2756, MAE: 0.2372, R²: 0.0152

📊 Round 83 Test Metrics:
   Loss: 0.0759, RMSE: 0.2756, MAE: 0.2372, R²: 0.0153

============================================================
🔄 Round 87 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 87 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0210
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0239
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0759, RMSE: 0.2756, MAE: 0.2372, R²: 0.0154

============================================================
🔄 Round 89 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 89 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0127
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0512
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0759, RMSE: 0.2756, MAE: 0.2372, R²: 0.0154

============================================================
🔄 Round 91 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0698 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0698, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0698, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0698, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0698, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0698, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0698)

============================================================
📊 Round 91 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0154
   Val:   Loss=0.0698, RMSE=0.2642, R²=0.0479
============================================================


============================================================
🔄 Round 92 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 92 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0268
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0252
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2371, R²: 0.0157

============================================================
🔄 Round 94 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 94 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0258
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0044
============================================================


============================================================
🔄 Round 95 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 95 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0365
   Val:   Loss=0.0859, RMSE=0.2930, R²=-0.0380
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2371, R²: 0.0159

============================================================
🔄 Round 96 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 96 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0290
   Val:   Loss=0.0736, RMSE=0.2713, R²=-0.0122
============================================================


============================================================
🔄 Round 98 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 98 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0260
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0034
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2371, R²: 0.0161

📊 Round 98 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2371, R²: 0.0161

📊 Round 98 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2371, R²: 0.0162

============================================================
🔄 Round 102 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0686 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0686, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0686, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0686, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0686, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0686, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0686)

============================================================
📊 Round 102 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0216
   Val:   Loss=0.0686, RMSE=0.2619, R²=0.0221
============================================================


============================================================
🔄 Round 103 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 103 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.0181
   Val:   Loss=0.0867, RMSE=0.2945, R²=0.0172
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0759, RMSE: 0.2754, MAE: 0.2371, R²: 0.0163

============================================================
🔄 Round 105 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 105 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0266
   Val:   Loss=0.0826, RMSE=0.2873, R²=0.0034
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0759, RMSE: 0.2754, MAE: 0.2371, R²: 0.0164

============================================================
🔄 Round 110 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 110 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0190
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0176
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0759, RMSE: 0.2754, MAE: 0.2370, R²: 0.0165

============================================================
🔄 Round 111 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 111 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0231
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0018
============================================================


============================================================
🔄 Round 112 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 112 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0192
   Val:   Loss=0.0779, RMSE=0.2790, R²=0.0260
============================================================


============================================================
🔄 Round 113 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 113 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0169
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0365
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0758, RMSE: 0.2754, MAE: 0.2370, R²: 0.0165

============================================================
🔄 Round 115 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 115 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0210
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0246
============================================================


============================================================
🔄 Round 117 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 117 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0163
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0266
============================================================


============================================================
🔄 Round 119 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 119 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2792, R²=0.0263
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0058
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0758, RMSE: 0.2754, MAE: 0.2370, R²: 0.0167

📊 Round 119 Test Metrics:
   Loss: 0.0758, RMSE: 0.2754, MAE: 0.2370, R²: 0.0167

============================================================
🔄 Round 124 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 124 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0217
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0235
============================================================


============================================================
🔄 Round 125 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 125 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0197
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0228
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0758, RMSE: 0.2754, MAE: 0.2370, R²: 0.0167

📊 Round 125 Test Metrics:
   Loss: 0.0758, RMSE: 0.2754, MAE: 0.2370, R²: 0.0167

============================================================
🔄 Round 128 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 128 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2813, R²=0.0217
   Val:   Loss=0.0794, RMSE=0.2819, R²=0.0201
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0758, RMSE: 0.2754, MAE: 0.2370, R²: 0.0168

============================================================
🔄 Round 129 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 129 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0245
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0108
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0758, RMSE: 0.2754, MAE: 0.2370, R²: 0.0168

============================================================
🔄 Round 130 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 130 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0150
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0480
============================================================


============================================================
🔄 Round 131 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 131 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0230
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0173
============================================================


============================================================
🔄 Round 132 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 132 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0243
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0048
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0758, RMSE: 0.2754, MAE: 0.2370, R²: 0.0168

============================================================
🔄 Round 133 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 133 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0237
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0151
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0758, RMSE: 0.2754, MAE: 0.2370, R²: 0.0168

📊 Round 133 Test Metrics:
   Loss: 0.0758, RMSE: 0.2754, MAE: 0.2370, R²: 0.0168

📊 Round 133 Test Metrics:
   Loss: 0.0758, RMSE: 0.2754, MAE: 0.2370, R²: 0.0168

============================================================
🔄 Round 137 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 137 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=0.0246
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0077
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0758, RMSE: 0.2754, MAE: 0.2370, R²: 0.0168

============================================================
🔄 Round 139 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 139 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0219
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0222
============================================================


============================================================
🔄 Round 140 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 140 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0209
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0266
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0758, RMSE: 0.2754, MAE: 0.2370, R²: 0.0168

============================================================
🔄 Round 144 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 144 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0253
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0094
============================================================


============================================================
🔄 Round 145 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 145 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0154
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0473
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0758, RMSE: 0.2754, MAE: 0.2370, R²: 0.0169

============================================================
🔄 Round 150 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 150 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0203
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0224
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0758, RMSE: 0.2754, MAE: 0.2370, R²: 0.0168

============================================================
🔄 Round 151 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 151 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0193
   Val:   Loss=0.0885, RMSE=0.2974, R²=0.0309
============================================================


============================================================
🔄 Round 153 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 153 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0238
   Val:   Loss=0.0778, RMSE=0.2790, R²=0.0137
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0758, RMSE: 0.2754, MAE: 0.2370, R²: 0.0168

============================================================
🔄 Round 155 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 155 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0162
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0356
============================================================


============================================================
🔄 Round 156 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 156 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0228
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0100
============================================================


============================================================
🔄 Round 157 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 157 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0224
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0202
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0758, RMSE: 0.2754, MAE: 0.2370, R²: 0.0168

📊 Round 157 Test Metrics:
   Loss: 0.0758, RMSE: 0.2754, MAE: 0.2370, R²: 0.0168

📊 Round 157 Test Metrics:
   Loss: 0.0758, RMSE: 0.2754, MAE: 0.2370, R²: 0.0168

============================================================
🔄 Round 160 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0685 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0685, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0685, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0685, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0686, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0686, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0685)

============================================================
📊 Round 160 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0224
   Val:   Loss=0.0685, RMSE=0.2618, R²=0.0156
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0758, RMSE: 0.2754, MAE: 0.2370, R²: 0.0168

============================================================
🔄 Round 162 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 162 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0163
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0435
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0758, RMSE: 0.2754, MAE: 0.2370, R²: 0.0168

============================================================
🔄 Round 164 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 164 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0234
   Val:   Loss=0.0740, RMSE=0.2720, R²=0.0124
============================================================


============================================================
🔄 Round 165 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 165 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0345
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0300
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0758, RMSE: 0.2754, MAE: 0.2370, R²: 0.0168

============================================================
🔄 Round 169 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 169 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0157
   Val:   Loss=0.0792, RMSE=0.2813, R²=0.0452
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0758, RMSE: 0.2754, MAE: 0.2370, R²: 0.0169

============================================================
🔄 Round 170 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 170 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0304
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0217
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0758, RMSE: 0.2754, MAE: 0.2370, R²: 0.0169

============================================================
🔄 Round 171 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 171 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0218
   Val:   Loss=0.0877, RMSE=0.2962, R²=0.0175
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0758, RMSE: 0.2753, MAE: 0.2370, R²: 0.0169

============================================================
🔄 Round 172 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 172 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0205
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0248
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0758, RMSE: 0.2753, MAE: 0.2370, R²: 0.0170

============================================================
🔄 Round 173 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 173 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0267
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0025
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0758, RMSE: 0.2753, MAE: 0.2370, R²: 0.0170

📊 Round 173 Test Metrics:
   Loss: 0.0758, RMSE: 0.2753, MAE: 0.2370, R²: 0.0170

📊 Round 173 Test Metrics:
   Loss: 0.0758, RMSE: 0.2753, MAE: 0.2370, R²: 0.0170

📊 Round 173 Test Metrics:
   Loss: 0.0758, RMSE: 0.2753, MAE: 0.2370, R²: 0.0170

============================================================
🔄 Round 182 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 182 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0173
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0401
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0758, RMSE: 0.2753, MAE: 0.2370, R²: 0.0171

============================================================
🔄 Round 185 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 185 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0217
   Val:   Loss=0.0785, RMSE=0.2801, R²=0.0176
============================================================


============================================================
🔄 Round 187 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 187 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0152
   Val:   Loss=0.0713, RMSE=0.2669, R²=0.0514
============================================================


============================================================
🔄 Round 190 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 190 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0202
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0287
============================================================


============================================================
🔄 Round 191 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 191 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=0.0243
   Val:   Loss=0.0775, RMSE=0.2783, R²=0.0109
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0758, RMSE: 0.2753, MAE: 0.2369, R²: 0.0173

📊 Round 191 Test Metrics:
   Loss: 0.0758, RMSE: 0.2753, MAE: 0.2369, R²: 0.0172

📊 Round 191 Test Metrics:
   Loss: 0.0758, RMSE: 0.2753, MAE: 0.2369, R²: 0.0173

============================================================
🔄 Round 198 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 198 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0188
   Val:   Loss=0.0756, RMSE=0.2749, R²=0.0356
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0758, RMSE: 0.2753, MAE: 0.2369, R²: 0.0173

============================================================
🔄 Round 199 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 199 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0197
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0277
============================================================


============================================================
🔄 Round 200 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 200 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0282
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0023
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0758, RMSE: 0.2753, MAE: 0.2369, R²: 0.0173

============================================================
🔄 Round 201 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 201 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0219
   Val:   Loss=0.0874, RMSE=0.2957, R²=0.0178
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0758, RMSE: 0.2753, MAE: 0.2369, R²: 0.0173

📊 Round 201 Test Metrics:
   Loss: 0.0758, RMSE: 0.2753, MAE: 0.2369, R²: 0.0173

============================================================
🔄 Round 203 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 203 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0212
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0143
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0758, RMSE: 0.2753, MAE: 0.2369, R²: 0.0174

============================================================
🔄 Round 204 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 204 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0263
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0013
============================================================


============================================================
🔄 Round 205 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 205 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2812, R²=0.0193
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0325
============================================================


============================================================
🔄 Round 206 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 206 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0313
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0205
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0758, RMSE: 0.2753, MAE: 0.2369, R²: 0.0173

============================================================
🔄 Round 207 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 207 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0188
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0339
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0758, RMSE: 0.2753, MAE: 0.2369, R²: 0.0172

============================================================
🔄 Round 213 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 213 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0167
   Val:   Loss=0.0719, RMSE=0.2682, R²=0.0424
============================================================


============================================================
🔄 Round 214 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 214 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0154
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0443
============================================================


============================================================
🔄 Round 215 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 215 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0240
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0120
============================================================


📊 Round 215 Test Metrics:
   Loss: 0.0758, RMSE: 0.2753, MAE: 0.2369, R²: 0.0171

📊 Round 215 Test Metrics:
   Loss: 0.0758, RMSE: 0.2753, MAE: 0.2369, R²: 0.0171

============================================================
🔄 Round 219 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 219 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0172
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0387
============================================================


============================================================
🔄 Round 221 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 221 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0241
   Val:   Loss=0.0784, RMSE=0.2799, R²=0.0108
============================================================


============================================================
🔄 Round 222 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 222 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0200
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0173
============================================================


📊 Round 222 Test Metrics:
   Loss: 0.0758, RMSE: 0.2753, MAE: 0.2369, R²: 0.0172

============================================================
🔄 Round 224 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 224 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0207
   Val:   Loss=0.0837, RMSE=0.2892, R²=0.0262
============================================================


📊 Round 224 Test Metrics:
   Loss: 0.0758, RMSE: 0.2753, MAE: 0.2369, R²: 0.0172

📊 Round 224 Test Metrics:
   Loss: 0.0758, RMSE: 0.2753, MAE: 0.2369, R²: 0.0172

============================================================
🔄 Round 229 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 229 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0252
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0064
============================================================


📊 Round 229 Test Metrics:
   Loss: 0.0758, RMSE: 0.2753, MAE: 0.2369, R²: 0.0173

📊 Round 229 Test Metrics:
   Loss: 0.0758, RMSE: 0.2753, MAE: 0.2369, R²: 0.0173

============================================================
🔄 Round 233 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 233 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0324
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0199
============================================================


📊 Round 233 Test Metrics:
   Loss: 0.0758, RMSE: 0.2753, MAE: 0.2369, R²: 0.0173

============================================================
🔄 Round 234 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 234 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0249
   Val:   Loss=0.0722, RMSE=0.2688, R²=0.0084
============================================================


📊 Round 234 Test Metrics:
   Loss: 0.0758, RMSE: 0.2753, MAE: 0.2369, R²: 0.0174

📊 Round 234 Test Metrics:
   Loss: 0.0758, RMSE: 0.2753, MAE: 0.2369, R²: 0.0174

============================================================
🔄 Round 238 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 238 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2770, R²=0.0229
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0033
============================================================


📊 Round 238 Test Metrics:
   Loss: 0.0758, RMSE: 0.2753, MAE: 0.2369, R²: 0.0175

============================================================
🔄 Round 242 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 242 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.0269
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0042
============================================================


============================================================
🔄 Round 245 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 245 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0107
   Val:   Loss=0.0760, RMSE=0.2756, R²=0.0661
============================================================


📊 Round 245 Test Metrics:
   Loss: 0.0758, RMSE: 0.2753, MAE: 0.2369, R²: 0.0176

============================================================
🔄 Round 247 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 247 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0209
   Val:   Loss=0.0787, RMSE=0.2806, R²=0.0260
============================================================


📊 Round 247 Test Metrics:
   Loss: 0.0758, RMSE: 0.2752, MAE: 0.2369, R²: 0.0176

============================================================
🔄 Round 249 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 249 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0205
   Val:   Loss=0.0853, RMSE=0.2920, R²=0.0272
============================================================


============================================================
🔄 Round 250 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 250 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0214
   Val:   Loss=0.0894, RMSE=0.2989, R²=0.0130
============================================================


📊 Round 250 Test Metrics:
   Loss: 0.0758, RMSE: 0.2752, MAE: 0.2369, R²: 0.0177

============================================================
🔄 Round 251 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 251 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0235
   Val:   Loss=0.0734, RMSE=0.2709, R²=0.0146
============================================================


📊 Round 251 Test Metrics:
   Loss: 0.0758, RMSE: 0.2752, MAE: 0.2369, R²: 0.0177

============================================================
🔄 Round 254 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 254 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2813, R²=0.0171
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0272
============================================================


📊 Round 254 Test Metrics:
   Loss: 0.0758, RMSE: 0.2752, MAE: 0.2369, R²: 0.0176

============================================================
🔄 Round 257 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 257 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0189
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0331
============================================================


📊 Round 257 Test Metrics:
   Loss: 0.0758, RMSE: 0.2752, MAE: 0.2369, R²: 0.0177

============================================================
🔄 Round 258 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 258 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0261
   Val:   Loss=0.0934, RMSE=0.3056, R²=0.0072
============================================================


📊 Round 258 Test Metrics:
   Loss: 0.0758, RMSE: 0.2752, MAE: 0.2369, R²: 0.0176

============================================================
🔄 Round 262 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 262 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0307
   Val:   Loss=0.0833, RMSE=0.2885, R²=-0.0121
============================================================


📊 Round 262 Test Metrics:
   Loss: 0.0758, RMSE: 0.2753, MAE: 0.2369, R²: 0.0176

============================================================
🔄 Round 264 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 264 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2810, R²=0.0190
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0155
============================================================


📊 Round 264 Test Metrics:
   Loss: 0.0758, RMSE: 0.2753, MAE: 0.2369, R²: 0.0176

============================================================
🔄 Round 265 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 265 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0224
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0189
============================================================


============================================================
🔄 Round 266 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 266 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0266
   Val:   Loss=0.0736, RMSE=0.2713, R²=-0.0028
============================================================


============================================================
🔄 Round 267 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 267 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0165
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0273
============================================================


============================================================
🔄 Round 270 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 270 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0235
   Val:   Loss=0.0755, RMSE=0.2749, R²=0.0121
============================================================


📊 Round 270 Test Metrics:
   Loss: 0.0758, RMSE: 0.2752, MAE: 0.2369, R²: 0.0177

============================================================
🔄 Round 271 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 271 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0155
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0431
============================================================


============================================================
🔄 Round 272 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0664 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0664, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0664, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0664, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0664, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0663, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0664)

============================================================
📊 Round 272 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0205
   Val:   Loss=0.0664, RMSE=0.2576, R²=0.0288
============================================================


📊 Round 272 Test Metrics:
   Loss: 0.0758, RMSE: 0.2752, MAE: 0.2369, R²: 0.0177

============================================================
🔄 Round 273 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 273 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0180
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0333
============================================================


📊 Round 273 Test Metrics:
   Loss: 0.0758, RMSE: 0.2752, MAE: 0.2369, R²: 0.0177

============================================================
🔄 Round 274 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 274 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0214
   Val:   Loss=0.0778, RMSE=0.2790, R²=0.0105
============================================================


📊 Round 274 Test Metrics:
   Loss: 0.0758, RMSE: 0.2752, MAE: 0.2369, R²: 0.0177

============================================================
🔄 Round 275 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 275 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0204
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0254
============================================================


============================================================
🔄 Round 276 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 276 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0246
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0060
============================================================


📊 Round 276 Test Metrics:
   Loss: 0.0758, RMSE: 0.2752, MAE: 0.2369, R²: 0.0177

📊 Round 276 Test Metrics:
   Loss: 0.0758, RMSE: 0.2752, MAE: 0.2369, R²: 0.0177

============================================================
🔄 Round 279 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 279 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0198
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0192
============================================================


📊 Round 279 Test Metrics:
   Loss: 0.0758, RMSE: 0.2752, MAE: 0.2369, R²: 0.0177

============================================================
🔄 Round 281 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 281 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0216
   Val:   Loss=0.0776, RMSE=0.2785, R²=-0.0098
============================================================


📊 Round 281 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2369, R²: 0.0178

============================================================
🔄 Round 284 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 284 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0216
   Val:   Loss=0.0716, RMSE=0.2676, R²=0.0063
============================================================


============================================================
🔄 Round 287 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 287 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0266
   Val:   Loss=0.0734, RMSE=0.2710, R²=0.0017
============================================================


📊 Round 287 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0179

📊 Round 287 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0179

============================================================
🔄 Round 290 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0707, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0707, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0707, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0707, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 290 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0175
   Val:   Loss=0.0707, RMSE=0.2660, R²=0.0427
============================================================


📊 Round 290 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0179

📊 Round 290 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2369, R²: 0.0179

📊 Round 290 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2369, R²: 0.0178

============================================================
🔄 Round 294 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 294 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0192
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0332
============================================================


📊 Round 294 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2369, R²: 0.0178

============================================================
🔄 Round 296 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 296 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2803, R²=0.0158
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0450
============================================================


📊 Round 296 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2369, R²: 0.0178

============================================================
🔄 Round 300 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 300 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0184
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0342
============================================================


📊 Round 300 Test Metrics:
   Loss: 0.0758, RMSE: 0.2752, MAE: 0.2369, R²: 0.0177

============================================================
🔄 Round 305 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 305 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0213
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0175
============================================================


📊 Round 305 Test Metrics:
   Loss: 0.0758, RMSE: 0.2752, MAE: 0.2369, R²: 0.0177

📊 Round 305 Test Metrics:
   Loss: 0.0758, RMSE: 0.2752, MAE: 0.2369, R²: 0.0176

📊 Round 305 Test Metrics:
   Loss: 0.0758, RMSE: 0.2752, MAE: 0.2369, R²: 0.0177

📊 Round 305 Test Metrics:
   Loss: 0.0758, RMSE: 0.2752, MAE: 0.2369, R²: 0.0177

============================================================
🔄 Round 315 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 315 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0250
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0032
============================================================


📊 Round 315 Test Metrics:
   Loss: 0.0758, RMSE: 0.2752, MAE: 0.2369, R²: 0.0177

============================================================
🔄 Round 320 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 320 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0167
   Val:   Loss=0.0753, RMSE=0.2745, R²=0.0283
============================================================


📊 Round 320 Test Metrics:
   Loss: 0.0758, RMSE: 0.2752, MAE: 0.2369, R²: 0.0176

============================================================
🔄 Round 322 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 322 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0217
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0159
============================================================


============================================================
🔄 Round 323 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 323 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2812, R²=0.0100
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0558
============================================================


============================================================
🔄 Round 327 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 327 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0190
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0325
============================================================


============================================================
🔄 Round 329 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 329 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2819, R²=0.0189
   Val:   Loss=0.0784, RMSE=0.2799, R²=0.0309
============================================================


📊 Round 329 Test Metrics:
   Loss: 0.0758, RMSE: 0.2753, MAE: 0.2369, R²: 0.0176

📊 Round 329 Test Metrics:
   Loss: 0.0758, RMSE: 0.2753, MAE: 0.2369, R²: 0.0176

📊 Round 329 Test Metrics:
   Loss: 0.0758, RMSE: 0.2753, MAE: 0.2369, R²: 0.0176

============================================================
🔄 Round 335 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 335 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0198
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0291
============================================================


📊 Round 335 Test Metrics:
   Loss: 0.0758, RMSE: 0.2753, MAE: 0.2369, R²: 0.0176

============================================================
🔄 Round 337 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 337 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0139
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0452
============================================================


📊 Round 337 Test Metrics:
   Loss: 0.0758, RMSE: 0.2752, MAE: 0.2369, R²: 0.0177

============================================================
🔄 Round 339 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 339 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0102
   Val:   Loss=0.0787, RMSE=0.2806, R²=0.0509
============================================================


📊 Round 339 Test Metrics:
   Loss: 0.0758, RMSE: 0.2752, MAE: 0.2369, R²: 0.0177

============================================================
🔄 Round 340 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 340 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0239
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0143
============================================================


📊 Round 340 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2369, R²: 0.0178

============================================================
🔄 Round 343 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 343 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0224
   Val:   Loss=0.0751, RMSE=0.2741, R²=0.0198
============================================================


📊 Round 343 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0179

============================================================
🔄 Round 346 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 346 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0280
   Val:   Loss=0.0710, RMSE=0.2664, R²=-0.0104
============================================================


============================================================
🔄 Round 348 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 348 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0295
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0081
============================================================


📊 Round 348 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0180

📊 Round 348 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0181

============================================================
🔄 Round 351 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0701 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0701, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0701, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0701, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0701, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0701, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0701)

============================================================
📊 Round 351 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0210
   Val:   Loss=0.0701, RMSE=0.2647, R²=0.0212
============================================================


============================================================
🔄 Round 352 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 352 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0266
   Val:   Loss=0.0719, RMSE=0.2681, R²=-0.0003
============================================================


============================================================
🔄 Round 354 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 354 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0205
   Val:   Loss=0.0751, RMSE=0.2740, R²=-0.0009
============================================================


📊 Round 354 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0182

📊 Round 354 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0183

📊 Round 354 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0183

============================================================
🔄 Round 359 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 359 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0190
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0122
============================================================


📊 Round 359 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0183

============================================================
🔄 Round 361 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 361 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2790, R²=0.0277
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0007
============================================================


============================================================
🔄 Round 362 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 362 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0300
   Val:   Loss=0.0783, RMSE=0.2799, R²=-0.0116
============================================================


📊 Round 362 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2368, R²: 0.0184

============================================================
🔄 Round 364 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 364 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2790, R²=0.0147
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0474
============================================================


============================================================
🔄 Round 366 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 366 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0206
   Val:   Loss=0.0787, RMSE=0.2806, R²=0.0274
============================================================


📊 Round 366 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2368, R²: 0.0184

============================================================
🔄 Round 367 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 367 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0294
   Val:   Loss=0.0802, RMSE=0.2831, R²=-0.0080
============================================================


📊 Round 367 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2368, R²: 0.0183

📊 Round 367 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0183

============================================================
🔄 Round 369 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 369 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2785, R²=0.0301
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0081
============================================================


============================================================
🔄 Round 370 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 370 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2810, R²=0.0220
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0172
============================================================


============================================================
🔄 Round 371 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 371 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0328
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0193
============================================================


============================================================
🔄 Round 372 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 372 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0107
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0578
============================================================


============================================================
🔄 Round 374 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 374 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0220
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0220
============================================================


============================================================
🔄 Round 376 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 376 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0182
   Val:   Loss=0.0889, RMSE=0.2981, R²=0.0345
============================================================


============================================================
🔄 Round 377 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 377 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0248
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0062
============================================================


📊 Round 377 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0183

📊 Round 377 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0183

============================================================
🔄 Round 383 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 383 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0119
   Val:   Loss=0.0758, RMSE=0.2754, R²=0.0615
============================================================


📊 Round 383 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2368, R²: 0.0183

============================================================
🔄 Round 384 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0707, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0707, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0707, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0707, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 384 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0237
   Val:   Loss=0.0707, RMSE=0.2660, R²=0.0026
============================================================


📊 Round 384 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2368, R²: 0.0184

============================================================
🔄 Round 385 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 385 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0210
   Val:   Loss=0.0874, RMSE=0.2957, R²=0.0259
============================================================


============================================================
🔄 Round 386 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 386 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0233
   Val:   Loss=0.0880, RMSE=0.2967, R²=0.0146
============================================================


📊 Round 386 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2368, R²: 0.0184

============================================================
🔄 Round 387 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 387 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0291
   Val:   Loss=0.0713, RMSE=0.2670, R²=-0.0185
============================================================


📊 Round 387 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0183

📊 Round 387 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0183

============================================================
🔄 Round 390 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 390 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0229
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0101
============================================================


📊 Round 390 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0182

============================================================
🔄 Round 395 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 395 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0285
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0066
============================================================


============================================================
🔄 Round 396 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 396 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0237
   Val:   Loss=0.0751, RMSE=0.2741, R²=0.0095
============================================================


📊 Round 396 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0183

📊 Round 396 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0183

============================================================
🔄 Round 402 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 402 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0206
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0269
============================================================


📊 Round 402 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2368, R²: 0.0183

============================================================
🔄 Round 407 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 407 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0250
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0067
============================================================


📊 Round 407 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0183

============================================================
🔄 Round 409 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 409 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0230
   Val:   Loss=0.0790, RMSE=0.2812, R²=0.0172
============================================================


📊 Round 409 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0183

============================================================
🔄 Round 411 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 411 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0201
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0277
============================================================


📊 Round 411 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0182

============================================================
🔄 Round 413 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 413 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0181
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0196
============================================================


📊 Round 413 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0181

============================================================
🔄 Round 415 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0706 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0706, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0706, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0707, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0707, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0707, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0706)

============================================================
📊 Round 415 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0116
   Val:   Loss=0.0706, RMSE=0.2658, R²=0.0603
============================================================


📊 Round 415 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0181

📊 Round 415 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0181

============================================================
🔄 Round 417 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 417 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0262
   Val:   Loss=0.0859, RMSE=0.2930, R²=-0.0015
============================================================


============================================================
🔄 Round 418 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 418 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0183
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0264
============================================================


============================================================
🔄 Round 419 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 419 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0188
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0270
============================================================


📊 Round 419 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0181

============================================================
🔄 Round 421 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 421 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0166
   Val:   Loss=0.0732, RMSE=0.2706, R²=0.0299
============================================================


============================================================
🔄 Round 423 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 423 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0208
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0257
============================================================


📊 Round 423 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0180

📊 Round 423 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0181

============================================================
🔄 Round 425 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 425 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0208
   Val:   Loss=0.0849, RMSE=0.2913, R²=0.0251
============================================================


============================================================
🔄 Round 426 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 426 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2812, R²=0.0320
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0209
============================================================


============================================================
🔄 Round 429 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 429 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0260
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0020
============================================================


============================================================
🔄 Round 430 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 430 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0223
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0193
============================================================


📊 Round 430 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0181

📊 Round 430 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0181

📊 Round 430 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0181

============================================================
🔄 Round 434 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 434 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0225
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0072
============================================================


📊 Round 434 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0182

============================================================
🔄 Round 435 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 435 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0257
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0064
============================================================


📊 Round 435 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0182

📊 Round 435 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0182

============================================================
🔄 Round 438 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 438 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=0.0256
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0087
============================================================


📊 Round 438 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0182

============================================================
🔄 Round 439 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0706 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0706, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0706, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0706, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0706)

============================================================
📊 Round 439 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0298
   Val:   Loss=0.0706, RMSE=0.2657, R²=-0.0163
============================================================


📊 Round 439 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0182

📊 Round 439 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0182

============================================================
🔄 Round 442 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 442 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0236
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0150
============================================================


============================================================
🔄 Round 445 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 445 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0170
   Val:   Loss=0.0905, RMSE=0.3009, R²=0.0288
============================================================


📊 Round 445 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0181

============================================================
🔄 Round 448 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 448 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0238
   Val:   Loss=0.0722, RMSE=0.2686, R²=0.0083
============================================================


📊 Round 448 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0180

📊 Round 448 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0180

============================================================
🔄 Round 453 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 453 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0247
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0106
============================================================


============================================================
🔄 Round 455 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 455 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0167
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0412
============================================================


📊 Round 455 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0179

============================================================
🔄 Round 458 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 458 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0182
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0192
============================================================


📊 Round 458 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0179

============================================================
🔄 Round 459 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 459 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0204
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0272
============================================================


📊 Round 459 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0179

📊 Round 459 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0179

📊 Round 459 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0179

📊 Round 459 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0180

============================================================
🔄 Round 466 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 466 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0283
   Val:   Loss=0.0819, RMSE=0.2863, R²=-0.0141
============================================================


📊 Round 466 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0180

============================================================
🔄 Round 470 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 470 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0144
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0217
============================================================


============================================================
🔄 Round 471 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 471 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0134
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0526
============================================================


📊 Round 471 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0181

============================================================
🔄 Round 473 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0706, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0706, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 473 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0203
   Val:   Loss=0.0705, RMSE=0.2656, R²=0.0127
============================================================


============================================================
🔄 Round 477 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 477 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=0.0258
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0019
============================================================


📊 Round 477 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0181

============================================================
🔄 Round 479 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 479 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0210
   Val:   Loss=0.0779, RMSE=0.2792, R²=0.0226
============================================================


📊 Round 479 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0181

============================================================
🔄 Round 481 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 481 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0185
   Val:   Loss=0.0754, RMSE=0.2747, R²=0.0242
============================================================


============================================================
🔄 Round 485 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0683 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0683, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0683, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0683, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0683, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0683, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0683)

============================================================
📊 Round 485 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0254
   Val:   Loss=0.0683, RMSE=0.2613, R²=0.0031
============================================================


📊 Round 485 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0180

📊 Round 485 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0181

============================================================
🔄 Round 487 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0705, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 487 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0283
   Val:   Loss=0.0705, RMSE=0.2656, R²=-0.0101
============================================================


📊 Round 487 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0181

============================================================
🔄 Round 489 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 489 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0319
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0243
============================================================


📊 Round 489 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0181

📊 Round 489 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0181

============================================================
🔄 Round 491 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 491 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0261
   Val:   Loss=0.0740, RMSE=0.2721, R²=-0.0058
============================================================


📊 Round 491 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0182

============================================================
🔄 Round 498 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 498 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=0.0238
   Val:   Loss=0.0849, RMSE=0.2913, R²=0.0117
============================================================


📊 Round 498 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0182

============================================================
🔄 Round 499 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 499 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0274
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0018
============================================================


============================================================
🔄 Round 500 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 500 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0132
   Val:   Loss=0.0744, RMSE=0.2727, R²=0.0507
============================================================


📊 Round 500 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0183

============================================================
🔄 Round 502 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 502 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0223
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0199
============================================================


📊 Round 502 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0182

📊 Round 502 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0182

📊 Round 502 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0182

============================================================
🔄 Round 506 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 506 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0193
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0317
============================================================


📊 Round 506 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0182

============================================================
🔄 Round 507 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 507 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0247
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0090
============================================================


📊 Round 507 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0182

============================================================
🔄 Round 509 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 509 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=0.0257
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0071
============================================================


📊 Round 509 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0182

============================================================
🔄 Round 513 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 513 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=0.0145
   Val:   Loss=0.0732, RMSE=0.2705, R²=0.0380
============================================================


============================================================
🔄 Round 514 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 514 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0090
   Val:   Loss=0.0739, RMSE=0.2718, R²=0.0660
============================================================


============================================================
🔄 Round 516 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 516 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=0.0154
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0250
============================================================


📊 Round 516 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0182

============================================================
🔄 Round 518 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 518 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0220
   Val:   Loss=0.0899, RMSE=0.2999, R²=0.0167
============================================================


📊 Round 518 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0182

============================================================
🔄 Round 522 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 522 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0249
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0091
============================================================


📊 Round 522 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0183

📊 Round 522 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2368, R²: 0.0183

============================================================
🔄 Round 526 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 526 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0152
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0481
============================================================


📊 Round 526 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2368, R²: 0.0184

============================================================
🔄 Round 527 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 527 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0238
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0120
============================================================


📊 Round 527 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2368, R²: 0.0184

============================================================
🔄 Round 528 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 528 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0162
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0437
============================================================


============================================================
🔄 Round 529 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 529 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0189
   Val:   Loss=0.0740, RMSE=0.2721, R²=0.0346
============================================================


📊 Round 529 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2368, R²: 0.0184

============================================================
🔄 Round 531 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 531 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0221
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0208
============================================================


📊 Round 531 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2368, R²: 0.0184

📊 Round 531 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2368, R²: 0.0185

📊 Round 531 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2368, R²: 0.0185

============================================================
🔄 Round 537 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 537 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2783, R²=0.0217
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0229
============================================================


📊 Round 537 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2368, R²: 0.0186

📊 Round 537 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2368, R²: 0.0186

============================================================
🔄 Round 542 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 542 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0194
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0164
============================================================


============================================================
🔄 Round 543 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0673 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0673, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0673, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0673, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0673, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0673, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0673)

============================================================
📊 Round 543 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0183
   Val:   Loss=0.0673, RMSE=0.2594, R²=0.0218
============================================================


============================================================
🔄 Round 544 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 544 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0089
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0718
============================================================


============================================================
🔄 Round 545 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 545 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0227
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0170
============================================================


📊 Round 545 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2367, R²: 0.0188

📊 Round 545 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2367, R²: 0.0188

📊 Round 545 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2367, R²: 0.0188

============================================================
🔄 Round 551 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 551 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0190
   Val:   Loss=0.0755, RMSE=0.2747, R²=0.0346
============================================================


📊 Round 551 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2367, R²: 0.0188

📊 Round 551 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2367, R²: 0.0188

📊 Round 551 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2367, R²: 0.0188

============================================================
🔄 Round 559 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0680 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0680, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0680, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0680, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0680, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0680, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0680)

============================================================
📊 Round 559 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0267
   Val:   Loss=0.0680, RMSE=0.2608, R²=-0.0047
============================================================


📊 Round 559 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2367, R²: 0.0187

📊 Round 559 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2368, R²: 0.0187

============================================================
🔄 Round 564 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 564 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0195
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0301
============================================================


📊 Round 564 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2368, R²: 0.0186

📊 Round 564 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2368, R²: 0.0186

============================================================
🔄 Round 568 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 568 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0183
   Val:   Loss=0.0861, RMSE=0.2935, R²=0.0284
============================================================


📊 Round 568 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2368, R²: 0.0186

============================================================
🔄 Round 569 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 569 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0239
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0118
============================================================


📊 Round 569 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2368, R²: 0.0186

============================================================
🔄 Round 570 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 570 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=0.0286
   Val:   Loss=0.0848, RMSE=0.2911, R²=-0.0031
============================================================


📊 Round 570 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2368, R²: 0.0186

============================================================
🔄 Round 571 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 571 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0210
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0265
============================================================


📊 Round 571 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2368, R²: 0.0186

📊 Round 571 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2368, R²: 0.0186

============================================================
🔄 Round 574 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 574 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0210
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0224
============================================================


📊 Round 574 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2368, R²: 0.0186

❌ Client client_18 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_status:14, grpc_message:"Socket closed"}"
>
