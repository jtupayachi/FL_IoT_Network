[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34017434-3bf6-441f-ac8c-1b6503eb1228
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2391a5b6-2fdc-46c2-a16e-66eb24f0cf2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7eff090-e527-4cd7-b53e-672aefa06c4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4906fd4-8cd7-4822-8bfd-619901657394
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de54ca80-64ce-4c5a-953b-f1bf5b64db6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d64a0ff6-c10b-41d3-951e-d47161b14d1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d53452e6-df98-4367-aefc-ba28e471350f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8af81e6-4b54-4e17-a619-c98f63d57cb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84c5f415-125e-4a54-84e2-9f459b0711ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3215ceaf-ee55-423c-8224-65dc275759ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb90f277-dbbb-4b4c-bb73-fa5d37ff7b7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92e6fd24-1e04-4770-839f-35920758d37b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 929fda8b-2cab-4ad2-b884-e1cb974326f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70c79a4c-c757-402d-ad07-0e1b7e5bf3c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da27cff3-23e1-4b05-be26-be2ab1967483
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9bbb526-28e0-4e47-b991-c0fb0d0466ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a1ae92a-c447-434d-9373-a1142cabe93c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d84dea3c-a090-481b-aaac-6b286d8d6f6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea18960f-630f-4949-8b33-c8c209a26b6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f2c8186-2614-44a2-ad6e-1e855aed7c18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a09343cc-b585-4ba5-bee0-ba4af2b435a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2cf15e2a-09fa-48bc-ad27-e9becbbed084
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74f29127-885d-46e1-b995-87710e91eec9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae41416a-0273-4068-8856-c8f852563872
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c30bf04-1d5f-43b1-9b2f-c56d73bfae8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2440533b-f0a1-407a-9db5-6d0553d72274
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ac389df-16bd-4d54-ac5e-f332c76d8cef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eac5e420-d4d2-412a-8cea-577d1bc3a9c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94cc096b-9793-4312-9575-a3550d0960a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 612afcea-72e9-4935-9fea-ed428676e777
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 023571fd-4d39-44b0-a150-4b9cb0b19b3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ade7cae7-fb11-4053-a80d-34cf88664141
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8642634a-ab40-4252-af20-8ffcfdb0fbe3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a293030-f983-4f13-9966-a5de9fd59147
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82ececfc-29a3-46d2-ad5f-cc77ba89969e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ffd6e3e-d759-4cc0-8ae8-8ad62d096f47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa9e1526-3c4e-4ad9-a1a2-09ceb2c7840f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a273726-d188-418f-8333-5465884eca0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da934198-877e-45d4-a6ee-2698634054f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56373a99-6b4c-4ef9-8a38-0d1e88c87454
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3baa5ee6-425e-4d52-ac73-19650665da3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3c78d6f-68c5-40ca-bfac-2be71c79fd8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99c3c656-76fa-4a17-9ad3-a0fccba42ccb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 844c548e-1577-499b-9c15-241b9b1af4cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b02b8195-af59-4804-a7a9-66c530f00590
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14ce142f-f64a-4ed3-9353-2ddbdf008986
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60f9de17-d6f5-4244-98b5-89cba23f2234
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 076c9ae0-e8ab-470c-aa78-be1be97b038d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bf7b30e-7c8b-486a-9f77-ab4a3252057a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3cdf943-3790-4ff6-a683-4a6c4aa885dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2edd89c3-dbb5-4139-b6f5-8db39ee518bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50ca65fd-50ad-41c1-bdda-7c85fa026dce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b164927a-1e41-4c05-b0d0-f914ea146e8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 208153e8-a3f9-45e2-9bab-be22475e5913
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 363ee522-6dab-4a74-a1d1-b1c87fb026be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 590649c5-4639-4d1b-88ab-4eeb3788253f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86d3ac49-6dfa-4772-bb83-874dfa886ff2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba046986-f67b-4742-bd42-9a01d56b7536
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac48868a-8943-4a61-843e-60b0e7e6d651
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 926abe21-1391-4030-9843-ca8bbeb4639b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 305d719a-38d4-41c2-a440-cde4331319b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2449e9ee-bfef-4a98-806f-d6e9d7944ccc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9437182-cb8a-4196-8ebf-7aebadf249dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6aee3af-fce0-4b68-bbf1-0e4702020962
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4dcfbeda-128b-48eb-96c8-737fdd3f8889
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1db92231-8d31-483e-a6af-1d46b4aa7a06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fa71ae7-26da-4755-91e7-e6cc6e6fe304
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9e38994-0281-404e-988e-bfbd745e022d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dff4fc55-7b70-4fdb-8ff1-bca5bed219bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57148ef9-b2ee-419d-8c80-c50c4804078d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da95d33b-5270-4036-a0b1-a78bf0ab9579
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7660a148-ce1d-4cf9-8660-b4dae4b99b5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50c069c9-37c6-4b04-8536-8e790efb31be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e34ac4c-7f87-4c21-8c65-e159562eccf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6de8161c-ba03-4521-a971-fc86f76d61c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 883e7dbf-7071-44d4-be0e-6f9a609ed7aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54709c60-9459-49ae-bc85-7556ba522fbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2f1a583-0af0-4f9f-993f-8010d617e281
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19d461de-5f11-45cd-bde9-3db8b9b8836e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42c31c2f-397f-4d08-965a-f3ff299a56a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5874a89-2297-4e70-9696-0e8f8e4113ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 566224c2-215d-434c-bb2d-03d090ef8252
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aef4f543-d104-4c53-9c0a-1ac034f3f92f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0d5c88c-d791-4cfb-b242-64e68f6697c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cc3d450-0f17-4730-b97d-77162c3611e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1bad29e-f0c0-4007-807d-9d48033b0004
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51d57509-ae52-40d0-bef8-a4eb8a357ca5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d403d4a-9459-401a-89d6-971b263836b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f6ff321-d261-4ca9-a199-1ec236f4dd82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edffbf95-962f-42a3-8ffe-b53c276fa080
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message befcfebb-83c0-47dc-a705-4a7c901a3f99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b412f57d-99f8-483c-8494-2795376e9648
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f91b515-123b-4c8e-bf9b-26188ad5402f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38aeee19-a1b3-47ab-8d27-b93030b3761e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a20a1a1-1984-4eea-8eba-e6de966e152c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06c5dc41-f90f-473d-805a-cb8afc486457
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23ffac62-ec64-47a3-9ae3-45b88f7c9fc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce93f139-8043-43ef-a1be-316601ec1c3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da7c52d1-99d1-41e2-a212-45fc7ed62201
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 744bd0dd-56c7-4e5c-b632-ce5287a50c90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f892dbd7-63b8-4743-bb0b-b69ce6c6f6c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9a44e9b-e66d-4088-b012-6ae3bf46e1ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f684c617-563b-470f-a734-15f310bb007a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8de99448-9818-472f-aabc-900471fba1bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8200ed7c-59aa-4920-b9dc-989a9ed62ee5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27607383-09b8-4231-92d6-b13285050296
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef85a0d1-cf5c-46f3-a13f-b18209c6f150
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a574e09d-8285-4963-b589-2b596c0b1ef9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49aa5e8d-82b0-4ecb-b3a4-aff7c2da48c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 174765fd-2827-40af-9636-0791f2ef352d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1fee132-135e-448f-84ee-0b332b22098a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3266ed87-c2fd-48f5-a247-b563f67c8cab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a8995a0-c118-4b4e-80fd-d9d30387007b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d28c6597-ce6f-4308-aca0-e952017895d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b00d208-79f8-424d-b185-62f87e7f7384
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fecb0e6-9fb6-4278-9caf-ddafcb7ef8f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d04fcfb8-28d5-41e6-8c5e-4ddcde02d56e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 378d4c73-f878-4cd0-b78f-eadbcb8e207f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d753621-067b-4038-ae37-0b384d7f8780
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02cc1f39-b880-4b6f-ab05-3d226e3f5ed6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9cd51156-b404-4604-9a5f-5520653d7a16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4faeec77-5961-4088-9b92-e8f05ef1f7cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3720917-1dd7-4b62-9d38-b321c2a1d679
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48b8499c-edb4-485d-b12b-609f338600a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c076c5f-6a3d-4e57-a122-9c10c7e48740
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7d65389-c1fc-443e-bd94-d5d051e6ccb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67841ac0-5710-47be-a9d6-fa7d95260410
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ec7ae10-8772-4623-bf27-64cc85b5945e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87975317-c625-4ec9-9f7f-0410f6c3f527
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa5cdd39-d776-4655-8407-53a4932577e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7b59055-0de1-4d60-b8ae-8c8d8fa7b329
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b99b4c3d-c688-4666-85fc-7664e7833c87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a24abb60-2a3d-43fb-99f0-2f461ec6f78a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0de9c7c-fa87-4c1a-9fec-fab6f3b80cad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1409814d-4196-4e67-ae3e-a18d3795b6f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ad0d6d1-ae92-4b09-926e-7d9badc3758d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 782ae2b3-8969-4f7a-943e-5a77d770498c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cdd98b73-7aca-459a-89d4-6ed2ee50af78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94ef738d-2a06-4d2f-a13c-0ebc88fccf46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07e33597-afdb-43d9-ba41-321abf3f9bc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a57721fd-3728-4a89-bb88-acfe175682b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28008ba6-2329-46fc-b597-20426421c2bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76469265-ea15-4ea3-8ea5-1153c4fb64ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 396c53ad-67b8-4ee6-a199-3178e722cbed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8811c63-e965-4d7f-8eed-894de035f4dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c588b4e-b191-4a4a-a347-63ebd1c0505d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00a1289b-274f-425d-bea1-120cc7cf16d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84bc81e2-bf85-42f9-82dd-781e1e45616a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b569982d-52d8-4632-8982-625fff1b73ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8dd3145-6476-480a-8fb6-3d76032137a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2e6edd6-f54a-4115-a158-ee004b8cd2d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f8ac29a-147c-4d1f-92cb-b7c292a25ef0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8862b456-a145-4b3f-a4d8-5da22d4c8183
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ff28f74-f855-4252-941c-749df52de5d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e735f557-8d89-475c-b29d-03ffdfd2af15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5051d9c-6ec6-4444-b30b-0c4922b8feea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fed2e73-eb16-4cab-b741-f7ac58494ae0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ba602e8-8d55-4abe-bc30-c1cfef98ced5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f5d904b-b6ed-46fa-b6d9-f2cf08cb035c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d45a4cfc-fc6e-4138-9a29-571cfb4afb66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c989de5-4cf4-40aa-ba67-ef1b8c0aa5bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f0d04e8-d848-409d-9180-aa7c71c66fbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4629b355-b39f-4b8b-a58e-64fe7706cd29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a11d8775-6ffb-43bd-82b1-adff3def1ac8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cbb92f4-646d-4c11-a076-d14cd8df84e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b770ccd1-abe5-4418-9484-101111051313
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19a9defb-74a4-4a6e-9c62-a7f0aba74b56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30ac1fb9-2f39-46eb-a951-1c5bc9dccd7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d616183c-fcef-4d8f-ad98-5ae599149112
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5630ecc4-8cc5-4d15-8ad0-26ab4641e226
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 744c2c99-7c95-4e62-a030-e1b164b5f7ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4fd05fc-9d46-4d47-9831-aa2825d70348
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5374cb2d-ff2d-4905-9d85-e000c9248a67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd43d472-68fd-432d-be36-f0f3bd045960
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02314d26-c163-4c6a-bfb9-4f42019476a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 349def93-f706-40f1-b603-95732d12986e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1378db76-90ee-47b2-aa9f-8d41603f6cb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45a74222-e3f5-4991-ace9-a233649e4d43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e49518be-20e5-4c65-954a-9c1f0686e240
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3127f9ec-90d2-4c29-a45b-47d9e2ef29f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae1acce3-7a7b-4ae4-9e64-caa39c7a7a4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca735905-b37c-4998-bc45-da1da8a03c29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcc74314-f55f-4a6f-979e-22729b459443
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7af336e8-7613-430b-a075-b017e92e9086
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fb18532-c398-4a95-9ef7-a7134338523e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fb7cb88-c3f7-41bd-a090-5e799afd2dec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a38f947-b940-4b58-974c-1e3d951d1914
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b593d07f-7cb6-4977-82d2-20eb8015714f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5e137bf-713d-402b-82e9-72ce2dd72a41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e8fe563-380e-4758-aeb0-1f5f3716ff7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e501be6d-c09a-4ef8-983c-6bcfc25a8047
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b4e69b2-69bf-4121-be7c-7a9c4c42cf6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbe3db49-bb37-403a-8090-6a05af6c48ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15fed3b3-1bda-4b76-970b-886c637f8103
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 192e1958-c9bf-416e-9ab4-cc8cbdf27f03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b267039e-497c-4eb4-a3a9-60d22faa277f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af5b9688-eb3d-41dc-b3e5-b31f00d89211
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cbf27fb-08e9-4668-a916-c9dd4414cda4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ca70a81-9d9b-45a4-a314-fe29510ccf98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c85822d-681b-4e19-84de-42b56f1ead42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fee8614-40ff-402b-8747-31f795fce9e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3973cf84-ad3c-4529-8516-51fd5b041198
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e80a01c5-c0f4-4d7e-a1f2-b5f26459f4ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 451d06d2-00ba-46fe-881e-6711146d6b6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42c5c598-58e1-46e5-a056-2e80b1ac656c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32da9bae-c559-4eb5-8209-55800cc7f410
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28addb70-6c29-41d4-8fff-51dc42b9f1d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e919822-b775-41a4-8207-8d0888f06882
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e25bf41f-d2aa-4d1a-8f96-adeac936239a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f8b13e5-72ea-4b21-b04b-322a2492f803
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b32e347b-f3a7-44a8-a610-1352699901bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cb5f2ef-519e-460a-8ef5-7a1ee48393c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 895360c8-3512-4254-903e-4bef163c1f82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94b51e65-8415-464f-a5b3-2b38c34f69b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c16a9218-c0c6-406a-b3ef-9619f83b27f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45c48921-787e-4599-8160-063ff9914f47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f97f9a28-05d1-42ea-834f-f6e9156bd321
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f73786a-a116-4935-87d7-34570013dd82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7277d44c-cd57-43bb-9f63-ca74dc651b0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 922c9427-7931-4b7f-9d8c-7506b07aa0fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e75f03b6-3e7d-415e-bcf7-8cb76b5cf440
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c83cff3-5b08-485a-9bb5-0c46e110e90b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 961e4dcb-ec1a-4e53-a334-e6e0ed01dc19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea0000cc-3336-4ce5-8109-2378de510f7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b3f01a8-c5c6-47cb-bd40-ea8e009b90b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7cf3348f-8cc8-4dd7-8dd5-f310c467de44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97d3d71b-b844-43a5-9393-d08ee365028f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5da57ff-76a7-49c2-bf85-b1bc38bc2307
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4da94c40-e964-4d48-815f-68bb35964de8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aec7f2d3-7824-4305-ad72-b5abd0f6eae8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cce55f1-e084-41af-a758-cd97dfbecbf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fea3de48-ccba-4fec-ae4a-f28621859b4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7efed4eb-f335-45de-b778-8f8cacc09406
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f61af44a-52c0-47ef-bc25-f537a345f5b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2eb7e0ae-ef24-40a8-af87-e9ec15705670
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bf449f9-a497-471d-9f93-c4911f901bd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 203ebffc-7812-4644-a24a-03af1bf81c82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44a46e58-5a06-40b4-863f-c17ccd9e6a06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee6abb51-6fc0-4f68-9aaa-bc33e5fa3eab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 885d649a-d2ab-4f4c-a7a2-dba88e4ab47b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e5943b0-35dd-40fc-845a-28b6e0348794
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17970d5a-071c-40a1-8b10-30b836defd6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77d0d038-0cbc-4039-9a8f-0941edb1b685
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ac3b714-f8d3-49a5-8f0e-f18b7055cdb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f086a1e7-e253-41c0-b009-64a386707f2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f495cda-8a10-46d0-a414-612e07855614
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d39de65d-6318-4f40-ae91-6695b1ac567d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60733088-f497-41cd-808d-a05a6f3ef0d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 912dc15c-8227-4896-8adf-c12f856ad2d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b4878e8-fe65-42da-8752-6d1073faa136
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be864204-dec7-4c07-8498-235fd1f4c27a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8382c069-f31f-4795-b979-6ca9efebd43d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0341f67-8750-42ad-9a12-06f06c11a3c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c926c165-fa7f-4c9a-a79b-dee3ca85dcea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e095d3f4-ff88-4cb9-8707-913af7bb1ff6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84ec5236-1fde-4079-889d-f3f33e2977ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00ea80d4-bec6-4fd4-bbf5-a5dc33129f5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a119f528-af02-42fc-b6fa-606e44617c91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30e1d21e-44a3-4b0f-a5b4-8224889f3bde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aab7c8b8-3ff4-440d-b621-57d41193d4dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ec04001-645e-4a9c-85b8-6ec1ea095b19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5723d1e3-5b33-4da9-ada6-a8bb77cb2fce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ab7463e-772a-478e-b679-f64e5e8a478b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8818d269-d7b3-4150-91b0-ae0ded9580f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7008eb5-bb32-4a6c-b7aa-ac2a0c0b6702
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53c7864e-3271-477c-ac32-ff1851a6d370
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fc2572a-f6a6-40c2-bd11-ba0494f38aee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af616d98-4a5c-4d21-9cb7-737303d18f89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4250ac5-1bd9-45c7-8533-29bf64c182e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2c214d9-7064-48b4-a95b-e9d5171bddd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1eb27ccf-94f4-4637-9c63-32841256cc17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a09e9c90-5255-47f0-a3eb-7dc026192dfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a226cb9-8f7e-4062-aaca-f4f6231deb75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4c5e0a1-c3af-42d0-9adb-70cc12793cfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04501a8c-c4b9-41f3-9ce2-50076e09fc78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9cd6c8e-4972-46c8-8974-3e71e71fe787
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9aa5f9d-2ad6-4438-bddd-6cdecb152404
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2d8fc65-08ed-464c-86f7-5c4c581d561c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ee582a5-d7ce-452f-a819-79b60037c077
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9764f1e-eeba-4c4a-b055-846cc53ddd99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6882c656-850a-46d2-ae35-83e74aa9a702
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7456f709-7471-4a89-8911-722b0958016b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45668f1b-0fed-444b-9c15-848049732700
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7755d645-faa3-4e87-b04a-826ed41500f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a348b0de-2086-4aee-b2e6-16c4fa2383c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1928b770-5b0b-463f-a20e-3b0cb38b6185
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1371a555-66cc-494c-bf56-4f8b907cbda2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 259560e7-bc46-4306-a625-04cd2406307c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d428430-ffca-4532-b0bb-85e553ac89fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3aba8af0-d012-4716-9789-e1dd57b4b5e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 791f9e70-7206-4561-81f9-8cdf1c6c5e2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47afa5e0-c147-44ea-aa61-c93d1e85ec9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d32acfa3-b97a-444a-885c-a5382c8c87f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0de4e551-2265-4ec1-847e-aba0ee08d15e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7357252f-ea5a-4776-90ea-6f58781d1250
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a1cc0b0-d850-4702-bc30-b207f0b4c80a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28c91398-ad0f-480a-ac18-bedff137866b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 808aa83d-dd72-48a3-bb14-f43aa02d2901
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a487cd6e-93e2-4488-b8a4-a34119173df2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c6cb47d-3655-4525-811d-1eebeec424d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f5c7c19-0aae-4546-b0b1-0a9441838777
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53951fdf-4e38-4362-a363-4fd31a21e398
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c1ec515-d8e5-4912-ba18-0456c1423394
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e07b121d-80c3-4f38-876c-60b043e92116
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c21db484-e0f8-4f66-a380-8f4208626f59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f45cad4a-6600-42ea-962d-409f06cb65b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eecd9666-4ba4-49e7-8c37-6a9460b5dcb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45b5ad29-54cc-4ef3-9292-e347505a871e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e9711b7-12d2-414d-a9e6-fa0a02e6a25b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc904e18-9b91-476f-ac4b-5d61da805f23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14943fc2-96b7-40e3-b5e4-917abb0a102e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 940192c1-0e20-4cfd-8d86-ed9633d3bb13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85aca022-806f-4769-8fc3-850de072976a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e9c0815-5796-420e-9e7f-bcf44dd2b553
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ef0688b-a4ca-4783-b248-f0b3521c2391
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f52f7b2-0002-427d-8baf-7bd3cdf9647c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37717539-6fb1-4f88-9497-1ff111cd324d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b45b4223-8f0f-493a-b8c6-49ed4b62277e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12db7136-cb51-45e3-a90d-1d0844f5850b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e429b36-9cf2-43ef-ad9b-b4dd25c36548
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d22006ef-3572-45d5-8fd2-2e7fc362ffe2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6137db7-627d-4dd2-9a54-4bbaf708158a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42d2c12d-9392-475b-9b24-4395a3ae56bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1dedb0df-8945-4c78-90dd-fc771b1da60a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d4a55b6-7870-4a12-bed0-646db5cfc97a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c5d51af-6c63-45cf-8305-58e4b5da8cda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88cfa506-7668-4dab-9607-9a2b2d6b1e0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8098a86d-353b-4756-af86-2adc39d351c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c439cb91-6013-4796-86d2-f8b3ffdf40a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 536a54c2-aad7-479a-bf19-1f000f099d7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f067eb5d-cd10-43d3-a0d4-aa516d4182ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64a8e82f-48f4-4297-bcca-d54a5e2c4ac2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92026171-f790-4a3d-aaf1-1c6ca6173b36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e65b476e-e9f5-4885-b63d-33eb50f84aa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 006f4bc4-1509-4b82-8e59-6079e6916ab2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db4d2025-62a4-423f-a27c-08103d60e731
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de0f6ba5-aa2d-4ed7-ad4e-ecf4d5ea84bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98b43788-e46c-405a-9823-3c54398d8652
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5dd43518-efec-4513-8803-667af830f764
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bbfde77-f4a2-49e2-954d-a81e1d821047
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11c28cf0-3670-4b3d-9bd5-5562182fc924
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30947643-e82a-478f-a718-dfd1129c3d3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 536034be-fe5b-463e-9436-ae2023a24f2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce7fa954-4e12-47b4-9d0a-3a6ec0ad0933
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03d0af12-32fa-43b6-aa00-07ff8211adf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f100817-d62c-45f4-aa98-a78966f3acda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 388454b6-3ef5-414a-a569-0abe9bc672d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e261ebe9-8817-4eac-8a97-3073ac3ee8e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a7e62dc-5ce3-4720-ba5a-9b773716dbf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60849c76-dc6a-46f4-91b9-7c56d6dbd964
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7ac139b-0605-461d-a43b-c637aa4b4548
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ab4255a-02aa-466a-abe8-932ba5b79b50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9220365a-1ba6-4dd2-8f92-11c39b07da5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0402ee5-b085-4d8b-b4b4-8aab58d9df2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7b3715c-188c-40e1-843b-1c06c926a677
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e79b307d-af6e-4010-a7dc-645ad8b13105
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30f80546-12d8-4643-9db7-4f8842f194c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9347169-f8cb-4e2e-9e21-76f9eca97a88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef19c8a9-59f3-4d23-8c26-fe9b9234e3fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 296e07d5-d05d-4c06-a4b6-613d3c26ea78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 321d9775-f6d0-4dfd-a309-0f7064f51140
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 399d57a9-82a5-4c10-bba8-5d1b68a97c26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40d0e243-6a73-40c8-a204-e9e340748748
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0527049-5c6c-4e6e-80fc-a685c6e9797a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12e086d6-8212-4c59-b83f-c39f7e4750b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cde60998-bdb5-43d0-bc2b-9e79e948bb6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a272928d-c85a-4919-80b0-58b01c00609d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddf5b557-2fc9-49af-9643-e4df3b09b35e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c57c58ba-ccb4-4b55-924f-bc32e80d6e08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 757665ae-3c27-4734-9ad9-d3686271ca47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7202f95-9ccf-4067-a8a2-cc4516f49bcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a78f914f-90da-4ed2-b9ea-d8d7a4df746c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 507d281e-c3b1-4a2a-a40b-d29fbb6007cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 344cda99-7568-472f-a470-70e3a909b5a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ea0ff9a-cb87-499f-8ec8-7badb498f255
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64e9b105-9d17-4d08-8078-3b10caf253ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ab7f8e5-780e-4f8c-8af7-e8affe8d0bfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f36a02c-d61a-434e-b28f-54281195fe57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84f00b0f-becd-4e97-a82a-5b2be783aa89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2a725ac-2b64-4073-a9fe-eccd097037f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da09cbbb-afa0-482b-b16c-4159d52e109c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a409dad3-e5a6-403f-94a4-8740450a1abc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3655659-c3e6-4424-800c-3a8c14e2ef0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e72a320b-0702-4781-8c10-d1638c5680ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78e8aecf-6902-4d6d-8cff-8a6ed92f5786
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5d9d1b1-f994-42b2-ba78-ab0418692af4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c689cf1-5d28-4bdd-bea4-1f63f3363859
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca0e3d2f-acbc-4126-87c3-211ed64bc22c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 973b3c78-ee79-4701-86db-c75ad23df29c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a046acd-298c-4507-9387-5f1047ebc18b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c456c2d-67de-475d-8253-3e308ac25eba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3be60dc-e9c0-4d07-a31d-895c6c931373
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a15fd1c-3989-462b-a352-8abd9a5db960
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80edf56a-c784-4649-880e-2df70c91981c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae9ee39a-123f-4599-a335-ab38eac8c8e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b22c81cc-8659-48fc-a725-6c7c334bb7c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bed3bf25-450a-4138-8809-599a5c31466d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 521810ce-fba9-4d6c-bed9-d7c45f620ccc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23ba3a59-d657-4832-9846-942fe9b65a44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d71bcc82-4cda-42e5-a897-dfcafbbd3732
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07047ae7-3be9-41c1-bb28-e92a7f7bb849
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58571f35-453d-43c8-a86d-929b16f75045
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 444dff47-60e6-4a0d-95aa-81213cb267c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5441ae3-0eca-48f6-bab8-7d18c0ecab4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6dd0f363-b78d-43b4-b5ec-e74dc2429359
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff5fae0d-0657-4fe8-bdad-6df5fdef19b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6772bd09-4f41-4209-b304-9547690d1614
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5de9d68f-3fa8-4873-8cde-1dff20e446c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac719b1d-fa52-48ba-a101-57a68475ca7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fe9ea99-a87d-4cfa-b8ef-f88727861065
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ef85c6d-a211-4673-bb7e-3d8f4462d4fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e422a47-6ab4-44dd-a54f-8b9f4b8ec6c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57e25964-ae8f-4c2b-b21c-004c45565049
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08e3a07b-6ad3-4197-863e-62536fa7db29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57764895-4cc3-415d-b456-bc16217a2200
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e26e7762-9a89-4b64-b653-7a5cee9b7ab6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fae6309-d420-45ab-b7b1-600295709149
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d8001cf-59d8-4e98-97d9-15640cea44a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f5d4b5b-4683-4629-818d-d373e885a1a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd1c97ab-defe-4f90-88d9-ead3d0780269
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd6fdd82-3bc4-4a07-a58e-571cf933f03a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa72232c-1520-4c59-bc0f-509b19cbd315
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 436b669a-4144-434d-9c97-045abac94dbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4055c89f-9be6-4593-8a16-bd8477d6df2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53e1a78f-ff24-4c60-8307-910a35071312
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e8a7d1f-ebff-4c1e-8aef-90ba137964f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dae3b4da-a510-4050-af25-c43dd8b37583
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a3136d1-4ff2-4f5a-b625-862f303a4628
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ba041d9-dcef-4d37-a134-c07c8a8f8b35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef4bf5ae-f8cb-4990-87bb-2bccc753c0bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f389fc9-a21e-4de3-9746-b1212290f79d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 678df2a8-c8b3-4a45-9e1d-eb3b78d63a5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6dc296b-d095-4520-8776-84b76f5f4fa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d474a1a1-f5f2-45d7-b593-5cc2ac044917
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5e16d0a-12d2-4871-864d-29fcdab7efac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3c4591d-61f9-4a49-b01c-99fbd5c7126d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bafe1cfc-7031-40b0-84e6-16f51ca7f745
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2c0f696-81ca-4a37-bba4-1d7e6f2db538
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5acbbcf-b829-4117-b996-771c19b5d9f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 423afb85-753a-46f1-b9de-7e0c9b799573
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4582af0a-263c-4ee6-9701-ee087c5f600d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e94342f-1cf1-451e-9e33-4e5e6ef8af68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6cc70aa-b61c-4cec-a302-d1f86ecede98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c03f11d-6143-4eaf-8c4d-52003b78acb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a6a560b-c5fe-4138-bee4-d229f8397e32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc878a27-6c98-47da-87f5-d114580dbde8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9668adaa-8c0d-42ac-b22c-5adc9bc231f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a86e5934-ad2c-45a0-a23c-595e730e170d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d622d93e-f2a8-42f3-905a-80f9a57db3cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae83722c-3984-4a78-b227-9b74495a22d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 837c6a3e-eb1e-408d-81ec-e9ca8019001b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6dca9b6-4eca-4c6d-a157-6a2fd71c5356
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92bd2877-be33-48f6-8393-be9332e8fda5
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_1
Server: localhost:8688
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_1
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_1/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_1/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_1/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_1/test_labels.txt

📊 Raw data loaded:
   Train: X=(6065, 24), y=(6065,)
   Test:  X=(1517, 24), y=(1517,)

⚠️  Limiting training data: 6065 → 800 samples
⚠️  Limiting test data: 1517 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_1 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 1 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1988, val=0.0879 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0878, val=0.0868 (↓), lr=0.001000
   • Epoch   3/100: train=0.0840, val=0.0878, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0851, val=0.0890, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0851, val=0.0886, patience=3/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0831, val=0.0871, patience=9/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 1 Summary - Client client_1
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0001
   Val:   Loss=0.0868, RMSE=0.2946, R²=0.0037
============================================================


============================================================
🔄 Round 3 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1888, val=0.0801 (↓), lr=0.000250
   • Epoch   2/100: train=0.0895, val=0.0819, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0866, val=0.0804, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0856, val=0.0803, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0854, val=0.0803, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0852, val=0.0804, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 3 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0021
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0015
============================================================


============================================================
🔄 Round 4 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1302, val=0.1187 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.0921, val=0.0921 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.0837, val=0.0876 (↓), lr=0.000063
   • Epoch   4/100: train=0.0833, val=0.0871, patience=1/15, lr=0.000063
   • Epoch   5/100: train=0.0833, val=0.0872, patience=2/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0831, val=0.0872, patience=8/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 4 Summary - Client client_1
   Epochs: 18/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0038
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0087
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.1018, RMSE: 0.3190, MAE: 0.2666, R²: -0.2574

============================================================
🔄 Round 5 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1021, val=0.0913 (↓), lr=0.000016
   ✓ Epoch   2/100: train=0.0988, val=0.0881 (↓), lr=0.000016
   ✓ Epoch   3/100: train=0.0959, val=0.0856 (↓), lr=0.000016
   ✓ Epoch   4/100: train=0.0936, val=0.0838 (↓), lr=0.000016
   📉 Epoch 5: LR reduced 0.000016 → 0.000008
   ✓ Epoch   5/100: train=0.0920, val=0.0824 (↓), lr=0.000008
   • Epoch  11/100: train=0.0888, val=0.0799, patience=1/15, lr=0.000008
   • Epoch  21/100: train=0.0869, val=0.0783, patience=2/15, lr=0.000008
   • Epoch  31/100: train=0.0862, val=0.0778, patience=5/15, lr=0.000008
   • Epoch  41/100: train=0.0860, val=0.0777, patience=15/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 5 Summary - Client client_1
   Epochs: 41/100 (early stopped)
   LR: 0.000016 → 0.000008 (1 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0003
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0038
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.1096, RMSE: 0.3311, MAE: 0.2747, R²: -0.3546

============================================================
🔄 Round 9 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0921, val=0.0835 (↓), lr=0.000008
   • Epoch   2/100: train=0.0913, val=0.0831, patience=1/15, lr=0.000008
   ✓ Epoch   3/100: train=0.0905, val=0.0827 (↓), lr=0.000008
   • Epoch   4/100: train=0.0898, val=0.0824, patience=1/15, lr=0.000008
   📉 Epoch 5: LR reduced 0.000008 → 0.000004
   ✓ Epoch   5/100: train=0.0893, val=0.0821 (↓), lr=0.000004
   ✓ Epoch  11/100: train=0.0879, val=0.0816 (↓), lr=0.000004
   📉 Epoch 13: LR reduced 0.000004 → 0.000002
   📉 Epoch 21: LR reduced 0.000002 → 0.000001
   • Epoch  21/100: train=0.0870, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 9 Summary - Client client_1
   Epochs: 26/100 (early stopped)
   LR: 0.000008 → 0.000001 (3 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=-0.0326
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0070
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2425, R²: 0.0143

============================================================
🔄 Round 11 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 11 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0106
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0216
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2458, R²: -0.0191

============================================================
🔄 Round 13 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0881, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0858, val=0.0878, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 13 Summary - Client client_1
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=-0.0243
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0162
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2452, R²: -0.0139

============================================================
🔄 Round 14 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 14 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2897, R²=-0.0294
   Val:   Loss=0.0919, RMSE=0.3032, R²=0.0356
============================================================


============================================================
🔄 Round 15 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 15 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0024
   Val:   Loss=0.0897, RMSE=0.2995, R²=0.0196
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2415, R²: 0.0231

📊 Round 15 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2409, R²: 0.0276

📊 Round 15 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2406, R²: 0.0292

📊 Round 15 Test Metrics:
   Loss: 0.0785, RMSE: 0.2803, MAE: 0.2404, R²: 0.0297

============================================================
🔄 Round 20 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 20 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0130
   Val:   Loss=0.0722, RMSE=0.2688, R²=-0.0117
============================================================


============================================================
🔄 Round 21 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 21 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0084
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0137
============================================================


============================================================
🔄 Round 23 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 23 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0053
   Val:   Loss=0.0754, RMSE=0.2745, R²=0.0348
============================================================


============================================================
🔄 Round 26 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 26 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0110
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0045
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2404, R²: 0.0303

============================================================
🔄 Round 27 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 27 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=0.0072
   Val:   Loss=0.0860, RMSE=0.2932, R²=0.0288
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2404, R²: 0.0304

============================================================
🔄 Round 29 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 29 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0140
   Val:   Loss=0.0937, RMSE=0.3061, R²=-0.0008
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2404, R²: 0.0305

============================================================
🔄 Round 33 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 33 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0093
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0291
============================================================


============================================================
🔄 Round 35 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 35 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0160
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0016
============================================================


============================================================
🔄 Round 36 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 36 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0213
   Val:   Loss=0.0858, RMSE=0.2928, R²=-0.0158
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2404, R²: 0.0304

============================================================
🔄 Round 40 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 40 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=0.0146
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0093
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2405, R²: 0.0302

============================================================
🔄 Round 45 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 45 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0160
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0086
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2405, R²: 0.0301

📊 Round 45 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2405, R²: 0.0300

📊 Round 45 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2405, R²: 0.0299

============================================================
🔄 Round 51 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 51 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0175
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0017
============================================================


============================================================
🔄 Round 55 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 55 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0138
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0199
============================================================


============================================================
🔄 Round 56 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 56 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0104
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0276
============================================================


============================================================
🔄 Round 57 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 57 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0073
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0474
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0785, RMSE: 0.2803, MAE: 0.2405, R²: 0.0297

============================================================
🔄 Round 60 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 60 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0115
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.0246
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2406, R²: 0.0295

============================================================
🔄 Round 62 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 62 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0186
   Val:   Loss=0.0873, RMSE=0.2954, R²=0.0008
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2406, R²: 0.0294

============================================================
🔄 Round 65 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 65 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0124
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0234
============================================================


============================================================
🔄 Round 67 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 67 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0198
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0046
============================================================


============================================================
🔄 Round 69 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 69 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0204
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0062
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2406, R²: 0.0292

============================================================
🔄 Round 73 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 73 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0145
   Val:   Loss=0.0722, RMSE=0.2687, R²=0.0123
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2406, R²: 0.0291

============================================================
🔄 Round 74 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 74 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0180
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0056
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2406, R²: 0.0291

📊 Round 74 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2406, R²: 0.0292

============================================================
🔄 Round 77 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 77 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0157
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0125
============================================================


============================================================
🔄 Round 79 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 79 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0181
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0029
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2406, R²: 0.0292

📊 Round 79 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2406, R²: 0.0292

📊 Round 79 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2406, R²: 0.0292

============================================================
🔄 Round 82 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 82 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0222
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0177
============================================================


============================================================
🔄 Round 84 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 84 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0190
   Val:   Loss=0.0811, RMSE=0.2847, R²=0.0020
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2406, R²: 0.0292

============================================================
🔄 Round 87 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 87 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0169
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0111
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2406, R²: 0.0292

============================================================
🔄 Round 89 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 89 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0229
   Val:   Loss=0.0793, RMSE=0.2815, R²=-0.0172
============================================================


============================================================
🔄 Round 90 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 90 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0188
   Val:   Loss=0.0918, RMSE=0.3030, R²=0.0049
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2406, R²: 0.0292

============================================================
🔄 Round 92 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 92 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0098
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0367
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2406, R²: 0.0291

============================================================
🔄 Round 94 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 94 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0149
   Val:   Loss=0.0755, RMSE=0.2747, R²=0.0186
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2406, R²: 0.0291

============================================================
🔄 Round 95 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 95 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0119
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0088
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2406, R²: 0.0290

📊 Round 95 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2406, R²: 0.0290

📊 Round 95 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2406, R²: 0.0290

📊 Round 95 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2406, R²: 0.0290

============================================================
🔄 Round 100 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 100 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0082
   Val:   Loss=0.0888, RMSE=0.2980, R²=0.0419
============================================================


============================================================
🔄 Round 101 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 101 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0080
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0414
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2406, R²: 0.0290

============================================================
🔄 Round 102 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 102 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0084
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0452
============================================================


============================================================
🔄 Round 103 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 103 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0125
   Val:   Loss=0.0868, RMSE=0.2947, R²=0.0262
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2406, R²: 0.0289

============================================================
🔄 Round 105 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 105 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0108
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0023
============================================================


============================================================
🔄 Round 106 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 106 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0245
   Val:   Loss=0.0878, RMSE=0.2964, R²=-0.0180
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2406, R²: 0.0289

============================================================
🔄 Round 107 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 107 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0207
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0078
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2406, R²: 0.0289

📊 Round 107 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2406, R²: 0.0289

============================================================
🔄 Round 110 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 110 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0179
   Val:   Loss=0.0840, RMSE=0.2899, R²=0.0062
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2406, R²: 0.0289

============================================================
🔄 Round 111 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 111 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0070
   Val:   Loss=0.0841, RMSE=0.2899, R²=0.0497
============================================================


============================================================
🔄 Round 114 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 114 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0167
   Val:   Loss=0.0896, RMSE=0.2993, R²=0.0122
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2406, R²: 0.0290

============================================================
🔄 Round 118 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 118 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0188
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0031
============================================================


============================================================
🔄 Round 119 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 119 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0135
   Val:   Loss=0.0852, RMSE=0.2918, R²=0.0187
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2406, R²: 0.0289

============================================================
🔄 Round 120 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 120 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0138
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0243
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2406, R²: 0.0289

============================================================
🔄 Round 121 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 121 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0131
   Val:   Loss=0.0881, RMSE=0.2968, R²=0.0260
============================================================


============================================================
🔄 Round 122 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 122 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0153
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0154
============================================================


============================================================
🔄 Round 123 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 123 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0100
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0360
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2406, R²: 0.0290

============================================================
🔄 Round 127 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 127 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=0.0167
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0064
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2406, R²: 0.0290

📊 Round 127 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2406, R²: 0.0290

📊 Round 127 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2406, R²: 0.0290

============================================================
🔄 Round 130 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0935 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0935, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0935, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 130 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0236
   Val:   Loss=0.0935, RMSE=0.3058, R²=-0.0215
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2406, R²: 0.0290

============================================================
🔄 Round 131 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 131 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0194
   Val:   Loss=0.0811, RMSE=0.2847, R²=0.0016
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2406, R²: 0.0290

============================================================
🔄 Round 133 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 133 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0196
   Val:   Loss=0.0936, RMSE=0.3059, R²=0.0035
============================================================


============================================================
🔄 Round 136 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 136 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0171
   Val:   Loss=0.0889, RMSE=0.2981, R²=0.0113
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2406, R²: 0.0291

============================================================
🔄 Round 137 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 137 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0108
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0361
============================================================


============================================================
🔄 Round 138 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 138 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0203
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0007
============================================================


============================================================
🔄 Round 139 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 139 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0138
   Val:   Loss=0.0720, RMSE=0.2684, R²=0.0235
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2406, R²: 0.0291

============================================================
🔄 Round 140 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 140 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0148
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0078
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2406, R²: 0.0291

============================================================
🔄 Round 142 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0952 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0952, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0952, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0952, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0952, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0952, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0952)

============================================================
📊 Round 142 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0155
   Val:   Loss=0.0952, RMSE=0.3086, R²=0.0159
============================================================


============================================================
🔄 Round 143 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 143 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0207
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0023
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2406, R²: 0.0292

📊 Round 143 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2406, R²: 0.0292

============================================================
🔄 Round 146 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 146 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0139
   Val:   Loss=0.0910, RMSE=0.3017, R²=0.0179
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2406, R²: 0.0292

📊 Round 146 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2405, R²: 0.0293

📊 Round 146 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2405, R²: 0.0293

============================================================
🔄 Round 152 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 152 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0119
   Val:   Loss=0.0811, RMSE=0.2847, R²=0.0226
============================================================


============================================================
🔄 Round 154 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 154 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0174
   Val:   Loss=0.0739, RMSE=0.2719, R²=0.0095
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2405, R²: 0.0295

============================================================
🔄 Round 156 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 156 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0207
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0033
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2405, R²: 0.0295

============================================================
🔄 Round 157 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 157 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0252
   Val:   Loss=0.0919, RMSE=0.3032, R²=-0.0168
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2405, R²: 0.0295

📊 Round 157 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2405, R²: 0.0295

============================================================
🔄 Round 162 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 162 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0095
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0446
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2405, R²: 0.0296

============================================================
🔄 Round 166 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 166 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0218
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0138
============================================================


============================================================
🔄 Round 167 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 167 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0152
   Val:   Loss=0.0895, RMSE=0.2991, R²=0.0190
============================================================


============================================================
🔄 Round 168 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 168 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0164
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0154
============================================================


============================================================
🔄 Round 171 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 171 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0175
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0116
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2405, R²: 0.0295

============================================================
🔄 Round 175 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 175 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0211
   Val:   Loss=0.0794, RMSE=0.2817, R²=-0.0052
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2405, R²: 0.0295

============================================================
🔄 Round 176 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 176 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0109
   Val:   Loss=0.0826, RMSE=0.2875, R²=0.0374
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2405, R²: 0.0295

============================================================
🔄 Round 178 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 178 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0178
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0030
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2405, R²: 0.0296

============================================================
🔄 Round 180 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 180 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0133
   Val:   Loss=0.0844, RMSE=0.2906, R²=0.0280
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2405, R²: 0.0296

📊 Round 180 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2405, R²: 0.0296

============================================================
🔄 Round 183 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 183 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0164
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0158
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2405, R²: 0.0296

📊 Round 183 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2405, R²: 0.0296

============================================================
🔄 Round 187 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0712 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 187 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=0.0203
   Val:   Loss=0.0712, RMSE=0.2668, R²=-0.0038
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2405, R²: 0.0296

============================================================
🔄 Round 188 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 188 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0189
   Val:   Loss=0.0888, RMSE=0.2981, R²=0.0048
============================================================


============================================================
🔄 Round 189 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 189 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0193
   Val:   Loss=0.0909, RMSE=0.3014, R²=0.0056
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2405, R²: 0.0296

📊 Round 189 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2405, R²: 0.0296

📊 Round 189 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2405, R²: 0.0296

📊 Round 189 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2405, R²: 0.0296

============================================================
🔄 Round 194 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 194 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0154
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0206
============================================================


============================================================
🔄 Round 195 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 195 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0204
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0243
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0785, RMSE: 0.2803, MAE: 0.2405, R²: 0.0296

============================================================
🔄 Round 196 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 196 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=0.0174
   Val:   Loss=0.0797, RMSE=0.2822, R²=0.0070
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0785, RMSE: 0.2803, MAE: 0.2405, R²: 0.0296

============================================================
🔄 Round 199 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 199 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0178
   Val:   Loss=0.0873, RMSE=0.2955, R²=0.0112
============================================================


============================================================
🔄 Round 200 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 200 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0187
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0070
============================================================


============================================================
🔄 Round 201 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 201 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0179
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0171
============================================================


============================================================
🔄 Round 202 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 202 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0147
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0224
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0785, RMSE: 0.2803, MAE: 0.2405, R²: 0.0296

📊 Round 202 Test Metrics:
   Loss: 0.0785, RMSE: 0.2803, MAE: 0.2405, R²: 0.0296

📊 Round 202 Test Metrics:
   Loss: 0.0785, RMSE: 0.2803, MAE: 0.2405, R²: 0.0296

============================================================
🔄 Round 205 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 205 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0145
   Val:   Loss=0.0920, RMSE=0.3033, R²=0.0230
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0785, RMSE: 0.2803, MAE: 0.2405, R²: 0.0297

============================================================
🔄 Round 208 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 208 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0165
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0119
============================================================


============================================================
🔄 Round 210 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 210 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0138
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0206
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2404, R²: 0.0298

============================================================
🔄 Round 211 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 211 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0140
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0260
============================================================


📊 Round 211 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2404, R²: 0.0299

============================================================
🔄 Round 212 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 212 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0170
   Val:   Loss=0.0884, RMSE=0.2972, R²=0.0011
============================================================


📊 Round 212 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2404, R²: 0.0299

============================================================
🔄 Round 213 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 213 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0150
   Val:   Loss=0.0896, RMSE=0.2993, R²=0.0120
============================================================


📊 Round 213 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2404, R²: 0.0300

============================================================
🔄 Round 217 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 217 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0046
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0588
============================================================


📊 Round 217 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2404, R²: 0.0300

============================================================
🔄 Round 224 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 224 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0179
   Val:   Loss=0.0854, RMSE=0.2923, R²=0.0114
============================================================


============================================================
🔄 Round 225 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 225 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0128
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0320
============================================================


============================================================
🔄 Round 226 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 226 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=0.0181
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0103
============================================================


============================================================
🔄 Round 229 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 229 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0225
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0142
============================================================


============================================================
🔄 Round 231 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 231 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2897, R²=0.0219
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0065
============================================================


📊 Round 231 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2404, R²: 0.0301

============================================================
🔄 Round 232 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 232 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0156
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0197
============================================================


📊 Round 232 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2404, R²: 0.0300

📊 Round 232 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2404, R²: 0.0300

============================================================
🔄 Round 235 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 235 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0131
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0261
============================================================


============================================================
🔄 Round 240 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 240 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2897, R²=0.0108
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0404
============================================================


📊 Round 240 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2404, R²: 0.0300

============================================================
🔄 Round 243 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 243 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0127
   Val:   Loss=0.0882, RMSE=0.2971, R²=0.0246
============================================================


📊 Round 243 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2404, R²: 0.0300

============================================================
🔄 Round 245 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 245 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0128
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0140
============================================================


📊 Round 245 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2404, R²: 0.0300

============================================================
🔄 Round 247 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 247 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0136
   Val:   Loss=0.0931, RMSE=0.3051, R²=0.0211
============================================================


📊 Round 247 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2404, R²: 0.0300

============================================================
🔄 Round 250 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 250 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=0.0162
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0171
============================================================


============================================================
🔄 Round 252 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 252 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0238
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0153
============================================================


📊 Round 252 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2404, R²: 0.0300

============================================================
🔄 Round 255 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 255 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0143
   Val:   Loss=0.0884, RMSE=0.2973, R²=0.0251
============================================================


============================================================
🔄 Round 256 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 256 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0078
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0530
============================================================


📊 Round 256 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2404, R²: 0.0300

============================================================
🔄 Round 259 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 259 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0162
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0186
============================================================


📊 Round 259 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2404, R²: 0.0301

📊 Round 259 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2404, R²: 0.0301

============================================================
🔄 Round 262 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 262 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0114
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0282
============================================================


📊 Round 262 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2403, R²: 0.0302

📊 Round 262 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2403, R²: 0.0302

============================================================
🔄 Round 266 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 266 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0166
   Val:   Loss=0.0783, RMSE=0.2797, R²=0.0147
============================================================


============================================================
🔄 Round 267 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 267 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0195
   Val:   Loss=0.0802, RMSE=0.2831, R²=0.0047
============================================================


📊 Round 267 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2403, R²: 0.0301

============================================================
🔄 Round 268 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 268 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0203
   Val:   Loss=0.0937, RMSE=0.3061, R²=0.0038
============================================================


============================================================
🔄 Round 270 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 270 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0136
   Val:   Loss=0.0892, RMSE=0.2987, R²=0.0149
============================================================


📊 Round 270 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2403, R²: 0.0302

📊 Round 270 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2403, R²: 0.0302

📊 Round 270 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2403, R²: 0.0302

============================================================
🔄 Round 280 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 280 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0183
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0087
============================================================


📊 Round 280 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2403, R²: 0.0302

📊 Round 280 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2403, R²: 0.0302

============================================================
🔄 Round 283 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 283 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0188
   Val:   Loss=0.0775, RMSE=0.2783, R²=0.0073
============================================================


📊 Round 283 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2403, R²: 0.0302

============================================================
🔄 Round 284 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 284 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0209
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0185
============================================================


============================================================
🔄 Round 287 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 287 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0200
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0084
============================================================


============================================================
🔄 Round 289 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 289 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0164
   Val:   Loss=0.0898, RMSE=0.2996, R²=0.0005
============================================================


📊 Round 289 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2403, R²: 0.0302

📊 Round 289 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2403, R²: 0.0303

============================================================
🔄 Round 295 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 295 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0159
   Val:   Loss=0.0881, RMSE=0.2969, R²=0.0200
============================================================


============================================================
🔄 Round 297 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 297 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0145
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0245
============================================================


📊 Round 297 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2403, R²: 0.0303

============================================================
🔄 Round 298 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 298 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0104
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0410
============================================================


📊 Round 298 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2403, R²: 0.0304

📊 Round 298 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2403, R²: 0.0304

============================================================
🔄 Round 302 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 302 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0237
   Val:   Loss=0.0921, RMSE=0.3035, R²=-0.0291
============================================================


📊 Round 302 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2403, R²: 0.0305

============================================================
🔄 Round 308 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 308 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0137
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0207
============================================================


📊 Round 308 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2403, R²: 0.0305

============================================================
🔄 Round 309 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 309 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0200
   Val:   Loss=0.0747, RMSE=0.2734, R²=-0.0341
============================================================


📊 Round 309 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2403, R²: 0.0305

📊 Round 309 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2403, R²: 0.0305

============================================================
🔄 Round 311 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 311 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0233
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0084
============================================================


📊 Round 311 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2403, R²: 0.0305

============================================================
🔄 Round 312 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 312 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0204
   Val:   Loss=0.0928, RMSE=0.3046, R²=-0.0049
============================================================


📊 Round 312 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2403, R²: 0.0305

📊 Round 312 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2403, R²: 0.0305

📊 Round 312 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2403, R²: 0.0306

📊 Round 312 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2403, R²: 0.0307

📊 Round 312 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2402, R²: 0.0307

============================================================
🔄 Round 323 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 323 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0202
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0009
============================================================


📊 Round 323 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2402, R²: 0.0307

============================================================
🔄 Round 325 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 325 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0137
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0275
============================================================


📊 Round 325 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2402, R²: 0.0307

============================================================
🔄 Round 327 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 327 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0099
   Val:   Loss=0.0890, RMSE=0.2983, R²=0.0283
============================================================


📊 Round 327 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2402, R²: 0.0308

============================================================
🔄 Round 329 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 329 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0103
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0373
============================================================


📊 Round 329 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2402, R²: 0.0308

📊 Round 329 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2402, R²: 0.0308

📊 Round 329 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2402, R²: 0.0309

============================================================
🔄 Round 332 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0957 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0957, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0957, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0957, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0957, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0957, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0957)

============================================================
📊 Round 332 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0176
   Val:   Loss=0.0957, RMSE=0.3094, R²=0.0145
============================================================


============================================================
🔄 Round 334 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 334 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0131
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0326
============================================================


============================================================
🔄 Round 335 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 335 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0190
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0035
============================================================


============================================================
🔄 Round 336 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 336 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0133
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0298
============================================================


📊 Round 336 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2402, R²: 0.0308

============================================================
🔄 Round 339 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 339 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0212
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0112
============================================================


============================================================
🔄 Round 340 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 340 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0143
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0269
============================================================


============================================================
🔄 Round 344 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 344 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0253
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0226
============================================================


============================================================
🔄 Round 346 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 346 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0227
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0106
============================================================


📊 Round 346 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2402, R²: 0.0306

============================================================
🔄 Round 347 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 347 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0223
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0066
============================================================


============================================================
🔄 Round 348 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 348 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0224
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0146
============================================================


============================================================
🔄 Round 350 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 350 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=0.0105
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0420
============================================================


📊 Round 350 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2402, R²: 0.0306

📊 Round 350 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2402, R²: 0.0306

============================================================
🔄 Round 353 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 353 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0132
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0307
============================================================


============================================================
🔄 Round 356 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 356 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0167
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0035
============================================================


📊 Round 356 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2402, R²: 0.0305

============================================================
🔄 Round 361 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 361 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0222
   Val:   Loss=0.0895, RMSE=0.2991, R²=-0.0407
============================================================


📊 Round 361 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2402, R²: 0.0305

============================================================
🔄 Round 363 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 363 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0211
   Val:   Loss=0.0892, RMSE=0.2987, R²=0.0011
============================================================


📊 Round 363 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2402, R²: 0.0305

============================================================
🔄 Round 369 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 369 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=0.0200
   Val:   Loss=0.0769, RMSE=0.2773, R²=-0.0015
============================================================


📊 Round 369 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2402, R²: 0.0307

============================================================
🔄 Round 373 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 373 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0161
   Val:   Loss=0.0841, RMSE=0.2899, R²=0.0209
============================================================


============================================================
🔄 Round 374 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 374 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0145
   Val:   Loss=0.0748, RMSE=0.2734, R²=0.0282
============================================================


============================================================
🔄 Round 375 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 375 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0185
   Val:   Loss=0.0902, RMSE=0.3004, R²=0.0095
============================================================


============================================================
🔄 Round 378 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 378 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0176
   Val:   Loss=0.0884, RMSE=0.2973, R²=0.0074
============================================================


📊 Round 378 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2402, R²: 0.0307

📊 Round 378 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2402, R²: 0.0307

📊 Round 378 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2402, R²: 0.0307

============================================================
🔄 Round 381 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 381 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0160
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0090
============================================================


============================================================
🔄 Round 382 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 382 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2884, R²=0.0158
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0155
============================================================


📊 Round 382 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2402, R²: 0.0308

📊 Round 382 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2402, R²: 0.0307

============================================================
🔄 Round 385 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 385 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0159
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0194
============================================================


📊 Round 385 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2402, R²: 0.0307

============================================================
🔄 Round 386 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 386 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0111
   Val:   Loss=0.0720, RMSE=0.2684, R²=0.0446
============================================================


📊 Round 386 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2402, R²: 0.0307

============================================================
🔄 Round 388 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 388 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0183
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0092
============================================================


📊 Round 388 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2402, R²: 0.0308

📊 Round 388 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2402, R²: 0.0309

📊 Round 388 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2402, R²: 0.0309

============================================================
🔄 Round 394 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 394 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0175
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0114
============================================================


📊 Round 394 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2402, R²: 0.0309

📊 Round 394 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2402, R²: 0.0309

📊 Round 394 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2402, R²: 0.0309

============================================================
🔄 Round 400 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 400 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0233
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0100
============================================================


📊 Round 400 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2402, R²: 0.0309

============================================================
🔄 Round 402 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 402 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0157
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0178
============================================================


📊 Round 402 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2402, R²: 0.0309

============================================================
🔄 Round 404 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 404 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0209
   Val:   Loss=0.0879, RMSE=0.2964, R²=-0.0411
============================================================


📊 Round 404 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2402, R²: 0.0309

📊 Round 404 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2402, R²: 0.0309

============================================================
🔄 Round 407 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 407 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0266
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0217
============================================================


============================================================
🔄 Round 408 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 408 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0177
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0111
============================================================


📊 Round 408 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2402, R²: 0.0310

============================================================
🔄 Round 410 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 410 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0137
   Val:   Loss=0.0858, RMSE=0.2928, R²=0.0297
============================================================


📊 Round 410 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2402, R²: 0.0310

============================================================
🔄 Round 411 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 411 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0110
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0379
============================================================


============================================================
🔄 Round 413 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 413 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=0.0210
   Val:   Loss=0.0769, RMSE=0.2772, R²=-0.0023
============================================================


📊 Round 413 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2401, R²: 0.0311

============================================================
🔄 Round 414 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 414 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0141
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0273
============================================================


📊 Round 414 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2401, R²: 0.0312

📊 Round 414 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2401, R²: 0.0312

============================================================
🔄 Round 416 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0950 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0950, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0950, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0950, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0950, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0950, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0950)

============================================================
📊 Round 416 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0261
   Val:   Loss=0.0950, RMSE=0.3082, R²=-0.0167
============================================================


📊 Round 416 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2401, R²: 0.0312

📊 Round 416 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2401, R²: 0.0312

============================================================
🔄 Round 420 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 420 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=0.0170
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0181
============================================================


📊 Round 420 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2401, R²: 0.0313

📊 Round 420 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2401, R²: 0.0313

📊 Round 420 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2401, R²: 0.0313

📊 Round 420 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2401, R²: 0.0313

📊 Round 420 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2401, R²: 0.0313

============================================================
🔄 Round 429 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0672 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0672, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0672, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0672, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0672, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0672, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0672)

============================================================
📊 Round 429 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2952, R²=0.0150
   Val:   Loss=0.0672, RMSE=0.2592, R²=0.0291
============================================================


📊 Round 429 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2401, R²: 0.0313

============================================================
🔄 Round 430 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 430 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0162
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0117
============================================================


============================================================
🔄 Round 431 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 431 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0147
   Val:   Loss=0.0924, RMSE=0.3040, R²=0.0262
============================================================


============================================================
🔄 Round 432 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 432 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0108
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0232
============================================================


============================================================
🔄 Round 434 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 434 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0181
   Val:   Loss=0.0878, RMSE=0.2964, R²=0.0144
============================================================


============================================================
🔄 Round 435 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 435 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0092
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0389
============================================================


============================================================
🔄 Round 436 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 436 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0099
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0429
============================================================


============================================================
🔄 Round 437 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 437 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0176
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0111
============================================================


============================================================
🔄 Round 438 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 438 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2915, R²=0.0182
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.0120
============================================================


============================================================
🔄 Round 439 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 439 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0053
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0620
============================================================


============================================================
🔄 Round 442 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 442 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0144
   Val:   Loss=0.0768, RMSE=0.2772, R²=0.0301
============================================================


============================================================
🔄 Round 443 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 443 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0233
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0282
============================================================


============================================================
🔄 Round 444 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 444 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0226
   Val:   Loss=0.0750, RMSE=0.2738, R²=-0.0072
============================================================


============================================================
🔄 Round 445 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 445 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0217
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0037
============================================================


============================================================
🔄 Round 446 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 446 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0197
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0081
============================================================


📊 Round 446 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2401, R²: 0.0315

============================================================
🔄 Round 447 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 447 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0134
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0311
============================================================


📊 Round 447 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2401, R²: 0.0315

============================================================
🔄 Round 448 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 448 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0162
   Val:   Loss=0.0901, RMSE=0.3002, R²=0.0214
============================================================


📊 Round 448 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2401, R²: 0.0316

============================================================
🔄 Round 451 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 451 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0214
   Val:   Loss=0.0858, RMSE=0.2928, R²=0.0019
============================================================


============================================================
🔄 Round 455 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 455 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0163
   Val:   Loss=0.0874, RMSE=0.2957, R²=0.0193
============================================================


📊 Round 455 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2400, R²: 0.0317

📊 Round 455 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2400, R²: 0.0317

📊 Round 455 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2400, R²: 0.0318

============================================================
🔄 Round 458 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 458 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=0.0265
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0215
============================================================


============================================================
🔄 Round 459 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 459 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0179
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0149
============================================================


============================================================
🔄 Round 466 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 466 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0172
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0184
============================================================


============================================================
🔄 Round 468 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 468 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0055
   Val:   Loss=0.0866, RMSE=0.2942, R²=0.0604
============================================================


============================================================
🔄 Round 472 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 472 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0065
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0405
============================================================


============================================================
🔄 Round 474 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 474 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=0.0165
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0176
============================================================


📊 Round 474 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2401, R²: 0.0317

============================================================
🔄 Round 476 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0701 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0701, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0701, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0701, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0701, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0701, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0701)

============================================================
📊 Round 476 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0165
   Val:   Loss=0.0701, RMSE=0.2647, R²=0.0207
============================================================


📊 Round 476 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2400, R²: 0.0317

============================================================
🔄 Round 480 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 480 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0059
   Val:   Loss=0.0909, RMSE=0.3015, R²=0.0227
============================================================


📊 Round 480 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2400, R²: 0.0318

============================================================
🔄 Round 481 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 481 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=0.0202
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0060
============================================================


📊 Round 481 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2400, R²: 0.0318

============================================================
🔄 Round 482 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 482 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0149
   Val:   Loss=0.0733, RMSE=0.2708, R²=0.0288
============================================================


📊 Round 482 Test Metrics:
   Loss: 0.0784, RMSE: 0.2799, MAE: 0.2400, R²: 0.0318

============================================================
🔄 Round 491 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 491 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0192
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0023
============================================================


📊 Round 491 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2400, R²: 0.0318

📊 Round 491 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2400, R²: 0.0318

============================================================
🔄 Round 493 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 493 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0181
   Val:   Loss=0.0763, RMSE=0.2763, R²=0.0149
============================================================


============================================================
🔄 Round 494 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 494 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0099
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0408
============================================================


📊 Round 494 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2400, R²: 0.0318

============================================================
🔄 Round 495 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 495 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0128
   Val:   Loss=0.0744, RMSE=0.2727, R²=0.0246
============================================================


============================================================
🔄 Round 496 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 496 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0206
   Val:   Loss=0.0920, RMSE=0.3033, R²=-0.0215
============================================================


📊 Round 496 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2400, R²: 0.0318

📊 Round 496 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2400, R²: 0.0317

============================================================
🔄 Round 499 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 499 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0171
   Val:   Loss=0.0877, RMSE=0.2962, R²=0.0105
============================================================


📊 Round 499 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2400, R²: 0.0317

============================================================
🔄 Round 500 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 500 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0192
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0096
============================================================


============================================================
🔄 Round 502 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 502 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0226
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0061
============================================================


📊 Round 502 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2400, R²: 0.0318

============================================================
🔄 Round 503 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 503 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0139
   Val:   Loss=0.0863, RMSE=0.2937, R²=0.0315
============================================================


============================================================
🔄 Round 504 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 504 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0201
   Val:   Loss=0.0834, RMSE=0.2889, R²=0.0076
============================================================


📊 Round 504 Test Metrics:
   Loss: 0.0784, RMSE: 0.2799, MAE: 0.2400, R²: 0.0318

============================================================
🔄 Round 507 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 507 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0171
   Val:   Loss=0.0884, RMSE=0.2972, R²=0.0112
============================================================


📊 Round 507 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2400, R²: 0.0318

📊 Round 507 Test Metrics:
   Loss: 0.0784, RMSE: 0.2799, MAE: 0.2400, R²: 0.0318

============================================================
🔄 Round 509 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 509 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0118
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0398
============================================================


📊 Round 509 Test Metrics:
   Loss: 0.0784, RMSE: 0.2799, MAE: 0.2400, R²: 0.0318

============================================================
🔄 Round 511 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 511 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0134
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0285
============================================================


📊 Round 511 Test Metrics:
   Loss: 0.0784, RMSE: 0.2799, MAE: 0.2400, R²: 0.0319

============================================================
🔄 Round 514 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 514 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0197
   Val:   Loss=0.0908, RMSE=0.3014, R²=0.0104
============================================================


============================================================
🔄 Round 515 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 515 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0120
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0029
============================================================


============================================================
🔄 Round 516 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 516 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0261
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0181
============================================================


📊 Round 516 Test Metrics:
   Loss: 0.0784, RMSE: 0.2799, MAE: 0.2400, R²: 0.0319

============================================================
🔄 Round 518 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 518 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=0.0182
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0083
============================================================


📊 Round 518 Test Metrics:
   Loss: 0.0784, RMSE: 0.2799, MAE: 0.2400, R²: 0.0319

============================================================
🔄 Round 520 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 520 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0206
   Val:   Loss=0.0847, RMSE=0.2911, R²=0.0038
============================================================


============================================================
🔄 Round 522 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 522 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0164
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0077
============================================================


📊 Round 522 Test Metrics:
   Loss: 0.0784, RMSE: 0.2799, MAE: 0.2400, R²: 0.0319

📊 Round 522 Test Metrics:
   Loss: 0.0784, RMSE: 0.2799, MAE: 0.2400, R²: 0.0318

📊 Round 522 Test Metrics:
   Loss: 0.0784, RMSE: 0.2799, MAE: 0.2400, R²: 0.0318

============================================================
🔄 Round 528 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 528 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0142
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0306
============================================================


📊 Round 528 Test Metrics:
   Loss: 0.0784, RMSE: 0.2799, MAE: 0.2400, R²: 0.0318

============================================================
🔄 Round 529 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 529 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=0.0194
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0003
============================================================


============================================================
🔄 Round 530 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 530 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2897, R²=0.0166
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0214
============================================================


📊 Round 530 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2400, R²: 0.0318

============================================================
🔄 Round 532 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 532 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0176
   Val:   Loss=0.0841, RMSE=0.2899, R²=0.0103
============================================================


============================================================
🔄 Round 535 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 535 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2877, R²=0.0193
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0066
============================================================


📊 Round 535 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2400, R²: 0.0318

============================================================
🔄 Round 539 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 539 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0222
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0088
============================================================


============================================================
🔄 Round 540 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 540 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0141
   Val:   Loss=0.0771, RMSE=0.2778, R²=0.0260
============================================================


📊 Round 540 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2400, R²: 0.0317

============================================================
🔄 Round 541 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 541 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0208
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0019
============================================================


============================================================
🔄 Round 542 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 542 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0167
   Val:   Loss=0.0818, RMSE=0.2861, R²=0.0150
============================================================


📊 Round 542 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2400, R²: 0.0316

📊 Round 542 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2400, R²: 0.0316

============================================================
🔄 Round 544 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 544 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=0.0115
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0411
============================================================


📊 Round 544 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2400, R²: 0.0316

📊 Round 544 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2401, R²: 0.0316

============================================================
🔄 Round 547 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 547 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0133
   Val:   Loss=0.0743, RMSE=0.2726, R²=0.0374
============================================================


📊 Round 547 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2401, R²: 0.0315

============================================================
🔄 Round 550 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 550 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0172
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0193
============================================================


📊 Round 550 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2401, R²: 0.0315

📊 Round 550 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2401, R²: 0.0316

============================================================
🔄 Round 557 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 557 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=0.0209
   Val:   Loss=0.0766, RMSE=0.2767, R²=0.0002
============================================================


============================================================
🔄 Round 558 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 558 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0191
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0103
============================================================


📊 Round 558 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2400, R²: 0.0317

============================================================
🔄 Round 561 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0985 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0986, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0986, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0986, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0986, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0986, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0985)

============================================================
📊 Round 561 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0202
   Val:   Loss=0.0985, RMSE=0.3139, R²=0.0096
============================================================


📊 Round 561 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2400, R²: 0.0317

📊 Round 561 Test Metrics:
   Loss: 0.0784, RMSE: 0.2799, MAE: 0.2400, R²: 0.0318

============================================================
🔄 Round 566 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 566 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0196
   Val:   Loss=0.0826, RMSE=0.2873, R²=0.0055
============================================================


============================================================
🔄 Round 567 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 567 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0128
   Val:   Loss=0.0768, RMSE=0.2772, R²=0.0394
============================================================


============================================================
🔄 Round 569 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 569 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0166
   Val:   Loss=0.0909, RMSE=0.3015, R²=0.0200
============================================================


📊 Round 569 Test Metrics:
   Loss: 0.0784, RMSE: 0.2799, MAE: 0.2400, R²: 0.0318

📊 Round 569 Test Metrics:
   Loss: 0.0784, RMSE: 0.2799, MAE: 0.2400, R²: 0.0318

📊 Round 569 Test Metrics:
   Loss: 0.0784, RMSE: 0.2799, MAE: 0.2400, R²: 0.0319

❌ Client client_1 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_message:"Socket closed", grpc_status:14}"
>
