[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fbab7be-b26c-4eb5-8173-7d9e8ac4d6a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc209c96-2691-4b13-9ea3-88b81b478a38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42aad2fc-6260-44ef-ac91-67f2094db8e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8cf7f0dc-52da-46f6-9b34-bbfb0331b3a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ccb09510-c584-421f-8a02-a219b9320d34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bdeb233-4fb5-49ab-8387-76dc4adcecb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6dbce0c-bc6f-42d4-a8f3-0d5ca44f5aef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43bf541a-c2a3-4ef8-8ace-dd64374c1d44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d9e9155-5c83-4cbd-903c-544be813b0f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 542d6804-1aa2-40fd-b27f-bd4b5755a19f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cdda04d-9690-471c-9894-63475dcb668b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d614735-87c1-4ee9-81b7-fc4a085d791b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52ef94ff-fda8-4cd4-a730-ad17a96ddb49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9b044b3-56e7-4247-b4c8-8c85386c4597
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a0a9e3d-f5ab-444f-addb-cb2520e0b7d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49833130-f7b6-4855-8b72-6afd374a1e74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad79e014-f2f8-4c95-b8ee-93bc3c6d8eac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c35760d4-1b96-4dea-810a-44bd4622b129
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3a08b3c-2fc4-40ac-9c11-cfd5dd234c15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cca1f50-835d-4e6a-8c90-1ecd3219996d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ace57bd7-fd9e-4b5c-8cfd-9c74fc4756a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c59c12a6-ea86-4328-aede-eda81011e9cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47ea72b3-200d-4e6c-ba38-a7ad8260185d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a98b4c16-f6aa-4f9c-bb2b-ce4a4ef80e4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb0d4ddd-ec74-4eb6-93f6-ba75ace2339d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38290c39-a294-4ea6-aac1-08b1cdf94e09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b24dcf69-7fe4-4560-a36b-e478d14a5f2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e38ea85-e38d-4c01-b045-f946b46c32ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97bd4e74-7fd4-4571-be70-e81626630496
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 900e1a2a-5138-43de-bc42-b1dcda216392
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f48b461-a6df-40a0-aa0e-0eb3129ec34c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f9ae1fc-7eb6-4fb7-aa32-3e565cce8e9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ec3c8f0-e237-4447-93ef-94edf170ecb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 967c464a-1f9d-4c35-b5b9-6fcb01fc8f6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f77a997f-22fa-4763-89f8-99f122cf5098
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23a2eb28-43d1-4fb6-80e0-43ddd9eae4d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad545dfb-046d-4f5e-9e3a-a7dfdf1eb058
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25c0a189-f332-471c-9a0e-91f7a7489d53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d48e44d7-a278-4a05-83f8-7a99a5a9a6bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c4945d7-b0d3-4130-b3b9-eea1bb2887d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58e0e11e-3fbb-4441-a1f8-108a4018aa18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf74d968-4839-495e-a11b-c97dadb376d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 745f8921-8b4b-49bb-84c7-6cf58b87651b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 942157eb-1206-4083-b39f-a550711b407c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af831ae9-e9cf-410b-890d-f0e158a3eba5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ed02e03-143a-487c-b1a1-b09b1a2e5d15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10d667d8-6de2-4dce-97fc-4069716f1629
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa01b210-9fc4-4242-8654-65926aa6633a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee227b0b-5e4a-41cb-8379-3fb7149d0068
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78632c73-8153-43bb-b766-b91968300e7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25b95adf-afa9-46b8-898f-8ee9a1316457
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2192d7f-d80c-4fb6-93d6-159374e0a162
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47fdb768-5538-4373-be3a-371f34f5552e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b0a8557-716f-4684-869f-6ac010047f0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eee9eb16-eaed-4b72-a445-06365617bdb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f59f8e60-69ed-47a0-9fa7-830b24f9196d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c166c2bb-86c9-46ce-ada9-274eaacecaed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5187121f-4ea8-47a0-a7fc-3246e90233c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f943589-6388-462c-ae54-7e88ec1ccccb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d12e286-f56e-4366-a5f6-030118915705
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c22016dd-e507-45a0-8dc2-56a20d64a228
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e3b49da-7424-4a12-affb-cff33663d989
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d60b9caa-0f58-4a68-a9a4-e988cd4e73cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41d4da5a-06b3-44db-86bd-2603b458f4a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf00b28a-ad69-46e8-9147-7fc445d28573
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c8cee7d-200d-4f4f-ac3c-fdc9d784f5c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05634bc9-f722-425c-aa08-a13cbcca885d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 621b28c6-565e-4ad8-acc2-e3af6de768dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cc55eb5-50ba-4997-935d-ebfd1490970a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9fc9036-a5a4-440e-9514-6fed6aba2bf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccf09f25-5d34-4b44-97f2-7f91706daa69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 033e3a45-f281-4269-ada1-de8ad51e13bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 218b7608-5819-4c12-a56e-13e362f2f7ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0eb19ed-0386-439c-be2b-ecc31b2a097d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b31e0ad6-3264-4c94-b9b1-cb318684bf50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd865e09-ae51-4a8c-88a2-4fae8207a0f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d06ddbe4-c11f-4a44-a513-d566d609c4c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e91c2c33-fbcd-44ca-81a3-a7ffadad96e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b2fad3b-a2f4-46a7-8b67-b0a313543d04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e46d6e4d-269d-475c-a97a-41bfd1878a87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8cd83d21-db30-4c3b-bd34-324433578ab5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04a7f7a3-e14d-4c4d-baa0-baea7734a36e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a440845-146d-401e-99dc-e49eb7db31ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96c6ad08-c76a-4c40-8320-5f06bc6f877c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4ecebd1-dfb5-4008-9573-0514b1d1e3c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b22c607-2d3a-4ee3-b97e-9413f506fb13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d28b82c-eb36-4c02-881d-480ce97fec11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf17772f-3cf2-495c-9767-c2fa65e4216e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 388cb7bf-5d3c-4e48-af2e-91173625f8f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d72a613a-0e29-4075-98c9-e6426472b469
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5709a0f1-e532-420a-a321-09f21ef3f204
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 691d15d2-eec7-4998-9369-a7a46dec4b90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 657f545f-bfb8-4d69-adb3-a3d7bddd849b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84118e95-4c7a-45ab-b8fd-e9519656592e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a8bbae5-a088-4a5d-9f87-898b795fef78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e8f6429-9d52-4e24-87f3-236339673606
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba564135-6c38-410b-9c73-8d9ebfac9610
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ed489ee-94c4-4e4d-a053-fb067e24cfae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d75bbc3-0b6b-40f0-a688-09c51ff9e256
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c3b9867-720d-4871-893d-27f6deb8fa92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cff04574-7208-4424-8399-1ce946a87314
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3b36630-99ef-4ffb-beda-b7807db937a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a0f4798-f6f5-494b-9765-8db8d07199d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94e96521-0b65-4072-a416-7f44fb376cbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bd141b1-e964-4f4a-b4d6-fa62471b8a6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7dc29b0-04cb-4846-aea7-8b35bc1396a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 833fc86f-ff02-45a9-b04c-d4e12deb30ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86f778de-c04e-4826-966c-53955838545a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc0bd976-402e-4540-abdc-a5010ee642e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6203fc63-7078-4696-bcde-284a70c78dd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f11bb4bf-3fe7-47e1-9a3c-608ace31b00e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfc30595-da25-4bd0-95e3-9d5f5bf317f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5586a379-4ad3-4213-b812-17f6b16bdf39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32474270-4973-49b3-9577-3bab0c0efaf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 384d55cc-7092-49d9-b1cc-83615065374d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df909f5c-83b2-4302-8007-a7be07fa705c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4fe66f37-038e-457e-ae17-1002301fdaf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0ad9a62-6dc8-41ff-a84c-edeb97412a60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0eb43606-3fdc-491a-97b0-99ab8bd84088
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6704512f-2b7e-4ba0-a413-3bb7ceb5820b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d9ef643-fc18-40e7-9ae8-1c39807421a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3724099-9f84-49a5-bc80-b218f2f3af30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad3683fc-d14e-4e13-b460-0b2fa10938fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f646eedd-3dea-4f4d-bf07-0e7f0652bd65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6755656e-f4b7-4995-bd1f-1f312184da72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 691e33e1-566a-4730-bcc6-90718f1ee61e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17d9a293-34f0-49e6-b132-0ccd82fe6828
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d43187cb-e3cd-425b-a628-ebe6e07d86dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df5735f5-7ccc-4fe9-bf70-57dc70e2ddbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3fbf124-0fa1-4cdd-8f40-8b8d420b22f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a88bdac7-07f1-4fc6-9d56-b62baaa862cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32754646-9c7c-4529-8124-4a4d64ce2d1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75a7c4a1-1af9-4069-ba95-47422ce15de5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7292c757-49ab-457e-bada-611bdd23bc8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf6271ea-df7e-4e30-a7b7-86da1c304838
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae92e078-11a5-4f1e-b220-4be18ca92308
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a6d4a3c-28e8-4768-ac88-7f3aceddf269
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 465a6bf3-184f-4068-8883-13407c373cb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8377d962-89fa-4138-9b5f-72cbdb0c08ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 738c356e-bd75-412a-b17f-9ed3401d730b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6881a4a-e9ca-4380-b725-457593929074
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec2dd87f-9887-4a46-8196-97156fe7a2e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46021d91-5f51-4b27-908c-735e0a2102ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7781af83-c65a-44c3-887d-8b0e419c1add
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05457f07-1dda-4ed2-ae89-7fbaf4ed3d30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 376abdb4-3e4c-4867-a92f-fc9251e93a1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dba7b6f5-173a-4e69-8b5e-9aecc3ab2caf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fde0b6f-9c25-461a-a409-0ba82b404735
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fbc2c8e-980f-49fa-af62-0c5d2ad187e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 503a7503-e7d5-4ede-9914-45389adc124f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75e963a9-8dd5-44f2-9ef8-9de07063ac4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 077bc49f-3aac-4b6d-b489-7a5834812f45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 811677f3-50ba-4828-932c-aca58fe4db3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f150894-cd77-4d3c-955e-73be45921de1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d8140e1-ab2a-456a-a342-407238063866
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbec0300-5dbd-450b-bab6-898118bc4658
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0679860-6715-4bac-ab5a-6dbead14e2eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7235be24-b16c-4f66-becf-64ed861fcaf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abab3ac5-c560-46c6-860e-761899670a95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9245c7c4-9e96-472d-9073-091762a36b3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 066ffd93-4b24-4551-8638-6b62291b6d6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4c8bc63-d5c9-4de2-88bf-1dca5d94763a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75529c52-a4d3-44dd-bc04-4f177379ab01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d8ad752-5196-4cbb-bc9b-d0e74fd80e39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf1e09d7-f66a-499b-9f56-d7b2f58db745
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df259de1-f38c-4707-b56d-6a41abaa2856
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfbbb064-c5c2-4f6d-aae1-98d7b2785b1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6920f26e-c94e-4738-ac56-ea6befa546a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 625b252d-db2e-4901-af51-e0e6dc555e6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9820ea9d-4cb9-4b3e-bc40-bb4efee1b698
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f4d9024-f267-483e-ba4c-c1ba52e1836e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad2b51f9-50bc-4513-b650-e8fb1d9a036c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1038ae7-df7e-41a1-bbf6-865f6e45597a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 743efeef-5ff9-4ad8-b312-573247c5e681
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85f01bed-6dae-40af-a24d-56c0bc4747e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 963b0a55-2d37-4cd6-bcca-069bbbb28717
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73dd8cac-9180-4fc5-b842-3641a9291c0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b674bc6e-212b-4c18-984a-2aaf09c43ebc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfa64059-92f3-47b0-8150-38d18175a3ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2baed71f-fe2d-465b-9fe4-37bc51ab2511
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb6f92cb-f912-40c6-a5f8-ace2968d85de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4235693-9f84-4704-92ce-adc89474710d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c12f4a61-67b7-4d50-b3f3-74dd3f95e9d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a884a234-c062-4a93-b92a-3f43f104ce64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f0450a8-fb42-4d79-9259-4eb60fd1fc64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b669a462-1f3f-425a-bd0f-328d838a4990
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dad83111-caa3-4f5c-8e3f-35088efe3870
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2374f027-443f-4cd9-9bc3-b8b8e9f98699
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edf72bc1-38e2-4733-b4c2-5ecc70735412
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73d8ef8b-7ac4-4fd3-9a09-43530935c77a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74e9c66f-e94d-464a-a990-c584660ab017
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0d16f0d-a025-450f-b159-d72dec366043
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f6fb31c-212d-4b53-8578-e5d2a1334ce2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50e7ffa9-d79e-4149-87ba-473b51823908
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5e8ad52-a210-4b93-a0bc-40d9bb8985c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3de3b38b-7f01-4cc8-a31d-1e8c327f3112
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9644074c-cf25-4874-9491-55cdb2467c7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0887b528-417f-477b-8384-9de7289babfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a7f81f3-245d-4833-a8fd-d03bac43f1e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06ccf5d3-8090-4d21-9d1a-f72a16bd1a03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 599fedc5-e84e-45ea-bbd7-e2b007a61d8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 252507f4-2e86-4e18-a176-32acc0a172a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe88ad69-1523-46cf-a977-15cf90808119
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62efecec-af87-49a6-9700-7c55c354b43d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe6e31e9-6138-4778-93b6-2eabb1025f92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c022e0c1-6251-40e5-9cca-f84eca497b9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5b5870c-7def-47e6-aab5-2b1d67f2a142
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c500d30-247c-475d-a235-425baab7a884
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 405f9ad3-d922-4f03-a08d-8ffa1f802b09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80c4a899-d03f-4b0c-baf8-b975bcefdb6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a7c9b27-bc4b-4b64-a1ac-a07a48dbaa69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 703fc314-536b-471a-bdea-ba4c5e02d605
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e0fe24f-304e-4abb-a866-71e40ffcd366
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d500217-3820-49f6-94a0-ffea77e3d2a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c08d259a-853a-408d-bfac-f7fca341efe8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36fc7d49-07ed-424e-8d6c-5583180ba5aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 642e31ec-eee7-464a-91fb-4b56d22625ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da3c78eb-2625-4dbc-bf1c-c5548247760d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0aa490e-2fa4-4ca9-a399-27cdb31d77f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60d81fda-c69b-4442-acc0-aa6aa2a165ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ba181c6-b6ee-4385-aae1-e36a98adb02c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 264d7e71-1dc6-48b9-b8c6-5057305e3c75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e978cb6-9aa8-4774-9f85-2791b28579c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af009d1c-f0d3-4d58-a1fb-0cfe2b0d361a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90372b63-032c-4de4-8960-b035ebd72270
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52b47ca2-6abd-47e0-b917-aaa2230e09ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2b90d23-a26b-4005-8fb8-c7876b61548e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67741627-53e7-4bf1-9c4e-a20d0946a4be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcb64558-75b0-49ac-b313-33f3a50961f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50f56b6b-1405-4e08-a7e3-36e989ba4066
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ce9446e-f1b1-4538-9df3-afa52a73e11b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18794b8f-5450-40d6-b306-e423e3edf82c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb72adde-66da-46ab-834a-06cf2ef7f025
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1fd4ca4-7382-4d96-91ba-9cdaa09aee59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74d2d909-b811-4a64-8288-4d0ffc8ad14a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b9e8983-e659-4737-894a-8b95b5267b56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64b78c88-dfc6-495c-a1d3-c5ca2b8123d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce4666bf-a68e-46de-ab9b-772ed13c508e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a3eb7ba-d9dc-4b9f-bb15-97d6829aae4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cf65b2d-4c5a-416e-a7e3-7efa6b4fdde2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35cebb94-07f2-4b71-9f68-3eb7b9f2ad10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34b13124-65dd-4aee-822c-b90e5ccd4517
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8449adb3-2a44-4caf-a3e9-bc24b7400c85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b155b8e-bf06-4e0d-ad87-b60cfa5f312c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20d940a1-f906-415f-89b5-72dec07b1c5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c01aa95e-0374-42fa-b05c-55622b557f28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38f44169-8001-4ca5-a454-b91cd2042197
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9770c2d-87f2-4e98-9cd2-6019b599237c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fe3ff03-e38a-4309-a2a0-82035034e31e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6945e778-140a-4f58-9c9b-850bf9f18c18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a677c23-4e05-4617-a140-a1c14bb6698a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38f47d81-4f5d-4966-a47d-e4e6813c38d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cc33810-e958-43f9-a178-94070388a301
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc781281-a8df-4047-b732-629f89255134
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be763a32-afae-42b2-9b3d-0d0d4fcc6669
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4598e2c-9d72-418f-bb2b-9479d72eb1cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 498df64f-9129-498b-b856-c3ea64d5ec31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e069a497-9e11-4ea3-8f73-75b53719be1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c383fd91-bada-423c-9a95-4b9cc90b095d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79f78f90-2228-4588-9a77-df989341f233
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91cd4beb-742c-4a94-aa10-c691a1eda18d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94507c30-fea2-4e11-a56b-4150ee94f648
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9bcb4582-2426-45e5-8eb0-96f59c996531
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82bfc345-7e35-452c-ba5e-e597edd03193
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af0ee384-cfe2-4132-bd1b-26419283ae31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e079f5c-2924-483f-a95c-935d8c09f629
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afec9e9e-8a10-42f3-bd1b-2cb05bd84a67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8565ee3d-dd13-448e-8d66-324ec86b058a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5089c5dd-0037-484f-9a9e-761615cc46cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3e736ac-47a2-4dba-b4df-a64d1e3ceb97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d431297-24fb-4ad3-aabe-0d74877dbd57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 558d2888-899b-4ca1-9051-f724921b48f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f7cdfa1-f64e-4def-8ef0-06efb9c33303
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bc1a4f3-4df0-44ad-a86e-df69f971102a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f68b834-a6df-4961-af3d-161c916b32ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca718bff-07cb-4fa5-8e80-8131953176e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c32d768-fbd4-4323-8420-c69ec7d025eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8bfa81b-b50d-478f-b219-131e3011ade0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0b90fba-649c-4781-bad0-4c826ab0a215
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33ca883e-8464-4907-8046-df0b4199f649
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6088820-82b7-4768-8b35-b1f265af8582
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ecdd7e20-3f35-49de-a81c-54679e07e18d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6017f668-048c-42bb-9e85-a4e08daba8e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5faee6b9-b6ff-4a1b-8e13-239de5ead707
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33161b17-314c-4cc6-b571-6bce13231bb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4511b101-0d96-4be4-a59d-8ca693fca1f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0844794-53e8-4491-888e-dc6b62d56bcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eeb68779-9099-4368-9c1b-451f853952cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3eed27c9-38e9-483c-8ac0-9ff066a03d1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffdc6fba-7415-44e1-aa45-a63944cfaaf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 493a246b-44b7-44c0-aea3-234ce3c724c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ecfab8f-14ee-409d-8337-8cc6c9f59d02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b889bd75-4ce4-4d1b-8d03-b250da991c57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28c1c05c-5d6b-4fed-920b-51c16280ee5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f70e3af-4133-416c-80b8-5ffcc48d0d60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0c9f16b-5f3c-4740-8496-7a795dc4b48c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d59e846f-fa7b-468c-b97d-34a57b5a341e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc219dcb-e4ac-4641-aba1-7c070fff919a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a37e458-aac2-4c40-9060-da2bd6281196
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dcff7c37-cccb-4a05-93df-16ca70495f86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 679234e1-e5cc-46e3-bd4b-be70f4878afe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a9fcc61-a4bb-4ee4-af52-0d080172a815
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5ac2be9-a38d-4f12-aacb-bfc87c175a24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3107d3e6-6e20-4155-82c4-44baa403bd69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acb34065-9462-46cc-bf7a-1f70281fb26b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fdb7289-a49d-4fc4-805f-67b9e463770d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d17cadb0-ef54-4aa1-a58a-3118ec66c47e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4053b233-9890-47a2-afee-661f2ddacfed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60f7a81f-0f96-4859-8d29-d9f992bd6b42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d0bf351-ef04-4fbf-a8af-6b412da3509b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce2bdfe0-31f0-4eea-90ac-f488029f94a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31c32b4e-ec89-414b-ba37-e68bbde71e86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94a84980-04bd-4bda-ba2b-adf1ec7e77a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c78a30c6-0ec6-4061-adca-490fc72bede7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4f97079-0a64-4f1f-8c2d-7ea3fcba7267
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d123092-0191-4c68-a6df-2a7ebde55f5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b33a0d64-1ee3-4526-a053-a6c19afec2c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6aa97c9c-715f-4787-8b63-e53af789124d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d179f8b0-e54a-4f56-9792-3aa889a975cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9c9cd1c-71d6-4c3e-ad35-e2822e83d189
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a883499d-e3a8-47dd-9116-4d61b5e96ab2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0dd0967-f544-4572-968e-02649d3034e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 984bc2d2-e48f-45e9-8cff-3f663f017953
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e30ea9f-5604-4f0b-aa55-57a9889bd61c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76af3062-252f-4189-a00a-947ff7c178b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7dc18a9-f194-4245-9627-ef23e1dc9de2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0e28b80-65d2-48fa-9e96-3c4098f28a7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55bb6f94-e2bf-48b7-aa5b-6bca42bae74f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 230f0b13-f521-465a-aa91-ea63a7d1b39c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b668e943-e1be-410c-8008-5c3e6d2d521d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0b2a51d-ace8-4d3d-8e5f-1e710a377f3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d48874f-0f0f-4f62-b0fc-40dab88b5dfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7d52c90-a5dc-48c0-b90b-334d48a0df84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65848e6f-f5cf-4e21-aa87-01c1ab08b62c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ed655f4-cf5e-4a79-a9be-666080a5f982
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14ef206b-242d-4b40-ae29-e3c4d8bdc903
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fd87596-2191-4523-89d8-a77502c2e81e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c4870c6-d7cf-463b-aeec-4b474a3b7f0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0e67a8d-cc8e-4e3b-b1c9-bb12d361fbda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e149e6cb-9dc9-45bc-af07-88afec540251
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5dc98de2-fe99-4024-ae39-3663ae0e3f48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d00f5c7b-ad59-46a3-81c0-c300683ee86a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a635e08-d1fc-4788-b653-2c6644d47588
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8285371a-ae8e-430f-90b7-56f184d8c9f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9feb6e12-1f76-48de-bb5c-029264c51a47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af5a50b7-c0c5-4fa0-a6e3-bea6be39ccad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0794ec8f-93eb-4cc9-938e-c6d131eba9e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 331a9f84-4c12-4b46-9e7b-24477446fbf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 867ec6f9-5cf3-4c54-be80-708ba6ad0197
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 709fddf0-ba8f-4269-b0e2-dd962752df3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bf4af5b-0adf-4711-a790-33cb406846e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3cafc7f-1b93-4abe-9fc0-10324bb68c47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c936fb9-cd71-4885-9ed7-7b80f7d7ec75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae6db0c6-9ddd-4687-ada2-69ee0e56aab5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 877c4e6c-1607-4a66-80ff-ead69a6785cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a5c387e-d36b-425e-b377-087346b5b7b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af567c3c-556e-476a-a2c4-0f3d54bb56ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53edfca0-e421-4e43-b9c5-cb1e76125fca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96848f36-e1d5-4728-ae93-0329cfecd937
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 516484df-8ef7-4d53-8aba-88bd0fd56769
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02fc7e29-cdeb-4373-929d-814ee5be7d76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06fa95bf-8093-4aef-b6c5-1c05ee1215f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f98f3df5-f7e4-421b-941c-32a42417e48a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4a9ecb2-151e-49a3-bb3d-b3032922ca42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 110d556a-f12f-4bea-b33a-9644dca9778b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ad07efa-3b11-45e2-8e5a-ae7a6c137356
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bdcbf20-c1c8-42ab-8b87-dde1194c7078
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf6d61c2-97c5-4aed-8f61-355f8a8c4562
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94aab02b-efa6-46af-b6b7-541d1d10ce74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ffc4163-dc97-4b50-8c24-729ed09943c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fcfdf18-1464-4732-a2c1-f5e6c8648fec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce2ed758-c05f-4232-bab1-5b3a78e6d501
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e19f083-fc76-43d4-b46a-412949ae190c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fb7a145-bed1-4de6-9651-a145caf35613
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abd7e1ad-59b1-4da5-bf01-1f7a1c71cced
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 736aa2a1-c40a-4ca7-a6ad-c890e42ce6ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1215d640-e9eb-4947-a3f7-b1bc34f85ecc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75a4b135-17b1-4172-be3f-2ff24019e42a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2346f39-a13f-4cbd-974f-f2829a837788
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e262292e-d14a-4212-befa-2c4434cc63ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc8928f1-0bc0-46df-80e8-2019a2183c80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b342600-80a0-444c-b32f-489bc7c752e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65e6d3e0-00ca-4738-9050-f32ffdfeefa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7795029-ff98-4015-a775-3add9d345ba3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4082ef6f-67de-45d7-b0c5-3a2bc0bc178d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd20b898-abb8-4fc3-9c9d-c0ee8089c4bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f3b451d-aba6-4589-b1dc-18d4df42624c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a60ed6df-7164-4d80-a28e-62d8a8be8ed4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 572c40fa-fe0a-49bf-ba14-f6ed6629f4dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac1ca75e-2438-4b2d-9bf9-d76fdccf0cc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd0e1e22-f169-4495-a91a-5e026fe1a45a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6f06a33-2554-497b-8f38-392231e9b585
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9b1492f-f0b9-4860-929e-db7ad60b9229
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbbb18b0-b5f6-465a-8e32-da8a99e7d37c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39f967af-f737-43c6-99c2-0be703d69c66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71152324-7e0d-4ae5-a0ac-4828436b9377
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd8f33c9-ef16-4725-a12c-19734cb129a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 585ff250-4e2e-4487-bf5f-e39a19129f52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a262079-d2be-498a-83e1-0b78d2865043
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f62b0201-08d9-4edb-8328-e24d361bebdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32e16ed2-0143-4684-9312-0c46f60d8def
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3523e3c-b8de-4840-9072-96aeb4e66f18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91ca3450-fd23-438f-a600-def20c2d0644
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58e1c360-0ebe-4538-8843-94e09493c061
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 016c0c7d-c91f-4479-85ee-8eb975b9d7a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5c386bf-8391-4d2f-8fa4-f7f3b3290c8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c18c83a-fc20-459a-b7ff-c4c580406aa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 679fffde-0c08-4bf6-a0b8-bb0317f6a6f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea879e5d-db49-441a-8e68-517b615b66b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be6e08f0-58d7-4337-97ff-926562d8a375
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c031200-af9f-412f-bd8f-81e8c46b6c8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4db917d-4359-4697-b620-946a54872e04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d63e020-d2f2-432d-a392-75a048e5bdbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 262c8a72-1fa1-4247-9eb0-1d44664da2cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 174da0eb-236d-4afe-88b5-19df26a2ede9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06d01b92-c426-4136-b631-57423aa866c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87e73981-d743-4652-892e-8ee2175624df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25ef8db0-3711-4c46-bb0f-679601eb1bb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 021d2bdf-57a1-46f7-ab33-c679619e077c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24ab907b-16f8-4e9b-bfda-2de1425c391e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f530475f-85cb-47bc-936f-c9a829820e09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81889b1e-0aca-442f-bc6e-f9ec58975232
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a4f6f91-d002-4c08-89a9-9e2aff13b660
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffcf3128-f97e-424f-9fa3-f6d77fd3b1c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a93c458d-084b-47e5-9d45-14837ec04f0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f000c6a9-2c49-4e70-b37c-0f71d05e171e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af564737-a828-45b7-a5bc-98882c56328e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a40c175-64d8-4b03-8f0d-f3a9a249e83f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97b72057-7125-416b-9b66-6982e568998d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 281391ff-4081-4292-b594-836394d66728
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b4d9152-304d-47cf-b969-445c8aa8f041
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 869eb20e-17c8-4505-affb-9d3491a8f606
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f48ab9c4-8032-44bf-a93a-16ec008a2d9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a85e57e-748c-4797-a733-1050ab31407c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e60f6a0c-51d5-4ff6-8e4f-20d942e4b060
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 167893a5-7db9-42fa-95b0-40287e542178
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e487683d-994d-4bbe-a01d-c685626f19fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 852e04b7-a023-4a28-a220-5019a54f2f0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed37a7b4-ac03-4d45-b0fa-0b9d4b57828b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3f9b26b-4411-41b8-9d4b-fbb4c3d8a332
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 227d8c1e-e712-4f5b-92da-10a1c4829227
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97f6a74c-0bef-4f8f-9504-c3a2e321bf6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c6ed224-6f3f-460a-9cd7-90fb505ce87b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48421428-fc96-4552-864b-d2387ab175db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30994c02-0722-4d3c-85a9-b14b05aa2966
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be313f43-69f9-4a44-ac3e-4d21c6baec0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41a52dd4-2f76-4bd4-8035-7be87a7686e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6411f51d-da38-4287-bcb5-0dbf100a8425
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eedd68ab-b39d-481f-9939-2d49aa39c9b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38110744-d218-4ae8-89af-fdef8ffdd114
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8ca462c-001c-4788-af28-dab90f022c61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bcaf640-5dfd-465b-9b1b-efce77aaca0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9abf7cad-b42f-465e-921f-6c13a7d40d01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6aa6cbb4-b46b-4131-88ba-bc145a6ef77b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f62a86b-6a58-4230-a621-fabfd7210dc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e364a4b9-5af5-4ec7-98b6-b5ef6b21bab9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea230bcb-0fcf-4d4f-838f-0be8587d966e
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_20
Server: localhost:8688
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_20
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_20/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_20/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_20/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_20/test_labels.txt

📊 Raw data loaded:
   Train: X=(6680, 24), y=(6680,)
   Test:  X=(1670, 24), y=(1670,)

⚠️  Limiting training data: 6680 → 800 samples
⚠️  Limiting test data: 1670 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_20 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.3890, RMSE: 0.6237, MAE: 0.5534, R²: -3.7235

📊 Round 0 Test Metrics:
   Loss: 0.0968, RMSE: 0.3111, MAE: 0.2620, R²: -0.1755

============================================================
🔄 Round 5 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0773 (↓), lr=0.001000
   • Epoch   2/100: train=0.0906, val=0.0786, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0901, val=0.0777, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0892, val=0.0777, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0892, val=0.0778, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0877, val=0.0779, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 5 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=0.0008
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0042
============================================================


============================================================
🔄 Round 6 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1018, val=0.0773 (↓), lr=0.000250
   • Epoch   2/100: train=0.0894, val=0.0777, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0886, val=0.0770, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0886, val=0.0770, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0885, val=0.0770, patience=4/15, lr=0.000250
   • Epoch  11/100: train=0.0880, val=0.0770, patience=10/15, lr=0.000250
   📉 Epoch 13: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 6 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000125 (1 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=-0.0022
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0037
============================================================


============================================================
🔄 Round 7 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0911 (↓), lr=0.000125
   • Epoch   2/100: train=0.0860, val=0.0906, patience=1/15, lr=0.000125
   • Epoch   3/100: train=0.0856, val=0.0906, patience=2/15, lr=0.000125
   • Epoch   4/100: train=0.0855, val=0.0906, patience=3/15, lr=0.000125
   📉 Epoch 5: LR reduced 0.000125 → 0.000063
   • Epoch   5/100: train=0.0854, val=0.0906, patience=4/15, lr=0.000063
   • Epoch  11/100: train=0.0852, val=0.0906, patience=10/15, lr=0.000063
   📉 Epoch 13: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 7 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0034
   Val:   Loss=0.0911, RMSE=0.3018, R²=-0.0094
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0856, RMSE: 0.2925, MAE: 0.2527, R²: -0.0391

============================================================
🔄 Round 8 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0951 (↓), lr=0.000031
   • Epoch   2/100: train=0.0852, val=0.0948, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0847, val=0.0946, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0843, val=0.0946, patience=3/15, lr=0.000031
   📉 Epoch 5: LR reduced 0.000031 → 0.000016
   • Epoch   5/100: train=0.0841, val=0.0947, patience=4/15, lr=0.000016
   • Epoch  11/100: train=0.0838, val=0.0949, patience=10/15, lr=0.000016
   📉 Epoch 13: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0951)

============================================================
📊 Round 8 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0146
   Val:   Loss=0.0951, RMSE=0.3084, R²=-0.0017
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2496, R²: -0.0151

📊 Round 8 Test Metrics:
   Loss: 0.0849, RMSE: 0.2913, MAE: 0.2507, R²: -0.0305

📊 Round 8 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2494, R²: -0.0139

📊 Round 8 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2483, R²: -0.0005

============================================================
🔄 Round 15 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0841 (↓), lr=0.000008
   • Epoch   2/100: train=0.0873, val=0.0841, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0871, val=0.0842, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0869, val=0.0842, patience=3/15, lr=0.000008
   📉 Epoch 5: LR reduced 0.000008 → 0.000004
   • Epoch   5/100: train=0.0868, val=0.0843, patience=4/15, lr=0.000004
   • Epoch  11/100: train=0.0865, val=0.0844, patience=10/15, lr=0.000004
   📉 Epoch 13: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 15 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0022
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0164
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2481, R²: 0.0029

============================================================
🔄 Round 17 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0826 (↓), lr=0.000002
   • Epoch   2/100: train=0.0866, val=0.0826, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0866, val=0.0826, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0866, val=0.0826, patience=3/15, lr=0.000002
   📉 Epoch 5: LR reduced 0.000002 → 0.000001
   • Epoch   5/100: train=0.0866, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 17 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0108
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0036
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2483, R²: -0.0001

============================================================
🔄 Round 18 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 18 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=0.0046
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0288
============================================================


============================================================
🔄 Round 19 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 19 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0048
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0255
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2485, R²: -0.0030

============================================================
🔄 Round 23 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 23 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=0.0005
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0385
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2485, R²: -0.0028

📊 Round 23 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: -0.0024

📊 Round 23 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: -0.0017

============================================================
🔄 Round 29 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 29 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=0.0161
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0204
============================================================


============================================================
🔄 Round 30 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 30 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0013
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0423
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2483, R²: 0.0001

📊 Round 30 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2482, R²: 0.0004

============================================================
🔄 Round 33 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 33 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=0.0131
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0258
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2482, R²: 0.0007

============================================================
🔄 Round 34 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 34 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0084
   Val:   Loss=0.0833, RMSE=0.2887, R²=0.0171
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2482, R²: 0.0011

📊 Round 34 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2482, R²: 0.0015

============================================================
🔄 Round 42 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 42 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0122
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0005
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2481, R²: 0.0023

============================================================
🔄 Round 43 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 43 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0090
   Val:   Loss=0.0898, RMSE=0.2997, R²=0.0152
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2481, R²: 0.0024

📊 Round 43 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0025

📊 Round 43 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0027

📊 Round 43 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0028

============================================================
🔄 Round 52 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 52 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2932, R²=0.0093
   Val:   Loss=0.0849, RMSE=0.2913, R²=0.0141
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2480, R²: 0.0033

============================================================
🔄 Round 53 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 53 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0058
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0249
============================================================


============================================================
🔄 Round 54 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 54 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=0.0039
   Val:   Loss=0.0896, RMSE=0.2993, R²=0.0273
============================================================


============================================================
🔄 Round 56 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 56 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0134
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0021
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2480, R²: 0.0036

📊 Round 56 Test Metrics:
   Loss: 0.0821, RMSE: 0.2864, MAE: 0.2480, R²: 0.0036

============================================================
🔄 Round 58 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 58 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=0.0147
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0150
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2480, R²: 0.0037

============================================================
🔄 Round 65 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 65 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0048
   Val:   Loss=0.0870, RMSE=0.2949, R²=0.0308
============================================================


============================================================
🔄 Round 66 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 66 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2949, R²=0.0021
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0452
============================================================


============================================================
🔄 Round 67 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 67 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0133
   Val:   Loss=0.0929, RMSE=0.3048, R²=-0.0005
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2479, R²: 0.0041

============================================================
🔄 Round 68 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0935 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0935, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0935, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 68 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0109
   Val:   Loss=0.0935, RMSE=0.3058, R²=0.0031
============================================================


============================================================
🔄 Round 69 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 69 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0084
   Val:   Loss=0.0882, RMSE=0.2971, R²=0.0186
============================================================


============================================================
🔄 Round 70 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 70 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0164
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0208
============================================================


============================================================
🔄 Round 73 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 73 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=0.0027
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0354
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2479, R²: 0.0043

📊 Round 73 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2479, R²: 0.0044

============================================================
🔄 Round 77 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 77 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0086
   Val:   Loss=0.0848, RMSE=0.2913, R²=0.0155
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2479, R²: 0.0044

============================================================
🔄 Round 79 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 79 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2959, R²=0.0035
   Val:   Loss=0.0785, RMSE=0.2801, R²=0.0396
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2479, R²: 0.0044

📊 Round 79 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2479, R²: 0.0045

============================================================
🔄 Round 82 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 82 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0098
   Val:   Loss=0.0872, RMSE=0.2953, R²=0.0115
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2479, R²: 0.0045

============================================================
🔄 Round 84 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 84 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=0.0143
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0166
============================================================


============================================================
🔄 Round 85 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 85 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=0.0125
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0002
============================================================


============================================================
🔄 Round 86 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 86 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0073
   Val:   Loss=0.0897, RMSE=0.2994, R²=0.0184
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2479, R²: 0.0046

============================================================
🔄 Round 87 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 87 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0139
   Val:   Loss=0.0895, RMSE=0.2991, R²=-0.0251
============================================================


============================================================
🔄 Round 88 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 88 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0153
   Val:   Loss=0.0912, RMSE=0.3020, R²=-0.0076
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2479, R²: 0.0046

============================================================
🔄 Round 91 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 91 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=0.0120
   Val:   Loss=0.0842, RMSE=0.2901, R²=0.0028
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2479, R²: 0.0047

============================================================
🔄 Round 93 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 93 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0118
   Val:   Loss=0.0890, RMSE=0.2983, R²=0.0055
============================================================


============================================================
🔄 Round 95 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 95 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=0.0118
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0033
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2479, R²: 0.0048

============================================================
🔄 Round 97 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 97 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0033
   Val:   Loss=0.0850, RMSE=0.2916, R²=0.0134
============================================================


============================================================
🔄 Round 98 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 98 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=0.0010
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0514
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2479, R²: 0.0049

📊 Round 98 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2479, R²: 0.0049

📊 Round 98 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2479, R²: 0.0049

📊 Round 98 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2479, R²: 0.0049

============================================================
🔄 Round 103 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 103 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0145
   Val:   Loss=0.0855, RMSE=0.2923, R²=-0.0203
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2479, R²: 0.0049

============================================================
🔄 Round 104 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 104 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0094
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0029
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2479, R²: 0.0050

============================================================
🔄 Round 106 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 106 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=0.0081
   Val:   Loss=0.0766, RMSE=0.2767, R²=0.0167
============================================================


============================================================
🔄 Round 108 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 108 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=0.0045
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0322
============================================================


============================================================
🔄 Round 109 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 109 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=0.0135
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0125
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2479, R²: 0.0050

============================================================
🔄 Round 112 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 112 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0079
   Val:   Loss=0.0921, RMSE=0.3034, R²=0.0188
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2479, R²: 0.0051

============================================================
🔄 Round 114 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 114 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0071
   Val:   Loss=0.0909, RMSE=0.3015, R²=0.0168
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2479, R²: 0.0051

============================================================
🔄 Round 115 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0961 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0961, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0961, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0961, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0962, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0962, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0961)

============================================================
📊 Round 115 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2884, R²=0.0075
   Val:   Loss=0.0961, RMSE=0.3100, R²=0.0084
============================================================


============================================================
🔄 Round 117 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 117 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2927, R²=0.0085
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0173
============================================================


============================================================
🔄 Round 119 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 119 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0139
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0073
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2479, R²: 0.0052

============================================================
🔄 Round 122 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 122 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0044
   Val:   Loss=0.0909, RMSE=0.3015, R²=0.0316
============================================================


============================================================
🔄 Round 123 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 123 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0094
   Val:   Loss=0.0876, RMSE=0.2960, R²=0.0106
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2479, R²: 0.0052

📊 Round 123 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2479, R²: 0.0052

============================================================
🔄 Round 129 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 129 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0055
   Val:   Loss=0.0833, RMSE=0.2887, R²=0.0121
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2479, R²: 0.0053

============================================================
🔄 Round 133 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 133 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=0.0114
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0017
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2479, R²: 0.0053

📊 Round 133 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2479, R²: 0.0053

============================================================
🔄 Round 136 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 136 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0127
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0019
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2479, R²: 0.0053

============================================================
🔄 Round 139 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 139 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0150
   Val:   Loss=0.0919, RMSE=0.3032, R²=-0.0210
============================================================


============================================================
🔄 Round 140 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 140 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0143
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0316
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2479, R²: 0.0054

============================================================
🔄 Round 141 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 141 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0098
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0056
============================================================


============================================================
🔄 Round 142 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 142 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0068
   Val:   Loss=0.0872, RMSE=0.2953, R²=0.0031
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2479, R²: 0.0054

============================================================
🔄 Round 143 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 143 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=0.0120
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0025
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2479, R²: 0.0054

============================================================
🔄 Round 144 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 144 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2945, R²=0.0147
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0085
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2479, R²: 0.0054

============================================================
🔄 Round 146 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 146 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0124
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0352
============================================================


============================================================
🔄 Round 148 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 148 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0121
   Val:   Loss=0.0915, RMSE=0.3025, R²=0.0029
============================================================


============================================================
🔄 Round 149 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 149 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0127
   Val:   Loss=0.0910, RMSE=0.3017, R²=0.0007
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2479, R²: 0.0054

============================================================
🔄 Round 151 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 151 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=0.0114
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0070
============================================================


============================================================
🔄 Round 152 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 152 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0100
   Val:   Loss=0.0837, RMSE=0.2892, R²=0.0061
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2479, R²: 0.0054

============================================================
🔄 Round 153 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 153 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0095
   Val:   Loss=0.0898, RMSE=0.2996, R²=0.0084
============================================================


============================================================
🔄 Round 154 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 154 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0060
   Val:   Loss=0.0914, RMSE=0.3023, R²=0.0151
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2479, R²: 0.0055

📊 Round 154 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2479, R²: 0.0055

📊 Round 154 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2479, R²: 0.0055

============================================================
🔄 Round 159 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 159 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=0.0120
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0028
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2479, R²: 0.0055

============================================================
🔄 Round 160 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0971 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0971, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0971, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0971, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0971, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0971, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0971)

============================================================
📊 Round 160 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0126
   Val:   Loss=0.0971, RMSE=0.3117, R²=-0.0062
============================================================


============================================================
🔄 Round 161 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 161 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=0.0072
   Val:   Loss=0.0806, RMSE=0.2838, R²=0.0034
============================================================


============================================================
🔄 Round 163 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 163 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=0.0006
   Val:   Loss=0.0876, RMSE=0.2959, R²=0.0359
============================================================


============================================================
🔄 Round 164 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 164 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0041
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0342
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2479, R²: 0.0055

============================================================
🔄 Round 165 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 165 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=0.0107
   Val:   Loss=0.0749, RMSE=0.2737, R²=0.0008
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2479, R²: 0.0055

📊 Round 165 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2479, R²: 0.0056

============================================================
🔄 Round 167 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 167 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0149
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0056
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2479, R²: 0.0056

============================================================
🔄 Round 173 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 173 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=0.0111
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0084
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2479, R²: 0.0057

============================================================
🔄 Round 177 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 177 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0122
   Val:   Loss=0.0891, RMSE=0.2986, R²=-0.0093
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2479, R²: 0.0057

📊 Round 177 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2479, R²: 0.0057

============================================================
🔄 Round 180 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 180 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=0.0092
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0063
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2479, R²: 0.0057

============================================================
🔄 Round 185 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 185 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=0.0164
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0147
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2479, R²: 0.0057

============================================================
🔄 Round 186 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 186 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0072
   Val:   Loss=0.0917, RMSE=0.3028, R²=0.0207
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2479, R²: 0.0057

============================================================
🔄 Round 192 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 192 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0130
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0043
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2479, R²: 0.0058

📊 Round 192 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2479, R²: 0.0058

============================================================
🔄 Round 195 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 195 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0130
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0157
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2479, R²: 0.0058

============================================================
🔄 Round 199 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 199 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=0.0044
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0194
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2479, R²: 0.0058

📊 Round 199 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2479, R²: 0.0059

============================================================
🔄 Round 205 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 205 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0084
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0199
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2479, R²: 0.0059

📊 Round 205 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2479, R²: 0.0059

============================================================
🔄 Round 209 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 209 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0082
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0176
============================================================


============================================================
🔄 Round 211 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 211 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=0.0073
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0230
============================================================


============================================================
🔄 Round 213 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 213 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2916, R²=0.0077
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0136
============================================================


📊 Round 213 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2479, R²: 0.0059

============================================================
🔄 Round 216 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 216 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0046
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0360
============================================================


📊 Round 216 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2479, R²: 0.0059

============================================================
🔄 Round 217 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 217 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0118
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0097
============================================================


📊 Round 217 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2479, R²: 0.0059

============================================================
🔄 Round 222 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 222 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0103
   Val:   Loss=0.0852, RMSE=0.2920, R²=0.0033
============================================================


📊 Round 222 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2479, R²: 0.0060

============================================================
🔄 Round 225 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 225 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0091
   Val:   Loss=0.0893, RMSE=0.2989, R²=-0.0142
============================================================


📊 Round 225 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2479, R²: 0.0060

============================================================
🔄 Round 226 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 226 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=0.0054
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0273
============================================================


============================================================
🔄 Round 227 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 227 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0133
   Val:   Loss=0.0897, RMSE=0.2995, R²=0.0009
============================================================


============================================================
🔄 Round 228 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 228 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=0.0086
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0202
============================================================


📊 Round 228 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2479, R²: 0.0060

📊 Round 228 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2479, R²: 0.0060

============================================================
🔄 Round 230 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0946 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0946, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0946, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0946, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0946, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0946)

============================================================
📊 Round 230 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0113
   Val:   Loss=0.0946, RMSE=0.3076, R²=0.0035
============================================================


============================================================
🔄 Round 234 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 234 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0233
   Val:   Loss=0.0917, RMSE=0.3029, R²=-0.0564
============================================================


📊 Round 234 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2479, R²: 0.0061

============================================================
🔄 Round 235 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 235 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2971, R²=0.0114
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0049
============================================================


============================================================
🔄 Round 236 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 236 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=0.0130
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0042
============================================================


============================================================
🔄 Round 237 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 237 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0101
   Val:   Loss=0.0897, RMSE=0.2995, R²=0.0133
============================================================


📊 Round 237 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2479, R²: 0.0061

============================================================
🔄 Round 239 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 239 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0068
   Val:   Loss=0.0868, RMSE=0.2947, R²=0.0191
============================================================


📊 Round 239 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2479, R²: 0.0062

============================================================
🔄 Round 243 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 243 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=0.0056
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0217
============================================================


📊 Round 243 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2479, R²: 0.0062

📊 Round 243 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2479, R²: 0.0062

============================================================
🔄 Round 246 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 246 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0109
   Val:   Loss=0.0900, RMSE=0.3000, R²=0.0070
============================================================


============================================================
🔄 Round 247 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 247 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=0.0137
   Val:   Loss=0.0919, RMSE=0.3031, R²=-0.0124
============================================================


📊 Round 247 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2479, R²: 0.0062

📊 Round 247 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2479, R²: 0.0062

============================================================
🔄 Round 250 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 250 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0118
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0024
============================================================


============================================================
🔄 Round 251 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 251 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0151
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0066
============================================================


📊 Round 251 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2479, R²: 0.0062

============================================================
🔄 Round 254 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 254 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0126
   Val:   Loss=0.0891, RMSE=0.2986, R²=0.0046
============================================================


📊 Round 254 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2479, R²: 0.0062

📊 Round 254 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2479, R²: 0.0062

============================================================
🔄 Round 258 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 258 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=0.0077
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0234
============================================================


📊 Round 258 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2479, R²: 0.0063

============================================================
🔄 Round 259 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 259 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0051
   Val:   Loss=0.0897, RMSE=0.2995, R²=0.0103
============================================================


📊 Round 259 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2479, R²: 0.0063

============================================================
🔄 Round 261 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 261 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0141
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0150
============================================================


📊 Round 261 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2479, R²: 0.0063

📊 Round 261 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2479, R²: 0.0063

============================================================
🔄 Round 264 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 264 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0058
   Val:   Loss=0.0849, RMSE=0.2913, R²=0.0262
============================================================


📊 Round 264 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2479, R²: 0.0063

📊 Round 264 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2479, R²: 0.0063

📊 Round 264 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2479, R²: 0.0063

📊 Round 264 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2479, R²: 0.0063

============================================================
🔄 Round 270 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 270 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0119
   Val:   Loss=0.0889, RMSE=0.2981, R²=0.0027
============================================================


📊 Round 270 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2479, R²: 0.0063

📊 Round 270 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2479, R²: 0.0064

============================================================
🔄 Round 274 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 274 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=0.0138
   Val:   Loss=0.0849, RMSE=0.2915, R²=-0.0053
============================================================


📊 Round 274 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2479, R²: 0.0064

📊 Round 274 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2479, R²: 0.0064

============================================================
🔄 Round 278 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 278 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0067
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0256
============================================================


📊 Round 278 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2479, R²: 0.0064

============================================================
🔄 Round 279 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 279 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0106
   Val:   Loss=0.0906, RMSE=0.3010, R²=0.0119
============================================================


📊 Round 279 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2479, R²: 0.0064

============================================================
🔄 Round 280 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 280 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=0.0141
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0018
============================================================


📊 Round 280 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2479, R²: 0.0064

============================================================
🔄 Round 283 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 283 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0191
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0200
============================================================


============================================================
🔄 Round 284 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 284 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0125
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0539
============================================================


📊 Round 284 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2479, R²: 0.0065

============================================================
🔄 Round 287 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 287 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2969, R²=0.0063
   Val:   Loss=0.0758, RMSE=0.2754, R²=0.0268
============================================================


📊 Round 287 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2478, R²: 0.0065

============================================================
🔄 Round 288 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 288 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0129
   Val:   Loss=0.0870, RMSE=0.2949, R²=0.0029
============================================================


📊 Round 288 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2478, R²: 0.0065

📊 Round 288 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2478, R²: 0.0065

============================================================
🔄 Round 291 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 291 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0132
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0124
============================================================


============================================================
🔄 Round 292 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 292 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0136
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0139
============================================================


📊 Round 292 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2478, R²: 0.0065

============================================================
🔄 Round 293 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 293 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0106
   Val:   Loss=0.0932, RMSE=0.3053, R²=0.0098
============================================================


📊 Round 293 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2478, R²: 0.0065

📊 Round 293 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2478, R²: 0.0065

============================================================
🔄 Round 296 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 296 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0089
   Val:   Loss=0.0922, RMSE=0.3036, R²=0.0197
============================================================


📊 Round 296 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2478, R²: 0.0065

============================================================
🔄 Round 297 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 297 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0123
   Val:   Loss=0.0924, RMSE=0.3039, R²=0.0067
============================================================


📊 Round 297 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2478, R²: 0.0065

============================================================
🔄 Round 299 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 299 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=0.0073
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0225
============================================================


============================================================
🔄 Round 302 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 302 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0085
   Val:   Loss=0.0896, RMSE=0.2993, R²=0.0212
============================================================


📊 Round 302 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2478, R²: 0.0065

📊 Round 302 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2478, R²: 0.0065

📊 Round 302 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2478, R²: 0.0065

============================================================
🔄 Round 308 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 308 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=0.0079
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0194
============================================================


============================================================
🔄 Round 309 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 309 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=0.0130
   Val:   Loss=0.0864, RMSE=0.2940, R²=0.0040
============================================================


📊 Round 309 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2478, R²: 0.0065

============================================================
🔄 Round 310 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 310 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0091
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0167
============================================================


============================================================
🔄 Round 312 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 312 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=0.0077
   Val:   Loss=0.0875, RMSE=0.2959, R²=0.0149
============================================================


📊 Round 312 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2478, R²: 0.0065

============================================================
🔄 Round 313 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 313 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0135
   Val:   Loss=0.0810, RMSE=0.2847, R²=0.0019
============================================================


📊 Round 313 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2478, R²: 0.0066

============================================================
🔄 Round 314 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 314 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=0.0126
   Val:   Loss=0.0746, RMSE=0.2732, R²=-0.0062
============================================================


============================================================
🔄 Round 315 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 315 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0129
   Val:   Loss=0.0912, RMSE=0.3020, R²=-0.0070
============================================================


📊 Round 315 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2478, R²: 0.0066

============================================================
🔄 Round 316 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 316 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0085
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0226
============================================================


📊 Round 316 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2478, R²: 0.0066

============================================================
🔄 Round 317 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 317 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0076
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0225
============================================================


============================================================
🔄 Round 319 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 319 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0080
   Val:   Loss=0.0852, RMSE=0.2918, R²=0.0174
============================================================


📊 Round 319 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2478, R²: 0.0066

============================================================
🔄 Round 320 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 320 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0127
   Val:   Loss=0.0854, RMSE=0.2923, R²=0.0039
============================================================


============================================================
🔄 Round 323 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 323 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0121
   Val:   Loss=0.0855, RMSE=0.2925, R²=0.0054
============================================================


============================================================
🔄 Round 324 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 324 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=0.0099
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0166
============================================================


📊 Round 324 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2478, R²: 0.0066

============================================================
🔄 Round 327 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 327 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0121
   Val:   Loss=0.0886, RMSE=0.2977, R²=0.0078
============================================================


📊 Round 327 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2478, R²: 0.0066

📊 Round 327 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2478, R²: 0.0066

============================================================
🔄 Round 329 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 329 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0098
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0155
============================================================


📊 Round 329 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2478, R²: 0.0066

============================================================
🔄 Round 333 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 333 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0071
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0273
============================================================


============================================================
🔄 Round 335 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0941 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0941, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0941, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0941, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0941, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0941, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0941)

============================================================
📊 Round 335 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0086
   Val:   Loss=0.0941, RMSE=0.3067, R²=0.0129
============================================================


📊 Round 335 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2478, R²: 0.0067

📊 Round 335 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2478, R²: 0.0067

📊 Round 335 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2478, R²: 0.0067

📊 Round 335 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2478, R²: 0.0067

============================================================
🔄 Round 344 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0944 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0944, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0944, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0944, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0944, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0944, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0944)

============================================================
📊 Round 344 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0110
   Val:   Loss=0.0944, RMSE=0.3072, R²=0.0123
============================================================


📊 Round 344 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2478, R²: 0.0068

============================================================
🔄 Round 347 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 347 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2964, R²=0.0095
   Val:   Loss=0.0767, RMSE=0.2770, R²=0.0182
============================================================


============================================================
🔄 Round 348 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 348 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=0.0066
   Val:   Loss=0.0790, RMSE=0.2810, R²=0.0323
============================================================


============================================================
🔄 Round 351 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 351 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0083
   Val:   Loss=0.0895, RMSE=0.2991, R²=0.0223
============================================================


📊 Round 351 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2478, R²: 0.0068

============================================================
🔄 Round 352 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 352 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0121
   Val:   Loss=0.0879, RMSE=0.2964, R²=0.0088
============================================================


📊 Round 352 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2478, R²: 0.0068

============================================================
🔄 Round 357 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 357 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0114
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0033
============================================================


📊 Round 357 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2478, R²: 0.0069

============================================================
🔄 Round 360 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 360 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=0.0103
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0033
============================================================


📊 Round 360 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2478, R²: 0.0069

📊 Round 360 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2478, R²: 0.0069

============================================================
🔄 Round 364 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 364 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0115
   Val:   Loss=0.0939, RMSE=0.3065, R²=0.0077
============================================================


📊 Round 364 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2478, R²: 0.0069

📊 Round 364 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2478, R²: 0.0069

============================================================
🔄 Round 367 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 367 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0121
   Val:   Loss=0.0841, RMSE=0.2901, R²=0.0084
============================================================


📊 Round 367 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2478, R²: 0.0069

📊 Round 367 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2478, R²: 0.0069

📊 Round 367 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2478, R²: 0.0069

============================================================
🔄 Round 373 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 373 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0107
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0276
============================================================


📊 Round 373 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2478, R²: 0.0069

============================================================
🔄 Round 374 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 374 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0086
   Val:   Loss=0.0880, RMSE=0.2967, R²=0.0229
============================================================


📊 Round 374 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2478, R²: 0.0070

============================================================
🔄 Round 377 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 377 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=0.0171
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0227
============================================================


📊 Round 377 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2478, R²: 0.0070

============================================================
🔄 Round 378 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 378 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=0.0015
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0358
============================================================


============================================================
🔄 Round 379 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 379 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=0.0097
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0165
============================================================


============================================================
🔄 Round 380 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0938, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 380 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0153
   Val:   Loss=0.0938, RMSE=0.3063, R²=-0.0168
============================================================


📊 Round 380 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2478, R²: 0.0070

============================================================
🔄 Round 383 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 383 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0162
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0155
============================================================


============================================================
🔄 Round 385 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 385 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=0.0086
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0147
============================================================


============================================================
🔄 Round 386 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 386 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0126
   Val:   Loss=0.0882, RMSE=0.2970, R²=0.0075
============================================================


============================================================
🔄 Round 387 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 387 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0100
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0105
============================================================


============================================================
🔄 Round 388 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 388 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=0.0085
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0218
============================================================


============================================================
🔄 Round 389 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 389 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=0.0094
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0219
============================================================


============================================================
🔄 Round 390 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 390 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=0.0118
   Val:   Loss=0.0830, RMSE=0.2882, R²=0.0070
============================================================


============================================================
🔄 Round 391 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 391 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0126
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0074
============================================================


📊 Round 391 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2478, R²: 0.0070

============================================================
🔄 Round 397 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 397 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0141
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0005
============================================================


📊 Round 397 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2478, R²: 0.0071

📊 Round 397 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2478, R²: 0.0071

📊 Round 397 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2478, R²: 0.0071

============================================================
🔄 Round 405 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 405 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=0.0134
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0049
============================================================


============================================================
🔄 Round 406 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 406 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=0.0051
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0357
============================================================


📊 Round 406 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2478, R²: 0.0071

============================================================
🔄 Round 407 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.1007 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.1007, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.1007, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.1007, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.1007, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.1007, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1007)

============================================================
📊 Round 407 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0182
   Val:   Loss=0.1007, RMSE=0.3173, R²=-0.0097
============================================================


============================================================
🔄 Round 408 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 408 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0080
   Val:   Loss=0.0937, RMSE=0.3060, R²=-0.0059
============================================================


📊 Round 408 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2478, R²: 0.0071

============================================================
🔄 Round 409 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 409 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=0.0031
   Val:   Loss=0.0747, RMSE=0.2734, R²=0.0508
============================================================


📊 Round 409 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2478, R²: 0.0071

📊 Round 409 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2478, R²: 0.0071

============================================================
🔄 Round 411 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0979 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0979, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0979, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0979, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0979, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0979, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0979)

============================================================
📊 Round 411 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0174
   Val:   Loss=0.0979, RMSE=0.3128, R²=-0.0184
============================================================


📊 Round 411 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2478, R²: 0.0071

============================================================
🔄 Round 413 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 413 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0094
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0078
============================================================


============================================================
🔄 Round 415 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 415 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=0.0122
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0071
============================================================


============================================================
🔄 Round 417 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0967 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0967, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0967, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0967, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0967, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0967, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0967)

============================================================
📊 Round 417 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0161
   Val:   Loss=0.0967, RMSE=0.3109, R²=-0.0026
============================================================


============================================================
🔄 Round 418 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 418 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=0.0158
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0054
============================================================


📊 Round 418 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2478, R²: 0.0071

📊 Round 418 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2478, R²: 0.0071

============================================================
🔄 Round 421 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 421 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=0.0143
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0023
============================================================


📊 Round 421 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2478, R²: 0.0071

📊 Round 421 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2478, R²: 0.0071

============================================================
🔄 Round 423 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 423 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0111
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0145
============================================================


📊 Round 423 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2478, R²: 0.0071

📊 Round 423 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2478, R²: 0.0071

📊 Round 423 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2478, R²: 0.0072

============================================================
🔄 Round 433 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 433 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2954, R²=0.0119
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0119
============================================================


============================================================
🔄 Round 436 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 436 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0051
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0355
============================================================


============================================================
🔄 Round 437 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 437 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0062
   Val:   Loss=0.0853, RMSE=0.2920, R²=0.0256
============================================================


📊 Round 437 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2478, R²: 0.0072

============================================================
🔄 Round 439 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 439 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=0.0185
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0164
============================================================


============================================================
🔄 Round 440 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 440 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=0.0102
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0167
============================================================


============================================================
🔄 Round 441 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 441 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0164
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0083
============================================================


============================================================
🔄 Round 442 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 442 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0063
   Val:   Loss=0.0865, RMSE=0.2942, R²=0.0329
============================================================


============================================================
🔄 Round 443 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 443 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=0.0149
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0008
============================================================


============================================================
🔄 Round 444 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 444 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2928, R²=0.0176
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0111
============================================================


📊 Round 444 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2478, R²: 0.0072

📊 Round 444 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2478, R²: 0.0072

📊 Round 444 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2478, R²: 0.0072

📊 Round 444 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2478, R²: 0.0072

📊 Round 444 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2478, R²: 0.0072

============================================================
🔄 Round 452 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 452 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=0.0192
   Val:   Loss=0.0779, RMSE=0.2792, R²=-0.0218
============================================================


============================================================
🔄 Round 453 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 453 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2952, R²=0.0162
   Val:   Loss=0.0792, RMSE=0.2815, R²=-0.0090
============================================================


📊 Round 453 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2478, R²: 0.0072

📊 Round 453 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2478, R²: 0.0072

============================================================
🔄 Round 456 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 456 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0078
   Val:   Loss=0.0915, RMSE=0.3026, R²=0.0276
============================================================


============================================================
🔄 Round 458 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 458 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0138
   Val:   Loss=0.0906, RMSE=0.3010, R²=0.0053
============================================================


============================================================
🔄 Round 460 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0942, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0942, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0942, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 460 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0091
   Val:   Loss=0.0942, RMSE=0.3069, R²=0.0194
============================================================


============================================================
🔄 Round 463 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 463 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=0.0157
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0199
============================================================


============================================================
🔄 Round 465 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 465 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0091
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0247
============================================================


============================================================
🔄 Round 466 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 466 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0130
   Val:   Loss=0.0855, RMSE=0.2925, R²=0.0091
============================================================


📊 Round 466 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2478, R²: 0.0073

📊 Round 466 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2478, R²: 0.0073

📊 Round 466 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2478, R²: 0.0073

============================================================
🔄 Round 471 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 471 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=0.0099
   Val:   Loss=0.0805, RMSE=0.2838, R²=0.0219
============================================================


📊 Round 471 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2478, R²: 0.0073

============================================================
🔄 Round 472 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 472 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0055
   Val:   Loss=0.0882, RMSE=0.2969, R²=0.0280
============================================================


📊 Round 472 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2478, R²: 0.0073

============================================================
🔄 Round 476 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 476 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0077
   Val:   Loss=0.0854, RMSE=0.2923, R²=0.0291
============================================================


📊 Round 476 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2478, R²: 0.0073

============================================================
🔄 Round 478 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 478 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0111
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0026
============================================================


📊 Round 478 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2478, R²: 0.0073

📊 Round 478 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2478, R²: 0.0073

============================================================
🔄 Round 482 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 482 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0144
   Val:   Loss=0.0890, RMSE=0.2983, R²=0.0042
============================================================


📊 Round 482 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2478, R²: 0.0073

============================================================
🔄 Round 483 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 483 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2915, R²=0.0129
   Val:   Loss=0.0881, RMSE=0.2967, R²=0.0101
============================================================


============================================================
🔄 Round 485 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 485 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0092
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0254
============================================================


============================================================
🔄 Round 487 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 487 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=0.0088
   Val:   Loss=0.0776, RMSE=0.2785, R²=0.0272
============================================================


============================================================
🔄 Round 488 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 488 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2944, R²=0.0116
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0157
============================================================


📊 Round 488 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2478, R²: 0.0074

============================================================
🔄 Round 489 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 489 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=0.0121
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0099
============================================================


📊 Round 489 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2478, R²: 0.0074

============================================================
🔄 Round 491 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 491 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0150
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0067
============================================================


📊 Round 491 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2478, R²: 0.0074

📊 Round 491 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2478, R²: 0.0074

============================================================
🔄 Round 493 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 493 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=0.0075
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0263
============================================================


============================================================
🔄 Round 495 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 495 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0068
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0336
============================================================


📊 Round 495 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2478, R²: 0.0074

============================================================
🔄 Round 496 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 496 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0114
   Val:   Loss=0.0907, RMSE=0.3012, R²=-0.0026
============================================================


📊 Round 496 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2478, R²: 0.0074

📊 Round 496 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2478, R²: 0.0074

============================================================
🔄 Round 501 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 501 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0175
   Val:   Loss=0.0891, RMSE=0.2984, R²=-0.0078
============================================================


============================================================
🔄 Round 502 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 502 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0169
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0157
============================================================


============================================================
🔄 Round 504 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 504 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0131
   Val:   Loss=0.0851, RMSE=0.2918, R²=0.0095
============================================================


============================================================
🔄 Round 509 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 509 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0072
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0322
============================================================


📊 Round 509 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2478, R²: 0.0075

============================================================
🔄 Round 512 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 512 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0119
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0147
============================================================


📊 Round 512 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2478, R²: 0.0075

============================================================
🔄 Round 514 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 514 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=0.0112
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0007
============================================================


📊 Round 514 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2478, R²: 0.0075

============================================================
🔄 Round 516 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 516 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0158
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0208
============================================================


============================================================
🔄 Round 517 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 517 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0135
   Val:   Loss=0.0908, RMSE=0.3014, R²=0.0060
============================================================


============================================================
🔄 Round 518 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 518 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2932, R²=0.0162
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0031
============================================================


📊 Round 518 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2478, R²: 0.0075

📊 Round 518 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2478, R²: 0.0075

============================================================
🔄 Round 522 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 522 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0182
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0147
============================================================


============================================================
🔄 Round 524 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 524 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0194
   Val:   Loss=0.0937, RMSE=0.3061, R²=-0.0133
============================================================


============================================================
🔄 Round 525 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0943 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0943, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0943, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0943, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0943, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0943, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0943)

============================================================
📊 Round 525 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0078
   Val:   Loss=0.0943, RMSE=0.3071, R²=0.0286
============================================================


📊 Round 525 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2478, R²: 0.0075

============================================================
🔄 Round 526 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 526 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2964, R²=0.0122
   Val:   Loss=0.0764, RMSE=0.2765, R²=0.0136
============================================================


============================================================
🔄 Round 527 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 527 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2964, R²=0.0132
   Val:   Loss=0.0764, RMSE=0.2763, R²=0.0072
============================================================


📊 Round 527 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2478, R²: 0.0076

============================================================
🔄 Round 532 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 532 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0119
   Val:   Loss=0.0885, RMSE=0.2975, R²=0.0133
============================================================


============================================================
🔄 Round 537 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 537 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0101
   Val:   Loss=0.0901, RMSE=0.3002, R²=0.0133
============================================================


📊 Round 537 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2478, R²: 0.0076

============================================================
🔄 Round 538 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 538 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=0.0120
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0079
============================================================


============================================================
🔄 Round 539 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 539 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0140
   Val:   Loss=0.0906, RMSE=0.3010, R²=0.0047
============================================================


============================================================
🔄 Round 540 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 540 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0123
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0133
============================================================


============================================================
🔄 Round 541 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 541 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0106
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0029
============================================================


📊 Round 541 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2478, R²: 0.0076

============================================================
🔄 Round 545 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 545 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2949, R²=0.0088
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0040
============================================================


📊 Round 545 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2478, R²: 0.0077

============================================================
🔄 Round 546 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 546 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0148
   Val:   Loss=0.0893, RMSE=0.2989, R²=0.0020
============================================================


📊 Round 546 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2478, R²: 0.0077

============================================================
🔄 Round 548 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 548 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0151
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0029
============================================================


============================================================
🔄 Round 551 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 551 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0138
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0067
============================================================


📊 Round 551 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2478, R²: 0.0077

📊 Round 551 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2478, R²: 0.0077

📊 Round 551 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2478, R²: 0.0077

📊 Round 551 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2478, R²: 0.0077

📊 Round 551 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2478, R²: 0.0077

============================================================
🔄 Round 560 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 560 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=0.0091
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0228
============================================================


📊 Round 560 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2478, R²: 0.0077

📊 Round 560 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2478, R²: 0.0077

📊 Round 560 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2478, R²: 0.0077

============================================================
🔄 Round 565 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 565 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0148
   Val:   Loss=0.0916, RMSE=0.3027, R²=-0.0053
============================================================


📊 Round 565 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2478, R²: 0.0077

============================================================
🔄 Round 568 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 568 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0092
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0268
============================================================


📊 Round 568 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2478, R²: 0.0077

============================================================
🔄 Round 572 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0966 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0966, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0966, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0966, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0966, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0966, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0966)

============================================================
📊 Round 572 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0134
   Val:   Loss=0.0966, RMSE=0.3107, R²=0.0090
============================================================


============================================================
🔄 Round 573 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 573 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0136
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0086
============================================================


📊 Round 573 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2478, R²: 0.0077

============================================================
🔄 Round 574 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 574 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0178
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0140
============================================================


============================================================
🔄 Round 575 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 575 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=0.0139
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0056
============================================================


❌ Client client_20 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_message:"Socket closed", grpc_status:14}"
>
