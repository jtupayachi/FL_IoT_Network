[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02987ecf-21a8-46a1-8a3a-e6166a194c2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c338de74-3ab8-4d50-9c9e-20c528cfdf39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bdc887fa-ab7d-4c08-a2e1-a7645a00cf3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 353e3068-fb0d-42bd-8180-2c4ead206322
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94f9d687-970a-4c8b-a496-fb0cd50da49c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38b53332-53a4-433f-8eb3-9ce215517895
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b0d12dd-5c71-4f9c-a735-45c1741afdee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a73782f3-bccf-40d5-ab89-abceb591a78f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2527748c-94fd-4fa4-83f0-001ea45bbbb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6574adc1-6523-43ac-9d82-54940bc9cf87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac4fecf4-c21b-42e6-83cc-29abdde436b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52a2510a-a3b6-433c-8749-762b142867b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86daac09-2ce3-4356-8df0-1f2ce370af29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 259a6bf6-f360-4680-951f-7a15b02beff9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44e8afe0-2131-4f4b-9166-3fc032b54e80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e6f19da-f80e-4eb9-9144-8a421b3bd97b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7ba8ad5-6edf-4cf8-b59a-89a04a4fbf9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7e3c052-cc60-473e-97df-83c17b2ec88a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a13d2da-a84c-42b4-8fc7-4bbc70892a84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9c9ca26-c349-44f9-8c49-e4ec991b078b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01563837-e5ea-44a8-8647-d7d04fc2b3c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 733fb635-0d21-4bb8-ad03-09d2dbfd5650
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1100d9e0-0299-46ad-a1e0-d04d0a972020
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cb93a53-0b66-45d7-bc93-33519a7f06bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e5f2e24-d76e-4398-92d1-55f421ea3b1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b896510-4a46-4e33-9a09-0d2a74d4d4aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95bc7d0b-5149-4227-a16c-b8501dd29e57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79980858-1b7a-409c-8377-3aea773b417e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edca717e-700f-42a7-b04a-8141451a0a84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfd92bbe-544b-4b18-9937-c43a46364c46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47a3f427-1493-4eea-8dca-663240eb5017
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 581bc82b-92c9-48c6-b8b9-d3c230c1eeb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9ecea91-a494-4106-962c-6a345b5344f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8503ac3-4f70-43d1-8e8f-ea1084c6d1e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d09a4ca6-ac09-4651-9bf6-5c89c84350b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bf435b3-c2f3-4b35-81a6-4f42d3f2d02d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 448c6335-a724-45c3-a4ee-cba564880dcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4e3eae8-a2e5-475d-88e0-4858e4abd7d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1380211f-5823-441a-9839-64f3c40950d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb34dc03-7a19-42c4-949e-abe4eea30545
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0f5485e-43ea-4cae-bead-f8dc822c6336
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 664b5081-7297-4cea-977d-d11818d259a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c60fe7a6-cea2-42bc-869f-c88ebfabcddb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d09a965-396a-4a0d-9650-307a8729190f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c36c1d1e-1ee5-414e-9a5a-54b3687fcda5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbabf8a2-da19-4491-85ff-6f142e1fdbba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f6cfda8-4d58-4d9f-a1d1-1828e7983ed2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9792b382-74d9-44b1-b016-c081d5f4f45f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d25231b-a6ac-4b32-a803-f8e4a5b48e36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbfe9c87-1956-4cca-a023-9162a123ad27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5950dd8-34e4-42ba-adb0-4b9858f9cc78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55646112-72a4-46da-ab12-237882a15dfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73d166b1-b57a-4e3a-8238-11267a8ea055
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9372a073-43d0-49f7-bdea-25de521e2798
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ebde780-ce97-491d-aa4d-ac1b554d288d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 356220d4-aed6-423d-8d76-bdd3ce7349a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7af21a2-8c8f-419f-9c12-645d5a509317
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcda783d-02db-4225-b950-a7005695faeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8da8b57c-958e-4e5e-9626-03c1898da6ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a3fe009-ab22-43cc-b4d4-1ff3101a834e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad74621a-ae6f-4a81-886c-abd3cc4aea7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1aad6bf5-f6cf-4597-a4de-e4fd3d49b309
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2657058b-170c-4ac8-a329-c6649982f94d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c39f93f7-cf39-4f29-8e72-8448b043d21f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4999e90-b387-484d-9c10-536e5fba05dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fafedd14-bbe5-4d95-9aa8-34c2c1704cd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91fa632a-2e9d-4298-9fbc-66de99f2245b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bb11bc9-af4d-4f6f-bbe3-969d70cb5f53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb06a3b7-0526-4ac5-a18f-a69e3328be0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b3dc767-c21e-43c8-b459-4905a7267931
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bdd45e4-7e30-47df-991d-465df9b9b6b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1383410c-03fb-4bde-bda4-a33f8e8ad2e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6900bc6e-e750-4750-9ef6-ba892bcf8d93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1af973cc-0a20-4810-962d-4cbc4b087647
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 663bb878-b49a-4127-8acc-264ea3ef06de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c5e9433-9290-48e4-96a7-64efb1c4f8f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e221a4e4-ac85-4304-931c-fe86ef7475f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09004135-846c-4ce2-a376-7224a4a4a8a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ba25b35-bdec-4d59-a973-a3855c18fe00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a470cd1-c148-4c7f-999d-244a0f8a3cc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0280cdf-8e12-4efa-8260-cf3ca8838a8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02c9bb2d-a4b3-45c9-94db-ce8146a9c882
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92b3a342-ec3d-4c20-9306-5ebd8c4b46c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4b032a4-6afd-43b7-9248-201906ae8469
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6caa959a-2b91-456b-baed-8164dec32c5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8c70aff-15bf-44fc-9fbd-a02c6e47a0a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2af0fd3-bfde-4bda-a7cf-f09a2ee6d29c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1028bd7-192e-431f-8e2d-9b8eb6b1f48c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 428ce94c-d6c4-4426-b9f1-db1d76cae670
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6af4aec9-242c-41aa-84c1-8ba290065ae7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 626c64e2-286f-4482-baeb-b305882df98f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50fb54b7-595c-4064-bf1e-da1c98cf21a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b66c31c1-b965-4a55-8cdd-6ff49323b8f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dcab1c3a-c373-49ab-8e4e-1f6db00bc4c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dca93cfe-53b8-47cd-93f4-62b6f840a69a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e24cacc-fbb7-4769-a119-f60f1297f029
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8142d6d1-d58d-43b3-8a14-44a0ab6ee123
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe355abe-4e3f-4050-8573-971ba2e66227
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41ca0ff0-33e7-4f54-9d77-af17500912d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58c6cbbf-204f-4b8a-820b-becb20828bf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4aa6326b-656b-4dc4-9bf3-41e8b9500848
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66f8745d-5635-49c8-8d40-76d0f1994fab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e884946-c739-4a17-852e-e71fca1e5263
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5552bfad-493b-41f9-9e61-72833ce0f84a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66e59ff4-79eb-448f-bbf0-3cdb9c9e140f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94eb0a99-7bd9-4d3f-87b9-7d941a389e01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84b3c381-521f-4e53-87fb-38a06759a960
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23762395-b937-4a46-b1fc-b552fcfdf7d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30c25556-ab03-4216-a2fe-eab30628dee4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46a061a2-0853-43c9-93de-6134563a42d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ede03012-196a-4458-8d50-85fe1c3589fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 586f28ad-bc5b-4906-89ca-c3c30022a125
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 467f5a43-ff73-4ea5-a2d5-7bb7e292321c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c545bed-ebf5-4b1e-a82d-8a9e3d12135f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06b6d221-9eb9-4956-8354-7c4711be8193
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce6dccb8-e390-4372-a02d-887fbba61be6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9ab971d-d78b-4435-9db0-3e6297a1fff2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2286ced-82bf-4e5c-92d6-797156056239
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0386458-2b59-456b-a099-4c0aef6707ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90baacfd-47c6-4461-b3ad-783e2addd6e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b341b8c7-ffe3-4aa8-800b-ac4f5b3998c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6c354e3-f556-4106-8ec8-3f5ba90c0341
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 478d4dd9-4075-4f92-bfe1-1b5d49c3d164
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d72467d-17ca-442a-acfe-44715d895fa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ca1c76f-eb25-4e74-9391-d73b405a2c85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e2b5e02-bfd4-4da6-8ea4-437ef4ed8091
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59c8abcb-cc3a-4830-8bc7-08b733e16287
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9dafc56f-5c09-4e11-a0a6-907c241be2b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abd49e27-4dc1-4f3b-8dda-aabd51a7bbdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0ccbc70-33c5-461f-911b-d2ffc534aad4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57e33a77-ae12-4057-94d2-d072f88c3d51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4db8f8d5-dda2-4f40-a85e-ef972641e1e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28f42957-b591-4350-8ec4-4114fa2170de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91bbce5d-9a61-4a8c-8f63-a739cf3b0504
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 570c9fe6-6a6d-4d40-bc1c-81a74bc160a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2f09308-5350-4a0d-b5b8-6271ac3947e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45c21d6a-a416-48b9-bf2e-a66c484be32b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a274df0-04ca-4d2f-954b-f406b6b7dd2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fffc42cc-7625-4a18-8c07-65377cdc7574
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2de8e558-8d54-4b0d-8091-67d64adf0c6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a832d69e-3ff4-4de3-abe3-1bf800c64742
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6bdd118-269e-4865-bd07-21459ae5fe0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94800a41-e019-4c3d-bbe3-2d76af916865
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69f921cd-ba47-4a80-8a7a-c674c83e2337
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d29d73f-6a62-4bd1-8f97-6ea6eab2aabb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a8fbe4c-c000-4879-a0b2-4b00fa44769c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 610aecda-44e1-4180-95aa-fc30c974a2a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49c61f97-e1f5-4e0b-bec7-1e7b3fbc7799
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5713eea2-44c0-498d-9a1f-45f49971e1a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2579126e-320c-4c25-b53b-173a8c60645c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fe54513-e9fd-4828-bd4f-79c408eeae8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2cb2a5c6-3140-4139-8af7-4df8793c1530
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ef0fb31-2150-4f89-8455-1e3a5f1471d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49ab6ad8-316d-489c-9d7a-61a36ec57d26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6659b1d-93b3-4d89-9a21-9c54dd3be174
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd0e88cb-8e6f-446f-9976-32542018ff7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8d2a014-5fc6-486c-b4fd-3acef8dddfd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74a46e1a-a695-4f5a-8c8c-ac2ceb2695fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 848ae0e3-750d-4f06-af30-5d6a67916d36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44b056aa-781c-4056-a525-543873bb7f5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8b11d89-a302-4f54-b126-9c9453db9c6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d007950-1609-4f30-8e2f-7813e83b984d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17d2ed86-e0ca-4e99-b3ce-58ae3b531fab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 198ebd31-8fcc-445a-a167-f9c3e716c6b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6ee1de5-202a-4aca-b635-8f2956786c84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec38250b-e861-4789-adda-0a76088aef1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bbed596-2315-4c70-b1bf-340b3b3d67ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 915cd5b2-7c6e-4046-86f3-cb2eb5740176
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a39b6402-6d47-46b8-8744-dc2b91458a28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 179a84a3-62b7-4cc6-97ad-56b19fbb1dbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b4dc781-dced-473f-b69d-5330b13ebfc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7b119cf-34a0-4b30-b333-4f72840ccc74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bdf83d2f-ce7e-4ea9-8161-0bb3f7e4b92b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 608d18fd-74fc-4f7b-81ec-0023408d512e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e24f4ede-bc2c-4d6c-aa61-1ba7bc04f2ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc50f7f4-89ef-40c8-8acd-bef725df2cf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abd84752-fa42-4d28-aaaf-5c699866c65d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25c719c2-1537-460c-8f64-e08f3d03ee86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f06bd51f-9c05-49fd-836e-046349432f5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 914a8bb4-9140-4f0e-89b5-020723c9183c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ef4516c-b07e-42cb-a0a7-093fd67d114c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78e4d811-0fe0-4a85-9343-99afd59edcb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 534d42c0-938a-4106-9679-72cb2452947a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ea0e5b3-9d29-4ec3-9dd2-51f53b556d37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1833e0a0-dfe6-4984-8ff3-ebd4a78c3d2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed1e6689-0c25-4d0a-bb9d-a1963a021972
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb43c150-84cc-4440-aac3-e7078459e63c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3a32e56-6b23-4246-8528-ec0f678bc583
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57b8c724-da2e-4d8c-8115-b33cdcbb3a66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5e3f427-1941-46df-9524-529126a5fbbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fae6a95-a273-4fb0-839e-8aaf31085909
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc806b01-d917-4690-8631-5b31eed908b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3fc9ad1-6070-496a-9d3e-840a672e016f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19305bc1-0872-4115-b68b-f2a442529de1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bdce8041-a434-4855-ad18-c14f90c17515
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ef82c67-8ab2-4d58-8ea0-203c5f6b43a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f40f05b-a344-4a0e-874f-e0843f7d5563
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe7445c0-5504-4c1e-8196-f777497ef258
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa9878fc-d914-4319-9c4c-83917d2d00da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5dc8391e-ad87-41a2-94af-9e2052cc8d49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebeb1085-5fc7-4b1b-b3b4-c72484883442
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8ece706-22c6-4697-96b1-bce99ba77e57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cb73e51-f0f3-426e-b5c4-12830146f043
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f81ca98e-becc-4c4e-8322-c1deffd4a3c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8372322f-7f6f-4af1-94bf-161da1e4f3df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3dfe7b3a-8388-46f3-bc48-a82e1fd14cd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ba534f9-eb4c-45ec-bf7c-a51de059705b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d40a9b84-4428-423e-8b7b-c84c4dee4538
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7fb8a9b-a8ea-49e2-a766-dd33be566a4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd334180-2bab-4165-8f2c-cd27d3cf9d12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5732994d-e023-4534-9e90-6eaff3c75f22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e112de8-d879-4eda-b65e-5b9b284c51cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b601b280-6709-4eda-8c87-e968218135c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6438617c-1f27-4298-be2d-d4df58204d7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5e7507f-9b54-4167-8a38-8580e34b3d80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2c9248b-57cd-4dac-b1a4-705bf09c18fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15474b67-8212-48f8-b4ef-10a50c011bff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed47c4c6-2eb4-4129-86d5-9857b077dfb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d83cf796-7f44-4442-bd7b-7e661eeaadbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b3cc6c3-aa5b-45b8-a9df-b098e0c6d4cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 495e776f-d9c5-4e58-a127-5c29b8298f48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ff8b81a-b5a4-4313-803c-a0dcc3b650e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea6a4ab5-7440-4c49-ad82-d2e5cb49260a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e291b8e-98c0-444f-ba43-fe80a2a13c3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d656c8b4-5682-4687-bf7f-f7215e57b608
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c64cd99-c8f8-4848-a0ee-cff654aceff3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3736cb9b-c367-4111-a324-51b5912efc82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd2036eb-7715-49ba-a7ba-bf5dc8c909ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 905890fd-abba-45ce-bc6a-7926b66e107e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a994c072-8108-4391-9b0b-2a26f6c89a7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b691c98c-555f-43ce-9843-2cadb2cb2f5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 680649d5-19dc-41e9-b5ee-4c68db1fbe57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b67b3f9-e3b0-49f8-abd2-d145e5014849
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8de58b6-a1fc-4ce3-b5c1-807a9b33a126
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3070c8a-40d2-47a9-acf0-c74a950303ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1d05c98-da3b-49ad-bd0b-bc4b9528802d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 288e1103-74b9-4641-8101-0c0649a9427e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5d6e4bf-157b-44a1-a34d-5e436693c746
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad7b249e-d719-448f-ba72-8f3b937bd546
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 633d169a-a3b6-49bf-807e-7d0f1cb21654
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67b13406-e4d9-4748-88e0-11e14260cd3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5736ff10-03a1-4b6e-b35d-70a6f8f56d66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76dd5509-f735-40d0-b7f6-3940dcafbd10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6422e770-4037-494a-8ff9-c58327a1e156
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51f843d1-b117-473d-bb00-1471250ac51d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06adbcac-66a6-4a10-b396-4225ccc8c026
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0bceaca-c763-4879-9f91-e1915ede6be6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6802a9d6-f78e-4216-b661-d1d6987f6ca4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb93b2d7-98be-4f51-b147-9b85b076296f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb13158f-b9aa-405a-a3a9-08ba5799eb44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50b58636-c8a5-43b4-b6a6-0167fb26dcf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0994d4f5-cc9a-40c3-8c6d-408840f0c867
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e135d374-2844-46e1-a7c7-d2f2f5d3bc7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5aa4232-947b-458e-bef6-487b73e5d8f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8ea1921-660e-49b4-af19-504998ffc8aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77336f1d-d00f-4d64-9b14-11f71d3ad71f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1723ce76-df0a-4cf3-9f43-3637b6b35037
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e1bb67e-9fba-4a9e-ab7d-da2c7a2b10da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2dff98a6-4974-4fb0-9391-1b358227cd87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 163335e0-81aa-4342-b0fb-b830d805174b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f510074-5fd0-44c3-b050-f2e56b7f2ef5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 300b31a7-6e1f-4e20-8f84-93307164bc55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 667de09e-111f-4c4f-a915-cae491b1a161
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7ec02cf-aee1-4ac7-afb6-283b6896c8db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6ed13b8-f441-486b-bfb2-76931689cb0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 366422a1-4198-43d4-aeaa-3247f2bde73a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bde9f9e4-1247-4ff5-a771-3b1fa8b1eaa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61f7ad35-ec54-4ff3-aa58-dc7c45b9b97b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea783ed7-3586-4985-8747-1aa2eea64b54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 067693aa-af5a-4bb9-9f67-8318353cc4e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0590d24-966a-460a-ac59-5abbff38ce25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2aa78d2-a7cd-48f4-a981-b46823f69fb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1de6654f-2af8-4684-8694-e1e376431f31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efc7e336-7ab8-4191-9666-7e3530c00797
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5a01c52-b0a0-4dfa-8555-77ad4c4f58c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7de9d459-9ead-4495-a843-6200070faf00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66c636df-8a97-4941-9ffa-0e7f542d1443
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00154afe-c1e3-473f-994a-a874435438c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f493c663-3176-4b5e-a873-7b30f1c5856c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19e2e97f-f019-4d7a-a071-1096f28a5a37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2015e76d-f966-4308-bed9-c0a7f1affa8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2a66f9b-93aa-42d2-a3b6-cc525f36872a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38740e5e-ffcd-44a7-8e9b-1005febb4d16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb6be11a-31f6-4778-a129-31c7cca23c51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41a7004a-8eb2-45e7-bd49-5c346f51d78e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69f238f9-b530-41b2-8dd9-806a2bff6a94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3b5a765-c8a7-4802-bcc2-d7a886176af7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a1c480a-01af-4319-ac3b-91da338d3ee8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6398388e-1132-4a55-a382-b434140bfd42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15bf686d-1d1f-48bf-8071-bd9627bf3b1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bdfda12b-f30c-4ce9-9047-e07647f066ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca3db8a2-a10f-46b7-a42a-892e2e4ca4bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fadf2468-7360-4cf2-a877-5fb7747e28e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f255b3b2-ccc7-40ca-89e5-96ff8a4f6b34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 024fc3eb-c371-4b04-aaeb-9eb3d92f84ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 670f82b1-15e0-4cc0-b3e3-3dd85e727da3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7f1aef1-4435-4dad-8263-ebf139ff3f29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e9947db-840d-4521-8053-9bcff7c1e5f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 927b5e20-49a3-4ecf-9869-b146fca806cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1dbe469c-87d7-4645-8592-3d28f4ff153f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3efc90e2-f9fc-4468-8f6c-34c3e77bfeec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 182d3686-630f-4847-8d91-31c51d2e291c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ec9b1c0-d02e-42f7-872f-0714bf3a0156
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2198ae4-ee17-4b21-9691-226b0b1e3edd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 437d9ae4-5be8-419b-b22f-9ed060d9e589
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1643c15-bfe6-4405-96b0-978fdde9540f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76d587ec-cba2-4161-a8be-789af2907a31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa215c9f-f999-45d7-9713-0563348bfbdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab5c7b37-fe0a-4d73-bfb3-70f9f58cb707
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8010d749-a09a-4585-96cf-d8148e6e0fd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bec98693-8133-49ec-a560-72a3afaec06e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48335f62-2ccf-470c-8b0d-20a3453fbad9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb092343-8a2b-4c0b-94d9-c7ddc1e4b986
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02431fc7-ea85-4253-b33f-2ed5a21ef52b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ada4fc8-b7af-4187-b02a-45d1ec9d5a55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56f0024f-0a01-4195-a97c-e8405135ab15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f572e256-3a30-4122-ade7-41332305e7f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33db1c3a-eaba-4e99-b06b-a189f0bf4710
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5347dd62-a9d6-462f-9bc5-c5b273a3e10a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68f07391-13f0-4e9a-8615-247c70caf266
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e178ac7-f9f7-4398-96f9-3f18b3b4c81c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89d9c2bf-7531-4c7a-a424-1403e90276d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73a40bac-8f2f-4924-8bb0-f5cdc9610cb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffe8ecae-1945-4dbb-aeea-82cfcd87c779
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd7ec875-7aaf-49c4-bc59-c4a1e311dd2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8aec2539-278d-4bc9-9c57-c0419ecad103
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acc46071-edfe-42e6-ad61-ce1769900b33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 683a5797-eb65-4867-93b2-402336130b9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70973f3e-bc7e-4033-9f51-f2aa6815d357
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7be582fc-27a4-4f56-b3f6-fec253af08f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 987da58c-b158-41df-bc89-db7bc5d41725
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4bf44d3-17b1-40a0-b9f8-946c890da1cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9aa47e69-dafc-41d2-98dd-47df49e15ed3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db1f18cc-acd9-49cb-82a6-b12acd956461
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61795fea-c67e-4974-8a7f-8717a6801c80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51aa4951-b21e-45c3-9198-ef7ca5fce19f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20100001-6d29-4e19-86ef-126d3e2cb086
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69f79fc1-dacb-47b2-aa8b-cc9ba737dc19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77752c57-0b71-42c6-a318-25681f10c9e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7aa91459-2e6a-44e5-b7ff-9ba79f500646
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d0b8b60-5784-457a-9784-80e5ae6cf742
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2dc2e34d-4057-4428-bb28-ac4dc98a4342
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 034ee198-9bad-4d75-a8f4-51f10de9d80c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a30ae0c2-c50d-4acc-b58b-5c922b0c5517
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1efbc1c-9f7d-4b8d-a9de-e8c0f0f7af3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffce5538-3ae5-4e5e-9e34-561516ac1bb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 006511b9-4bca-46c0-9dbc-f036ba0a3c89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35a11a2f-c00e-41b9-bc7d-ac6e7adec235
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 346034c4-e035-44a4-a33d-9b4410c48ca4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a389abf5-1fe0-4787-a799-d039f73a700c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 577646b8-fd70-48e6-bd84-7a7e9d5dd873
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51ef0160-44cb-4ba2-8dce-d53c5d391e29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13a7e31f-96b7-4eae-95ea-881a2abf34b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fa67980-383f-4406-ba6c-1aed225b8ca7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f761c08-d37d-41a2-85c3-e673b681da44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a4abd19-e0ff-4e10-a890-ac77ac0709de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd4c7a82-91fa-4b77-aa1e-bc44ae86fce8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae8a742c-86d2-446d-8285-23b12be42950
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d9bdd30-7cba-4af1-a6f4-523478d4d652
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8f064bc-0155-427d-ac45-4f6629b9c69a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f0de0d8-7420-4793-8b72-be58decbf3fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 199e8f4b-e025-4976-bbf1-cbee343f2e66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82294b6a-a4b6-4989-ab38-b511a494f916
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7140e99-296d-4962-afca-02879c87f088
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74f09d4e-0452-4e87-b99b-c96280b12a85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41aa0132-7d9a-43cf-93fb-61e137d658f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6368932-6364-41a2-aa9e-c4abd3d975f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e246829-4d0c-48cf-8ffe-63e212a634ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63786bfa-5a4b-405f-8774-8b0fdb68781d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73b91a59-8936-45b9-a831-0fa26695a50e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8b34dcc-4284-4978-9bb4-3bcaf72bbcd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29f5087b-7c12-465c-87c0-a3e6f9aead27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32fb7a3d-ef61-4521-825a-8e3cd7fd0be4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8531b687-cb89-4557-9725-575ddc264739
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 811246fb-5db6-42c9-be70-b4435156a531
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ca87e45-4589-4ab2-955e-4bd233443912
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dae5d2a3-00ed-4e7e-8025-2c481e1ce03c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3800f2b4-10ac-4b8b-8954-45f0fe9abac3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15f98efd-81fc-491f-b3ed-63f2e0c5a900
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f46e569-2eee-4b9a-9ea4-703ac9f70158
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f973bd7-4227-4372-8c62-0e26d03063b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3edfd481-6e3b-4275-b002-f3cf2e5bdb19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12a0b727-f1c1-4efb-9515-fb6c52d58b3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5928498-5be8-459d-82e0-4b50bdb2f401
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 090304a0-a50f-48bc-936f-2d7dd0c4d06d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fb21b77-01e5-4eb1-8e0f-f39afbe78858
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f01dcaa-1c10-4269-affe-dc3aa077abcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21ca6353-1d27-40cd-a37e-866746632c13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5195ab05-dfae-4644-b3d1-2d8eafa8b496
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28cb1c70-9ff3-4418-91b0-b001fcd1e724
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a081355-5508-4fbb-ad83-da1ad6b30491
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a18087d9-0207-4b90-a109-b2b546f492fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f64ddaf-ad18-47de-94bd-a0adfef6b8e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1eff04d9-b110-49a6-bfdb-7ef2cc76f5ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8860e3b-88dd-4d94-a0a8-4db6d120a083
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2b02124-39bd-44db-9504-0213a304a7bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba3a702a-3933-4d1a-8dc7-3add38798b78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15a77ccb-e7d3-4f6a-a7b3-32c5e52fbbf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78cb2bb0-fdfd-42ee-8370-c969077e8d68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8ed4095-f174-4743-90f4-11a79bf4f3c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac82a37b-dc0c-413a-8c7f-e26af11ca295
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b13c9b4-8a23-4c8f-92a1-71f919032df7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9bdea000-8e9f-4c48-b92b-e4f29400b38b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bdb7f1b2-e872-41cc-b869-841d90524796
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e973d342-ee4b-43e7-b8da-525bf8a12fdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f83e0b2-46c0-4ec0-b9db-de0e924e2a74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4358f6db-a646-4098-90c3-174eb7a5da54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98ed2d18-8e6b-4ae2-8540-3463cf50664b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a88831a-f8d0-44c2-ba0e-ac0195017d73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3090687d-b71a-4c10-a939-68fef48e40ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96747cc0-d08c-49b9-871f-7690ede73a4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 019fe9e1-f37c-4007-9f09-4689e386563d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f384b1c-53e8-45f5-a51e-850ed5644fd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bcca0bb-6014-48b3-9b6a-00d089b1de63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 563ffb73-92dc-44a1-aea3-d33b58c82cf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7b5ebd0-fa8f-428a-926d-9e06226555f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cce6edc2-d17b-41c7-9471-fee3f105d41b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 853b0bdd-fcd1-4df9-a7a1-9fab52d9d405
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d121c42d-5c72-460d-8779-0c4396c699df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bbec5b5-5250-41d7-aa35-834ad8bdf0a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30c8af63-2f2f-4eed-ad81-bb0b8af5f547
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa155c23-4f05-4e40-8666-f6f17c70b67e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4dd9e334-9b18-47d8-ac4a-949b0c501756
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b21dc375-90f4-4a17-ad82-9a0c7aab8bbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4599046c-c46d-45df-9dca-8facb9f770f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f605f50b-ec1d-4324-aa64-935cc8c86955
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 808a282c-0d27-4f54-b869-68b77f260c91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fed5a14b-a39a-4980-aaa5-ec28974a8c4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a04dd58-4a99-45b3-ba8d-8f1721169970
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 743dc7a0-d164-4ac8-a959-dee61b09554f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7b6029c-c2ff-4d8d-b371-26ce111a34e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7dd3fd0-f55b-415a-b394-89bb4c5242bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30f02d19-6b61-4da8-93bf-f38f8cc67118
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec405f33-4797-4f38-9d13-71d54b6f33b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4a68cf3-c905-4e6b-9445-4d1b3b58c79b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59a4e078-b9b1-44ef-8b99-550adbddba2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f09de66-c361-4ac6-be89-d3fe629aec1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce919980-dca5-4a35-874d-1ea30f17040f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b87fbb4d-07d4-4de8-b74a-9b98e89af45d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5106fa8c-3e2d-4d76-b0ea-ad9f3dde4f0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8eaa3e71-99ee-444a-a1c3-c2b0aa0c9e39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be0d64a7-78ef-4132-bc6c-8e77a34630f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b0a6595-6ece-4120-9916-6e3b8e231490
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2941931-d440-438f-a035-be03a831af23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56bf2a95-93f7-43e8-94a4-fa76f36bb4b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ba831c7-cffb-47e1-90cc-c55d97cc2ecd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b683b6e8-ba6e-420e-b4b6-d7d4e6f715ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3015c97-e262-41a1-93e0-a369144052a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c49be9bd-ce16-4c4f-9991-ff40e9eba700
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83da64bb-f12b-4f98-9113-108c02afa0fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4a64af9-c64e-40a0-8e0f-094c508013a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a22023c-c2b6-4e48-9b14-d97a9e19487b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c1f5c67-8e0d-485b-8e92-dc3fa8158f67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7be8664b-eecb-4e5f-8e3e-74fa0f2748aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1375becd-5859-4704-96e4-62c5a011ea61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d12d9f6d-ae8f-4095-9118-fe662c1af552
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afcd9473-c4f6-4eae-9907-9eccdcd733a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4e0bfa0-0a3a-4987-acc8-8bd2e846fae0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 642f0186-9b3d-4a1a-a933-2134aa6a090f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 822b6d10-09b8-432c-9a5c-20caf57a2fb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95ac0746-e6cf-4036-a0ee-1867209c6626
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae2fd9f5-d76c-44b3-9af2-de60c24685f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2bacd76-1c04-4d57-b8f6-a7f319e95af0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 552cd477-4004-4ba6-af3d-19ed4ff2cdf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e412340-03c2-45ce-b2a0-7ca8ca2f98d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44d96c1c-a19c-4515-b5b4-e9e494120655
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b93ff9ef-dbd4-4157-8739-8e7571786580
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5720fe29-4dcc-4b96-afe8-ea0168da38bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 471802a8-b527-4add-922d-a44926fb8d37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27ef5f5d-0752-4b44-b117-c33585816e5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fa7fe7a-cb45-44f5-86aa-0fc7874a389e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6681cbf6-3fc0-4ede-b8d4-d3270399e847
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 530d03b2-ba94-4c6e-af4a-e8b6fc7f9e07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3879856-e05b-4042-8967-e8751f86e319
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b148aca5-c198-4494-ae76-983c76d446c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d9494ee-1b4f-4ce9-ac2e-699a28d9b5c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 849e7931-c2e9-40a4-a9e2-163fd3ad3ffc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31d010b3-56e2-4cf7-a847-554bba510ebd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dff1db07-7055-41ed-a1ea-8f85bf4bab1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 787ec6bf-16de-4587-89d0-1a0af496bf89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3443ca05-dbc0-463a-aec9-2cc184fa1edc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fccdf7e-40a2-41a9-b28a-b21e9440f752
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_21
Server: localhost:8688
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_21
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_21/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_21/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_21/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_21/test_labels.txt

📊 Raw data loaded:
   Train: X=(4800, 24), y=(4800,)
   Test:  X=(1200, 24), y=(1200,)

⚠️  Limiting training data: 4800 → 800 samples
⚠️  Limiting test data: 1200 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_21 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 1 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1909, val=0.0692 (↓), lr=0.001000
   • Epoch   2/100: train=0.0865, val=0.0810, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0808, val=0.0701, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0787, val=0.0699, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0784, val=0.0714, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0773, val=0.0710, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0692)

============================================================
📊 Round 1 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0078
   Val:   Loss=0.0692, RMSE=0.2630, R²=-0.0423
============================================================


============================================================
🔄 Round 2 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0765 (↓), lr=0.000250
   • Epoch   2/100: train=0.0775, val=0.0768, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0770, val=0.0766, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0771, val=0.0766, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0770, val=0.0765, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0765, val=0.0766, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 2 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0008
   Val:   Loss=0.0765, RMSE=0.2765, R²=-0.0100
============================================================


============================================================
🔄 Round 4 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1185, val=0.0962 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.0803, val=0.0778 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.0766, val=0.0767 (↓), lr=0.000063
   • Epoch   4/100: train=0.0766, val=0.0771, patience=1/15, lr=0.000063
   • Epoch   5/100: train=0.0764, val=0.0773, patience=2/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0762, val=0.0774, patience=8/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 4 Summary - Client client_21
   Epochs: 18/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0006
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0052
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.0938, RMSE: 0.3062, MAE: 0.2571, R²: -0.1880

📊 Round 4 Test Metrics:
   Loss: 0.1011, RMSE: 0.3179, MAE: 0.2650, R²: -0.2803

============================================================
🔄 Round 7 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0773 (↓), lr=0.000016
   • Epoch   2/100: train=0.0782, val=0.0773, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0778, val=0.0774, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0774, val=0.0775, patience=3/15, lr=0.000016
   📉 Epoch 5: LR reduced 0.000016 → 0.000008
   • Epoch   5/100: train=0.0771, val=0.0776, patience=4/15, lr=0.000008
   • Epoch  11/100: train=0.0765, val=0.0780, patience=10/15, lr=0.000008
   📉 Epoch 13: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 7 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=-0.0267
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0036
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2418, R²: -0.0219

============================================================
🔄 Round 13 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0798 (↓), lr=0.000004
   • Epoch   2/100: train=0.0812, val=0.0796, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0808, val=0.0794, patience=2/15, lr=0.000004
   ✓ Epoch   4/100: train=0.0805, val=0.0792 (↓), lr=0.000004
   📉 Epoch 5: LR reduced 0.000004 → 0.000002
   • Epoch   5/100: train=0.0802, val=0.0790, patience=1/15, lr=0.000002
   ✓ Epoch  11/100: train=0.0794, val=0.0787 (↓), lr=0.000002
   📉 Epoch 13: LR reduced 0.000002 → 0.000001
   • Epoch  21/100: train=0.0789, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 13 Summary - Client client_21
   Epochs: 26/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=-0.0403
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0042
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2401, R²: -0.0034

============================================================
🔄 Round 14 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0764, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0794, val=0.0761, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 14 Summary - Client client_21
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0243
   Val:   Loss=0.0763, RMSE=0.2762, R²=-0.0409
============================================================


============================================================
🔄 Round 15 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 15 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=-0.0193
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0132
============================================================


============================================================
🔄 Round 17 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0653 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0653, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0653, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0653, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0653, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0653, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0653)

============================================================
📊 Round 17 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0016
   Val:   Loss=0.0653, RMSE=0.2556, R²=-0.0095
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2389, R²: 0.0093

============================================================
🔄 Round 21 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 21 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0003
   Val:   Loss=0.0742, RMSE=0.2724, R²=-0.0345
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0784, RMSE: 0.2799, MAE: 0.2390, R²: 0.0073

📊 Round 21 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2390, R²: 0.0077

============================================================
🔄 Round 24 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 24 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2790, R²=-0.0078
   Val:   Loss=0.0740, RMSE=0.2721, R²=0.0123
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: 0.0094

📊 Round 24 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2388, R²: 0.0103

============================================================
🔄 Round 32 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 32 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2765, R²=0.0027
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0189
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2387, R²: 0.0119

📊 Round 32 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2387, R²: 0.0123

============================================================
🔄 Round 37 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 37 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2756, R²=-0.0046
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0114
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2387, R²: 0.0129

============================================================
🔄 Round 41 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 41 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=-0.0018
   Val:   Loss=0.0741, RMSE=0.2721, R²=0.0051
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2387, R²: 0.0133

📊 Round 41 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2386, R²: 0.0135

============================================================
🔄 Round 45 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 45 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=-0.0059
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0142
============================================================


============================================================
🔄 Round 47 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 47 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=-0.0073
   Val:   Loss=0.0736, RMSE=0.2713, R²=0.0286
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2386, R²: 0.0139

============================================================
🔄 Round 48 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 48 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0027
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0180
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2386, R²: 0.0140

============================================================
🔄 Round 49 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 49 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2761, R²=-0.0036
   Val:   Loss=0.0790, RMSE=0.2810, R²=0.0080
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2386, R²: 0.0141

📊 Round 49 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2386, R²: 0.0143

============================================================
🔄 Round 52 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0746, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0746, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0746, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 52 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0744, RMSE=0.2727, R²=-0.0013
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0289
============================================================


============================================================
🔄 Round 53 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 53 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2748, R²=-0.0107
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0498
============================================================


============================================================
🔄 Round 54 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0745, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 54 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2735, R²=0.0063
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0219
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2386, R²: 0.0145

============================================================
🔄 Round 55 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 55 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0005
   Val:   Loss=0.0736, RMSE=0.2713, R²=-0.0005
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2386, R²: 0.0146

============================================================
🔄 Round 56 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 56 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=-0.0039
   Val:   Loss=0.0767, RMSE=0.2770, R²=0.0157
============================================================


============================================================
🔄 Round 57 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 57 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2779, R²=-0.0027
   Val:   Loss=0.0748, RMSE=0.2735, R²=0.0072
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2386, R²: 0.0147

📊 Round 57 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2386, R²: 0.0148

📊 Round 57 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2386, R²: 0.0148

📊 Round 57 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2386, R²: 0.0149

============================================================
🔄 Round 63 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0640 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0640, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0640, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0640, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0640, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0640, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0640)

============================================================
📊 Round 63 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0018
   Val:   Loss=0.0640, RMSE=0.2530, R²=0.0123
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0778, RMSE: 0.2788, MAE: 0.2386, R²: 0.0150

📊 Round 63 Test Metrics:
   Loss: 0.0778, RMSE: 0.2788, MAE: 0.2386, R²: 0.0151

============================================================
🔄 Round 66 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 66 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=-0.0004
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0007
============================================================


============================================================
🔄 Round 67 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 67 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0028
   Val:   Loss=0.0719, RMSE=0.2681, R²=-0.0085
============================================================


============================================================
🔄 Round 68 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 68 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0020
   Val:   Loss=0.0767, RMSE=0.2769, R²=-0.0054
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2386, R²: 0.0152

📊 Round 68 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2386, R²: 0.0153

📊 Round 68 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2386, R²: 0.0153

============================================================
🔄 Round 73 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0700 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0700, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0700, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0700, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0700)

============================================================
📊 Round 73 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0045
   Val:   Loss=0.0700, RMSE=0.2646, R²=-0.0157
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2386, R²: 0.0153

============================================================
🔄 Round 74 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0701 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0701, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0701, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0701, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0701, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0701, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0701)

============================================================
📊 Round 74 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0057
   Val:   Loss=0.0701, RMSE=0.2647, R²=-0.0222
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2386, R²: 0.0154

📊 Round 74 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2385, R²: 0.0154

📊 Round 74 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2385, R²: 0.0154

============================================================
🔄 Round 81 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 81 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2744, R²=0.0009
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0006
============================================================


============================================================
🔄 Round 82 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0743, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0743, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0743, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0743, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0743, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0743, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 82 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0744, RMSE=0.2727, R²=0.0009
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0166
============================================================


============================================================
🔄 Round 83 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 83 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0024
   Val:   Loss=0.0746, RMSE=0.2731, R²=-0.0079
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2385, R²: 0.0154

📊 Round 83 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2385, R²: 0.0155

============================================================
🔄 Round 86 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 86 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2741, R²=0.0015
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0017
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2385, R²: 0.0155

============================================================
🔄 Round 87 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 87 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0051
   Val:   Loss=0.0728, RMSE=0.2698, R²=-0.0251
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2385, R²: 0.0155

📊 Round 87 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2385, R²: 0.0155

============================================================
🔄 Round 89 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0746, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0746, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0746, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0745, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 89 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0744, RMSE=0.2727, R²=0.0053
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0137
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2385, R²: 0.0156

📊 Round 89 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2385, R²: 0.0156

📊 Round 89 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2385, R²: 0.0157

============================================================
🔄 Round 96 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 96 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0034
   Val:   Loss=0.0725, RMSE=0.2692, R²=-0.0083
============================================================


============================================================
🔄 Round 97 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 97 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2774, R²=0.0016
   Val:   Loss=0.0757, RMSE=0.2752, R²=0.0001
============================================================


============================================================
🔄 Round 98 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 98 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=-0.0025
   Val:   Loss=0.0743, RMSE=0.2725, R²=0.0154
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0157

============================================================
🔄 Round 101 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 101 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2747, R²=0.0022
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0066
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0158

📊 Round 101 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0158

============================================================
🔄 Round 106 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 106 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2750, R²=0.0058
   Val:   Loss=0.0809, RMSE=0.2843, R²=-0.0156
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0158

📊 Round 106 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0158

📊 Round 106 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0159

📊 Round 106 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0159

============================================================
🔄 Round 116 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0694 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0694, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0694, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0694, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0694, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0694, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0694)

============================================================
📊 Round 116 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=-0.0016
   Val:   Loss=0.0694, RMSE=0.2634, R²=0.0103
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0159

============================================================
🔄 Round 118 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 118 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0037
   Val:   Loss=0.0717, RMSE=0.2678, R²=-0.0155
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0159

============================================================
🔄 Round 119 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0647 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0647, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0647, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0647, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0647, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0647, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0647)

============================================================
📊 Round 119 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=-0.0021
   Val:   Loss=0.0647, RMSE=0.2544, R²=0.0167
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0159

============================================================
🔄 Round 120 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 120 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2774, R²=-0.0077
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0364
============================================================


============================================================
🔄 Round 125 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 125 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2754, R²=-0.0083
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0147
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0159

📊 Round 125 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0160

📊 Round 125 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0160

📊 Round 125 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0160

📊 Round 125 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0160

============================================================
🔄 Round 138 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 138 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0081
   Val:   Loss=0.0797, RMSE=0.2822, R²=-0.0296
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0160

📊 Round 138 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0160

============================================================
🔄 Round 140 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0744, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0744, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0744, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0744, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0744, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0744, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 140 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0745, RMSE=0.2730, R²=0.0050
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0100
============================================================


============================================================
🔄 Round 141 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 141 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=0.0073
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0245
============================================================


============================================================
🔄 Round 145 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 145 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=0.0028
   Val:   Loss=0.0733, RMSE=0.2708, R²=-0.0014
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0160

📊 Round 145 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0160

📊 Round 145 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0160

📊 Round 145 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0160

📊 Round 145 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0160

📊 Round 145 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0160

============================================================
🔄 Round 155 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 155 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2765, R²=0.0030
   Val:   Loss=0.0775, RMSE=0.2783, R²=-0.0065
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0160

============================================================
🔄 Round 159 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 159 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0011
   Val:   Loss=0.0743, RMSE=0.2725, R²=0.0069
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0160

📊 Round 159 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0160

============================================================
🔄 Round 162 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 162 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0085
   Val:   Loss=0.0756, RMSE=0.2750, R²=-0.0468
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0160

📊 Round 162 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0160

📊 Round 162 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0160

📊 Round 162 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0160

============================================================
🔄 Round 166 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 166 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2774, R²=0.0006
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0003
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0161

📊 Round 166 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0161

📊 Round 166 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0161

============================================================
🔄 Round 174 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 174 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2748, R²=0.0078
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0195
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0161

📊 Round 174 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0161

============================================================
🔄 Round 176 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0690 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0690, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0690, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0690, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0690, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0690, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0690)

============================================================
📊 Round 176 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0030
   Val:   Loss=0.0690, RMSE=0.2627, R²=-0.0012
============================================================


============================================================
🔄 Round 177 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0689 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0689, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0689, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0689, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0689, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0689, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0689)

============================================================
📊 Round 177 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0010
   Val:   Loss=0.0689, RMSE=0.2626, R²=0.0064
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0161

============================================================
🔄 Round 178 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 178 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=-0.0029
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0068
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0161

📊 Round 178 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0161

============================================================
🔄 Round 181 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0701 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0701, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0701, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0701, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0701, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0701, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0701)

============================================================
📊 Round 181 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0047
   Val:   Loss=0.0701, RMSE=0.2647, R²=-0.0089
============================================================


============================================================
🔄 Round 182 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 182 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2749, R²=-0.0044
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0266
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0161

📊 Round 182 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0161

============================================================
🔄 Round 186 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 186 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=-0.0026
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0201
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0161

============================================================
🔄 Round 188 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 188 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0071
   Val:   Loss=0.0757, RMSE=0.2752, R²=-0.0354
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0161

📊 Round 188 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0162

============================================================
🔄 Round 192 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 192 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0007
   Val:   Loss=0.0721, RMSE=0.2684, R²=0.0090
============================================================


============================================================
🔄 Round 193 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 193 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0022
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0011
============================================================


============================================================
🔄 Round 195 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0668 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0668, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0668, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0668, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0668, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0668, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0668)

============================================================
📊 Round 195 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=-0.0026
   Val:   Loss=0.0668, RMSE=0.2584, R²=0.0272
============================================================


============================================================
🔄 Round 196 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 196 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0056
   Val:   Loss=0.0792, RMSE=0.2815, R²=-0.0114
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0162

📊 Round 196 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0162

============================================================
🔄 Round 200 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 200 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2737, R²=0.0016
   Val:   Loss=0.0834, RMSE=0.2887, R²=0.0046
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0162

📊 Round 200 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0162

============================================================
🔄 Round 203 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 203 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=-0.0070
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0366
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0162

============================================================
🔄 Round 204 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 204 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0026
   Val:   Loss=0.0766, RMSE=0.2767, R²=-0.0181
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0162

📊 Round 204 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0162

============================================================
🔄 Round 208 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0738, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0738, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0738, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0738, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0738, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0738, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 208 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0739, RMSE=0.2719, R²=-0.0006
   Val:   Loss=0.0871, RMSE=0.2951, R²=0.0132
============================================================


============================================================
🔄 Round 209 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 209 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2749, R²=0.0067
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0144
============================================================


============================================================
🔄 Round 214 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 214 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0037
   Val:   Loss=0.0754, RMSE=0.2746, R²=-0.0005
============================================================


📊 Round 214 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0161

============================================================
🔄 Round 216 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0675 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0675, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0675, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0675, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0675, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0675, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0675)

============================================================
📊 Round 216 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0031
   Val:   Loss=0.0675, RMSE=0.2598, R²=0.0003
============================================================


============================================================
🔄 Round 218 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 218 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0066
   Val:   Loss=0.0727, RMSE=0.2696, R²=-0.0136
============================================================


📊 Round 218 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0162

📊 Round 218 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0162

============================================================
🔄 Round 221 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 221 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2783, R²=0.0015
   Val:   Loss=0.0730, RMSE=0.2701, R²=0.0080
============================================================


📊 Round 221 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0162

============================================================
🔄 Round 224 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 224 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0073
   Val:   Loss=0.0735, RMSE=0.2711, R²=-0.0141
============================================================


📊 Round 224 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0162

📊 Round 224 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0162

============================================================
🔄 Round 227 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 227 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0057
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0232
============================================================


📊 Round 227 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0162

📊 Round 227 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0162

============================================================
🔄 Round 230 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 230 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0057
   Val:   Loss=0.0724, RMSE=0.2691, R²=-0.0123
============================================================


📊 Round 230 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0162

============================================================
🔄 Round 231 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0701 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0701, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0701, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0701, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0701, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0701, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0701)

============================================================
📊 Round 231 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0053
   Val:   Loss=0.0701, RMSE=0.2648, R²=-0.0085
============================================================


📊 Round 231 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0162

============================================================
🔄 Round 233 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 233 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=-0.0014
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0181
============================================================


============================================================
🔄 Round 236 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 236 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0064
   Val:   Loss=0.0787, RMSE=0.2804, R²=-0.0166
============================================================


📊 Round 236 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0163

============================================================
🔄 Round 237 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0644 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0644, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0644, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0644, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0643, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0643, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0644)

============================================================
📊 Round 237 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0027
   Val:   Loss=0.0644, RMSE=0.2537, R²=0.0051
============================================================


============================================================
🔄 Round 238 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 238 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=-0.0018
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0239
============================================================


============================================================
🔄 Round 239 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0694 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0694, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0694, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0694, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0694, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0694, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0694)

============================================================
📊 Round 239 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0030
   Val:   Loss=0.0694, RMSE=0.2635, R²=0.0015
============================================================


📊 Round 239 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0163

============================================================
🔄 Round 240 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 240 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=-0.0045
   Val:   Loss=0.0717, RMSE=0.2678, R²=0.0289
============================================================


============================================================
🔄 Round 241 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 241 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2752, R²=-0.0023
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0195
============================================================


📊 Round 241 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0163

============================================================
🔄 Round 244 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0693 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0693, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0693, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0693, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0693, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0693, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0693)

============================================================
📊 Round 244 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0042
   Val:   Loss=0.0693, RMSE=0.2633, R²=-0.0050
============================================================


📊 Round 244 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0163

📊 Round 244 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0163

============================================================
🔄 Round 249 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 249 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0065
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0078
============================================================


📊 Round 249 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0163

============================================================
🔄 Round 250 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 250 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0048
   Val:   Loss=0.0762, RMSE=0.2761, R²=-0.0134
============================================================


📊 Round 250 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0163

============================================================
🔄 Round 251 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 251 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0062
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0078
============================================================


📊 Round 251 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0163

============================================================
🔄 Round 256 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0702, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0702, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 256 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0102
   Val:   Loss=0.0702, RMSE=0.2649, R²=-0.0275
============================================================


📊 Round 256 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0163

📊 Round 256 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0163

📊 Round 256 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0163

============================================================
🔄 Round 259 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 259 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=0.0041
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0099
============================================================


📊 Round 259 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0163

============================================================
🔄 Round 261 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 261 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2745, R²=0.0003
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0145
============================================================


============================================================
🔄 Round 262 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 262 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2788, R²=0.0027
   Val:   Loss=0.0716, RMSE=0.2675, R²=0.0070
============================================================


📊 Round 262 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0163

📊 Round 262 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0164

============================================================
🔄 Round 267 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 267 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=0.0091
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0239
============================================================


📊 Round 267 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0164

============================================================
🔄 Round 268 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0749, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 268 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2735, R²=0.0050
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0063
============================================================


📊 Round 268 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0164

============================================================
🔄 Round 270 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 270 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0008
   Val:   Loss=0.0749, RMSE=0.2737, R²=0.0149
============================================================


📊 Round 270 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0164

============================================================
🔄 Round 271 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 271 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2772, R²=0.0089
   Val:   Loss=0.0751, RMSE=0.2741, R²=-0.0248
============================================================


============================================================
🔄 Round 272 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 272 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2747, R²=-0.0039
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0155
============================================================


============================================================
🔄 Round 273 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0684 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0684, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0684, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0684, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0684, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0684, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0684)

============================================================
📊 Round 273 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0071
   Val:   Loss=0.0684, RMSE=0.2616, R²=-0.0121
============================================================


📊 Round 273 Test Metrics:
   Loss: 0.0776, RMSE: 0.2787, MAE: 0.2385, R²: 0.0164

📊 Round 273 Test Metrics:
   Loss: 0.0776, RMSE: 0.2787, MAE: 0.2385, R²: 0.0164

============================================================
🔄 Round 276 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 276 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0067
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0084
============================================================


============================================================
🔄 Round 279 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 279 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2785, R²=0.0032
   Val:   Loss=0.0723, RMSE=0.2689, R²=0.0038
============================================================


📊 Round 279 Test Metrics:
   Loss: 0.0776, RMSE: 0.2787, MAE: 0.2385, R²: 0.0164

============================================================
🔄 Round 281 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0687 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0687, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0687, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0687, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0687, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0687, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0687)

============================================================
📊 Round 281 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=-0.0036
   Val:   Loss=0.0687, RMSE=0.2620, R²=0.0183
============================================================


📊 Round 281 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0164

============================================================
🔄 Round 284 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 284 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2743, R²=-0.0008
   Val:   Loss=0.0815, RMSE=0.2854, R²=0.0191
============================================================


📊 Round 284 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0165

============================================================
🔄 Round 285 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 285 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2756, R²=0.0072
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0110
============================================================


📊 Round 285 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0165

📊 Round 285 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0165

============================================================
🔄 Round 288 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 288 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0036
   Val:   Loss=0.0737, RMSE=0.2714, R²=0.0015
============================================================


============================================================
🔄 Round 290 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 290 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2748, R²=0.0058
   Val:   Loss=0.0803, RMSE=0.2835, R²=-0.0125
============================================================


============================================================
🔄 Round 291 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 291 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0041
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0015
============================================================


📊 Round 291 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0165

============================================================
🔄 Round 292 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 292 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=-0.0006
   Val:   Loss=0.0734, RMSE=0.2710, R²=0.0055
============================================================


📊 Round 292 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0165

============================================================
🔄 Round 294 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 294 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0086
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0186
============================================================


📊 Round 294 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0165

============================================================
🔄 Round 297 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 297 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2743, R²=0.0036
   Val:   Loss=0.0815, RMSE=0.2854, R²=0.0043
============================================================


📊 Round 297 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0165

============================================================
🔄 Round 298 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 298 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2765, R²=0.0089
   Val:   Loss=0.0766, RMSE=0.2767, R²=-0.0163
============================================================


============================================================
🔄 Round 300 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0645 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0645, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0645, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0645, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0645, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0645, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0645)

============================================================
📊 Round 300 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0035
   Val:   Loss=0.0645, RMSE=0.2539, R²=0.0348
============================================================


📊 Round 300 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0165

============================================================
🔄 Round 301 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 301 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0107
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0242
============================================================


📊 Round 301 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0165

📊 Round 301 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0165

============================================================
🔄 Round 305 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 305 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0058
   Val:   Loss=0.0749, RMSE=0.2737, R²=-0.0148
============================================================


============================================================
🔄 Round 306 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 306 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0040
   Val:   Loss=0.0733, RMSE=0.2707, R²=-0.0037
============================================================


📊 Round 306 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0164

============================================================
🔄 Round 311 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 311 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=-0.0010
   Val:   Loss=0.0756, RMSE=0.2750, R²=0.0234
============================================================


📊 Round 311 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0165

📊 Round 311 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0165

============================================================
🔄 Round 315 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 315 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2743, R²=-0.0004
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0213
============================================================


📊 Round 315 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0165

📊 Round 315 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0165

============================================================
🔄 Round 320 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 320 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2746, R²=0.0051
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0019
============================================================


============================================================
🔄 Round 321 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 321 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2774, R²=0.0051
   Val:   Loss=0.0745, RMSE=0.2730, R²=0.0007
============================================================


📊 Round 321 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0165

============================================================
🔄 Round 324 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 324 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0745, RMSE=0.2730, R²=0.0084
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0206
============================================================


📊 Round 324 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0165

============================================================
🔄 Round 326 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0746, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0746, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0746, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0745, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 326 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0746, RMSE=0.2732, R²=0.0045
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0025
============================================================


📊 Round 326 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0165

📊 Round 326 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0165

============================================================
🔄 Round 328 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 328 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2748, R²=0.0062
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0162
============================================================


📊 Round 328 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0165

📊 Round 328 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0165

============================================================
🔄 Round 330 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 330 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0050
   Val:   Loss=0.0759, RMSE=0.2754, R²=-0.0002
============================================================


============================================================
🔄 Round 334 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 334 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0115
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0291
============================================================


📊 Round 334 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0165

============================================================
🔄 Round 337 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 337 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2774, R²=0.0004
   Val:   Loss=0.0744, RMSE=0.2727, R²=0.0216
============================================================


============================================================
🔄 Round 342 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 342 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2774, R²=0.0060
   Val:   Loss=0.0744, RMSE=0.2728, R²=-0.0071
============================================================


📊 Round 342 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0166

============================================================
🔄 Round 343 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 343 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2774, R²=0.0004
   Val:   Loss=0.0743, RMSE=0.2726, R²=0.0167
============================================================


============================================================
🔄 Round 344 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 344 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0049
   Val:   Loss=0.0718, RMSE=0.2679, R²=0.0005
============================================================


============================================================
🔄 Round 345 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 345 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2785, R²=0.0049
   Val:   Loss=0.0721, RMSE=0.2684, R²=0.0031
============================================================


============================================================
🔄 Round 346 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 346 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0024
   Val:   Loss=0.0711, RMSE=0.2667, R²=0.0093
============================================================


============================================================
🔄 Round 347 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 347 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0039
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0051
============================================================


📊 Round 347 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0166

============================================================
🔄 Round 348 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 348 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0008
   Val:   Loss=0.0716, RMSE=0.2676, R²=0.0015
============================================================


📊 Round 348 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0166

============================================================
🔄 Round 349 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 349 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2774, R²=0.0045
   Val:   Loss=0.0743, RMSE=0.2725, R²=0.0024
============================================================


📊 Round 349 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0166

============================================================
🔄 Round 353 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 353 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2769, R²=0.0018
   Val:   Loss=0.0756, RMSE=0.2749, R²=0.0165
============================================================


📊 Round 353 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0166

============================================================
🔄 Round 354 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 354 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0746, RMSE=0.2731, R²=0.0034
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0058
============================================================


📊 Round 354 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0166

============================================================
🔄 Round 356 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 356 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0051
   Val:   Loss=0.0745, RMSE=0.2729, R²=0.0010
============================================================


📊 Round 356 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0167

============================================================
🔄 Round 358 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 358 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2748, R²=0.0068
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0059
============================================================


📊 Round 358 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0167

============================================================
🔄 Round 361 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 361 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0000
   Val:   Loss=0.0752, RMSE=0.2743, R²=0.0235
============================================================


📊 Round 361 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0167

============================================================
🔄 Round 362 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0666 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0666, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0666, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0666, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0666, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0666, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0666)

============================================================
📊 Round 362 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0099
   Val:   Loss=0.0666, RMSE=0.2581, R²=-0.0246
============================================================


============================================================
🔄 Round 364 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0658 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0658, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0658, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0658, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0658, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0658, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0658)

============================================================
📊 Round 364 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0003
   Val:   Loss=0.0658, RMSE=0.2566, R²=0.0195
============================================================


📊 Round 364 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0167

📊 Round 364 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0167

============================================================
🔄 Round 367 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 367 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=0.0032
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0108
============================================================


============================================================
🔄 Round 368 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 368 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2741, R²=-0.0020
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0095
============================================================


📊 Round 368 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0167

============================================================
🔄 Round 369 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 369 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=0.0048
   Val:   Loss=0.0778, RMSE=0.2790, R²=0.0052
============================================================


============================================================
🔄 Round 371 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 371 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=0.0063
   Val:   Loss=0.0722, RMSE=0.2688, R²=-0.0012
============================================================


============================================================
🔄 Round 372 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 372 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0056
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0017
============================================================


📊 Round 372 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0167

📊 Round 372 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0167

📊 Round 372 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0167

============================================================
🔄 Round 376 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 376 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2749, R²=0.0097
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0138
============================================================


============================================================
🔄 Round 377 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0739, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0739, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0739, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0739, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0739, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0739, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 377 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0738, RMSE=0.2716, R²=0.0091
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0099
============================================================


📊 Round 377 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0167

============================================================
🔄 Round 379 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 379 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0003
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0187
============================================================


📊 Round 379 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0167

============================================================
🔄 Round 380 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 380 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0075
   Val:   Loss=0.0710, RMSE=0.2664, R²=-0.0066
============================================================


📊 Round 380 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0167

📊 Round 380 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0167

============================================================
🔄 Round 384 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 384 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=-0.0040
   Val:   Loss=0.0748, RMSE=0.2735, R²=0.0311
============================================================


📊 Round 384 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0168

============================================================
🔄 Round 385 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 385 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0097
   Val:   Loss=0.0740, RMSE=0.2719, R²=-0.0163
============================================================


============================================================
🔄 Round 386 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0728, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0728, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0728, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0727, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0727, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0727, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 386 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0727, RMSE=0.2696, R²=-0.0002
   Val:   Loss=0.0914, RMSE=0.3023, R²=0.0156
============================================================


============================================================
🔄 Round 387 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 387 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0101
   Val:   Loss=0.0750, RMSE=0.2739, R²=-0.0268
============================================================


📊 Round 387 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0168

📊 Round 387 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0168

============================================================
🔄 Round 390 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0698 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0698, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0698, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0698, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0698, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0698, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0698)

============================================================
📊 Round 390 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0029
   Val:   Loss=0.0698, RMSE=0.2642, R²=0.0126
============================================================


📊 Round 390 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0168

============================================================
🔄 Round 392 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0696 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0696, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0696, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0696, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0696, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0696, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0696)

============================================================
📊 Round 392 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=-0.0007
   Val:   Loss=0.0696, RMSE=0.2638, R²=0.0284
============================================================


📊 Round 392 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0168

📊 Round 392 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0168

============================================================
🔄 Round 395 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 395 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0040
   Val:   Loss=0.0734, RMSE=0.2709, R²=0.0076
============================================================


📊 Round 395 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0168

============================================================
🔄 Round 396 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 396 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0031
   Val:   Loss=0.0732, RMSE=0.2706, R²=0.0046
============================================================


📊 Round 396 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0168

============================================================
🔄 Round 397 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0730, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0730, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0730, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0730, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0730, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0730, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 397 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0728, RMSE=0.2699, R²=0.0037
   Val:   Loss=0.0907, RMSE=0.3011, R²=0.0054
============================================================


📊 Round 397 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0168

============================================================
🔄 Round 398 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 398 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0051
   Val:   Loss=0.0745, RMSE=0.2730, R²=0.0021
============================================================


📊 Round 398 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0168

📊 Round 398 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0168

============================================================
🔄 Round 402 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 402 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2754, R²=0.0107
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0172
============================================================


============================================================
🔄 Round 404 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 404 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2763, R²=0.0027
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0125
============================================================


📊 Round 404 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0168

============================================================
🔄 Round 408 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0675 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0675, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0675, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0675, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0675, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0675, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0675)

============================================================
📊 Round 408 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=-0.0001
   Val:   Loss=0.0675, RMSE=0.2598, R²=0.0280
============================================================


📊 Round 408 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0168

============================================================
🔄 Round 410 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 410 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0002
   Val:   Loss=0.0788, RMSE=0.2806, R²=0.0175
============================================================


📊 Round 410 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0168

📊 Round 410 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0168

============================================================
🔄 Round 417 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 417 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2746, R²=0.0021
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0140
============================================================


📊 Round 417 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2384, R²: 0.0168

============================================================
🔄 Round 419 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 419 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0031
   Val:   Loss=0.0765, RMSE=0.2765, R²=0.0064
============================================================


📊 Round 419 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2384, R²: 0.0168

📊 Round 419 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2384, R²: 0.0168

============================================================
🔄 Round 422 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 422 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2756, R²=0.0042
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0063
============================================================


============================================================
🔄 Round 424 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 424 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2742, R²=0.0025
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0156
============================================================


============================================================
🔄 Round 425 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0744, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0744, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0744, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0744, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0744, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0744, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 425 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0745, RMSE=0.2730, R²=0.0038
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0111
============================================================


📊 Round 425 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2384, R²: 0.0168

============================================================
🔄 Round 427 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 427 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0021
   Val:   Loss=0.0724, RMSE=0.2691, R²=-0.0022
============================================================


============================================================
🔄 Round 428 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 428 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0028
   Val:   Loss=0.0763, RMSE=0.2763, R²=0.0141
============================================================


============================================================
🔄 Round 429 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 429 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2740, R²=0.0062
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0125
============================================================


============================================================
🔄 Round 433 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 433 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2774, R²=0.0048
   Val:   Loss=0.0741, RMSE=0.2721, R²=0.0083
============================================================


📊 Round 433 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0168

📊 Round 433 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0168

============================================================
🔄 Round 435 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 435 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0117
   Val:   Loss=0.0788, RMSE=0.2806, R²=-0.0307
============================================================


📊 Round 435 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0168

📊 Round 435 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0168

📊 Round 435 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0168

============================================================
🔄 Round 438 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 438 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2744, R²=-0.0020
   Val:   Loss=0.0806, RMSE=0.2840, R²=0.0257
============================================================


📊 Round 438 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0168

============================================================
🔄 Round 440 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 440 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=-0.0004
   Val:   Loss=0.0732, RMSE=0.2705, R²=0.0265
============================================================


📊 Round 440 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0168

📊 Round 440 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0169

📊 Round 440 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2384, R²: 0.0169

============================================================
🔄 Round 446 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 446 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2740, R²=0.0089
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0221
============================================================


============================================================
🔄 Round 447 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 447 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0047
   Val:   Loss=0.0734, RMSE=0.2710, R²=-0.0250
============================================================


============================================================
🔄 Round 448 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 448 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0032
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0129
============================================================


============================================================
🔄 Round 449 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0703 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0703, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0703, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0703, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0703)

============================================================
📊 Round 449 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0030
   Val:   Loss=0.0703, RMSE=0.2652, R²=-0.0089
============================================================


============================================================
🔄 Round 450 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 450 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0085
   Val:   Loss=0.0741, RMSE=0.2722, R²=-0.0060
============================================================


📊 Round 450 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2384, R²: 0.0168

============================================================
🔄 Round 452 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0663 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0663, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0663, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0663, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0663, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0663, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0663)

============================================================
📊 Round 452 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0034
   Val:   Loss=0.0663, RMSE=0.2575, R²=0.0164
============================================================


============================================================
🔄 Round 455 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 455 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0136
   Val:   Loss=0.0748, RMSE=0.2735, R²=-0.0274
============================================================


📊 Round 455 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2384, R²: 0.0168

============================================================
🔄 Round 456 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 456 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2761, R²=0.0077
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0051
============================================================


📊 Round 456 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2384, R²: 0.0168

============================================================
🔄 Round 457 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 457 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2747, R²=0.0058
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0027
============================================================


📊 Round 457 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2384, R²: 0.0168

============================================================
🔄 Round 459 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0653 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0653, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0653, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0653, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0653, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0653, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0653)

============================================================
📊 Round 459 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=-0.0047
   Val:   Loss=0.0653, RMSE=0.2555, R²=0.0541
============================================================


============================================================
🔄 Round 460 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0730, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0730, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0730, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0730, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0730, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0730, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 460 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0732, RMSE=0.2706, R²=0.0096
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0066
============================================================


📊 Round 460 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2384, R²: 0.0168

============================================================
🔄 Round 461 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 461 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2758, R²=0.0085
   Val:   Loss=0.0775, RMSE=0.2785, R²=-0.0048
============================================================


📊 Round 461 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2384, R²: 0.0168

📊 Round 461 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2384, R²: 0.0168

============================================================
🔄 Round 463 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 463 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0099
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0114
============================================================


📊 Round 463 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2384, R²: 0.0168

============================================================
🔄 Round 465 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 465 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0051
   Val:   Loss=0.0721, RMSE=0.2685, R²=0.0084
============================================================


============================================================
🔄 Round 467 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0745, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 467 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0746, RMSE=0.2731, R²=0.0089
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0078
============================================================


📊 Round 467 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2384, R²: 0.0169

============================================================
🔄 Round 468 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0627 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0627, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0627, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0627, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0627, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0627, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0627)

============================================================
📊 Round 468 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0012
   Val:   Loss=0.0627, RMSE=0.2503, R²=0.0242
============================================================


📊 Round 468 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2384, R²: 0.0169

============================================================
🔄 Round 469 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 469 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2774, R²=0.0096
   Val:   Loss=0.0739, RMSE=0.2719, R²=-0.0093
============================================================


📊 Round 469 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2384, R²: 0.0169

============================================================
🔄 Round 470 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 470 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.0075
   Val:   Loss=0.0724, RMSE=0.2691, R²=-0.0013
============================================================


📊 Round 470 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2384, R²: 0.0169

============================================================
🔄 Round 472 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 472 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2763, R²=0.0066
   Val:   Loss=0.0763, RMSE=0.2761, R²=0.0031
============================================================


📊 Round 472 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2384, R²: 0.0169

============================================================
🔄 Round 474 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0661 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0661, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0661, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0661, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0661, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0661, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0661)

============================================================
📊 Round 474 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0070
   Val:   Loss=0.0661, RMSE=0.2570, R²=-0.0009
============================================================


============================================================
🔄 Round 475 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 475 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2743, R²=0.0052
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0085
============================================================


============================================================
🔄 Round 476 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 476 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0086
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0047
============================================================


📊 Round 476 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2384, R²: 0.0169

============================================================
🔄 Round 478 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 478 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0746, RMSE=0.2731, R²=0.0126
   Val:   Loss=0.0834, RMSE=0.2887, R²=-0.0198
============================================================


📊 Round 478 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2384, R²: 0.0169

📊 Round 478 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2384, R²: 0.0169

============================================================
🔄 Round 481 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0678 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0678, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0678, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0678, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0678, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0678, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0678)

============================================================
📊 Round 481 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0025
   Val:   Loss=0.0678, RMSE=0.2603, R²=0.0132
============================================================


============================================================
🔄 Round 485 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 485 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0045
   Val:   Loss=0.0744, RMSE=0.2727, R²=-0.0183
============================================================


📊 Round 485 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2384, R²: 0.0169

============================================================
🔄 Round 487 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0593 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0593, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0593, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0593, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0593, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0594, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0593)

============================================================
📊 Round 487 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0001
   Val:   Loss=0.0593, RMSE=0.2435, R²=0.0356
============================================================


📊 Round 487 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2384, R²: 0.0169

============================================================
🔄 Round 488 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 488 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2763, R²=0.0021
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0119
============================================================


📊 Round 488 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2384, R²: 0.0169

============================================================
🔄 Round 490 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0744, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0744, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0744, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0744, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0744, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0743, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 490 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0746, RMSE=0.2730, R²=0.0074
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0010
============================================================


============================================================
🔄 Round 492 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0743, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0743, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0743, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0743, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0743, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0743, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 492 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0743, RMSE=0.2725, R²=0.0096
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0109
============================================================


📊 Round 492 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2384, R²: 0.0170

============================================================
🔄 Round 494 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0748, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0748, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0748, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0748, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 494 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2736, R²=0.0089
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0105
============================================================


📊 Round 494 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2384, R²: 0.0170

============================================================
🔄 Round 500 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 500 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2747, R²=0.0090
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0128
============================================================


============================================================
🔄 Round 501 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 501 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0112
   Val:   Loss=0.0731, RMSE=0.2703, R²=-0.0559
============================================================


============================================================
🔄 Round 502 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 502 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2737, R²=0.0061
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0069
============================================================


============================================================
🔄 Round 503 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 503 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2765, R²=0.0042
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0050
============================================================


📊 Round 503 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2384, R²: 0.0170

📊 Round 503 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2384, R²: 0.0170

📊 Round 503 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2384, R²: 0.0170

============================================================
🔄 Round 507 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 507 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0065
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0014
============================================================


📊 Round 507 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2384, R²: 0.0170

============================================================
🔄 Round 509 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 509 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0089
   Val:   Loss=0.0725, RMSE=0.2692, R²=-0.0050
============================================================


📊 Round 509 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2384, R²: 0.0170

📊 Round 509 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2384, R²: 0.0170

📊 Round 509 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2384, R²: 0.0170

============================================================
🔄 Round 513 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 513 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0042
   Val:   Loss=0.0730, RMSE=0.2702, R²=0.0153
============================================================


📊 Round 513 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2384, R²: 0.0170

============================================================
🔄 Round 514 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 514 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0090
   Val:   Loss=0.0720, RMSE=0.2683, R²=-0.0057
============================================================


============================================================
🔄 Round 515 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 515 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2754, R²=0.0066
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0020
============================================================


📊 Round 515 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2384, R²: 0.0170

📊 Round 515 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2384, R²: 0.0171

============================================================
🔄 Round 525 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 525 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0070
   Val:   Loss=0.0732, RMSE=0.2706, R²=-0.0016
============================================================


============================================================
🔄 Round 527 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 527 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0084
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0018
============================================================


📊 Round 527 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2384, R²: 0.0171

============================================================
🔄 Round 530 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 530 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2749, R²=0.0073
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0008
============================================================


============================================================
🔄 Round 532 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 532 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0033
   Val:   Loss=0.0733, RMSE=0.2707, R²=0.0194
============================================================


📊 Round 532 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2384, R²: 0.0171

📊 Round 532 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2384, R²: 0.0171

============================================================
🔄 Round 537 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 537 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0088
   Val:   Loss=0.0779, RMSE=0.2792, R²=-0.0088
============================================================


📊 Round 537 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2384, R²: 0.0172

📊 Round 537 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2384, R²: 0.0172

============================================================
🔄 Round 539 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 539 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2763, R²=0.0060
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0080
============================================================


📊 Round 539 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2384, R²: 0.0172

============================================================
🔄 Round 540 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 540 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0031
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0138
============================================================


📊 Round 540 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2384, R²: 0.0172

============================================================
🔄 Round 542 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 542 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0028
   Val:   Loss=0.0720, RMSE=0.2683, R²=0.0129
============================================================


============================================================
🔄 Round 543 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 543 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2741, R²=0.0083
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0007
============================================================


============================================================
🔄 Round 544 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 544 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0019
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0154
============================================================


📊 Round 544 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2384, R²: 0.0172

📊 Round 544 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2384, R²: 0.0173

============================================================
🔄 Round 549 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 549 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0046
   Val:   Loss=0.0745, RMSE=0.2729, R²=0.0072
============================================================


📊 Round 549 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2384, R²: 0.0173

============================================================
🔄 Round 550 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 550 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0056
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0090
============================================================


============================================================
🔄 Round 551 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 551 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=0.0076
   Val:   Loss=0.0770, RMSE=0.2774, R²=-0.0031
============================================================


============================================================
🔄 Round 552 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 552 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0006
   Val:   Loss=0.0743, RMSE=0.2726, R²=-0.0005
============================================================


============================================================
🔄 Round 553 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0702, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0702, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 553 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=0.0004
   Val:   Loss=0.0702, RMSE=0.2649, R²=0.0324
============================================================


📊 Round 553 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2384, R²: 0.0173

============================================================
🔄 Round 554 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 554 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2743, R²=0.0078
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0098
============================================================


============================================================
🔄 Round 555 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 555 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=0.0105
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0138
============================================================


============================================================
🔄 Round 558 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 558 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2749, R²=0.0047
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0121
============================================================


📊 Round 558 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2384, R²: 0.0173

============================================================
🔄 Round 560 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 560 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0045
   Val:   Loss=0.0710, RMSE=0.2665, R²=0.0153
============================================================


============================================================
🔄 Round 561 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0729, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0729, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0729, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0729, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0729, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0729, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 561 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0730, RMSE=0.2703, R²=0.0117
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0121
============================================================


📊 Round 561 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2384, R²: 0.0173

============================================================
🔄 Round 563 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 563 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0021
   Val:   Loss=0.0751, RMSE=0.2741, R²=0.0138
============================================================


============================================================
🔄 Round 564 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0740, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0740, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0740, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0740, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0740, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0740, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 564 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0741, RMSE=0.2722, R²=0.0084
   Val:   Loss=0.0851, RMSE=0.2918, R²=0.0002
============================================================


============================================================
🔄 Round 567 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 567 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2749, R²=0.0104
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0079
============================================================


📊 Round 567 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2384, R²: 0.0173

============================================================
🔄 Round 569 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 569 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2744, R²=0.0022
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0126
============================================================


============================================================
🔄 Round 571 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0664 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0664, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0664, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0664, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0664, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0664, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0664)

============================================================
📊 Round 571 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2806, R²=0.0102
   Val:   Loss=0.0664, RMSE=0.2576, R²=-0.0112
============================================================


📊 Round 571 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2384, R²: 0.0173

============================================================
🔄 Round 572 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0745, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 572 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2736, R²=0.0152
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0267
============================================================


📊 Round 572 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2384, R²: 0.0173

============================================================
🔄 Round 573 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 573 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2748, R²=0.0086
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0142
============================================================


============================================================
🔄 Round 575 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 575 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=0.0052
   Val:   Loss=0.0789, RMSE=0.2810, R²=0.0034
============================================================


📊 Round 575 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2384, R²: 0.0173

============================================================
🔄 Round 576 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 576 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0084
   Val:   Loss=0.0762, RMSE=0.2761, R²=-0.0054
============================================================


❌ Client client_21 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_status:14, grpc_message:"Socket closed"}"
>
